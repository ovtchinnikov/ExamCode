==================================================
### Prüfungsprotokoll ###
Datum: 25.07.2025, 15:56:45 Uhr
Modus: Practice
Auswahl: Random (50 Fragen)
Random Seed: 2222

--- Endergebnis ---
Punkte: 34 von 50
Erfolgsquote: 68.00%
==================================================

--- Frage Nr. 164 (Richtig) ---
Frage: A user has unloaded data from a Snowflake table to an external stage.

Which command can be used to verify if data has been uploaded to the external stage named my_stage?
Deine Antwort:     B
Korrekte Antwort:  B

Erklärung:
Answer is correct List
--------------------------------------------------

--- Frage Nr. 642 (Richtig) ---
Frage: A single cluster virtual warehouse has no free resources.

What will happen to new queries that are run against this warehouse?
Deine Antwort:     C
Korrekte Antwort:  C

Erklärung:
When there is only single cluster virtual warehouse , it can not SCALE and hence new queries need to wait in the Queue
--------------------------------------------------

--- Frage Nr. 194 (Richtig) ---
Frage: In an auto-scaling multi-cluster virtual warehouse with the setting SCALING_POLICY = ECONOMY enabled, when is another cluster started?
Deine Antwort:     B
Korrekte Antwort:  B

Erklärung:
https://docs.snowflake.com/en/user-guide/warehouses-multicluster.html warehouse start Only if the system estimates there’s enough query load to keep the cluster busy for at least 6 minutes.
--------------------------------------------------

--- Frage Nr. 576 (Richtig) ---
Frage: What can be used to identify the database, schema, stage, and file path to a set of files, and to allow a role that has sufficient privileges on the stage to access the files?
Deine Antwort:     B
Korrekte Antwort:  B

Erklärung:
https://docs.snowflake.com/en/user-guide/unstructured-intro
It's B, File URL : URL that identifies the database, schema, stage, and file path to a set of files. A role that has sufficient privileges on the stage can access the files
--------------------------------------------------

--- Frage Nr. 558 (Richtig) ---
Frage: Which type of workload traditionally benefits from the use of the query acceleration service?
Deine Antwort:     B
Korrekte Antwort:  B

Erklärung:
B is correct
Correct Answer: B. Workloads that include on-demand data analyses Workloads that include on-demand data analyses: These types of workloads often involve complex queries that need to be executed quickly and efficiently. The query acceleration service is designed to speed up query processing for such workloads by allocating additional resources, thus reducing query response times and improving performance for ad-hoc and interactive queries.
--------------------------------------------------

--- Frage Nr. 275 (Richtig) ---
Frage: Which is the MINIMUM required Snowflake edition that a user must have if they want to use AWS/Azure Privatelink or Google Cloud Private Service Connect?
Deine Antwort:     D
Korrekte Antwort:  D

Erklärung:
Private connectivity to the Snowflake service requires Business Critical (or higher). https://docs.snowflake.com/en/user-guide/private-snowflake-service.html#private-connectivity-to-the-snowflake-service
--------------------------------------------------

--- Frage Nr. 878 (Richtig) ---
Frage: What does Snowflake recommend a user do if they need to connect to Snowflake with a tool or technology that is not listed in Snowflake’s partner ecosystem?
Deine Antwort:     D
Korrekte Antwort:  D

Erklärung:
D https://docs.snowflake.com/en/user-guide/ecosystem-all
D correct
--------------------------------------------------

--- Frage Nr. 105 (Richtig) ---
Frage: How a Snowpipe charges calculated?
Deine Antwort:     B
Korrekte Antwort:  B

Erklärung:
Correct answer  "Snowflake tracks the resource consumption of loads for all pipes in an account, with per-second/per-core granularity, as Snowpipe actively queues and processes data files. Per-core refers to the physical CPU cores in a compute server. The utilization recorded is then translated into familiar Snowflake credits, which are listed on the bill for your account."
https://docs.snowflake.com/en/user-guide/data-load-snowpipe-billing.html
--------------------------------------------------

--- Frage Nr. 784 (Falsch) ---
Frage: Which commands support a multiple-statement request to access and update Snowflake data? (Choose two.)
Deine Antwort:     C, D
Korrekte Antwort:  B, E

Erklärung:
https://docs.snowflake.com/en/sql-reference/transactions#explicit-transactions
Why not A. we can write multiple statements in a stored procedure.
--------------------------------------------------

--- Frage Nr. 238 (Richtig) ---
Frage: What is the default file size when unloading data from Snowflake using the COPY command?
Deine Antwort:     C
Korrekte Antwort:  C

Erklärung:
By default, COPY INTO location statements separate table data into a set of output files to take advantage of parallel operations. The maximum size for each file is set using the MAX_FILE_SIZE copy option. The default value is 16777216 (16 MB) but can be increased to accommodate larger files.  https://docs.snowflake.com/en/user-guide/data-unload-considerations.html
--------------------------------------------------

--- Frage Nr. 443 (Falsch) ---
Frage: What actions can be performed by consumers of shared databases? (Choose two.)
Deine Antwort:     A, E
Korrekte Antwort:  D, E

Erklärung:
DE Users in a consumer account can view/query data, but cannot insert or update data, or create any objects in the database. The following actions are not supported: Creating a clone of an imported database or any schemas/tables in the database.
Answer D and E.  https://docs.snowflake.com/en/user-guide/data-share-consumers#creating-streams-on-shared-views-or-tables  https://docs.snowflake.com/en/user-guide/data-share-consumers#general-limitations-for-imported-databases
Answer is Cand E  https://docs.snowflake.com/en/user-guide/data-share-consumers
--------------------------------------------------

--- Frage Nr. 521 (Falsch) ---
Frage: Which transformation is supported by a COPY INTO [table] command?
Deine Antwort:     D
Korrekte Antwort:  C

Erklärung:
Option C is correct, other are not possible when using the COPY INTO statement https://docs.snowflake.com/en/user-guide/data-load-transform
The COPY command supports: Column reordering column omission casts using a SELECT statement https://docs.snowflake.com/en/user-guide/data-load-transform
--------------------------------------------------

--- Frage Nr. 208 (Richtig) ---
Frage: Which feature is only available in the Enterprise or higher editions of Snowflake?
Deine Antwort:     A
Korrekte Antwort:  A

Erklärung:
Correct
https://docs.snowflake.com/en/user-guide/intro-editions.html#enterprise-edition
--------------------------------------------------

--- Frage Nr. 804 (Richtig) ---
Frage: Which MINIMUM set of privileges is required to temporarily bypass an active network policy by configuring the user object property MINS_TO_BYPASS_NETWORK_POLICY?
Deine Antwort:     D
Korrekte Antwort:  D

Erklärung:
It is possible to temporarily bypass a network policy for a set number of minutes by configuring the user object property MINS_TO_BYPASS_NETWORK_POLICY, which can be viewed by executing DESCRIBE USER. Only Snowflake can set the value for this object property. Please contact Snowflake Support to set a value for this property.
D only snowflake support allows that https://docs.snowflake.com/en/user-guide/network-policies#bypassing-a-network-policy
--------------------------------------------------

--- Frage Nr. 58 (Falsch) ---
Frage: Which of the following statements is true of zero-copy cloning?
Deine Antwort:     B
Korrekte Antwort:  D

Erklärung:
D is correct, but take into account that if the cloned or the original table make any change to the data, this change does not affect the other table. They are independent objects
From: https://docs.snowflake.com/en/sql-reference/sql/create-clone.html -- If the COPY GRANTS keywords are used, then the new object inherits any explicit access privileges granted on the original table but does not inherit any future grants defined for the object type in the schema.  If the COPY GRANTS keywords are not used, then the new object clone does not inherit any explicit access privileges granted on the original table but does inherit any future grants defined for the object type in the schema (using the GRANT <privileges> … TO ROLE … ON FUTURE syntax). Answer: D
--------------------------------------------------

--- Frage Nr. 1176 (Richtig) ---
Frage: What Snowflake function should be used to unload relational data to JSON?
Deine Antwort:     B
Korrekte Antwort:  B

Erklärung:
B. OBJECT_CONSTRUCT()
https://docs.snowflake.com/en/user-guide/data-unload-considerations
correct https://community.snowflake.com/s/article/Generating-a-JSON-Dataset-using-Relational-Data-in-Snowflake
--------------------------------------------------

--- Frage Nr. 351 (Richtig) ---
Frage: Which command is used to take away staged files from a Snowflake stage after a successful data ingestion?
Deine Antwort:     C
Korrekte Antwort:  C

Erklärung:
Answer C. https://docs.snowflake.com/en/user-guide/data-load-considerations-manage and https://docs.snowflake.com/en/sql-reference/sql/remove
Answer C
--------------------------------------------------

--- Frage Nr. 40 (Falsch) ---
Frage: A deterministic query is run at 8am, takes 5 minutes, and the results are cached. Which of the following statements are true? (Choose two.)
Deine Antwort:     A, B
Korrekte Antwort:  B, D

Erklärung:
BD I think, but bad wording on B: "previous" 24 hours would mean before the original query was run, so taken literally this is incorrect but I think they mean the next 24 hours.
BD Explanation for D is here  https://docs.snowflake.com/en/user-guide/querying-persisted-results.html
--------------------------------------------------

--- Frage Nr. 653 (Falsch) ---
Frage: Which data types in Snowflake are synonymous for FLOAT? (Choose two.)
Deine Antwort:     B, C
Korrekte Antwort:  B, E

Erklärung:
B, E is the correct answer. DOUBLE, DOUBLE PRECISION, REAL are synonymous with float
B,E is correct answer. DOUBLE, DOUBLE PRECISION, REAL are synonymous with float  https://docs.snowflake.com/en/sql-reference/intro-summary-data-types
Correct answer : BE https://docs.snowflake.com/en/sql-reference/data-types-numeric
--------------------------------------------------

--- Frage Nr. 248 (Richtig) ---
Frage: What Snowflake features allow virtual warehouses to handle high concurrency workloads? (Choose two.)
Deine Antwort:     B, D
Korrekte Antwort:  B, D

Erklärung:
Auto-scaling Multicluster warehouse
I think BD https://docs.snowflake.com/en/sql-reference/parameters.html#max-concurrency-level https://docs.snowflake.com/en/sql-reference/parameters.html#max-concurrency-level
--------------------------------------------------

--- Frage Nr. 561 (Richtig) ---
Frage: What step does Snowflake recommend when loading data from a stage?
Deine Antwort:     C
Korrekte Antwort:  C

Erklärung:
Answer C seems correct
Answer for Q #1116 is C external function https://docs.snowflake.com/en/user-guide/unstructured-intro
--------------------------------------------------

--- Frage Nr. 528 (Richtig) ---
Frage: How is role hierarchy established in Snowflake?
Deine Antwort:     C
Korrekte Antwort:  C

Erklärung:
C is the principle of parent child
"Granting a role to another role creates a “parent-child” relationship between the roles (also referred to as a role hierarchy)."
C  https://docs.snowflake.com/en/sql-reference/sql/grant-role#:~:text=GRANT%20ROLE-,GRANT%20ROLE,-Assigns%20a%20role
--------------------------------------------------

--- Frage Nr. 791 (Richtig) ---
Frage: A user is unloading data to a stage using this command:

copy into @message from (select object_construct('id', 1, 'first_name', 'Snowflake', 'last_name', 'User', 'city', 'Bozeman')) file_format = (type = json)

What will the output file in the stage be?
Deine Antwort:     A
Korrekte Antwort:  A

Erklärung:
You can use the OBJECT_CONSTRUCT function combined with the COPY command to convert the rows in a relational table to a single VARIANT column and unload the rows into a file.
https://docs.snowflake.com/en/user-guide/data-unload-considerations#:~:text=You%20can%20use%20the%20OBJECT_CONSTRUCT%20function%20combined%20with%20the%20COPY%20command%20to%20convert%20the%20rows%20in%20a%20relational%20table%20to%20a%20single%20VARIANT%20column%20and%20unload%20the%20rows%20into%20a%20file.
--------------------------------------------------

--- Frage Nr. 662 (Richtig) ---
Frage: Which Snowflake table type is only visible to the user who creates it, can have the same name as permanent tables in the same schema, and is dropped at the end of the session?
Deine Antwort:     A
Korrekte Antwort:  A

Erklärung:
Correct
https://docs.snowflake.com/en/user-guide/tables-temp-transient
--------------------------------------------------

--- Frage Nr. 86 (Richtig) ---
Frage: What is the minimum Snowflake edition that provides data sharing?
Deine Antwort:     A
Korrekte Antwort:  A

Erklärung:
Data sharing is possible in the Standard Edition also.  VPS (Virtual Private Snowflake) does not support Secure Data Sharing due to the current limitations against sharing data across regions.  Standard and Enterprise Editions support Secure Data Sharing with the usual caveats.
https://docs.snowflake.com/en/user-guide/intro-editions.html#data-sharing
--------------------------------------------------

--- Frage Nr. 695 (Falsch) ---
Frage: A Snowflake user wants to share data using my_share with account xy12345.

Which command should be used?
Deine Antwort:     B
Korrekte Antwort:  C

Erklärung:
ALTER SHARE [ IF EXISTS ] <name> { ADD | REMOVE } ACCOUNTS = <consumer_account> [ , <consumer_account> , ... ]  [ SHARE_RESTRICTIONS = { TRUE | FALSE } ]  ALTER SHARE [ IF  ALTER SHARE [ IF EXISTS ] <name> SET { [ ACCOUNTS = <consumer_account> [ , <consumer_account> ... ] ]
--------------------------------------------------

--- Frage Nr. 19 (Falsch) ---
Frage: Which of the following connectors allow Multi-Factor Authentication (MFA) authorization when connecting? (Choose all that apply.)
Deine Antwort:     A, C, D
Korrekte Antwort:  A, B, C, D, E

Erklärung:
MFA login is designed primarily for connecting to Snowflake through the  - web interface - but is also fully-supported by SnowSQL - and the Snowflake JDBC and ODBC drivers. Snowflake supports MFA token caching with the following drivers and connectors on macOS and Windows. This feature is not supported on Linux. - ODBC driver version 2.23.0 (or later). - JDBC driver version 3.12.16 (or later). - Python Connector for Snowflake version 2.3.7 (or later).
https://docs.snowflake.com/en/user-guide/security-mfa
--------------------------------------------------

--- Frage Nr. 772 (Falsch) ---
Frage: Which data types can be used in a Snowflake table that holds semi-structured data? (Choose two.)
Deine Antwort:     B, D
Korrekte Antwort:  A, D

Erklärung:
Correct answer
https://docs.snowflake.com/en/user-guide/semistructured-intro
--------------------------------------------------

--- Frage Nr. 279 (Richtig) ---
Frage: Which of the following indicates that it may be appropriate to use a clustering key for a table? (Choose two.)
Deine Antwort:     D, E
Korrekte Antwort:  D, E

Erklärung:
DE  Queries on the table are running slower than expected or have noticeably degraded over time. The clustering depth for the table is large.  https://docs.snowflake.com/en/user-guide/tables-clustering-keys#label-considerations-for-choosing-clustering
--------------------------------------------------

--- Frage Nr. 728 (Richtig) ---
Frage: By definition, a secure view is exposed only to users with what privilege?
Deine Antwort:     B
Korrekte Antwort:  B

Erklärung:
B is correct
B The definition of a secure view is only exposed to authorized users (i.e. users who have been granted the role that owns the view).
https://www.bing.com/search?q=By+definition%2C+a+secure+view+is+exposed+only+to+users+with+what+privilege%3F&qs=n&form=QBRE&sp=-1&lq=1&pq=by+definition%2C+a+secure+view+is+exposed+only+to+users+with+what+privilege%3F&sc=1-74&sk=&cvid=0C736B21938E4126ABA51B4764C220F0&ghsh=0&ghacc=0&ghpl=
--------------------------------------------------

--- Frage Nr. 100 (Falsch) ---
Frage: What is the most granular object that the Time Travel retention period can be defined on?
Deine Antwort:     A
Korrekte Antwort:  D

Erklärung:
To specify the data retention period for Time Travel:  The DATA_RETENTION_TIME_IN_DAYS object parameter can be used by users with the ACCOUNTADMIN role to set the default retention period for your account.  The same parameter can be used to explicitly override the default when creating a database, schema, and individual table.  The data retention period for a database, schema, or table can be changed at any time.
https://docs.snowflake.com/en/user-guide/data-time-travel.html#data-retention-period
--------------------------------------------------

--- Frage Nr. 575 (Richtig) ---
Frage: Which role is responsible for managing the billing and credit data within Snowflake?
Deine Antwort:     B
Korrekte Antwort:  B

Erklärung:
https://docs.snowflake.com/en/user-guide/security-access-control-considerations#using-the-accountadmin-role
The account administrator (i.e users with the ACCOUNTADMIN system role) role is the most powerful role in the system. This role alone is responsible for configuring parameters at the account level. Users with the ACCOUNTADMIN role can view and manage Snowflake billing and credit data, and can stop any running SQL statements.
--------------------------------------------------

--- Frage Nr. 371 (Falsch) ---
Frage: In order to access Snowflake Marketplace listings, who needs to accept the Snowflake Consumer Terms of Service?
Deine Antwort:     C
Korrekte Antwort:  D

Erklärung:
You must be an organization administrator (i.e. a user granted the ORGADMIN role) to accept the terms
D. ORGADMIN https://other-docs.snowflake.com/en/collaboration/consumer-becoming The organization administrator only needs to accept the Snowflake Provider and Consumer Terms once for your organization. After the terms have been accepted, anyone in your organization that has a role with the necessary privileges can become a consumer of listings.  Note  You must be an organization administrator (i.e. a user granted the ORGADMIN role) to accept the terms.
--------------------------------------------------

--- Frage Nr. 747 (Richtig) ---
Frage: Which REST API can be used with unstructured data?
Deine Antwort:     C
Korrekte Antwort:  C

Erklärung:
https://docs.snowflake.com/en/user-guide/data-load-unstructured-rest-api
The insertFiles API can be used to upload and insert unstructured data files into Snowflake. This is typically used for loading various types of unstructured data, such as JSON, XML, CSV, and more, into Snowflake for further processing or analysis.
--------------------------------------------------

--- Frage Nr. 982 (Richtig) ---
Frage: A user has 10 files in a stage containing new customer data. The ingest operation completes with no errors, using the following command:

COPY INTO my_table FROM @my_stage;

The next day the user adds 10 files to the stage so that now the stage contains a mixture of new customer data and updates to the previous data. The user did not remove the 10 original files.

If the user runs the same COPY INTO command what will happen?
Deine Antwort:     D
Korrekte Antwort:  D

Erklärung:
According to the Snowflake documentation, when you run the COPY INTO command again without removing the original files, all data from all of the files on the stage will be appended to the table
D is correct
D - only the new files will be appended B - SF doesn't know which customer is new (COPY doesn't care about the meaning of data, care about files (file names) which are new (no kept in metadata as loaded)
D is correct Loading Older Files¶ This section describes how the COPY INTO <table> command prevents data duplication differently based on whether the load status for a file is known or unknown. If you partition your data in stages using logical, granular paths by date (as recommended in Organizing Data by Path) and load data within a short period of time after staging it, this section largely does not apply to you. However, if the COPY command skips older files (i.e. historical data files) in a data load, this section describes how to bypass the default behavior. https://docs.snowflake.com/en/user-guide/data-load-considerations-load#executing-parallel-copy-statements-that-reference-the-same-data-files
--------------------------------------------------

--- Frage Nr. 51 (Richtig) ---
Frage: True or False: When a data share is established between a Data Provider and a Data Consumer, the Data Consumer can extend that data share to other Data
Consumers.
Deine Antwort:     B
Korrekte Antwort:  B

Erklärung:
yeah, you can not re-share your share. but in real live, I did it using dbt.
Consumer can't re-shared DB object to another consumer. https://docs.snowflake.com/en/user-guide/data-share-consumers.html
--------------------------------------------------

--- Frage Nr. 984 (Falsch) ---
Frage: Which of the following is the Snowflake Account_Usage.Metering_History view used for?
Deine Antwort:     B
Korrekte Antwort:  A

Erklärung:
The METERING_HISTORY view in the ACCOUNT_USAGE schema can be used to return the hourly credit usage for an account within the last 365 days (1 year).  https://docs.snowflake.com/en/sql-reference/account-usage/metering_history.html
A is correct: https://docs.snowflake.com/en/sql-reference/account-usage/metering_history.html#metering-history-view
--------------------------------------------------

--- Frage Nr. 186 (Richtig) ---
Frage: Where can a user find and review the failed logins of a specific user for the past 30 days?
Deine Antwort:     B
Korrekte Antwort:  B

Erklärung:
correct answer
https://docs.snowflake.com/en/sql-reference/account-usage/login_history.html
--------------------------------------------------

--- Frage Nr. 766 (Falsch) ---
Frage: What does Snowflake's search optimization service support?
Deine Antwort:     B
Korrekte Antwort:  C

Erklärung:
D. Casts on table columns (except for fixed-point numbers cast to strings): This statement is correct. The Search Optimization Service can accelerate queries where predicates involve casting a column to a different data type, with one specific exception: it does not support cases where a fixed-point number (e.g., NUMBER, DECIMAL, INT) is cast to a string type.
--------------------------------------------------

--- Frage Nr. 511 (Falsch) ---
Frage: What is the purpose of the STRIP_NULL_VALUES file format option when loading semi-structured data files into Snowflake?
Deine Antwort:     B
Korrekte Antwort:  D

Erklärung:
D is correct
Alternatively, if the “null” values in your files indicate missing values and have no other special meaning, we recommend setting the file format option STRIP_NULL_VALUES to TRUE when you load the semi-structured data files. This option removes OBJECT elements or ARRAY elements containing “null” values. https://docs.snowflake.com/en/user-guide/semistructured-considerations#label-variant-null
--------------------------------------------------

--- Frage Nr. 502 (Falsch) ---
Frage: A user with which privileges can create or manage other users in a Snowflake account? (Choose two.)
Deine Antwort:     A, D
Korrekte Antwort:  D, E

Erklärung:
D& E  Create users The USERADMIN system role can create users using SQL (CREATE USER).  If you prefer to use a custom role for this purpose, grant the CREATE USER privilege on the account to this role.  Modify users Only the role with the OWNERSHIP privilege on a user, or a higher role, can modify most user properties using SQL (ALTER USER). In addition, the role must have the global CREATE USER privilege.  https://docs.snowflake.com/en/user-guide/admin-user-management
Create users: The USERADMIN system role can create users using SQL (CREATE USER). If you prefer to use a custom role for this purpose, grant the CREATE USER privilege on the account to this role.  https://docs.snowflake.com/en/user-guide/admin-user-management
--------------------------------------------------

--- Frage Nr. 476 (Richtig) ---
Frage: Based on a review of a Query Profile, which scenarios will benefit the MOST from the use of a data clustering key? (Choose two.)
Deine Antwort:     B, E
Korrekte Antwort:  B, E

Erklärung:
From the documentation at ( https://docs.snowflake.com/en/user-guide/tables-clustering-keys ):   Snowflake recommends prioritizing keys in the order below:  Cluster columns that are most actively used in selective filters. For many fact tables involved in date-based queries (for example “WHERE invoice_date > x AND invoice date <= y”), choosing the date column is a good idea.[...]  If there is room for additional cluster keys, then consider columns frequently used in join predicates, for example “FROM table1 JOIN table2 ON table2.column_A = table1.column_B”.
https://docs.snowflake.com/en/user-guide/tables-clustering-keys
--------------------------------------------------

--- Frage Nr. 683 (Richtig) ---
Frage: What criteria does Snowflake use to determine the current role when initiating a session? (Choose two.)
Deine Antwort:     A, B
Korrekte Antwort:  A, B

Erklärung:
what about D?
Correct
the answer is correct https://docs.snowflake.com/en/user-guide/security-access-control-overview#label-access-control-role-enforcement:~:text=If%20a%20role,PUBLIC%20is%20used.
--------------------------------------------------

--- Frage Nr. 579 (Richtig) ---
Frage: Which query types will have significant performance improvement when run using the search optimization service? (Choose two.)
Deine Antwort:     B, D
Korrekte Antwort:  B, D

Erklärung:
Point lookup queries are queries that are expected to return a small number of rows. The search optimization service can improve the performance of point lookup queries that use:  Equality predicates (for example, <column_name> = <constant>).  Predicates that use IN (see example).  Example
B and D
https://docs.snowflake.com/en/user-guide/search-optimization/point-lookup-queries
--------------------------------------------------

--- Frage Nr. 452 (Richtig) ---
Frage: How can a user access information about a query execution plan without consuming virtual warehouse compute resources?
Deine Antwort:     B
Korrekte Antwort:  B

Erklärung:
EXPLAIN compiles the SQL statement, but does not execute it, so EXPLAIN does not require a running warehouse.  https://docs.snowflake.com/en/sql-reference/sql/explain
https://docs.snowflake.com/en/sql-reference/sql/explain "EXPLAIN compiles the SQL statement, but does not execute it, so EXPLAIN does not require a running warehouse.  Although EXPLAIN does not consume any compute credits, the compilation of the query does consume Cloud Service credits, just as other metadata operations do."  The EXPLAIN plan is the “logical” explain plan. It shows the operations that will be performed, and their logical relationship to each other. The actual execution order of the operations in the plan does not necessarily match the logical order shown by the plan. Hence, it is not clear 100%. Let's say A., not B.
--------------------------------------------------

--- Frage Nr. 67 (Richtig) ---
Frage: True or False: Micro-partition metadata enables some operations to be completed without requiring Compute.
Deine Antwort:     A
Korrekte Antwort:  A

Erklärung:
A. like count(*), min or max etc
https://blog.ippon.tech/innovative-snowflake-features-caching/
--------------------------------------------------

--- Frage Nr. 193 (Richtig) ---
Frage: Which data types does Snowflake support when querying semi-structured data? (Choose two.)
Deine Antwort:     A, D
Korrekte Antwort:  A, D

Erklärung:
Answer : Variant and Array https://docs.snowflake.com/en/user-guide/semistructured-intro.html#loading-semi-structured-data
--------------------------------------------------

--- Frage Nr. 845 (Richtig) ---
Frage: Which account usage view in Snowflake can be used to identify the most-frequently accessed tables?
Deine Antwort:     A
Korrekte Antwort:  A

Erklärung:
A. Access_History  The ACCESS_HISTORY view in Snowflake provides detailed information about user access to data, including which queries accessed specific tables and columns. This makes it useful for identifying the most-frequently accessed tables.
The "Access_History" view in Snowflake can be used to identify the most frequently accessed tables. This view contains information about the historical access patterns for tables and views in your Snowflake account, including details on queries, users, and access frequency. By querying this view, you can analyze which tables are being accessed most frequently in your Snowflake environment.
--------------------------------------------------

--- Frage Nr. 370 (Falsch) ---
Frage: How can the Query Profile be used to identify the costliest operator of a query?
Deine Antwort:     D
Korrekte Antwort:  B

Erklärung:
Answer B :  Operator Nodes by Execution Time:  A collapsible panel in the operator tree pane lists nodes by execution time in descending order, enabling users to quickly locate the costliest operator nodes in terms of execution time. The panel lists all nodes that lasted for 1% or longer of the total execution time of the query (or the execution time for the displayed query step, if the query was executed in multiple processing steps).  https://docs.snowflake.com/en/user-guide/ui-query-profile
B is correct https://docs.snowflake.com/en/user-guide/ui-query-profile
--------------------------------------------------

--- Frage Nr. 45 (Richtig) ---
Frage: What is the maximum compressed row size in Snowflake?
Deine Antwort:     B
Korrekte Antwort:  B

Erklärung:
MAX size for compressed data for semi-structured data type is also 16 MB. That means if our table has a semi-structured data type column with 16MB data other columns will have NULL data.
https://docs.snowflake.com/en/user-guide/data-load-considerations-prepare.html#semi-structured-data-size-limitations 16MB per row captured in the variant field
--------------------------------------------------

