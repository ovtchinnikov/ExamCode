Question,Question Type (multiple-choice or multi-select),Answer Option 1,Answer Option 2,Answer Option 3,Answer Option 4,Answer Option 5,Answer Option 6,Answer Option 7,Answer Option 8,Answer Option 9,Answer Option 10,Answer Option 11,Answer Option 12,Answer Option 13,Answer Option 14,Answer Option 15,Correct Response,Explanation,Knowledge Area
Snowflake provides a mechanism for its customers to override its natural clustering algorithms. This method is:,multiple-choice,A. Micro-partitions,B. Clustering keys,C. Key partitions,D. Clustered partitions,,,,,,,,,,,,2,"A company's security audit requires generating a report listing all Snowflake logins (e.g.. date and user) within the last 90 days.
https://community.snowflake.com/s/article/Snowflake-What-the-Cluster",
Which of the following are valid Snowflake Virtual Warehouse Scaling Policies? (Choose two.),multi-select,A. Custom,B. Economy,C. Optimized,D. Standard,,,,,,,,,,,,"2, 4","Answer is B/D.    objectProperties ::=  WAREHOUSE_SIZE = XSMALL | SMALL | MEDIUM | LARGE | XLARGE | XXLARGE | XXXLARGE | X4LARGE | X5LARGE | X6LARGE  MAX_CLUSTER_COUNT = <num>  MIN_CLUSTER_COUNT = <num>  SCALING_POLICY = STANDARD | ECONOMY  AUTO_SUSPEND = <num> | NULL  AUTO_RESUME = TRUE | FALSE  INITIALLY_SUSPENDED = TRUE | FALSE  RESOURCE_MONITOR = <monitor_name>  COMMENT = '<string_literal>'
https://community.snowflake.com/s/article/Snowflake-Visualizing-Warehouse-Performance",
True or False: A single database can exist in more than one Snowflake account.,multiple-choice,A. True,B. False,,,,,,,,,,,,,,1,"The question is where the single database (instance) can exist across multiple accounts. Replication creates a separate instance and keeps it in sync with primary DB, but the DB instance can only belong to one account. Its a tricky question
Through database replication, should be A https://docs.snowflake.com/en/user-guide/database-replication-intro.html",
Which of the following roles is recommended to be used to create and manage users and roles?,multiple-choice,A. SYSADMIN,B. SECURITYADMIN,C. PUBLIC,D. ACCOUNTADMIN,,,,,,,,,,,,2,"Here the answer should be SECURITYADMIN as it is parent of USERADMIN (which is the correct answer)  More details: https://docs.snowflake.com/en/user-guide/security-access-control-considerations  Attention  By default, when your account is provisioned, the first user is assigned the ACCOUNTADMIN role. This user should then create one or more additional users who are assigned the USERADMIN role. All remaining users should be created by the user(s) with the USERADMIN role or another role that is granted the global CREATE USER privilege.",
True or False: Bulk unloading of data from Snowflake supports the use of a SELECT statement.,multiple-choice,A. True,B. False,,,,,,,,,,,,,,2,"B UNLOAD INTO @stage_name/files FROM my_table FILE_FORMAT = (TYPE = 'CSV');
",
Select the different types of Internal Stages: (Choose three.),multi-select,A. Named Stage,B. User Stage,C. Table Stage,D. Schema Stage,,,,,,,,,,,,"1, 2, 3","ABC is the correct answer
ABC https://docs.snowflake.com/en/user-guide/data-load-local-file-system-create-stage.html",
True or False: A customer using SnowSQL / native connectors will be unable to also use the Snowflake Web Interface (UI) unless access to the UI is explicitly granted by support.,multiple-choice,A. True,B. False,,,,,,,,,,,,,,2,"WebUI and SnowSQL are available for all users. Answer is FALSE
https://docs.snowflake.com/en/user-guide/connecting.html",
Account-level storage usage can be monitored via:,multiple-choice,A. The Snowflake Web Interface (UI) in the Databases section,B. The Snowflake Web Interface (UI) in the Account -> Billing & Usage section,C. The Information Schema -> ACCOUNT_USAGE_HISTORY View,D. The Account Usage Schema -> ACCOUNT_USAGE_METRICS View,,,,,,,,,,,,2,"B is correct. for D it should be TABLE_STORAGE_METRICS not ACCOUNT_USAGE_METRICS. there is no view with account_usage_metrics name. if D has said view name is TABLE_STORAGE_METRICS then its correct
https://docs.snowflake.com/en/user-guide/admin-usage-billing.html",
Credit Consumption by the Compute Layer (Virtual Warehouses) is based on: (Choose two.),multi-select,A. Number of users,B. Warehouse size,C. Amount of data processed,D. # of clusters for the Warehouse,,,,,,,,,,,,"2, 3","B. Warehouse size: The size of the virtual warehouse is one of the primary factors that determine the credit consumption. Larger warehouses have more compute resources available, which allows them to process data faster and more efficiently, but also results in higher credit consumption.  C. Amount of data processed: The amount of data processed by the virtual warehouse is another key factor that determines credit consumption. Snowflake charges credits based on the amount of data processed, regardless of the number of users or the number of clusters used by the virtual warehouse.  A. Number of users and D. # of clusters for the warehouse are not direct factors in credit consumption by the compute layer. However, the number of users and the number of clusters used can indirectly affect credit consumption by impacting the amount of data processed and the warehouse size required to process that data efficiently.  Therefore, the credit consumption by the compute layer in Snowflake is primarily based on warehouse size and the amount of data processed.
B & C, Snowflake credits are charged based on the number of virtual warehouses you use, how long they run, and their size. https://docs.snowflake.com/en/user-guide/cost-understanding-compute",
Which statement best describes `clustering`?,multiple-choice,A. Clustering represents the way data is grouped together and stored within Snowflake's micro-partitions,B. The database administrator must define the clustering methodology for each Snowflake table,C. The clustering key must be included on the COPY command when loading data into Snowflake,D. Clustering can be disabled within a Snowflake account,,,,,,,,,,,,1,"Strongly agree, A is the correct the correct answer.
https://docs.snowflake.com/en/user-guide/tables-clustering-micropartitions.html  In Snowflake, as data is inserted/loaded into a table, clustering metadata is collected and recorded for each micro-partition created during the process. Snowflake then leverages this clustering information to avoid unnecessary scanning of micro-partitions during querying, significantly accelerating the performance of queries that reference these columns.",
True or False: The COPY command must specify a File Format in order to execute.,multiple-choice,A. True,B. False,,,,,,,,,,,,,,2,"False.  In Snowflake, the COPY command does not necessarily require specifying a File Format in order to execute. The COPY command can be used to load data into a table from various file formats such as CSV, JSON, Avro, Parquet, etc.  When a file format is not explicitly specified in the COPY command, Snowflake attempts to automatically infer the file format based on the file's extension or internal file structure. This automatic file format inference feature is known as ""automatic file format detection.""  However, if the file format cannot be determined automatically or if you want to override the automatic detection, you can explicitly specify a File Format in the COPY command using the FILE_FORMAT parameter.  So, while specifying a File Format can provide more control and customization over the data loading process, it is not mandatory for the COPY command to execute successfully.
The correct answer is FALSE. The file format can be defined at the stage, table, or copy into command.  Create Stage: https://docs.snowflake.com/en/sql-reference/sql/create-stage.html Create Table (STAGE_FILE_FORMAT option): https://docs.snowflake.com/en/sql-reference/sql/create-table.html Copy Into: https://docs.snowflake.com/en/sql-reference/sql/copy-into-table.html",
Which of the following commands sets the Virtual Warehouse for a session?,multiple-choice,A. COPY WAREHOUSE FROM <<config file>>;,B. SET WAREHOUSE = <<warehouse name>>;,C. USE WAREHOUSE <<warehouse name>>;,D. USE VIRTUAL_WAREHOUSE <<warehouse name>>;,,,,,,,,,,,,3,"The correct answer is C. According to snowflake docs,   ""A Snowflake session can only have one current warehouse at a time. The current warehouse for a session can be specified or changed at any time through the USE WAREHOUSE command.""
https://docs.snowflake.com/en/user-guide/warehouses-tasks.html",
Which of the following objects can be cloned? (Choose four.),multi-select,A. Tables,B. Named File Formats,C. Schemas,D. Shares,E. Databases,F. Users,,,,,,,,,,"1, 2, 3, 5","ABCE : Shares and Users cannot be cloned in Snowflake because they represent different types of objects and have different purposes.  Shares represent shared access to data within Snowflake, and they cannot be cloned because access to data is controlled through the sharing mechanism, not through copying the share itself.  Users represent individual accounts within Snowflake, and they cannot be cloned because each user account must have a unique name and must be associated with a unique set of permissions. Cloning a user would result in two users with the same name, which is not allowed in Snowflake.  Instead of cloning Shares or Users, you can use the Snowflake GRANT command to manage access to data and permissions in Snowflake. The GRANT command allows you to control access to data by granting specific privileges to users, roles, or groups.
ABCE https://docs.snowflake.com/en/sql-reference/sql/create-clone",
Which object allows you to limit the number of credits consumed within a Snowflake account?,multiple-choice,A. Account Usage Tracking,B. Resource Monitor,C. Warehouse Limit Parameter,D. Credit Consumption Tracker,,,,,,,,,,,,2,"True B is correct
We can control and set the limit for credit usage in Resource Monitors. https://docs.snowflake.com/en/user-guide/resource-monitors.html#:~:text=To%20help%20control%20costs%20and%20avoid%20unexpected%20credit%20usage%20caused%20by%20running%20warehouses%2C%20Snowflake%20provides%20resource%20monitors",
Snowflake is designed for which type of workloads? (Choose two.),multi-select,A. OLAP (Analytics) workloads,B. OLTP (Transactional) workloads,C. Concurrent workloads,D. On-premise workloads,,,,,,,,,,,,"1, 3",Check this new feature of Unistore! A new workload that delivers a modern approach to working with transactional and analytical data together in a single platform https://www.snowflake.com/blog/introducing-unistore/,
What are the three layers that make up Snowflake's architecture? (Choose three.),multi-select,A. Compute,B. Tri-Secret Secure,C. Storage,D. Cloud Services,,,,,,,,,,,,"1, 3, 4","Snowflake architecture is made up of compute , storage and cloud services layer primarily.
https://docs.snowflake.com/en/user-guide/intro-key-concepts.html",
Why would a customer size a Virtual Warehouse from an X-Small to a Medium?,multiple-choice,A. To accommodate more queries,B. To accommodate more users,C. To accommodate fluctuations in workload,D. To accommodate a more complex workload,,,,,,,,,,,,4,"Answer is D. As you mention warehouse resizing is not intended for handling concurrency issues(i.e handling more queries). The solution for A would be multi-clustering.
A is the correct answer.  Ref: https://docs.snowflake.com/en/user-guide/warehouses-considerations.html  Resizing a warehouse generally improves query performance, particularly for larger, more complex queries. It can also help reduce the queuing that occurs if a warehouse does not have enough compute resources to process all the queries that are submitted concurrently. Note that warehouse resizing is not intended for handling concurrency issues; instead, use additional warehouses to handle the workload or use a multi-cluster warehouse (if this feature is available for your account).",
True or False: Reader Accounts incur no additional Compute costs to the Data Provider since they are simply reading the shared data without making changes.,multiple-choice,A. True,B. False,,,,,,,,,,,,,,2,False. https://docs.snowflake.com/en/user-guide/data-sharing-reader-create.html#:~:text=The%20reader%20account%20is%20created%2C%20owned%2C%20and%20managed%20by%20the%20provider%20account%2C%20which%20assumes%20all%20responsibility%20for%20credit%20charges%20incurred%20by%20users%20in%20the%20reader%20account.,
Which of the following connectors allow Multi-Factor Authentication (MFA) authorization when connecting? (Choose all that apply.),multi-select,A. JDBC,B. SnowSQL,C. Snowflake Web Interface (UI),D. ODBC,E. Python,,,,,,,,,,,"1, 2, 3, 4, 5","MFA login is designed primarily for connecting to Snowflake through the  - web interface - but is also fully-supported by SnowSQL - and the Snowflake JDBC and ODBC drivers. Snowflake supports MFA token caching with the following drivers and connectors on macOS and Windows. This feature is not supported on Linux. - ODBC driver version 2.23.0 (or later). - JDBC driver version 3.12.16 (or later). - Python Connector for Snowflake version 2.3.7 (or later).
https://docs.snowflake.com/en/user-guide/security-mfa",
True or False: Snowflake charges a premium for storing semi-structured data.,multiple-choice,A. True,B. False,,,,,,,,,,,,,,2,"Snowflake does not charge extra for any special/semi-structure type of file.
https://snowflakecommunity.force.com/s/question/0D50Z00008ckwNuSAI/does-snowflake-charges-premium-for-storing-semi-structured-data",
Which of the following statements describes a benefit of Snowflake's separation of compute and storage? (Choose all that apply.),multi-select,A. Growth of storage and compute are tightly coupled together,B. Storage expands without the requirement to add more compute,C. Compute can be scaled up or down without the requirement to add more storage,D. Multiple compute clusters can access stored data without contention,,,,,,,,,,,,"2, 3, 4","BCD, all the three are correct
",
True or False: It is possible to unload structured data to semi-structured formats such as JSON and Parquet.,multiple-choice,A. True,B. False,,,,,,,,,,,,,,1,"A is the correct answer
A is correct: https://docs.snowflake.com/en/user-guide/data-unload-considerations.html#unloading-a-relational-table-to-json",
In which layer of its architecture does Snowflake store its metadata statistics?,multiple-choice,A. Storage Layer,B. Compute Layer,C. Database Layer,D. Cloud Services Layer,,,,,,,,,,,,3,"Cloud Service layer stores metadata of queries for optimization.
Correct answer should be ""C"".  https://docs.snowflake.com/en/user-guide/intro-key-concepts Database Storage¶ When data is loaded into Snowflake, Snowflake reorganizes that data into its internal optimized, compressed, columnar format. Snowflake stores this optimized data in cloud storage.  Snowflake manages all aspects of how this data is stored — the organization, file size, structure, compression, metadata, statistics, and other aspects of data storage are handled by Snowflake. The data objects stored by Snowflake are not directly visible nor accessible by customers; they are only accessible through SQL query operations run using Snowflake. 
Database Storage

When data is loaded into Snowflake, Snowflake reorganizes that data into its internal optimized, compressed, columnar format. Snowflake stores this optimized data in cloud storage.

Snowflake manages all aspects of how this data is stored — the organization, file size, structure, compression, metadata, statistics, and other aspects of data storage are handled by Snowflake. The data objects stored by Snowflake are not directly visible nor accessible by customers; they are only accessible through SQL query operations run using Snowflake.",
True or False: Data in fail-safe can be deleted by a user or the Snowflake team before it expires.,multiple-choice,A. True,B. False,,,,,,,,,,,,,,2,"Fail Safe can not be configured. Users, neither retrieve nor delete the data of fail safe.
https://blog.knoldus.com/ksnow-time-travel-and-fail-safe-in-snowflake/",
"True or False: Snowflake's data warehouse was built from the ground up for the cloud in lieu of using an existing database or a platform, like Hadoop, as a base.",multiple-choice,A. True,B. False,,,,,,,,,,,,,,2,https://docs.snowflake.com/en/user-guide/intro-key-concepts#:~:text=The%20Snowflake%20data%20platform%20is%20not%20built%20on%20any%20existing%20database%20technology%20or%20%E2%80%9Cbig%20data%E2%80%9D%20software%20platforms%20such%20as%20Hadoop.%20Instead%2C%20Snowflake%20combines%20a%20completely%20new%20SQL%20query%20engine%20with%20an%20innovative%20architecture%20natively%20designed%20for%20the%20cloud.   Answer is False.,
Which of the following statements are true of Virtual Warehouses? (Choose all that apply.),multi-select,A. Customers can change the size of the Warehouse after creation,B. A Warehouse can be resized while running,C. A Warehouse can be configured to suspend after a period of inactivity,D. A Warehouse can be configured to auto-resume when new queries are submitted,,,,,,,,,,,,"1, 2, 3, 4","All four are true  Additionally, multi-cluster warehouses support all the same properties and actions as single-cluster warehouses, including:  1)Specifying a warehouse size. 2)Resizing a warehouse at any time. 3)Auto-suspending a running warehouse due to inactivity; note that this does not apply to individual clusters, but rather the entire multi-cluster warehouse. 4)Auto-resuming a suspended warehouse when new queries are submitted.
https://docs.snowflake.com/en/user-guide/warehouses-multicluster.html",
The PUT command: (Choose two.),multi-select,A. Automatically creates a File Format object,B. Automatically uses the last Stage created,C. Automatically compresses files using Gzip,D. Automatically encrypts files,,,,,,,,,,,,"2, 4","First we will create a stage and then use PUT to load the data from onprem to that stage. Hence B. And the data will be transferred to the stage and will be encrypted, Hence D. So I guess it should be B and D.
Uploaded files are automatically encrypted with 128-bit or 256-bit keys.  AUTO_COMPRESS is TRUE by default and by default it uses GZIP.  https://docs.snowflake.com/en/sql-reference/sql/put.html",
Which type of table corresponds to a single Snowflake session?,multiple-choice,A. Temporary,B. Transient,C. Provisional,D. Permanent,,,,,,,,,,,,1,"Temporary tables are created in a session and they cannot be accessed through different session.
Temporary tables only exist within the session in which they were created and persist only for the remainder of the session. https://docs.snowflake.com/en/user-guide/tables-temp-transient.html#temporary-tables",
Which interfaces can be used to create and/or manage Virtual Warehouses?,multiple-choice,A. The Snowflake Web Interface (UI),B. SQL commands,C. Data integration tools,D. All of the above,,,,,,,,,,,,4,"The correct answer is D. All of the above.  Virtual Warehouses can be created and/or managed using the Snowflake Web Interface (UI), SQL commands, or data integration tools.  The Snowflake Web Interface (UI) is a graphical user interface that allows users to create and manage Virtual Warehouses. The Snowflake Web Interface (UI) is available in both a web browser and a mobile app.  SQL commands can be used to create and manage Virtual Warehouses. SQL commands can be executed using the Snowflake Web Interface (UI), the Snowflake Command Line Interface (CLI), or a data integration tool.  Data integration tools can be used to create and manage Virtual Warehouses. Data integration tools are software applications that allow users to extract, transform, and load data from a variety of sources into Snowflake.
https://docs.snowflake.com/en/user-guide/intro-key-concepts.html  A warehouse can be created through the web interface or using SQL:  Classic Web Interface Click on Warehouses Warehouses tab » Create  SQL Execute a CREATE WAREHOUSE command.",
When a Pipe is recreated using the CREATE OR REPLACE PIPE command:,multiple-choice,A. The Pipe load history is reset to empty,B. The REFRESH parameter is set to TRUE,C. Previously loaded files will be ignored,D. All of the above,,,,,,,,,,,,4,"D is correct  Recreating Pipes - Load History:(As per documentation) The load history for Snowpipe operations is stored in the metadata of the pipe object. When a pipe is recreated, the load history is dropped. In general, this condition only affects users if they subsequently execute an ALTER PIPE … REFRESH statement on the pipe. Doing so could load duplicate data from staged files in the storage location for the pipe if the data was already loaded successfully and the files were not deleted subsequently.  https://docs.snowflake.com/en/user-guide/data-load-snowpipe-manage#label-snowpipe-management-recreate-pipes",
What is the minimum Snowflake edition that customers planning on storing protected information in Snowflake should consider for regulatory compliance?,multiple-choice,A. Standard,B. Premier,C. Enterprise,D. Business Critical Edition,,,,,,,,,,,,3,"C. Enterprise Edition.  The Enterprise Edition of Snowflake offers advanced security features and capabilities that are designed to meet the stringent requirements of regulatory compliance. It includes features such as role-based access control (RBAC), encryption at rest and in transit, audit logging, fine-grained access controls, and data masking. These features help ensure the security and compliance of sensitive and protected data stored in Snowflake.  While other editions of Snowflake, such as Standard and Premier, also provide security features, the Enterprise Edition is specifically tailored for organizations with higher compliance and security requirements. It offers additional features and capabilities that address the needs of regulated industries and data protection standards.  Therefore, customers planning on storing protected information in Snowflake for regulatory compliance should consider the Enterprise Edition as a suitable option.
PII and HIPAA compliance are only supported for Business Critical Edition or higher. But the question should have been more specific as jjordan mentioned. https://docs.snowflake.com/en/user-guide/intro-editions.html#security-governance-data-protection",
Select the three types of tables that exist within Snowflake. (Choose three.),multi-select,A. Temporary,B. Transient,C. Provisional,D. Permanent,,,,,,,,,,,,"1, 2, 4","Temporary tables, Transient tables, Permanent tables exists in Snowflake.
https://community.snowflake.com/s/article/Making-Transient-table-by-Default",
True or False: Snowpipe via REST API can only reference External Stages as source.,multiple-choice,A. True,B. False,,,,,,,,,,,,,,2,"https://docs.snowflake.com/en/user-guide/data-load-snowpipe-rest-load B)  Stage your data files:  Internal stage: Use the PUT command to stage your files.  External stage: Use the client tools provided by the cloud provider to copy your files to the stage location (Amazon S3, Google Cloud Storage, or Microsoft Azure).",
True or False: A third-party tool that supports standard JDBC or ODBC but has no Snowflake-specific driver will be unable to connect to Snowflake.,multiple-choice,A. True,B. False,,,,,,,,,,,,,,2,"False.  A third-party tool that supports standard JDBC or ODBC can connect to Snowflake even without a Snowflake-specific driver. Snowflake provides JDBC and ODBC connectors that adhere to the standard JDBC and ODBC interfaces, allowing third-party tools to establish a connection to Snowflake using these standard protocols.  The Snowflake JDBC and ODBC connectors act as bridges between the third-party tools and the Snowflake service, enabling communication and data exchange. As long as the third-party tool supports JDBC or ODBC, it can utilize the Snowflake connectors to connect to Snowflake and interact with the data warehouse.  This approach ensures compatibility and interoperability with a wide range of tools and applications that support JDBC or ODBC, making it easier to integrate Snowflake into existing ecosystems or use preferred third-party tools for data analysis, reporting, or other purposes.
Answer is B False:  E.g. JDBC:  https://docs.snowflake.com/en/user-guide/jdbc.html  Snowflake provides a JDBC type 4 driver that supports core JDBC functionality. The JDBC driver must be installed in a 64-bit environment and requires Java 1.8 (or higher). The driver can be used with most client tools/applications that support JDBC for connecting to a database server.",
True or False: It is possible to load data into Snowflake without creating a named File Format object.,multiple-choice,A. True,B. False,,,,,,,,,,,,,,1,"True. Snowflake supports loading data without creating a named File Format object. Snowflake provides built-in file formats that can be used to load data without the need to create a file format object explicitly.  For example, to load a CSV file, you can use the built-in CSV file format by simply specifying the FILE_FORMAT option as CSV in the COPY INTO command. This allows you to quickly load data without the overhead of creating a named file format object.       Send a message...
https://docs.snowflake.com/en/user-guide/data-load-external-tutorial-create-file-format",
True or False: A table in Snowflake can only be queried using the Virtual Warehouse that was used to load the data.,multiple-choice,A. True,B. False,,,,,,,,,,,,,,2,"B is correct. you can query cached data without having virtual warehouse running
",
Which of the following statements are true of Snowflake data loading? (Choose three.),multi-select,A. VARIANT   null   values are not the same as SQL NULL values,"B. It is recommended to do frequent, single row DMLs",C. It is recommended to validate the data before loading into the Snowflake target table,D. It is recommended to use staging tables to manage MERGE statements,,,,,,,,,,,,"1, 3, 4","The result must be deterministic for merge so source can be any reference data source only constraint it should create/modify unique rows
Variant NULL values: https://docs.snowflake.com/en/user-guide/semistructured-considerations#label-variant-null",
Which statements are true of micro-partitions? (Choose two.),multi-select,A. They are approximately 16MB in size,B. They are stored compressed only if COMPRESS=TRUE on Table,C. They are immutable,D. They are only encrypted in the Enterprise edition and above,,,,,,,,,,,,"1, 3","- micro-partitions are small in size (50 to 500 MB, before compression) - 16 MB must comes from old version/question - COMPRESSION = NONE is the right
The size of 50-500MB is for uncompressed data and micropartition itself holds around 16MB(after compression). https://stackoverflow.com/questions/67945427/clarification-on-the-snowflake-micro-partition-size",
True or False: Query ID's are unique across all Snowflake deployments and can be used in communication with Snowflake Support to help troubleshoot issues.,multiple-choice,A. True,B. False,,,,,,,,,,,,,,1,"True.  Query IDs in Snowflake are unique across all Snowflake deployments. Each query executed in Snowflake is assigned a unique Query ID, which can be used to track and reference that specific query. Query IDs are system-generated and can be found in various monitoring and logging tools provided by Snowflake.  In case of any issues or troubleshooting needs, providing the Query ID to Snowflake Support can be helpful. Snowflake Support can use the Query ID to investigate the details and history of the specific query, assisting in troubleshooting and resolving any issues related to that query.  Therefore, the statement is true. Query IDs are unique across all Snowflake deployments and can be used in communication with Snowflake Support to help troubleshoot issues.
There is no proof that query_id is unique across all snowflake deployments. The support team needs both query_id and Account URL to minimize any delays in receiving a support response. https://community.snowflake.com/s/article/How-To-Submit-a-Support-Case-in-Snowflake-Lodge",
"A deterministic query is run at 8am, takes 5 minutes, and the results are cached. Which of the following statements are true? (Choose two.)",multi-select,A. The exact query will ALWAYS return the precomputed result set for the RESULT_CACHE_ACTIVE = time period,B. The same exact query will return the precomputed results if the underlying data hasn't changed and the results were last accessed within previous 24 hour period,C. The same exact query will return the precomputed results even if the underlying data has changed as long as the results were last accessed within the previous 24 hour period,D. The   24 hour   timer on the precomputed results gets renewed every time the exact query is executed,,,,,,,,,,,,"2, 4","BD I think, but bad wording on B: ""previous"" 24 hours would mean before the original query was run, so taken literally this is incorrect but I think they mean the next 24 hours.
BD Explanation for D is here  https://docs.snowflake.com/en/user-guide/querying-persisted-results.html",
Increasing the maximum number of clusters in a Multi-Cluster Warehouse is an example of:,multiple-choice,A. Scaling rhythmically,B. Scaling max,C. Scaling out,D. Scaling up,,,,,,,,,,,,3,"Scaling Max Clusters.   Stephen Okon Increasing the maximum number of clusters in a Multi-Cluster Warehouse is an example of: A. Scaling rhythmically B. Scaling max C. Scaling out D. Scaling up  The correct answer is B. Scaling max.  Scaling max refers to increasing the maximum limit of resources that can be allocated to a system or application. In the context of a Multi-Cluster Warehouse, increasing the maximum number of clusters would require more resources to be allocated to the system in order to accommodate the additional clusters. This is an example of scaling max because it involves increasing the maximum limit of resources that can be allocated to the Multi-Cluster Warehouse.  Scaling rhythmically, on the other hand, refers to increasing or decreasing resources in a gradual and predictable manner based on the workload of the system. Scaling out involves adding more instances of a system or application to distribute the workload across multiple nodes. Scaling up involves increasing the resources of a single node in order to handle a larger workload.
Correct answer : C https://docs.snowflake.com/en/user-guide/warehouses-considerations#scaling-up-vs-scaling-out  Snowflake supports two ways to scale warehouses: 1. Scale up by resizing a warehouse. 2. Scale out by adding clusters to a multi-cluster warehouse (requires Snowflake Enterprise Edition or higher).",
Which statement best describes Snowflake tables?,multiple-choice,A. Snowflake tables are logical representations of underlying physical data,B. Snowflake tables are the physical instantiation of data loaded into Snowflake,C. Snowflake tables require that clustering keys be defined to perform optimally,D. Snowflake tables are owned by a user,,,,,,,,,,,,1,"Was on exam 20/12/2022
https://docs.snowflake.com/en/user-guide/tables-micro-partitions.html",
Which item in the Data Warehouse migration process does not apply in Snowflake?,multiple-choice,A. Migrate Users,B. Migrate Schemas,C. Migrate Indexes,D. Build the Data Pipeline,,,,,,,,,,,,3,"Snowflake does not use indexes. Answer is C
",
Snowflake provides two mechanisms to reduce data storage costs for short-lived tables. These mechanisms are: (Choose two.),multi-select,A. Temporary Tables,B. Transient Tables,C. Provisional Tables,D. Permanent Tables,,,,,,,,,,,,"1, 2","Answer is correct.
https://docs.snowflake.com/en/user-guide/tables-storage-considerations.html",
What is the maximum compressed row size in Snowflake?,multiple-choice,A. 8KB,B. 16MB,C. 50MB,D. 4000GB,,,,,,,,,,,,2,"MAX size for compressed data for semi-structured data type is also 16 MB. That means if our table has a semi-structured data type column with 16MB data other columns will have NULL data.
https://docs.snowflake.com/en/user-guide/data-load-considerations-prepare.html#semi-structured-data-size-limitations 16MB per row captured in the variant field",
Which of the following are main sections of the top navigation of the Snowflake Web Interface (UI)? (Choose three.),multi-select,A. Databases,B. Tables,C. Warehouses,D. Worksheets,,,,,,,,,,,,"1, 3, 4","Answer is correct.
https://docs.snowflake.com/en/user-guide/snowflake-manager.html",
What is the recommended Snowflake data type to store semi-structured data like JSON?,multiple-choice,A. VARCHAR,B. RAW,C. LOB,D. VARIANT,,,,,,,,,,,,4,"Answer D is correct.
https://docs.snowflake.com/en/sql-reference/data-types-semistructured.html",
Which of the following statements are true of Snowflake releases: (Choose two.),multi-select,A. They happen approximately weekly,"B. They roll up and release approximately monthly, but customers can request early release application","C. During a release, new customer requests/queries/connections transparently move over to the newer version",D. A customer is assigned a 30 minute window (that can be moved anytime within a week) during which the system will be unavailable and customer is upgraded,,,,,,,,,,,,"1, 3","The answer looks A& C according to the documents on :- https://docs.snowflake.com/en/user-guide/intro-releases.html ""....Snowflake is committed to providing a seamless, always up-to-date experience for our users while also delivering ever-increasing value through rapid development and continual innovation. To meet this commitment, we deploy new releases each week.""  ""... This topic describes the process we follow for weekly releases, including the option to request 24-hour early access for Enterprise Edition (and higher) accounts to enable additional release testing (if desired).""",
Which of the following are common use cases for zero-copy cloning? (Choose three.),multi-select,A. Quick provisioning of Dev and Test/QA environments,B. Data backups,C. Point in time snapshots,D. Performance optimization,,,,,,,,,,,,"1, 2, 3","ABC is correct
https://community.snowflake.com/s/question/0D50Z00009C3VlMSAV/zero-copy-cloning",
"If a Small Warehouse is made up of 2 servers/cluster, how many servers/cluster make up a Medium Warehouse?",multiple-choice,A. 4,B. 16,C. 32,D. 128,,,,,,,,,,,,1,"Correct answer. With each warehouse size incremental increase everything doubles including cost
https://docs.snowflake.com/en/user-guide/warehouses-overview.html",
"True or False: When a data share is established between a Data Provider and a Data Consumer, the Data Consumer can extend that data share to other Data
Consumers.",multiple-choice,A. True,B. False,,,,,,,,,,,,,,2,"yeah, you can not re-share your share. but in real live, I did it using dbt.
Consumer can't re-shared DB object to another consumer. https://docs.snowflake.com/en/user-guide/data-share-consumers.html",
Which is true of Snowflake network policies? A Snowflake network policy: (Choose two.),multi-select,A. Is available to all Snowflake Editions,B. Is only available to customers with Business Critical Edition,C. Restricts or enables access to specific IP addresses,D. Is activated using an   ALTER DATABASE   command,,,,,,,,,,,,"1, 3","Sample SQL: create or replace network policy mypolicy1 allowed_ip_list=('192.168.1.0/24') blocked_ip_list=('192.168.1.99');
https://docs.snowflake.com/en/sql-reference/sql/create-network-policy.html",
True or False: Snowflake charges additional fees to Data Providers for each Share they create.,multiple-choice,A. True,B. False,,,,,,,,,,,,,,2,"According to the documentation sited:  ""The costs for sharing data with Snowflake are minimal and straightforward. Data providers simply pay Snowflake for the data they store, and data consumers pay for the compute resources their queries consume.""
https://docs.snowflake.com/en/user-guide/data-sharing-intro According to docs, there is no separate cost to provider for creating the Share. Shared data does not take up any storage in a consumer account and therefore does not contribute to the consumer’s monthly data storage charges. The only charges to consumers are for the compute resources (i.e. virtual warehouses) used to query the shared data.  Because no data is copied or exchanged, Secure Data Sharing setup is quick and easy for providers and access to the shared data is near-instantaneous for consumers",
"Query results are stored in the Result Cache for how long after they are last accessed, assuming no data changes have occurred?",multiple-choice,A. 1 Hour,B. 3 Hours,C. 12 hours,D. 24 hours,,,,,,,,,,,,4,"Answer is correct. ""Which holds the results of every query executed in the past 24 hours. These are available across virtual warehouses, so query results returned to one user is available to any other user on the system who executes the same query, provided the underlying data has not changed.""
https://community.snowflake.com/s/article/Caching-in-Snowflake-Data-Warehouse",
A role is created and owns 2 tables. This role is then dropped. Who will now own the two tables?,multiple-choice,A. The tables are now orphaned,B. The user that deleted the role,C. SYSADMIN,D. The assumed role that dropped the role,,,,,,,,,,,,4,"D Ownership of any objects owned by the dropped role is transferred to the role that executes the DROP ROLE command. To transfer ownership of each of these objects to a different role, use GRANT OWNERSHIP … COPY CURRENT GRANTS.
D is the RIGHT ANSWER  https://docs.snowflake.com/en/sql-reference/sql/drop-role#usage-notes  Ownership of any objects owned by the dropped role is transferred to the role that executes the DROP ROLE command. To transfer ownership of each of these objects to a different role, use GRANT OWNERSHIP … COPY CURRENT GRANTS.",
Which of the following connectors are available in the Downloads section of the Snowflake Web Interface (UI)? (Choose two.),multi-select,A. SnowSQL,B. ODBC,C. R,D. HIVE,,,,,,,,,,,,"1, 2","AB, but I think that ODBC is not a connector. It is a driver.
AB - Snow SQL and ODBC https://docs.snowflake.com/en/user-guide/snowflake-client-repository.html",
Which of the following DML commands isn't supported by Snowflake?,multiple-choice,A. UPSERT,B. MERGE,C. UPDATE,D. TRUNCATE TABLE,,,,,,,,,,,,1,"There is nothing called UPSERT in snowflake. MERGE = UPDATE+INSERT+DELETE. Also, unlike other databases TRUNCATE is considered DML in snowflake.
https://docs.snowflake.com/en/sql-reference/sql-dml.html",
Which of the following statements is true of zero-copy cloning?,multiple-choice,A. Zero-copy clones increase storage costs as cloning the table requires storing its data twice,B. All zero-copy clone objects inherit the privileges of their original objects,C. Zero-copy cloning is licensed as an additional Snowflake feature,"D. At the instance/instant a clone is created, all micro-partitions in the original table and the clone are fully shared",,,,,,,,,,,,4,"D is correct, but take into account that if the cloned or the original table make any change to the data, this change does not affect the other table. They are independent objects
From: https://docs.snowflake.com/en/sql-reference/sql/create-clone.html -- If the COPY GRANTS keywords are used, then the new object inherits any explicit access privileges granted on the original table but does not inherit any future grants defined for the object type in the schema.  If the COPY GRANTS keywords are not used, then the new object clone does not inherit any explicit access privileges granted on the original table but does inherit any future grants defined for the object type in the schema (using the GRANT <privileges> … TO ROLE … ON FUTURE syntax). Answer: D",
"True or False: When a user creates a role, they are initially assigned ownership of the role and they maintain ownership until it is transferred to another user.",multiple-choice,A. True,B. False,,,,,,,,,,,,,,1,"The statement is True.

When a user (or more precisely, the role active for that user) creates a new role in Snowflake, that role (the creator) is initially granted ownership (OWNERSHIP) of the newly created role. This ownership allows the creator to manage the new role, including granting it to other users or roles, or transferring its ownership to another role. Ownership of a role, like other securable objects, can be transferred to another role using the GRANT OWNERSHIP ON ROLE command.",
The Query History in the Snowflake Web Interface (UI) is kept for approximately:,multiple-choice,A. 60 minutes,B. 24 hours,C. 14 days,D. 30 days,E. 1 year,,,,,,,,,,,3,"QUERY_HISTORY View This Account Usage view can be used to query Snowflake query history by various dimensions (time range, session, user, warehouse, etc.) within the last 365 days (1 year).  The view is available in both the ACCOUNT_USAGE and READER_ACCOUNT_USAGE schemas with the following differences:
Answer should be C (14 days) As per docs - Query History page available under Activity Menu on Web UI, holds query data for 14 days. And you can Query_history view available in Account_Usage schema holds query data for 365 days  https://docs.snowflake.com/en/user-guide/ui-snowsight-activity#query-history https://docs.snowflake.com/en/sql-reference/account-usage/query_history",
"To run a Multi-Cluster Warehouse in auto-scale mode, a user would:",multiple-choice,A. Configure the Maximum Clusters setting to   Auto-Scale  ,B. Set the Warehouse type to   Auto  ,C. Set the Minimum Clusters and Maximum Clusters settings to the same value,D. Set the Minimum Clusters and Maximum Clusters settings to the different values,,,,,,,,,,,,4,"If you set the minimum cluster count less than the maximum cluster count, then the warehouse runs in Auto-scale mode.
The answer is correct as per  Auto-scale:  This mode is enabled by specifying different values for maximum and minimum number of clusters. In this mode, Snowflake starts and stops clusters as needed to dynamically manage the load on the warehouse:  As the number of concurrent user sessions and/or queries for the warehouse increases, and queries start to queue due to insufficient resources, Snowflake automatically starts additional clusters, up to the maximum number defined for the warehouse.  Similarly, as the load on the warehouse decreases, Snowflake automatically shuts down clusters to reduce the number of running clusters and, correspondingly, the number of credits used by the warehouse. refer: https://docs.snowflake.com/en/user-guide/warehouses-multicluster.html",
Which of the following terms best describes Snowflake's database architecture?,multiple-choice,A. Columnar shared nothing,B. Shared disk,"C. Multi-cluster, shared data",D. Cloud-native shared memory,,,,,,,,,,,,3,"Snowflake’s architecture is a hybrid of traditional shared-disk and shared-nothing database architectures. Similar to shared-disk architectures, Snowflake uses a central data repository for persisted data that is accessible from all compute nodes in the platform. Correct answer is C - The storage is shared however the compute is multi clustered https://www.snowflake.com/product/architecture/
Built from the ground up for the cloud, Snowflake’s unique multi-cluster shared data architecture delivers the performance, scale, elasticity, and concurrency today’s organizations require. https://www.snowflake.com/product/architecture/",
Which of the following are options when creating a Virtual Warehouse? (Choose two.),multi-select,A. Auto-drop,B. Auto-resize,C. Auto-resume,D. Auto-suspend,,,,,,,,,,,,"3, 4","The answer is correct. When creating a warehouse, you could assign auto-suspend time from 5 minutes to never and you could tick the auto-resume function ( it is ticked by default). The function means that if you stock use the warehouse, the warehouse will be suspended by your assigned auto suspended time and auto-resume when you start to query
https://help.pentaho.com/Documentation/9.1/Products/Create_Snowflake_warehouse",
A Virtual Warehouse's auto-suspend and auto-resume settings apply to:,multiple-choice,A. The primary cluster in the Virtual Warehouse,B. The entire Virtual Warehouse,C. The database the Virtual Warehouse resides in,D. The queries currently being run by the Virtual Warehouse,,,,,,,,,,,,2,"The answer CORRECT and those settings are applied on the entire VM
https://docs.snowflake.com/en/user-guide/warehouses-overview.html",
Fail-safe is unavailable on which table types? (Choose two.),multi-select,A. Temporary,B. Transient,C. Provisional,D. Permanent,,,,,,,,,,,,"1, 2","Transient and temporary tables have no Fail-safe period. As a result, no additional data storage charges are incurred beyond the Time Travel retention period.
https://docs.snowflake.com/en/user-guide/tables-temp-transient.html",
Which of the following objects is not covered by Time Travel?,multiple-choice,A. Tables,B. Schemas,C. Databases,D. Stages,,,,,,,,,,,,4,"Answer is correct. Restoring data-related objects (tables, schemas, and databases) that might have been accidentally or intentionally deleted.
https://docs.snowflake.com/en/user-guide/data-time-travel.html",
True or False: Micro-partition metadata enables some operations to be completed without requiring Compute.,multiple-choice,A. True,B. False,,,,,,,,,,,,,,1,"A. like count(*), min or max etc
https://blog.ippon.tech/innovative-snowflake-features-caching/",
Which of the following commands are not blocking operations? (Choose two.),multi-select,A. UPDATE,B. INSERT,C. MERGE,D. COPY,,,,,,,,,,,,"2, 4","BD  The following guidelines apply in most situations:  COMMIT operations (including both AUTOCOMMIT and explicit COMMIT) lock resources, but usually only briefly. UPDATE, DELETE, and MERGE statements hold locks that generally prevent them from running in parallel with other UPDATE, DELETE, and MERGE statements. Most INSERT and COPY statements write only new partitions. Those statements often can run in parallel with other INSERT and COPY operations, and sometimes can run in parallel with an UPDATE, DELETE, or MERGE statement.
Sorry INSERT and COPY. https://docs.snowflake.com/en/sql-reference/transactions.html Transactional operations acquire locks on a resource, such as a table, while that resource is being modified. Locks block other statements from modifying the resource until the lock is released.  The following guidelines apply in most situations:   COMMIT operations (including both AUTOCOMMIT and explicit COMMIT) lock resources, but usually only briefly.   UPDATE, DELETE, and MERGE statements hold locks that generally prevent them from running in parallel with other UPDATE, DELETE, and MERGE statements.   Most INSERT and COPY statements write only new partitions. Those statements often can run in parallel with other INSERT and COPY operations, and sometimes can run in parallel with an UPDATE, DELETE, or MERGE statement.",
Which of the following is true of Snowpipe via REST API? (Choose two.),multi-select,A. You can only use it on Internal Stages,B. All COPY INTO options are available during pipe creation,C. Snowflake automatically manages the compute required to execute the Pipe's COPY INTO commands,D. Snowpipe keeps track of which files it has loaded,,,,,,,,,,,,"3, 4","Snowpipe copy into has certain restrictions.
Answer is C & D.  Not B as:  https://docs.snowflake.com/en/sql-reference/sql/create-pipe.html#usage-notes  All COPY INTO <table> copy options are supported except for the following:  FILES = ( 'file_name1' [ , 'file_name2', ... ] )  ON_ERROR = ABORT_STATEMENT  SIZE_LIMIT = num  PURGE = TRUE | FALSE (i.e. automatic purging while loading)  FORCE = TRUE | FALSE",
"Snowflake recommends, as a minimum, that all users with the following role(s) should be enrolled in Multi-Factor Authentication (MFA):",multiple-choice,"A. SECURITYADMIN, ACCOUNTADMIN, PUBLIC, SYSADMIN","B. SECURITYADMIN, ACCOUNTADMIN, SYSADMIN","C. SECURITYADMIN, ACCOUNTADMIN",D. ACCOUNTADMIN,,,,,,,,,,,,4,"At a minimum, Snowflake strongly recommends that all users with the ACCOUNTADMIN role be required to use MFA.
Answer D is correct: https://docs.snowflake.com/en/user-guide/security-mfa.html",
When can a Virtual Warehouse start running queries?,multiple-choice,A. 12am-5am,B. Only during administrator defined time slots,C. When its provisioning is complete,D. After replication,,,,,,,,,,,,3,"C is correct, virtual warehouses can be configure to auto_resume=true/false, accordingly once it provision it start executing the queries.
https://docs.snowflake.com/en/user-guide/warehouses-overview.html  ""Warehouses can be started and stopped at any time.""",
True or False: Users are able to see the result sets of queries executed by other users that share their same role.,multiple-choice,A. True,B. False,,,,,,,,,,,,,,2,"Answer is B  Viewing Query Results  A user cannot view the result set from a query that another user executed. This behavior is intentional. For security reasons, only the user who executed a query can access the query results.
A user cannot view the result set from a query that another user executed. This behavior is intentional. For security reasons, only the user who executed a query can access the query results. This behavior is not connected to the Snowflake access control model for objects. Even a user with the ACCOUNTADMIN role cannot view the results for a query run by another user.  A user cannot view the result set from a query that another user executed, regardless of their assigned roles or privileges. Only the user who executed a query can access the query results.  https://docs.snowflake.com/en/user-guide/security-access-control-considerations.html#viewing-query-results",
True or False: The user has to specify which cluster a query will run on in a multi-cluster Warehouse.,multiple-choice,A. True,B. False,,,,,,,,,,,,,,2,"False - when select a warehouse you don't determine or have visibility to which cluster
",
True or False: Pipes can be suspended and resumed.,multiple-choice,A. True,B. False,,,,,,,,,,,,,,1,"I lean towards A as there might be a difference between ""suspended"" and ""paused"".
https://docs.snowflake.com/en/user-guide/data-load-snowpipe-intro.html#pausing-or-resuming-pipes Pausing or Resuming Pipes In addition to the pipe owner, a role that has the following minimum permissions can pause or resume the pipe:",
Which of the following languages can be used to implement Snowflake User Defined Functions (UDFs)? (Choose two.),multi-select,A. Java,B. Javascript,C. SQL,D. Python,,,,,,,,,,,,"2, 3","User-defined functions (UDFs) let you extend the system to perform operations that are not available through the built-in, system-defined functions provided by Snowflake. Snowflake currently supports the following languages for writing UDFs:  SQL: A SQL UDF evaluates an arbitrary SQL expression and returns either scalar or tabular results.  JavaScript: A JavaScript UDF lets you use the JavaScript programming language to manipulate data and return either scalar or tabular results.  Java: A Java UDF lets you use the Java programming language to manipulate data and return either scalar or tabular results.
ALL is correct. https://docs.snowflake.com/en/sql-reference/user-defined-functions.html  Snowflake currently supports the following languages for writing UDFs:  Java: A Java UDF lets you use the Java programming language to manipulate data and return either scalar or tabular results.  JavaScript: A JavaScript UDF lets you use the JavaScript programming language to manipulate data and return either scalar or tabular results.  Python: A Python UDF lets you use the Python programming language to manipulate data and return either scalar or tabular results.  SQL: A SQL UDF evaluates an arbitrary SQL expression and returns either scalar or tabular results.",
When should you consider disabling auto-suspend for a Virtual Warehouse? (Choose two.),multi-select,A. When users will be using compute at different times throughout a 24/7 period,B. When managing a steady workload,C. When the compute must be available with no delay or lag time,D. When you do not want to have to manually turn on the Warehouse each time a user needs it,,,,,,,,,,,,"2, 3","From snowflake documentation :  You might want to consider disabling auto-suspend for a warehouse if:  You have a heavy, steady workload for the warehouse.  You require the warehouse to be available with no delay or lag time. Warehouse provisioning is generally very fast (e.g. 1 or 2 seconds); however, depending on the size of the warehouse and the availability of compute resources to provision, it can take longer.
Source: https://docs.snowflake.com/en/user-guide/warehouses-considerations#automating-warehouse-suspension",
Which of the following are valid approaches to loading data into a Snowflake table? (Choose all that apply.),multi-select,A. Bulk copy from an External Stage,B. Continuous load using Snowpipe REST API,C. The Snowflake Web Interface (UI) data loading wizard,D. Bulk copy from an Internal Stage,,,,,,,,,,,,"1, 2, 4","All are valid but the question said ""valid approaches"" so as approach and not as spot operation, i think that the ""The Snowflake Web Interface (UI) data loading wizard"" is not a valid approach. Do you agree with me?
https://docs.snowflake.com/en/user-guide/data-load-overview.html",
"If auto-suspend is enabled for a Virtual Warehouse, the Warehouse is automatically suspended when:",multiple-choice,A. All Snowflakes sessions using the Warehouse are terminated.,B. The last query using the Warehouse completes.,C. There are no users logged into Snowflake.,D. The Warehouse is inactive for a specified period of time.,,,,,,,,,,,,4,Answer is D https://docs.snowflake.com/en/user-guide/warehouses-overview.html#auto-suspension-and-auto-resumption,
True or False: Multi-Factor Authentication (MFA) in Snowflake is only supported in conjunction with Single Sign-On (SSO).,multiple-choice,A. True,B. False,,,,,,,,,,,,,,2,"MFA token caching can be combined with connection caching in federated single sign-on. To combine these two features, ensure that the ALLOW_ID_TOKEN parameter is set to true in tandem with the ALLOW_CLIENT_MFA_CACHING parameter
https://docs.snowflake.com/en/user-guide/admin-security-fed-auth-use.html",
The number of queries that a Virtual Warehouse can concurrently process is determined by (Choose two.):,multi-select,A. The complexity of each query,B. The CONCURRENT_QUERY_LIMIT parameter set on the Snowflake account,C. The size of the data required for each query,D. The tool that is executing the query,,,,,,,,,,,,"1, 3","Answer is correct. The number of queries that a warehouse can concurrently process is determined by the size and complexity of each query. As queries are submitted, the warehouse calculates and reserves the compute resources needed to process each query. If the warehouse does not have enough remaining resources to process a query, the query is queued, pending resources that become available as other running queries complete.
https://docs.snowflake.com/en/user-guide/warehouses-overview.html#query-processing-and-concurrency AC are correct",
Which of the following statements are true of VALIDATION_MODE in Snowflake? (Choose two.),multi-select,A. The VALIDATION_MODE option is used when creating an Internal Stage,B. VALIDATION_MODE=RETURN_ALL_ERRORS is a parameter of the COPY command,C. The VALIDATION_MODE option will validate data to be loaded by the COPY statement while completing the load and will return the rows that could not be loaded without error,D. The VALIDATION_MODE option will validate data to be loaded by the COPY statement without completing the load and will return possible errors,,,,,,,,,,,,"2, 4","VALIDATION_MODE = RETURN_n_ROWS | RETURN_ERRORS | RETURN_ALL_ERRORS  String (constant) that instructs the COPY command to validate the data files instead of loading them into the specified table; i.e. the COPY command tests the files for errors but does not load them.
B and D are correct.  Validating the Data Load  The VALIDATION_MODE copy option instructs a COPY statement to validate the data to be loaded and return results based on the validation option specified. No data is loaded when this copy option is specified. For more information about the copy option, see COPY INTO <table>.  ref: https://docs.snowflake.com/en/user-guide/data-load-bulk-ts",
What privileges are required to create a task?,multiple-choice,A. The GLOBAL privilege CREATE TASK is required to create a new task.,B. Tasks are created at the Application level and can only be created by the Account Admin role.,"C. Many Snowflake DDLs are metadata operations only, and CREATE TASK DDL can be executed without virtual warehouse requirement or task specific grants.",D. The role must have access to the target schema and the CREATE TASK privilege on the schema itself.,,,,,,,,,,,,4,"Only CREATE TASK at the schema level is required, not global.  All tasks in a simple tree must have the same task owner (i.e. a single role must have the OWNERSHIP privilege on all of the tasks in the tree). All tasks in a simple tree must exist in the same schema.
Ans is D  Global Privileges dont have CREATE TASK in it CREATE TASK is present in Schema level privileges only  Doc: https://docs.snowflake.com/en/user-guide/security-access-control-privileges",
What are the three things customer want most from their enterprise data warehouse solution? (Choose three.),multi-select,A. On-premise availability,B. Simplicity,C. Open source based,D. Concurrency,E. Performance,,,,,,,,,,,"2, 4, 5","Snowflake Marketing Slide from their training. Definitely Simplicity, Concurrency and Performance is consistently mentioned.
",
True or False: Some queries can be answered through the metadata cache and do not require an active Virtual Warehouse.,multiple-choice,A. True,B. False,,,,,,,,,,,,,,1,"If there is no change in query then it will fetch from metadata cache I.e from cloud service layer.
https://metriccamp.com/snowflake/caching.html",
"When scaling out by adding clusters to a multi-cluster warehouse, you are primarily scaling for improved:",multiple-choice,A. Concurrency,B. Performance,,,,,,,,,,,,,,1,"Answer: A A. Concurrency is the primary benefit when scaling out by adding clusters to a multi-cluster warehouse.  By adding more clusters, you increase the number of compute resources available, which allows the warehouse to handle more queries and users concurrently. This can help prevent bottlenecks and improve overall query performance, but the primary goal of adding clusters is to increase concurrency.  B. Performance can also improve as a result of scaling out, but it is not the primary benefit. The main focus is on improving concurrency by enabling more users and queries to be processed simultaneously.
https://docs.snowflake.com/en/user-guide/warehouses-multicluster.html",
What is the minimum Snowflake edition that provides data sharing?,multiple-choice,A. Standard,B. Premier,C. Enterprise,D. Business Critical Edition,,,,,,,,,,,,1,"Data sharing is possible in the Standard Edition also.  VPS (Virtual Private Snowflake) does not support Secure Data Sharing due to the current limitations against sharing data across regions.  Standard and Enterprise Editions support Secure Data Sharing with the usual caveats.
https://docs.snowflake.com/en/user-guide/intro-editions.html#data-sharing",
"True or False: Each worksheet in the Snowflake Web Interface (UI) can be associated with different roles, databases, schemas, and Virtual Warehouses.",multiple-choice,A. True,B. False,,,,,,,,,,,,,,1,"these tests are very confusing. I guess it is false because the question means that the worksheets are not bound to a certain role, user...etc.. can change without losing the work done.  https://docs.snowflake.com/en/user-guide/ui-worksheet.html Dropdown menu:  Change the current database, schema, or warehouse for the current worksheet without losing your work.  Resume/suspend or resize your current warehouse.",
True or False: You can query the files in an External Stage directly without having to load the data into a table.,multiple-choice,A. True,B. False,,,,,,,,,,,,,,1,"Snowflake supports using standard SQL to query data files located in an internal (i.e. Snowflake) stage or named external (Amazon S3, Google Cloud Storage, or Microsoft Azure) stage. This can be useful for inspecting/viewing the contents of the staged files, particularly before loading or after unloading data.
https://docs.snowflake.com/en/user-guide/tables-external-intro.html",
The FLATTEN function is used to query which type of data in Snowflake?,multiple-choice,A. Structured data,B. Semi-structured data,C. Both of the above,D. None of the above,,,,,,,,,,,,2,"Correct answer  FLATTEN is used to unnest semi-structured data. Don't see an application for structured data as by definition it shouldn't be nested.
https://docs.snowflake.com/en/user-guide/querying-semistructured.html",
True or False: An active warehouse is required to run a COPY INTO statement.,multiple-choice,A. True,B. False,,,,,,,,,,,,,,2,"Should be false B: False. A COPY INTO statement in Snowflake does not require an active warehouse to run. The statement is used to load data into a Snowflake table from a file stored in a cloud-based object storage such as Amazon S3, Microsoft Azure Blob Storage, or Google Cloud Storage. An active warehouse is only required to perform computationally-intensive tasks such as data processing, querying, and data transformation.
https://docs.snowflake.com/en/user-guide/getting-started-tutorial-copy-into",
True or False: AWS Private Link provides a secure connection from the Customer's on-premise data center to the Snowflake.,multiple-choice,A. True,B. False,,,,,,,,,,,,,,2,"In addition, if you have an on-premises environment (e.g. a non-hosted data center), you can choose to use AWS Direct Connect, in conjunction with AWS PrivateLink, to connect all your virtual and physical environments in a single, private network.  therefore AWS private link alone wont work. Answer:False
https://docs.snowflake.com/en/user-guide/admin-security-privatelink.html  AWS PrivateLinkis an AWS service for creating private VPC endpoints that allow direct, secure connectivity between your AWS VPCs and the Snowflake VPC without traversing the public Internet. The connectivity is for AWS VPCs in the same AWS region.",
True or False: Snowflake's Global Services Layer gathers and maintains statistics on all columns in all micro-partitions.,multiple-choice,A. True,B. False,,,,,,,,,,,,,,1,"Snowflake is a single, integrated platform delivered as-a-service. It features storage, compute, and global services layers that are physically separated but logically integrated. Data workloads scale independently from one another, making it an ideal platform for data warehousing, data lakes, data engineering, data science, modern data sharing, and developing data applications. https://www.snowflake.com/product/architecture/",
True or False: It is best practice to define a clustering key on every table.,multiple-choice,A. True,B. False,,,,,,,,,,,,,,2,"Answer: B It is not always best practice in Snowflake to define a clustering key on every table. Clustering keys are used to group related rows physically together in a table, which can improve query performance by minimizing the amount of data that needs to be scanned or skipped during query execution. However, clustering keys should be chosen carefully based on the access patterns of the table, and the type of queries that will be run against it.  Defining a clustering key on every table may not always be necessary or beneficial. For example, in some cases, tables may be small or may not have well-defined access patterns, making clustering unnecessary. In other cases, tables may be loaded in a specific order or partitioned in a certain way that obviates the need for clustering.  Therefore, it is not a best practice to define a clustering key on every table in Snowflake, but rather to carefully consider the access patterns and usage of each table, and to choose clustering keys judiciously based on those factors.
https://dwgeek.com/how-to-create-snowflake-clustered-tables-examples.html/",
Which of the following statements is true of Snowflake?,multiple-choice,A. It was built specifically for the cloud,B. It was built as an on-premises solution and then ported to the cloud,C. It was designed as a hybrid database to allow customers to store data either on premises or in the cloud,D. It was built for Hadoop architecture,E. It's based on an Oracle Architecture,,,,,,,,,,,1,"Correct answer
https://www.stitchdata.com/resources/snowflake/",
What is the minimum Snowflake edition that provides multi-cluster warehouses and up to 90 days of Time Travel?,multiple-choice,A. Standard,B. Premier,C. Enterprise,D. Business Critical Edition,,,,,,,,,,,,3,"The answer is correct as B is not under the snowflake options; and extended time travel up to 90 days is available for Enterprise, Business Critical and VPS
https://docs.snowflake.com/en/user-guide/intro-editions.html",
How many shares can be consumed by a single Data Consumer?,multiple-choice,A. 1,B. 10,"C. 100, but can be increased by contacting support",D. Unlimited,,,,,,,,,,,,4,"Answer is correct.
https://docs.snowflake.com/en/user-guide/data-sharing-intro.html",
What is the lowest Snowflake edition that offers Time Travel up to 90 days?,multiple-choice,A. Standard Edition,B. Premier Edition,C. Enterprise Edition,D. Business Critical Edition,,,,,,,,,,,,3,"Only Standard has 1 day
https://docs.snowflake.com/en/user-guide/data-availability.html",
Which of the following statements are true about Schemas in Snowflake? (Choose two.),multi-select,A. A Schema may contain one or more Databases,B. A Database may contain one or more Schemas,C. A Schema is a logical grouping of Database Objects,D. Each Schema is contained within a Warehouse,,,,,,,,,,,,"2, 3","BC is correct . Warehouse is compute, it doesn't contain schema within
https://docs.snowflake.com/en/user-guide/data-sharing-mutiple-db.html",
True or False: You can resize a Virtual Warehouse while queries are running.,multiple-choice,A. True,B. False,,,,,,,,,,,,,,1,"False. You cannot resize a Virtual Warehouse in Snowflake while queries are running. You must first pause or terminate any running queries before resizing the Virtual Warehouse.
https://docs.snowflake.com/en/user-guide/warehouses-tasks.html",
What is the most granular object that the Time Travel retention period can be defined on?,multiple-choice,A. Account,B. Database,C. Schema,D. Table,,,,,,,,,,,,4,"To specify the data retention period for Time Travel:  The DATA_RETENTION_TIME_IN_DAYS object parameter can be used by users with the ACCOUNTADMIN role to set the default retention period for your account.  The same parameter can be used to explicitly override the default when creating a database, schema, and individual table.  The data retention period for a database, schema, or table can be changed at any time.
https://docs.snowflake.com/en/user-guide/data-time-travel.html#data-retention-period",
Which of the following statements is true of Snowflake micro-partitioning?,multiple-choice,A. Micro-partitioning has been known to introduce data skew,B. Micro-partitioning: requires a partitioning schema to be defined up front,C. Micro-partitioning is transparently completed using the ordering that occurs when the data is inserted/loaded,D. Micro-partitioning can be disabled within a Snowflake account,,,,,,,,,,,,3,"Option C is correct
https://docs.snowflake.com/en/user-guide/tables-clustering-micropartitions.html",
True or False: Snowflake bills for a minimum of five minutes each time a Virtual Warehouse is started.,multiple-choice,A. True,B. False,,,,,,,,,,,,,,2,"Because Snowflake utilizes per-second billing (with a 60-second minimum each time the warehouse starts), warehouses are billed only for the credits they actually consume when they are actively working.
https://docs.snowflake.com/en/user-guide/credits.html",
"When scaling up Virtual Warehouses by increasing Virtual Warehouse t-shirt size, you are primarily scaling for improved:",multiple-choice,A. Concurrency,B. Performance,,,,,,,,,,,,,,2,"Scaling up for performance and scaling out for concurrency
https://docs.snowflake.com/en/user-guide/warehouses-considerations.html#warehouse-resizing-improves-performance",
"As a best practice, clustering keys should only be defined on tables of which minimum size?",multiple-choice,A. Multi-Kilobyte (KB) Range,B. Multi-Megabyte (MB) Range,C. Multi-Gigabyte (GB) Range,D. Multi-Terabyte (TB) Range,,,,,,,,,,,,4,"D is correct Considerations for Choosing Clustering for a Table Whether you want faster response times or lower overall costs, clustering is best for a table that meets all of the following criteria:  The table contains a large number of micro-partitions. Typically, this means that the table contains multiple terabytes (TB) of data.
https://docs.snowflake.com/en/user-guide/tables-clustering-keys.html",
How a Snowpipe charges calculated?,multiple-choice,A. Per-second/per Warehouse size,B. Per-second/per-core granularity,C. Number of Pipes in account,D. Total storage bucket size,,,,,,,,,,,,2,"Correct answer  ""Snowflake tracks the resource consumption of loads for all pipes in an account, with per-second/per-core granularity, as Snowpipe actively queues and processes data files. Per-core refers to the physical CPU cores in a compute server. The utilization recorded is then translated into familiar Snowflake credits, which are listed on the bill for your account.""
https://docs.snowflake.com/en/user-guide/data-load-snowpipe-billing.html",
True or False: A Snowflake account is charged for data stored in both Internal and External Stages.,multiple-choice,A. True,B. False,,,,,,,,,,,,,,2,"False. There are no storage charges for external stages billed through Snowflake. We need to pay the external vendor directly and not to the snowflake.
https://docs.snowflake.com/en/user-guide/tables-external-intro.html#billing-for-external-tables For external, there are some overheads that will be billed",
"True or False: When active, a Pipe requires a dedicated Virtual Warehouse to execute.",multiple-choice,A. True,B. False,,,,,,,,,,,,,,1,"Correct Answer  Bulk-loading: Requires virtual warehouse to use COPY INTO command.   Snowpipe (continuous loading): Uses Snowflake-supplied compute resources and charges based on how much of that is used.
",
True or False: Snowflake supports federated authentication in all editions.,multiple-choice,A. True,B. False,,,,,,,,,,,,,,1,"Support for user SSO (single sign-on) through federated authentication - All Edition
Get the answer by searching federated authentication from https://docs.snowflake.com/en/user-guide/admin-security.html",
"True or False: When a new Snowflake object is created, it is automatically owned by the user who created it.",multiple-choice,A. True,B. False,,,,,,,,,,,,,,2,"To own an object means that a role has the OWNERSHIP privilege on the object. Each securable object is owned by a single role, which by default is the role used to create the object. When this role is assigned to users, they effectively have shared control over the object. In a regular schema, the owner role has all privileges on the object by default, including the ability to grant or revoke privileges on the object to other roles. In addition, ownership can be transferred from one role to another  https://docs.snowflake.com/en/user-guide/security-access-control-overview#securable-objects",
True or False: A Virtual Warehouse consumes Snowflake credits even when inactive.,multiple-choice,A. True,B. False,,,,,,,,,,,,,,2,"Correct Answer B  Warehouses are only billed for credit usage while running. When a warehouse is suspended, it does not use any credits.
https://docs.snowflake.com/en/user-guide/warehouses-multicluster.html",
"True or False: During data unloading, only JSON and CSV files can be compressed.",multiple-choice,A. True,B. False,,,,,,,,,,,,,,2,"Unloading supports structured formatting CSV format and unstructured JSON and Parquet formats only. Hence FALSE is correct answer.
During data loading, compression can be enabled for CSV, JSON PARQUET, AVRO, XML type files. ref: https://docs.snowflake.com/en/sql-reference/sql/create-file-format",
Which formats are supported for unloading data from Snowflake? (Choose two.),multi-select,"A. Delimited (CSV, TSV, etc.)",B. Avro,C. JSON,D. ORC,,,,,,,,,,,,"1, 3","The answer is correct as snow supported structured data file format as type of delimited such as CSV etc and etc while semi-structured type of Json and parquet
AC is correct. https://docs.snowflake.com/en/user-guide/intro-summary-unloading.html -- Output data file details table",
True or False: Data Providers can share data with only the Data Consumer.,multiple-choice,A. True,B. False,,,,,,,,,,,,,,2,"False. In Snowflake, data sharing is not limited to sharing data with only a single data consumer. Snowflake allows data providers to share data with multiple data consumers or even make data publicly accessible, depending on the configured sharing settings.  With Snowflake's secure data sharing capabilities, data providers can share specific datasets or entire databases with one or more data consumers. Data consumers can be given read-only access to the shared data, allowing them to query and analyze the data without being able to modify or change it. This flexible data sharing model enables collaboration and data exchange between different organizations or teams within an organization.  Furthermore, Snowflake also provides granular access controls and permissions, allowing data providers to define who can access their shared data and what level of access each data consumer has. This ensures data privacy and security while enabling effective data sharing and collaboration.
https://www.kpipartners.com/blog/data-sharing-in-snowflake",
The fail-safe retention period is how many days?,multiple-choice,A. 1 day,B. 7 days,C. 45 days,D. 90 days,,,,,,,,,,,,2,"B is correct, Failsafe is for 7 days
https://docs.snowflake.com/en/user-guide/data-failsafe.html",
"True or False: Once created, a micro-partition will never be changed.",multiple-choice,A. True,B. False,,,,,,,,,,,,,,1,"The immutability of micro partition it means that there could be changes in relation to the status of the data in micro partition, so it could be updated or deleted but this is kept as information. But the data itself cannot be changed.Even if update with the clustering key it will add new micropartitions with the changes
https://interworks.com/blog/kbridges/2019/03/12/time-travel-with-snowflake/",
What services does Snowflake automatically provide for customers that they may have been responsible for with their on-premise system? (Choose all that apply.),multi-select,A. Installing and configuring hardware,B. Patching software,C. Physical security,D. Maintaining metadata and statistics,,,,,,,,,,,,"2, 4","B. Patching software D. Maintaining metadata and statistics  Snowflake is a cloud-based data warehousing platform that eliminates the need for customers to manage hardware infrastructure, physical security, and related tasks. These responsibilities are handled by Snowflake's cloud infrastructure provider, and Snowflake also automatically manages the patching of software and maintenance of metadata and statistics for its customers. Option A (Installing and configuring hardware) and Option C (Physical security) are not provided by Snowflake since they are handled by the cloud infrastructure provider.
B and D are the correct options https://docs.snowflake.com/en/user-guide/intro-key-concepts#:~:text=There%20is%20no,handled%20by%20Snowflake.",
Which of the following statements would be used to export/unload data from Snowflake?,multiple-choice,A. COPY INTO @stage,B. EXPORT TO @stage,C. INSERT INTO @stage,"D. EXPORT_TO_STAGE(stage => @stage, select => 'select * from t1');",,,,,,,,,,,,1,"Correct answer
https://docs.snowflake.com/en/user-guide/data-unload-considerations.html",
"True or False: A 4X-Large Warehouse may, at times, take longer to provision than a X-Small Warehouse.",multiple-choice,A. True,B. False,,,,,,,,,,,,,,1,"You require the warehouse to be available with no delay or lag time. Warehouse provisioning is generally very fast (e.g. 1 or 2 seconds); however, depending on the size of the warehouse and the availability of compute resources to provision, it can take longer.
False   Provisioning the larger warehouse sizes 5X-Large and 6X-Large may take slightly longer while in preview.  https://docs.snowflake.com/en/user-guide/warehouses-overview.html",
How would you determine the size of the virtual warehouse used for a task?,multiple-choice,"A. Root task may be executed concurrently (i.e. multiple instances), it is recommended to leave some margins in the execution window to avoid missing instances of execution","B. Querying (SELECT) the size of the stream content would help determine the warehouse size. For example, if querying large stream content, use a larger warehouse size","C. If using the stored procedure to execute multiple SQL statements, it's best to test run the stored procedure separately to size the compute resource first","D. Since task infrastructure is based on running the task body on schedule, it's recommended to configure the virtual warehouse for automatic concurrency handling using Multi-cluster warehouse (MCW) to match the task schedule",,,,,,,,,,,,3,"C is the right answer as D talks about concurrency.
""Multi-cluster warehouses are best utilized for scaling resources to improve concurrency for users/queries. They are not as beneficial for improving the performance of slow-running queries or data loading. For these types of operations, resizing the warehouse provides more benefits.""  Snowflake representative explained this here https://community.snowflake.com/s/question/0D50Z00009F8nPTSAZ/how-to-choose-the-right-virtual-warehouse-size-in-snowflake-for-your-workload",
The Information Schema and Account Usage Share provide storage information for which of the following objects? (Choose three.),multi-select,A. Users,B. Tables,C. Databases,D. Internal Stages,,,,,,,,,,,,"2, 3, 4","select * from snowflake.information_schema.views where table_name like '%STORAGE%'  and table_schema in ('ACCOUNT_USAGE','INFORMATION_SCHEMA');  TABLE_CATALOG TABLE_SCHEMA TABLE_NAME SNOWFLAKE ACCOUNT_USAGE DATABASE_STORAGE_USAGE_HISTORY SNOWFLAKE ACCOUNT_USAGE STAGE_STORAGE_USAGE_HISTORY SNOWFLAKE ACCOUNT_USAGE STORAGE_USAGE SNOWFLAKE ACCOUNT_USAGE TABLE_STORAGE_METRICS SNOWFLAKE INFORMATION_SCHEMA TABLE_STORAGE_METRICS
We can get User info too. The Account Usage view can be used to query a list of all users in the account. The data is retained for 365 days (1 year).  https://docs.snowflake.com/en/sql-reference/account-usage/users.html",
What is the default File Format used in the COPY command if one is not specified?,multiple-choice,A. CSV,B. JSON,C. Parquet,D. XML,,,,,,,,,,,,1,"A is the correct answer
https://docs.snowflake.com/en/sql-reference/sql/copy-into-location.html",
True or False: Reader Accounts are able to extract data from shared data objects for use outside of Snowflake.,multiple-choice,A. True,B. False,,,,,,,,,,,,,,1,"Answer - A In few business scenarios where the data can be shared to non-Snowflake customer by using reader accounts feature. Reader accounts provide a quick, easy, and cost-effective way to share data without requiring the consumer to become a Snowflake customer.
https://docs.snowflake.com/en/user-guide/data-sharing-reader-create#what-is-restricted-allowed-in-a-reader-account True Unloading data using a storage integration. However, you can use the COPY INTO <location> command with your connection credentials to unload data into a cloud storage location.",
True or False: You can define multiple columns within a clustering key on a table.,multiple-choice,A. True,B. False,,,,,,,,,,,,,,1,"https://docs.snowflake.com/en/user-guide/tables-clustering-keys.html#strategies-for-selecting-clustering-keys. ""A single clustering key can contain one or more columns or expressions.""",
"True or False: Snowflake enforces unique, primary key, and foreign key constraints during DML operations.",multiple-choice,A. True,B. False,,,,,,,,,,,,,,2,"Snowflake supports defining and maintaining constraints, but does not enforce them, except for NOT NULL constraints, which are always enforced.
Only NOT NULL is enforced. https://docs.snowflake.com/en/sql-reference/constraints.html",
True or False: Loading data into Snowflake requires that source data files be no larger than 16MB.,multiple-choice,A. True,B. False,,,,,,,,,,,,,,2,"By default, COPY INTO location statements separate table data into a set of output files to take advantage of parallel operations. The maximum size for each file is set using the MAX_FILE_SIZE copy option. The default value is 16777216 (16 MB) but can be increased to accommodate larger files. The maximum file size supported is 5 GB for Amazon S3, Google Cloud Storage, or Microsoft Azure stages.  To unload data to a single output file (at the potential cost of decreased performance), specify the SINGLE = true copy option in your statement. You can optionally specify a name for the file in the path.
https://docs.snowflake.com/en/user-guide/data-load-considerations-prepare.html",
True or False: A Virtual Warehouse can be resized while suspended.,multiple-choice,A. True,B. False,,,,,,,,,,,,,,1,"Yes, it can be resized both when it is suspended or active (even when queries are running).
https://docs.snowflake.com/en/user-guide/warehouses-tasks.html#effects-of-resizing-a-suspended-warehouse",
"True or False: When you create a custom role, it is a best practice to immediately grant that role to ACCOUNTADMIN.",multiple-choice,A. True,B. False,,,,,,,,,,,,,,2,"By default, not even the ACCOUNTADMIN role can modify or drop objects created by a custom role. The custom role must be granted to the ACCOUNTADMIN role directly or, preferably, to another role in a hierarchy with the SYSADMIN role as the parent. The SYSADMIN role is managed by the ACCOUNTADMIN role. https://docs.snowflake.com/en/user-guide/security-access-control-considerations#managing-custom-roles  Even it is mentioned preferably SYSADMIN, the idea is to grant custom role to ACCOUNTADMIN.",
Which of the following accurately represents how a table fits into Snowflake's logical container hierarchy?,multiple-choice,A. Account -> Schema -> Database -> Table,B. Account -> Database -> Schema -> Table,C. Database -> Schema -> Table -> Account,D. Database -> Table -> Schema -> Account,,,,,,,,,,,,2,"Account -> Database -> Schema -> Table
https://docs.snowflake.com/en/sql-reference/ddl-database.html",
True or False: All Snowflake table types include fail-safe storage.,multiple-choice,A. True,B. False,,,,,,,,,,,,,,2,"Correct answer  Temporary tables do not have fail-safe functionality
",
What are two ways to create and manage Data Shares in Snowflake? (Choose two.),multi-select,A. Via the Snowflake Web Interface (UI),B. Via the DATA_SHARE=TRUE parameter,C. Via SQL commands,D. Via Virtual Warehouses,,,,,,,,,,,,"1, 3","Yes, A & C is the correct answer.
https://docs.snowflake.com/en/user-guide/data-sharing-provider.html",
True or False: Fail-safe can be disabled within a Snowflake account.,multiple-choice,A. True,B. False,,,,,,,,,,,,,,2,"B is correct answer, as fail-safe is non configurable, however, we can say indirectly yes because transient database/schema and tables are not having fail-safe option.
https://docs.snowflake.com/en/user-guide/data-failsafe.html",
True or False: It is possible for a user to run a query against the query result cache without requiring an active Warehouse.,multiple-choice,A. True,B. False,,,,,,,,,,,,,,1,"I upvoted this because it intuitively makes sense. But then I tested it in Snowflake and I was able to retrieve a result from the result cache using a SELECT while using a suspended warehouse (without auto resume). So A is indeed the correct answer.
Answer: A.  This question was answered in Snowflake community forums here  https://community.snowflake.com/s/question/0D50Z000088fREuSAM/does-the-query-results-cache-stays-in-cache-after-the-warehouse-is-suspended",
"True or False: When Snowflake is configured to use Single Sign-On (SSO), Snowflake receives the usernames and credentials from the SSO service and loads them into the customer's Snowflake account.",multiple-choice,A. True,B. False,,,,,,,,,,,,,,1,Yes it does.  Supported SSO Workflows Federated authentication enables the following SSO workflows:  Logging into Snowflake. Logging out of Snowflake. System timeout due to inactivity.  The behavior for each workflow is determined by whether the action is initiated within Snowflake or your IdP.  https://docs.snowflake.com/en/user-guide/admin-security-fed-auth-overview.html#supported-sso-workflows,
Which of the following are best practices for loading data into Snowflake? (Choose three.),multi-select,"A. Aim to produce data files that are between 100 MB and 250 MB in size, compressed.","B. Load data from files in a cloud storage service in a different region or cloud platform from the service or region containing the Snowflake account, to save on cost.",C. Enclose fields that contain delimiter characters in single or double quotes.,D. Split large files into a greater number of smaller files to distribute the load among the compute resources in an active warehouse.,"E. When planning which warehouse(s) to use for data loading, start with the largest warehouse possible.","F. Partition the staged data into large folders with random paths, allowing Snowflake to determine the best way to load each file.",,,,,,,,,,"1, 3, 4","A, C, D  https://docs.snowflake.com/en/user-guide/data-load-considerations.html  A. To optimize the number of parallel operations for a load, we recommend aiming to produce data files roughly 100-250 MB (or larger) in size compressed.  C. Fields that contain delimiter characters should be enclosed in quotes (single or double). If the data contains single or double quotes, then those quotes must be escaped.  D. Split larger files into a greater number of smaller files to distribute the load among the compute resources in an active warehouse.",
Which Snowflake feature is used for both querying and restoring data?,multiple-choice,A. Cluster keys,B. Time Travel,C. Fail-safe,D. Cloning,,,,,,,,,,,,2,"Querying, cloning, and restoring historical data in tables, schemas, and databases for up to 90 days through Snowflake Time Travel.
B  https://community.snowflake.com/s/article/How-to-query-time-travel-with-a-time-different-than-the-default-UTC",
What do the terms scale up and scale out refer to in Snowflake? (Choose two.),multi-select,A. Scaling out adds clusters of the same size to a virtual warehouse to handle more concurrent queries.,B. Scaling out adds clusters of varying sizes to a virtual warehouse.,C. Scaling out adds additional database servers to an existing running cluster to handle more concurrent queries.,D. Snowflake recommends using both scaling up and scaling out to handle more concurrent queries.,E. Scaling up resizes a virtual warehouse so it can handle more complex workloads.,F. Scaling up adds additional database servers to an existing running cluster to handle larger workloads.,,,,,,,,,,"1, 5","right ans very basic and important topic.
",
What is the minimum Snowflake edition that has column-level security enabled?,multiple-choice,A. Standard,B. Enterprise,C. Business Critical,D. Virtual Private Snowflake,,,,,,,,,,,,2,https://docs.snowflake.com/en/user-guide/security-column.html#:~:text=This%20feature%20requires%20Enterprise%20Edition%20(or%20higher).,
What parameter controls if the Virtual Warehouse starts immediately after the CREATE WAREHOUSE statement?,multiple-choice,A. INITIALLY_SUSPENDED = TRUE/FALSE,B. START_AFTER_CREATE = TRUE/FALSE,C. START_THE = 60 // (seconds from now),D. START_TIME = CURRENT_DATE(),,,,,,,,,,,,1,"Answer is correct: -  Syntax CREATE [ OR REPLACE ] WAREHOUSE [ IF NOT EXISTS ] <name>  [ [ WITH ] objectProperties ]  [ objectParams ] Where:  objectProperties ::=  WAREHOUSE_SIZE = XSMALL | SMALL | MEDIUM | LARGE | XLARGE | XXLARGE | XXXLARGE | X4LARGE | X5LARGE | X6LARGE  MAX_CLUSTER_COUNT = <num>  MIN_CLUSTER_COUNT = <num>  SCALING_POLICY = STANDARD | ECONOMY  AUTO_SUSPEND = <num> | NULL  AUTO_RESUME = TRUE | FALSE  INITIALLY_SUSPENDED = TRUE | FALSE  RESOURCE_MONITOR = <monitor_name>  COMMENT = '<string_literal>'  ENABLE_QUERY_ACCELERATION = TRUE | FALSE  QUERY_ACCELERATION_MAX_SCALE_FACTOR = <num>
",
"When cloning a database, what is cloned with the database? (Choose two.)",multi-select,A. Privileges on the database,B. Existing child objects within the database,C. Future child objects within the database,D. Privileges on the schemas within the database,E. Only schemas and tables within the database,,,,,,,,,,,"2, 4","B, D  For D: If the source object is a database or schema, for child objects contained in the source, the clone replicates all granted privileges on the corresponding child objects  https://docs.snowflake.com/en/user-guide/object-clone.html#access-control-privileges-for-cloned-objects",
Which of the following describes the Snowflake Cloud Services layer?,multiple-choice,A. Coordinates activities in the Snowflake account,B. Executes queries submitted by the Snowflake account users,C. Manages quotas on the Snowflake account storage,D. Manages the virtual warehouse cache to speed up queries,,,,,,,,,,,,1,"A. Coordinates activities in the Snowflake account - CLOUD SERVICE LAYER
 B. Executes queries submitted by the Snowflake account users - COMPUTE LAYER 
 C. Manages quotas on the Snowflake account storage - STORAGE LAYER 
 D. Manages the virtual warehouse cache to speed up queries - COMPUTE LAYER
",
What is the maximum total Continuous Data Protection (CDP) charges incurred for a temporary table?,multiple-choice,A. 30 days,B. 7 days,C. 48 hours,D. 24 hours,,,,,,,,,,,,4,"Thus, the maximum total CDP charges incurred for a temporary table are 1 day (or less if the table is explicitly dropped or dropped as a result of terminating the session). During this period, Time Travel can be performed on the table. https://docs.snowflake.com/en/user-guide/tables-storage-considerations.html",
"When reviewing a query profile, what is a symptom that a query is too large to fit into the memory?",multiple-choice,A. A single join node uses more than 50% of the query time,B. Partitions scanned is equal to partitions total,C. An AggregateOperator node is present,D. The query is spilling to remote storage,,,,,,,,,,,,4,"I agree with Answer D, if query spilling happens , query processing engine start saving the data to local disk if this is not sufficient then it start saving the data to remote disk, this process significantly impact query performance, the solution is use larger size warehouse.
For some operations (e.g. duplicate elimination for a huge data set), the amount of memory available for the compute resources used to execute the operation might not be sufficient to hold intermediate results. As a result, the query processing engine will start *spilling* the data to local disk. If the local disk space is not sufficient, the spilled data is then saved to remote disks. https://docs.snowflake.com/en/user-guide/ui-query-profile.html#queries-too-large-to-fit-in-memory",
What type of query benefits the MOST from search optimization?,multiple-choice,"A. A query that uses only disjunction (i.e., OR) predicates",B. A query that includes analytical expressions,C. A query that uses equality predicates or predicates that use IN,D. A query that filters on semi-structured data types,,,,,,,,,,,,3,The correct answer is C. 2: Below are the recommended checks to consider for the query:  At least one of the columns accessed through the query filter operation has at least 100k-200k distinct values.  The query uses equality predicate or predicates that use IN. The query returns a few rows with highly selective filters. The query typically runs for at least tens of seconds. https://community.snowflake.com/s/article/Search-Optimization-When-How-To-Use,
What transformations are supported in a CREATE PIPE ... AS COPY `¦ FROM (`¦) statement? (Choose two.),multi-select,A. Data can be filtered by an optional WHERE clause.,B. Incoming data can be joined with other tables.,C. Columns can be reordered.,D. Columns can be omitted.,E. Row level access can be defined.,,,,,,,,,,,"3, 4","Using a query as the source for the COPY statement for column reordering [C], column omission [D], and casts (i.e. transforming data during a load) is supported. For usage examples, see Transforming Data During a Load. Note that only simple SELECT statements are supported. Filtering using a WHERE clause is not supported [E].
CD is correct  https://docs.snowflake.com/en/sql-reference/sql/create-pipe.html",
Which of the following are characteristics of Snowflake virtual warehouses? (Choose two.),multi-select,A. Auto-resume applies only to the last warehouse that was started in a multi-cluster warehouse.,B. The ability to auto-suspend a warehouse is only available in the Enterprise edition or above.,C. SnowSQL supports both a configuration file and a command line option for specifying a default warehouse.,D. A user cannot specify a default warehouse when using the ODBC driver.,E. The default virtual warehouse size can be changed at any time.,,,,,,,,,,,"3,5","CE are correct. 
",
"Which command should be used to load data from a file, located in an external stage, into a table in Snowflake?",multiple-choice,A. INSERT,B. PUT,C. GET,D. COPY,,,,,,,,,,,,4,"D - COPY INTO exactly
GET does not support downloading files from external stages https://docs.snowflake.com/en/sql-reference/sql/get.html So the answer is COPY",
The Snowflake Cloud Data Platform is described as having which of the following architectures?,multiple-choice,A. Shared-disk,B. Shared-nothing,C. Multi-cluster shared data,D. Serverless query engine,,,,,,,,,,,,3,"Snowflake’s architecture is a hybrid of traditional shared-disk and shared-nothing database architectures. Similar to shared-disk architectures, Snowflake uses a central data repository for persisted data that is accessible from all compute nodes in the platform.
Correct answer is C - The storage is shared however the compute is multi clustered https://www.snowflake.com/product/architecture/",
Which of the following is a data tokenization integration partner?,multiple-choice,A. Protegrity,B. Tableau,C. DBeaver,D. SAP,,,,,,,,,,,,1,"The following partners facilitate external tokenization in Snowflake. To use these partner integrations, follow the instructions in the partner documentation or contact the partner to begin the configuration process:  ALTR  Baffle  Fortanix  MicroFocus CyberRes Voltage  Protegrity  Privacera  SecuPI  Skyflow
ALTR  Baffle  Comforte  Fortanix  MicroFocus CyberRes Voltage  Protegrity  Privacera  SecuPI  Skyflow  Spring Labs  https://docs.snowflake.com/en/user-guide/security-column-ext-token-use",
What versions of Snowflake should be used to manage compliance with Personal Identifiable Information (PII) requirements? (Choose two.),multi-select,A. Custom Edition,B. Virtual Private Snowflake,C. Business Critical Edition,D. Standard Edition,E. Enterprise Edition,,,,,,,,,,,"2, 3",https://docs.snowflake.com/en/user-guide/governance-classify-concepts.html This feature requires Enterprise Edition or higher. There is no Virtual Private Snowflake,
Which COPY INTO command outputs the data into one file?,multiple-choice,A. SINGLE=TRUE,B. MAX_FILE_NUMBER=1,C. FILE_NUMBER=1,D. MULTIPLE=FALSE,,,,,,,,,,,,1,"A. SINGLE=TRUE
https://docs.snowflake.com/en/sql-reference/sql/copy-into-location.html",
In which scenarios would a user have to pay Cloud Services costs? (Choose two.),multi-select,A. Compute Credits = 50 Credits Cloud Services = 10,B. Compute Credits = 80 Credits Cloud Services = 5,C. Compute Credits = 100 Credits Cloud Services = 9,D. Compute Credits = 120 Credits Cloud Services = 10,E. Compute Credits = 200 Credits Cloud Services = 26,,,,,,,,,,,"1, 5","AE. Cloud service cost is charged to User only when Cloud service cost exceeds compute cost by more than 10%.  A: 10/50 = 20% (exceed 10%) B: 5/80 = 6.25% (less than 10%) C: 9/100 = 9% (less than 10%) D: 10/120 = 8.33% (less than 10%) E: 26/200 = 13% (more than 10%).
Usage for cloud services is charged only if the daily consumption of cloud services exceeds 10% of the daily usage of virtual warehouses. The charge is calculated daily (in the UTC time zone). This ensures that the 10% adjustment is accurately applied each day, at the credit price for that day.  https://docs.snowflake.com/en/user-guide/cost-understanding-compute#cloud-service-credit-usage",
"A user created a new worksheet within the Snowsight UI and wants to share this with teammates.

How can this worksheet be shared?",multiple-choice,A. Create a zero-copy clone of the worksheet and grant permissions to teammates.,B. Create a private Data Exchange so that any teammate can use the worksheet.,C. Share the worksheet with teammates within Snowsight.,D. Create a database and grant all permissions to teammates.,,,,,,,,,,,,3,"Within Snowsight, a user can share a worksheet with teammates by clicking on the ""Share"" button in the toolbar and then entering the email addresses of the teammates to share the worksheet with. This will grant the specified users view access to the worksheet.  A is incorrect as zero-copy clones are used for making a copy of the data that the worksheet is working on, not for sharing the worksheet itself.  B is incorrect as private Data Exchange is used for sharing data sets, not worksheets.  D is incorrect as creating a database and granting all permissions is not necessary for sharing a worksheet, and granting all permissions is not recommended for security reasons.
https://docs.snowflake.com/en/user-guide/ui-snowsight-worksheets-gs.html#sharing-worksheets-and-folders",
Which command can be used to load data files into a Snowflake stage?,multiple-choice,A. JOIN,B. COPY INTO,C. PUT,D. GET,,,,,,,,,,,,3,"(up)load to stage - PUT (up)load from stage - COPY INTO FROM @ unload to stage - COPY INTO @ download from stage - GET
https://docs.snowflake.com/en/user-guide/data-load-local-file-system-stage.html",
What types of data listings are available in the Snowflake Data Marketplace? (Choose two.),multi-select,A. Reader,B. Consumer,C. Vendor,D. Standard,E. Personalized,,,,,,,,,,,"4, 5","The Snowflake Marketplace offers two types of data listings which define how data is shared and consumed. Once published, both types of listings are displayed to consumers in the selected regions. The key difference between free and personalized listings is the ability to access the data share.  Introduction to the Snowflake Marketplacehttps://other-docs.snowflake.com › marketplace › intro",
What is the maximum Time Travel retention period for a temporary Snowflake table?,multiple-choice,A. 90 days,B. 1 day,C. 7 days,D. 45 days,,,,,,,,,,,,2,"The time travel for temporary is 0-1 days
Max time travel for thttps://www.examtopics.com/exams/snowflake/snowpro-core/view/21/#emporary table is one day.",
When should a multi-cluster warehouse be used in auto-scaling mode?,multiple-choice,A. When it is unknown how much compute power is needed,B. If the select statement contains a large number of temporary tables or Common Table Expressions (CTEs),C. If the runtime of the executed query is very slow,D. When a large number of concurrent queries are run on the same warehouse,,,,,,,,,,,,4,"Auto-scale This mode is enabled by specifying different values for maximum and minimum number of clusters. In this mode, Snowflake starts and stops clusters as needed to dynamically manage the load on the warehouse:  As the number of concurrent user sessions and/or queries for the warehouse increases, and queries start to queue due to insufficient resources, Snowflake automatically starts additional clusters, up to the maximum number defined for the warehouse.  Similarly, as the load on the warehouse decreases, Snowflake automatically shuts down clusters to reduce the number of running clusters and, correspondingly, the number of credits used by the warehouse.
https://docs.snowflake.com/en/user-guide/warehouses-multicluster.html#:~:text=Auto%2Dscale,-You%20can%20choose&text=This%20mode%20is%20enabled%20by,while%20the%20warehouse%20is%20running.",
What happens when a cloned table is replicated to a secondary database? (Choose two.),multi-select,A. A read-only copy of the cloned tables is stored.,B. The replication will not be successful.,C. The physical data is replicated.,D. Additional costs for storage are charged to a secondary account.,E. Metadata pointers to cloned tables are replicated.,,,,,,,,,,,"3, 4","Replication and Cloning Cloned objects are replicated physically rather than logically to secondary databases. That is, cloned tables in a standard database do not contribute to the overall data storage unless or until DML operations on the clone add to or modify existing data. However, when a cloned table is replicated to a secondary database, the physical data is also replicated, increasing the data storage usage for your account.  https://docs.snowflake.com/en/user-guide/account-replication-considerations#replication-and-cloni",
Snowflake supports the use of external stages with which cloud platforms? (Choose three.),multi-select,A. Amazon Web Services,B. Docker,C. IBM Cloud,D. Microsoft Azure Cloud,E. Google Cloud Platform,F. Oracle Cloud,,,,,,,,,,"1, 4, 5","These suggested answers are trying to fail us . Docker ? Seriously ? AWS, Azure , GCP (A,D,E)
",
What is a limitation of a Materialized View?,multiple-choice,A. A Materialized View cannot support any aggregate functions,B. A Materialized View can only reference up to two tables,C. A Materialized View cannot be joined with other tables,D. A Materialized View cannot be defined with a JOIN,,,,,,,,,,,,4,"Materialized view can be joined with other tables. But you cannot include JOIN in a materialized view definition
https://docs.snowflake.com/en/user-guide/views-materialized.html#limitations-on-creating-materialized-views",
"In the Snowflake access control model, which entity owns an object by default?",multiple-choice,A. The user who created the object,B. The SYSADMIN role,C. Ownership depends on the type of object,D. The role used to create the object,,,,,,,,,,,,4,"To own an object means that a role has the OWNERSHIP privilege on the object. Each securable object is owned by a single role, which by default is the role used to create the object.
",
What is the minimum Snowflake edition required to use Dynamic Data Masking?,multiple-choice,A. Standard,B. Enterprise,C. Business Critical,D. Virtual Private Snowflake (VPC),,,,,,,,,,,,2,https://docs.snowflake.com/en/user-guide/security-column-ddm-use.html,
Which services does the Snowflake Cloud Services layer manage? (Choose two.),multi-select,A. Compute resources,B. Query execution,C. Authentication,D. Data storage,E. Metadata,,,,,,,,,,,"3, 5","C. Authentication E. Metadata
https://docs.snowflake.com/en/user-guide/intro-key-concepts.html",
"A company needs to allow some users to see Personally Identifiable Information (PII) while limiting other users from seeing the full value of the PII.

Which Snowflake feature will support this?",multiple-choice,A. Row access policies,B. Data masking policies,C. Data encryption,D. Role based access control,,,,,,,,,,,,2,"If you have a table with a column including PII, masking rows will not solve the issue. What we need is to make the data in this column visible to some, and masked to some. Thus we need to use dynamic data masking.
https://community.snowflake.com/s/article/How-to-Secure-PII-Data-with-Data-Masking",
"A user has unloaded data from a Snowflake table to an external stage.

Which command can be used to verify if data has been uploaded to the external stage named my_stage?",multiple-choice,A. view @my_stage,B. list @my_stage,C. show @my_stage,D. display @my_stage,,,,,,,,,,,,2,"Answer is correct List
",
Which tasks are performed in the Snowflake Cloud Services layer? (Choose two.),multi-select,A. Management of metadata,B. Computing the data,C. Maintaining Availability Zones,D. Infrastructure security,E. Parsing and optimizing queries,,,,,,,,,,,"1, 5","The option is ""Infrastructure security"" and not account security (authentication). Infrastructure is a broad term handled by Cloud Provider.
why not C also for Security?  https://docs.snowflake.com/en/user-guide/intro-key-concepts.html",
What is true about sharing data in Snowflake? (Choose two.),multi-select,A. The Data Consumer pays for data storage as well as for data computing.,"B. The shared data is copied into the Data Consumer account, so the Consumer can modify it without impacting the base data of the Provider.",C. A Snowflake account can both provide and consume shared data.,D. The Provider is charged for compute resources used by the Data Consumer to query the shared data.,E. The Data Consumer pays only for compute resources to query the shared data.,,,,,,,,,,,"3, 5","https://docs.snowflake.com/en/user-guide/data-sharing-intro.html  With Secure Data Sharing, no actual data is copied or transferred between accounts. The only charges to consumers are for the compute resources (i.e. virtual warehouses) used to query the shared data  Any full Snowflake account can both provide and consume shared data",
"The following JSON is stored in a VARIANT column called src of the CAR_SALES table:



A user needs to extract the dealership information from the JSON.

How can this be accomplished?",multiple-choice,A. select src:dealership from car_sales;,B. select src.dealership from car_sales;,C. select src:Dealership from car_sales;,D. select dealership from car_sales;,,,,,,,,,,,,1,"Use dot notation to traverse a path in a JSON object: <column>:<level1_element>.<level2_element>.<level3_element>. Optionally enclose element names in double quotes: <column>:""<level1_element>"".""<level2_element>"".""<level3_element>"".
Insert a colon : between the VARIANT column name and any first-level element: <column>:<level1_element>.  https://docs.snowflake.com/en/user-guide/querying-semistructured.html",
Which of the following significantly improves the performance of selective point lookup queries on a table?,multiple-choice,A. Clustering,B. Materialized Views,C. Zero-copy Cloning,D. Search Optimization Service,,,,,,,,,,,,4,"The search optimization service aims to significantly improve the performance of certain types of queries on tables, including:  Selective point lookup queries on tables. A point lookup query returns only one or a small number of distinct rows. Use case examples include:  Business users who need fast response times for critical dashboards with highly selective filters.  Data scientists who are exploring large data volumes and looking for specific subsets of data.  Data applications retrieving a small set of results based on an extensive set of filtering predicates.
https://docs.snowflake.com/en/user-guide/search-optimization-service.html#understanding-the-search-optimization-service",
Which of the following accurately describes shares?,multiple-choice,"A. Tables, secure views, and secure UDFs can be shared",B. Shares can be shared,C. Data consumers can clone a new table from a share,D. Access to a share cannot be revoked once granted,,,,,,,,,,,,1,"Snowflake enables sharing of data through named Snowflake objects called shares which supports data sharing by sharing tables, secure views, and secure UDFs in our Snowflake database (Data Provider) with other Snowflake accounts (Data Consumer).
https://docs.snowflake.com/en/user-guide/data-sharing-intro",
What are best practice recommendations for using the ACCOUNTADMIN system-defined role in Snowflake? (Choose two.),multi-select,A. Ensure all ACCOUNTADMIN roles use Multi-factor Authentication (MFA).,B. All users granted ACCOUNTADMIN role must be owned by the ACCOUNTADMIN role.,C. The ACCOUNTADMIN role must be granted to only one user.,"D. Assign the ACCOUNTADMIN role to at least two users, but as few as possible.",E. All users granted ACCOUNTADMIN role must also be granted SECURITYADMIN role.,,,,,,,,,,,"1, 4","All users assigned the ACCOUNTADMIN role should also be required to use multi-factor authentication (MFA) for login (for details, see Configuring Access Control).  Assign this role to at least two users.
Answers are correct - https://docs.snowflake.com/en/user-guide/security-access-control-considerations.html#:~:text=The%20account%20administrator%20%28i.e%20users%20with%20the%20ACCOUNTADMIN,data%2C%20and%20can%20stop%20any%20running%20SQL%20statements.",
"In the query profiler view for a query, which components represent areas that can be used to help optimize query performance? (Choose two.)",multi-select,A. Bytes scanned,B. Bytes sent over the network,C. Number of partitions scanned,D. Percentage scanned from cache,E. External bytes scanned,,,,,,,,,,,"1, 3","A. Bytes scanned represents the amount of data scanned by the query. By minimizing the number of bytes scanned, query performance can be improved.  C. Number of partitions scanned represents the number of partitions read during query execution. By minimizing the number of partitions scanned, query performance can be improved.  B, D, and E are incorrect statements. Bytes sent over the network, percentage scanned from cache, and external bytes scanned may provide useful information for monitoring or troubleshooting, but they are not directly related to optimizing query performance.
https://docs.snowflake.com/en/user-guide/ui-query-profile",
What is the minimum Snowflake edition required for row level security?,multiple-choice,A. Standard,B. Enterprise,C. Business Critical,D. Virtual Private Snowflake,,,,,,,,,,,,2,Row access policies implement row-level security - https://docs.snowflake.com/en/user-guide/security-row.html,
The is the minimum Fail-safe retention time period for transient tables?,multiple-choice,A. 1 day,B. 7 days,C. 12 hours,D. 0 days,,,,,,,,,,,,4,"Table Type Time Travel Retention Period (Days) Fail-safe Period (Days) Permanent 0 or 1 (for Snowflake Standard Edition) 7 0 to 90 (for Snowflake Enterprise Edition) 7 Transient 0 or 1 0 Temporary 0 or 1 0
https://docs.snowflake.com/en/user-guide/tables-temp-transient ""Transient tables are similar to permanent tables with the key difference that they do not have a Fail-safe period.""",
What is a machine learning and data science partner within the Snowflake Partner Ecosystem?,multiple-choice,A. Informatica,B. Power BI,C. Adobe,D. Data Robot,,,,,,,,,,,,4,"Answer is correct
https://docs.snowflake.com/en/user-guide/ecosystem-analytics.html",
Which statements are correct concerning the leveraging of third-party data from the Snowflake Data Marketplace? (Choose two.),multi-select,"A. Data is live, ready-to-query, and can be personalized.",B. Data needs to be loaded into a cloud provider as a consumer account.,C. Data is not available for copying or moving to an individual Snowflake account.,D. Data is available without copying or moving.,E. Data transformations are required when combining Data Marketplace datasets with existing data in Snowflake.,,,,,,,,,,,"1, 4","A. Data in the Snowflake Data Marketplace is already formatted and ready to query, and can be personalized for specific business needs.  D. Data from the Snowflake Data Marketplace is accessed through Snowflake's Secure Data Sharing technology, which allows users to access the data without copying or moving it to their own account.  B and C are incorrect statements. Loading data into a cloud provider as a consumer account is not required to leverage data from the Snowflake Data Marketplace, and the data can be accessed and used in a Snowflake account without restriction.  E is also an incorrect statement. Data transformations may not be required when combining Data Marketplace datasets with existing data in Snowflake, as it depends on the specific data being used and how it needs to be combined or analyzed.
https://docs.snowflake.com/en/user-guide/data-share-consumers",
What impacts the credit consumption of maintaining a materialized view? (Choose two.),multi-select,A. Whether or not it is also a secure view,B. How often the underlying base table is queried,C. How often the base table changes,D. Whether the materialized view has a cluster key defined,E. How often the materialized view is queried,,,,,,,,,,,"3, 4","In general, the costs are proportional to:  The number of materialized views created on each base table, and the amount of data that changes in each of those materialized views when the base table changes. Any changes to micro-partitions in the base table require eventual materialized view maintenance, whether those changes are due to reclustering or DML statements run on the base table.  The number of those materialized views that are clustered. Maintaining clustering (of either a table or a materialized view) adds costs.  https://docs.snowflake.com/en/user-guide/views-materialized.html#effects-of-changes-to-base-tables-on-materialized-views",
What COPY INTO SQL command should be used to unload data into multiple files?,multiple-choice,A. SINGLE=TRUE,B. MULTIPLE=TRUE,C. MULTIPLE=FALSE,D. SINGLE=FALSE,,,,,,,,,,,,4,"The default is SINGLE = FALSE (i.e. unload into multiple files).
https://docs.snowflake.com/en/user-guide/data-unload-overview.html#bulk-unloading-into-single-or-multiple-files",
"When cloning a database containing stored procedures and regular views, that have fully qualified table references, which of the following will occur?",multiple-choice,A. The cloned views and the stored procedures will reference the cloned tables in the cloned database.,"B. An error will occur, as views with qualified references cannot be cloned.","C. An error will occur, as stored objects cannot be cloned.",D. The stored procedures and views will refer to tables in the source database.,,,,,,,,,,,,4,"For sure D. Just tested this.
https://docs.snowflake.com/en/sql-reference/sql/create-clone.html",
"When loading data into Snowflake, how should the data be organized?",multiple-choice,A. Into single files with 100-250 MB of compressed data per file,B. Into single files with 1-100 MB of compressed data per file,C. Into files of maximum size of 1 GB of compressed data per file,D. Into files of maximum size of 4 GB of compressed data per file,,,,,,,,,,,,1,"Into single files with 100-250 MB of compressed data per file
",
Which of the following objects can be directly restored using the UNDROP command? (Choose two.),multi-select,A. Schema,B. View,C. Internal stage,D. Table,E. User,F. Role,,,,,,,,,,"1, 4","Account Objects: UNDROP DATABASE  Database Objects: UNDROP SCHEMA UNDROP TABLE UNDROP TAG
Answer is correct https://docs.snowflake.com/en/sql-reference/sql/undrop.html",
Which Snowflake SQL statement would be used to determine which users and roles have access to a role called MY_ROLE?,multiple-choice,A. SHOW GRANTS OF ROLE MY_ROLE,B. SHOW GRANTS TO ROLE MY_ROLE,C. SHOW GRANTS FOR ROLE MY_ROLE,D. SHOW GRANTS ON ROLE MY_ROLE,,,,,,,,,,,,1,It could A or B  Syntax SHOW GRANTS  SHOW GRANTS ON ACCOUNT  SHOW GRANTS ON <object_type> <object_name>  SHOW GRANTS TO { ROLE <role_name> | USER <user_name> | SHARE <share_name> }  SHOW GRANTS OF ROLE <role_name>  SHOW GRANTS OF SHARE <share_name>  SHOW FUTURE GRANTS IN SCHEMA { <schema_name> }  SHOW FUTURE GRANTS IN DATABASE { <database_name> }  SHOW FUTURE GRANTS TO ROLE <role_name>  https://docs.snowflake.com/en/sql-reference/sql/show-grants.html,
What is the MINIMUM edition of Snowflake that is required to use a SCIM security integration?,multiple-choice,A. Business Critical Edition,B. Standard Edition,C. Virtual Private Snowflake (VPS),D. Enterprise Edition,,,,,,,,,,,,2,"Its available for ALL editions so Standard edition is the answe
https://docs.snowflake.com/en/user-guide/admin-security.html  Its available for ALL editions so Standard edition is the answer",
"A user created a transient table and made several changes to it over the course of several days. Three days after the table was created, the user would like to go back to the first version of the table.

How can this be accomplished?",multiple-choice,"A. Use Time Travel, as long as DATA_RETENTION_TIME_IN_DAYS was set to at least 3 days.",B. The transient table version cannot be retrieved after 24 hours.,C. Contact Snowflake Support to have the data retrieved from Fail-safe storage.,D. Use the FAIL_SAFE parameter for Time Travel to retrieve the data from Fail-safe storage.,,,,,,,,,,,,2,"For transient table the time travel is from 0 to 1 days.
A use time travel https://community.snowflake.com/s/article/Time-Travel-Inherited-DATA-RETENTION-TIME-IN-DAYS-Parameter-Retained-in-Transient-Tables",
"When reviewing the load for a warehouse using the load monitoring chart, the chart indicates that a high volume of queries is always queuing in the warehouse.

According to recommended best practice, what should be done to reduce the queue volume? (Choose two.)",multi-select,A. Use multi-clustered warehousing to scale out warehouse capacity.,B. Scale up the warehouse size to allow queries to execute faster.,C. Stop and start the warehouse to clear the queued queries.,D. Migrate some queries to a new warehouse to reduce load.,E. Limit user access to the warehouse so fewer queries are run against it.,,,,,,,,,,,"1, 2","AB, the key word here is 'always' which indicates the action needed is for following computes but not necessarily current running queries. moving queued queries to new warehouse is temp solution. scale up and scale out is the permanent solution. https://docs.snowflake.com/en/user-guide/warehouses-load-monitoring.html#slow-query-performance",
"Which of the following features, associated with Continuous Data Protection (CDP), require additional Snowflake-provided data storage? (Choose two.)",multi-select,A. Tri-Secret Secure,B. Time Travel,C. Fail-safe,D. Data encryption,E. External stages,,,,,,,,,,,"2, 4","correct answer is  TimeTravel and Data Encryption. If you use the same link provided by other comments, you can see that Time Travel and Fail Safe as a same feature.
Correct Answer https://docs.snowflake.com/en/user-guide/data-cdp.html both Time Travel and Fail-safe require additional data storage, which has associated fees",
Where can a user find and review the failed logins of a specific user for the past 30 days?,multiple-choice,A. The USERS view in ACCOUNT_USAGE,B. The LOGIN_HISTORY view in ACCOUNT_USAGE,C. The ACCESS_HISTORY view in ACCOUNT_USAGE,D. The SESSIONS view in ACCOUNT_USAGE,,,,,,,,,,,,2,"correct answer
https://docs.snowflake.com/en/sql-reference/account-usage/login_history.html",
What is the purpose of an External Function?,multiple-choice,A. To call code that executes outside of Snowflake,B. To run a function in another Snowflake database,C. To share data in Snowflake with external parties,D. To ingest data from on-premises data sources,,,,,,,,,,,,1,Correct Answer https://docs.snowflake.com/en/sql-reference/external-functions-introduction.html#what-is-an-external-function,
Which of the following statements apply to Snowflake in terms of security? (Choose two.),multi-select,A. Snowflake leverages a Role-Based Access Control (RBAC) model.,B. Snowflake requires a user to configure an IAM user to connect to the database.,C. All data in Snowflake is encrypted.,D. Snowflake can run within a user's own Virtual Private Cloud (VPC).,E. All data in Snowflake is compressed.,,,,,,,,,,,"1, 3","Snowflake is a native 100% public cloud solution, you cannot host it on your OWN VPC. All data micro partitions are encrypted.
",
"A single user of a virtual warehouse has set the warehouse to auto-resume and auto-suspend after 10 minutes. The warehouse is currently suspended and the user performs the following actions:

1. Runs a query that takes 3 minutes to complete
2. Leaves for 15 minutes
3. Returns and runs a query that takes 10 seconds to complete
4. Manually suspends the warehouse as soon as the last query was completed

When the user returns, how much billable compute time will have been consumed?",multiple-choice,A. 4 minutes,B. 10 minutes,C. 14 minutes,D. 24 minutes,,,,,,,,,,,,3,"I think it is 14 mins because:  3 Minutes for running first time (starting the WH and first execution) Leave for 15 minutes. WH will be iddle after 10 mins. ==> 10 + 3 New execuion = Minimal is 1 minute billed.   so: 10+3+1 = 14
",
What can be used to view warehouse usage over time? (Choose two.),multi-select,A. The LOAD HISTORY view,B. The query history view,C. The SHOW WAREHOUSES command,D. The WAREHOUSE_METERING_HISTORY view,E. The billing and usage tab in the Snowflake web UI,,,,,,,,,,,"2, 5",Query history  https://docs.snowflake.com/en/sql-reference/account-usage.html#label-account-usage-warehouse-performance-query,
What actions will prevent leveraging of the ResultSet cache? (Choose two.),multi-select,A. Removing a column from the query SELECT list,B. Stopping the virtual warehouse that the query is running against,C. Clustering of the data used by the query,D. Executing the RESULTS_SCAN() table function,E. Changing a column that is not in the cached query,,,,,,,,,,,"1, 5","A. Removing a column from the query SELECT list:
The Result Set Cache relies on the exact query text (or a functionally identical query plan). If even a single column is removed or added to the SELECT list, the query text changes, and thus it will not be considered the same query as the cached one. This will prevent leveraging the cache.
Correct.

B. Stopping the virtual warehouse that the query is running against:
    The Result Set Cache is a global cache maintained by the Cloud Services layer, separate from individual virtual warehouses. Stopping, starting, or resizing a virtual warehouse does not affect the validity of cached query results. If an identical query is run on a different or restarted warehouse, it can still hit the cache.
Incorrect.

C. Clustering of the data used by the query:
Clustering is a storage optimization. If the data itself is modified in the micro-partitions that were used by the cached query (e.g., due to DML operations like INSERT, UPDATE, DELETE, or a re-clustering process that changes the underlying data files), then the Result Set Cache for queries relying on that data will be invalidated. While the act of clustering itself is a data reorganization, the direct cause of cache invalidation is the change in the underlying data. If ""Clustering"" implies that the data relevant to the query has been modified/reorganized, then the cache would be prevented. However, just having clustering defined doesn't prevent it; it's the change to the data. Compared to A and E, this is less direct as a preventative action.
Less direct, but can lead to invalidation if data changes.

D. Executing the RESULTS_SCAN() table function:
The RESULTS_SCAN() table function is specifically designed to retrieve the results of a previous query from the Result Set Cache (or a temporary internal stage if the result is too large for the cache). Therefore, executing this function actively leverages the cache; it does not prevent it.
Incorrect.

E. Changing a column that is not in the cached query:
The Result Set Cache is invalidated if any data within any column of any table involved in the cached query is modified. Snowflake's cache invalidation is based on the underlying micro-partitions. If a micro-partition involved in the original query is changed (even a column not directly selected or filtered), the checksum for that micro-partition changes, and any cached query results dependent on it are invalidated.
Correct.

Therefore, the two actions that will prevent leveraging the Result Set Cache are changes to the query text or changes to the underlying data.

The final answer is  
A,E",
Which statement is true about running tasks in Snowflake?,multiple-choice,A. A task can be called using a CALL statement to run a set of predefined SQL commands.,B. A task allows a user to execute a single SQL statement/command using a predefined schedule.,C. A task allows a user to execute a set of SQL commands on a predefined schedule.,D. A task can be executed using a SELECT statement to run a predefined SQL command.,,,,,,,,,,,,1,A task can execute any one of the following types of SQL code: Single SQL statement Call to a stored procedure Procedural logic using Snowflake Scripting Developer Guide  https://docs.snowflake.com/en/user-guide/tasks-intro,
Which data types does Snowflake support when querying semi-structured data? (Choose two.),multi-select,A. VARIANT,B. VARCHAR,C. XML,D. ARRAY,E. BLOB,,,,,,,,,,,"1, 4",Answer : Variant and Array https://docs.snowflake.com/en/user-guide/semistructured-intro.html#loading-semi-structured-data,
"In an auto-scaling multi-cluster virtual warehouse with the setting SCALING_POLICY = ECONOMY enabled, when is another cluster started?",multiple-choice,A. When the system has enough load for 2 minutes,B. When the system has enough load for 6 minutes,C. When the system has enough load for 8 minutes,D. When the system has enough load for 10 minutes,,,,,,,,,,,,2,https://docs.snowflake.com/en/user-guide/warehouses-multicluster.html warehouse start Only if the system estimates there’s enough query load to keep the cluster busy for at least 6 minutes.,
"What is the following SQL command used for?

Select * from table(validate(t1, job_id => '_last'));",multiple-choice,A. To validate external table files in table t1 across all sessions,B. To validate task SQL statements against table t1 in the last 14 days,C. To validate a file for errors before it gets executed using a COPY command,D. To return errors from the last executed COPY command into table t1 in the current session,,,,,,,,,,,,4,https://docs.snowflake.com/en/sql-reference/functions/validate.html,
"A sales table FCT_SALES has 100 million records.

The following query was executed:

SELECT COUNT (1) FROM FCT_SALES;

How did Snowflake fulfill this query?",multiple-choice,A. Query against the result set cache,B. Query against a virtual warehouse cache,C. Query against the most-recently created micro-partition,D. Query against the metadata cache,,,,,,,,,,,,4,"D. Query against the metadata cache >> METADATA-BASED RESULT
",
What happens when a virtual warehouse is resized?,multiple-choice,A. When increasing the size of an active warehouse the compute resource for all running and queued queries on the warehouse are affected.,B. When reducing the size of a warehouse the compute resources are removed only when they are no longer being used to execute any current statements.,C. The warehouse will be suspended while the new compute resource is provisioned and will resume automatically once provisioning is complete.,D. Users who are trying to use the warehouse will receive an error message until the resizing is complete.,,,,,,,,,,,,2,"B. When reducing the size of a warehouse the compute resources are removed only when they are no longer being used to execute any current statements.
https://docs.snowflake.com/en/user-guide/warehouses-tasks.html#:~:text=Resizing%20a%20running%20warehouse%20adds,each%20cluster%20in%20the%20warehouse.",
What tasks can be completed using the COPY command? (Choose two.),multi-select,A. Columns can be aggregated.,B. Columns can be joined with an existing table.,C. Columns can be reordered.,D. Columns can be omitted.,E. Data can be loaded without the need to spin up a virtual warehouse.,,,,,,,,,,,"3, 4",https://docs.snowflake.com/en/user-guide/data-load-transform.html,
Which Snowflake layer can be configured?,multiple-choice,A. Database Storage,B. Cloud Services,C. Query Processing,D. Application Services,,,,,,,,,,,,3,"In Snowflake, the Query Processing layer, which is represented by virtual warehouses, is the one that users can configure. You can adjust settings like the warehouse size (number of servers), auto-suspend, auto-resume, and multi-cluster scaling. The other layers, such as Database Storage and Cloud Services, are managed by Snowflake and not user-configurable.
",
What are supported file formats for unloading data from Snowflake? (Choose three.),multi-select,A. XML,B. JSON,C. Parquet,D. ORC,E. AVRO,F. CSV,,,,,,,,,,"2, 3, 6","even snowflake supports XML. Why this is not the correct answer.
JSON Parquet CSV  https://docs.snowflake.com/en/user-guide/data-unload-prepare",
The Snowflake cloud services layer is responsible for which tasks? (Choose two.),multi-select,A. Local disk caching,B. Authentication and access control,C. Metadata management,D. Query processing,E. Database storage,,,,,,,,,,,"2, 3","Correct answer should be BC Cloud Services: The cloud services layer is a collection of services that coordinate activities across Snowflake. These services tie together all of the different components of Snowflake in order to process user requests, from login to query dispatch. The cloud services layer also runs on compute instances provisioned by Snowflake from the cloud provider. Services managed in this layer include: Authentication Infrastructure management Metadata management Query parsing and optimization Access control
https://docs.snowflake.com/en/user-guide/intro-key-concepts.html",
What is a key feature of Snowflake architecture?,multiple-choice,A. Zero-copy cloning creates a mirror copy of a database that updates with the original.,B. Software updates are automatically applied on a quarterly basis.,C. Snowflake eliminates resource contention with its virtual warehouse implementation.,D. Multi-cluster warehouses allow users to run a query that spans across multiple clusters.,"E. Snowflake automatically sorts DATE columns during ingest, for fast retrieval by date.",,,,,,,,,,,3,"C is the answer. specialty of the Snowflake is Virtual warehouse to provide unlimited computing power thus avoids the contention during processing.
",
When publishing a Snowflake Data Marketplace listing into a remote region what should be taken into consideration? (Choose two.),multi-select,"A. There is no need to have a Snowflake account in the target region, a share will be created for each user.","B. The listing is replicated into all selected regions automatically, the data is not.",C. The user must have the ORGADMIN role available in at least one account to link accounts for replication.,D. Shares attached to listings in remote regions can be viewed from any account in an organization.,E. For a standard listing the user can wait until the first customer requests the data before replicating it to the target region.,,,,,,,,,,,"2, 3","B, C. B is right (https://docs.snowflake.com/en/user-guide/data-exchange-managing-data-listings.html#considerations-for-creating-a-listing-in-a-remote-region-and-replicating-data). C because of deduction. But makes sense. You need ORGADMIN to manage multiple accounts.",
When loading data into Snowflake via Snowpipe what is the compressed file size recommendation?,multiple-choice,A. 10-50 MB,B. 100-250 MB,C. 300-500 MB,D. 1000-1500 MB,,,,,,,,,,,,2,"To optimize the number of parallel operations for a load, we recommend aiming to produce data files roughly 100MB to 250MB in size, compressed. Splitting large files into a greater number of smaller files distributes the load among the servers in an active warehouse and increases performance.  https://community.snowflake.com/s/article/faq-does-snowflake-have-a-recommended-file-size-for-loading",
"Which Snowflake feature allows a user to substitute a randomly generated identifier for sensitive data, in order to prevent unauthorized users access to the data, before loading it into Snowflake?",multiple-choice,A. External Tokenization,B. External Tables,C. Materialized Views,D. User-Defined Table Functions (UDTF),,,,,,,,,,,,1,https://docs.snowflake.com/en/user-guide/security-column-ext-token.html#external-tokenization,
"Which of the following are examples of operations that require a Virtual Warehouse to complete, assuming no queries have been executed previously? (Choose three.)",multi-select,A. MIN(<< column value >>),B. COPY,C. SUM(<< column value >>),D. UPDATE,,,,,,,,,,,,"2, 3, 4","B,C,D are the answers. Min uses the Global cache / Service layer cache, hence it does not require the WH to execute query. So, A can be eliminated from answers.
",
What is the SNOWFLAKE.ACCOUNT_USAGE view that contains information about which objects were read by queries within the last 365 days (1 year)?,multiple-choice,A. VIEWS_HISTORY,B. OBJECT_HISTORY,C. ACCESS_HISTORY,D. LOGIN_HISTORY,,,,,,,,,,,,3,"Querying the ACCESS_HISTORY View  This Account Usage view can be used to query the access history of Snowflake objects (e.g. table, view, column) within the last 365 days (1 year).
ideally Two options are correct Access_History and LOGIN_HISTORY. As it has been asked to select any one so going with C https://docs.snowflake.com/en/sql-reference/account-usage.html#account-usage-views",
Which feature is only available in the Enterprise or higher editions of Snowflake?,multiple-choice,A. Column-level security,B. SOC 2 type II certification,C. Multi-factor Authentication (MFA),D. Object-level access control,,,,,,,,,,,,1,"Correct
https://docs.snowflake.com/en/user-guide/intro-editions.html#enterprise-edition",
Will data cached in a warehouse be lost when the warehouse is resized?,multiple-choice,"A. Possibly, if the warehouse is resized to a smaller size and the cache no longer fits.","B. Yes, because the compute resource is replaced in its entirety with a new compute resource.","C. No, because the size of the cache is independent from the warehouse size.","D. Yes, because the new compute resource will no longer have access to the cache encryption key.",,,,,,,,,,,,1,"Decreasing the size of a running warehouse removes compute resources from the warehouse. When the computer resources are removed, the cache associated with those resources is dropped, which can impact performance in the same way that suspending the warehouse can impact performance after it is resumed.  Keep this in mind when choosing whether to decrease the size of a running warehouse or keep it at the current size. In other words, there is a trade-off with regards to saving credits versus maintaining the cache.
https://docs.snowflake.com/en/user-guide/warehouses-considerations.html#scaling-up-vs-scaling-out. At the ""tip"" it states: ... which CAN impact performance ... ""Decreasing the size of a running warehouse removes compute resources from the warehouse. When the computer resources are removed, the cache associated with those resources is dropped, which can impact performance in the same way that suspending the warehouse can impact performance after it is resumed.""",
Which semi-structured file formats are supported when unloading data from a table? (Choose two.),multi-select,A. ORC,B. XML,C. Avro,D. Parquet,E. JSON,,,,,,,,,,,"4, 5","D. Parquet E. JSON
Structured: Delimited (CSV, TSV, etc.) Semi-structured: JSON, Parquet https://docs.snowflake.com/en/user-guide/data-unload-prepare.html",
"A running virtual warehouse is suspended.
What is the MINIMUM amount of time that the warehouse will incur charges for when it is restarted?",multiple-choice,A. 1 second,B. 60 seconds,C. 5 minutes,D. 60 minutes,,,,,,,,,,,,2,"Is thee right answer
",
What are the responsibilities of Snowflake's Cloud Service layer? (Choose three.),multi-select,A. Authentication,B. Resource management,C. Virtual warehouse caching,D. Query parsing and optimization,E. Query execution,F. Physical storage of micro-partitions,,,,,,,,,,"1, 3, 4","
Answer should be ACD.  To support A&D :  Services managed in this layer include:  Authentication Infrastructure management Metadata management Query parsing and optimization Access control  https://docs.snowflake.com/en/user-guide/intro-key-concepts.html#cloud-services  To support C :    This layer authenticates users, enforces security, performs query compilation and optimization, handles request query ""caching"", and more.   https://docs.snowflake.com/en/user-guide/cost-understanding-compute.html#cloud-service-credit-usage",
How long is the Fail-safe period for temporary and transient tables?,multiple-choice,A. There is no Fail-safe period for these tables.,B. 1 day,C. 7 days,D. 31 days,E. 90 days,,,,,,,,,,,1,"no fail safe for transient / temporary tables
https://docs.snowflake.com/en/user-guide/tables-temp-transient.html",
Which command should be used to download files from a Snowflake stage to a local folder on a client's machine?,multiple-choice,A. PUT,B. GET,C. COPY,D. SELECT,,,,,,,,,,,,2,"get is correct
https://docs.snowflake.com/en/sql-reference/sql/get.html",
How does Snowflake Fail-safe protect data in a permanent table?,multiple-choice,"A. Fail-safe makes data available up to 1 day, recoverable by user operations.","B. Fail-safe makes data available for 7 days, recoverable by user operations.","C. Fail-safe makes data available for 7 days, recoverable only by Snowflake Support.","D. Fail-safe makes data available up to 1 day, recoverable only by Snowflake Support.",,,,,,,,,,,,3,"C is correct answer
",
"A virtual warehouse is created using the following command:

Create warehouse my_WH with -
warehouse_size = MEDIUM
min_cluster_count = 1
max_cluster_count = 1
auto_suspend = 60
auto_resume = true;
What action should be taken to address this situation?",multiple-choice,A. Increase the warehouse size from Medium to 2XL.,B. Increase the value for the parameter MAX_CONCURRENCY_LEVEL.,C. Configure the warehouse to a multi-cluster warehouse.,D. Lower the value of the parameter STATEMENT_QUEUED_TIMEOUT_IN_SECONDS.,,,,,,,,,,,,3,"We can see that queries are queued starting from 4 queries running. Later 6 queries are running in concurrency. So queries are queued not for reaching the max possible number of queries, but for reaching the max Cluster utilization. Therefor, the best solution is to scale out (Answer C)
",
Which minimum Snowflake edition allows for a dedicated metadata store?,multiple-choice,A. Standard,B. Enterprise,C. Business Critical,D. Virtual Private Snowflake,,,,,,,,,,,,4,explained in tabular format https://docs.snowflake.com/en/user-guide/intro-editions.html#enterprise-edition,
Network policies can be set at which Snowflake levels? (Choose two.),multi-select,A. Role,B. Schema,C. User,D. Database,E. Account,F. Tables,,,,,,,,,,"3, 5",Identifying a Network Policy Activated at the Account or User Level https://docs.snowflake.com/en/user-guide/network-policies.html#creating-network-policies,
What are the correct parameters for time travel and fail-safe in the Snowflake Enterprise Edition?,multiple-choice,A. Default Time Travel Retention is set to 0 days. Maximum Time Travel Retention is 30 days. Fail Safe retention time is 1 day.,B. Default Time Travel Retention is set to 1 day. Maximum Time Travel Retention is 365 days. Fail Safe retention time is 7 days.,C. Default Time Travel Retention is set to 0 days. Maximum Time Travel Retention is 90 days. Fail Safe retention time is 7 days.,D. Default Time Travel Retention is set to 1 day. Maximum Time Travel Retention is 90 days. Fail Safe retention time is 7 days.,E. Default Time Travel Retention is set to 7 days. Maximum Time Travel Retention is 1 day. Fail Safe retention time is 90 days.,F. Default Time Travel Retention is set to 90 days. Maximum Time Travel Retention is 7 days. Fail Safe retention time is 356 days.,,,,,,,,,,4,"Verified from snowflake documentation. D is the right answer.
",
Which of the following objects are contained within a schema? (Choose two.),multi-select,A. Role,B. Stream,C. Warehouse,D. External table,E. User,F. Share,,,,,,,,,,"2, 4","A. Role (ACCOUNT) B. Stream (SCHEMA) C. Warehouse (ACCOUNT) D. External table (SCHEMA) E. User (ACCOUNT) F. Share (DATABASE)
https://docs.snowflake.com/en/user-guide/security-access-control-overview.html",
Which of the following statements describe features of Snowflake data caching? (Choose two.),multi-select,"A. When a virtual warehouse is suspended, the data cache is saved on the remote storage layer.","B. When the data cache is full, the least-recently used data will be cleared to make room.",C. A user can only access their own queries from the query result cache.,D. A user must set USE_METADATA_CACHE to TRUE to use the metadata cache in queries.,E. The RESULT_SCAN table function can access and filter the contents of the query result cache.,,,,,,,,,,,"2, 5","Option A is incorrect because when a virtual warehouse is suspended, the data cache is not saved on the remote storage layer. The data cache is cleared when a virtual warehouse is suspended and any data that needs to be cached is reloaded from the remote storage layer when the virtual warehouse is resumed.  Option C is incorrect because the query result cache is a shared cache and all users can access the data that has been cached. There are no restrictions based on user access.  Option D is incorrect because the metadata cache is used by default in queries and there is no need for a user to explicitly set USE_METADATA_CACHE to TRUE.  Option B is correct because Snowflake automatically manages its data cache and evicts the least-recently used data when the cache becomes full.  Option E is correct because the RESULT_SCAN table function can be used to query and filter the data that has been cached in the query result cache.
result_scan: can return query results of past 24 hours: https://docs.snowflake.com/en/sql-reference/functions/result_scan.html",
"A table needs to be loaded. The input data is in JSON format and is a concatenation of multiple JSON documents. The file size is 3 GB. A warehouse size S is being used. The following COPY INTO command was executed:
COPY INTO SAMPLE FROM @~/SAMPLE.JSON (TYPE=JSON)
The load failed with this error:
Max LOB size (16777216) exceeded, actual size of parsed column is 17894470.
How can this issue be resolved?",multiple-choice,A. Compress the file and load the compressed file.,B. Split the file into multiple files in the recommended size range (100 MB - 250 MB).,C. Use a larger-sized warehouse.,D. Set STRIP_OUTER_ARRAY=TRUE in the COPY INTO command.,,,,,,,,,,,,4,"If the data exceeds 16 MB, enable the STRIP_OUTER_ARRAY file format option for the COPY INTO <table> command to remove the outer array structure and load the records into separate table rows:  https://docs.snowflake.com/en/user-guide/semistructured-considerations.html#data-size-limitations",
What is a feature of a stored procedure in Snowflake?,multiple-choice,A. They can be created as secure and hide the underlying metadata from all users.,B. They can access tables from a single database.,C. They can only contain a single SQL statement.,D. They can be created to run with a caller's rights or an owner's rights.,,,,,,,,,,,,4,"A - False - When you specify that the UDF or procedure is secure, these details are visible only to authorized users – in other words, to users who are granted a role that owns the function.
D is correct...https://docs.snowflake.com/en/sql-reference/stored-procedures-rights",
Which columns are part of the result set of the Snowflake LATERAL FLATTEN command? (Choose two.),multi-select,A. CONTENT,B. PATH,C. BYTE_SIZE,D. INDEX,E. DATATYPE,,,,,,,,,,,"2, 4","answer - BD In Snowflake, the LATERAL FLATTEN command is used to unnest semi-structured data stored in variant or object columns. When you execute the LATERAL FLATTEN command, it generates a new virtual table with the unnested data.  The result set of the LATERAL FLATTEN command includes the following columns:  KEY: This column contains the key or path to the unnested element within the original semi-structured data. INDEX: This column represents the index of the unnested element within the array or object. ELEMENT: This column contains the value of the unnested element. These three columns make up the result set of the LATERAL FLATTEN command and provide the necessary information to access and process the unnested data.
https://docs.snowflake.com/en/sql-reference/functions/flatten.html",
What is the minimum Snowflake edition required to create a materialized view?,multiple-choice,A. Standard Edition,B. Enterprise Edition,C. Business Critical Edition,D. Virtual Private Snowflake Edition,,,,,,,,,,,,2,"https://docs.snowflake.com/en/sql-reference/sql/create-materialized-view.html#:~:text=Materialized%20views%20require%20Enterprise%20Edition,upgrading%2C%20please%20contact%20Snowflake%20Support.",
"Which Snowflake function will interpret an input string as a JSON document, and produce a VARIANT value?",multiple-choice,A. parse_json(),B. json_extract_path_text(),C. object_construct(),D. flatten,,,,,,,,,,,,1,"Interprets an input string as a JSON document, producing a VARIANT value.  Syntax PARSE_JSON( <expr> )
https://docs.snowflake.com/en/sql-reference/functions/parse_json.html",
How are serverless features billed?,multiple-choice,A. Per second multiplied by an automatic sizing for the job,"B. Per minute multiplied by an automatic sizing for the job, with a minimum of one minute","C. Per second multiplied by the size, as determined by the SERVERLESS_FEATURES_SIZE account parameter","D. Serverless features are not billed, unless the total cost for the month exceeds 10% of the warehouse credits, on the account",,,,,,,,,,,,4,"Charges for serverless features are calculated based on total usage of snowflake-managed compute resources measured in compute-hours. Compute-Hours are calculated on a per second basis, rounded up to the nearest whole second. The number of credits consumed per compute hour varies depending on the serverless feature.
Charges for serverless features are calculated based on total usage of snowflake-managed compute resources measured in compute-hours. Compute-Hours are calculated on a per second basis, rounded up to the nearest whole second. The number of credits consumed per compute hour varies depending on the serverless feature. To learn how many credits are consumed by a serverless feature, refer to the “Serverless Feature Credit Table” in the Snowflake service consumption table. https://docs.snowflake.com/en/user-guide/cost-understanding-compute#serverless-credit-usage",
Which Snowflake architectural layer is responsible for a query execution plan?,multiple-choice,A. Compute,B. Data storage,C. Cloud services,D. Cloud provider,,,,,,,,,,,,3,"Cloud Services The cloud services layer is a collection of services that coordinate activities across Snowflake. These services tie together all of the different components of Snowflake in order to process user requests, from login to query dispatch. The cloud services layer also runs on compute instances provisioned by Snowflake from the cloud provider.  Services managed in this layer include:  Authentication  Infrastructure management  Metadata management  Query parsing and optimization  Access control
https://docs.snowflake.com/en/user-guide/intro-key-concepts.html#query-processing",
"When unloading to a stage, which of the following is a recommended practice or approach?",multiple-choice,A. Set SINGLE = TRUE for larger files.,B. Use OBJECT_CONSTRUCT(*) when using Parquet.,C. Avoid the use of the CAST function.,D. Define an individual file format.,,,,,,,,,,,,4,Avoid use of the CAST function is not an answer https://docs.snowflake.com/en/user-guide/data-unload-considerations.html,
"Which SQL commands, when committed, will consume a stream and advance the stream offset? (Choose two.)",multi-select,A. UPDATE TABLE FROM STREAM,B. SELECT FROM STREAM,C. INSERT INTO TABLE SELECT FROM STREAM,D. ALTER TABLE AS SELECT FROM STREAM,E. BEGIN COMMIT,,,,,,,,,,,"1, 3","AC The stream position (i.e. offset) is advanced when the stream is used in a DML statement. The position is updated at the end of the transaction to the beginning timestamp of the transaction. The stream describes change records starting from the current position of the stream and ending at the current transactional timestamp.  To ensure multiple statements access the same change records in the stream, surround them with an explicit transaction statement (BEGIN .. COMMIT). An explicit transaction locks the stream, so that DML updates to the source object are not reported to the stream until the transaction is committed.
https://docs.snowflake.com/en/user-guide/streams-intro  To advance the offset of a stream to the current table version without consuming the change data in a DML operation, complete either of the following actions:  Recreate the stream (using the CREATE OR REPLACE STREAM syntax).  Insert the current change data into a temporary table. In the INSERT statement, query the stream but include a WHERE clause that filters out all of the change data (e.g. WHERE 0 = 1).",
On which of the following cloud platforms can a Snowflake account be hosted? (Choose three.),multi-select,A. Amazon Web Services,B. Private Virtual Cloud,C. Oracle Cloud,D. Microsoft Azure Cloud,E. Google Cloud Platform,F. Alibaba Cloud,,,,,,,,,,"1, 4, 5","ADE is the way
https://docs.snowflake.com/en/user-guide/intro-cloud-platforms.html#:~:text=A%20Snowflake%20account%20can%20be,Microsoft%20Azure%20(Azure)",
What Snowflake role must be granted for a user to create and manage accounts?,multiple-choice,A. ACCOUNTADMIN,B. ORGADMIN,C. SECURITYADMIN,D. SYSADMIN,,,,,,,,,,,,3,"The user administrator (USERADMIN) role includes the privileges to create and manage users and roles (assuming ownership of those roles or users has not been transferred to another role).
The correct answer is C.  The user administrator (USERADMIN) role includes the privileges to create and manage users and roles (assuming ownership of those roles or users has not been transferred to another role).  The security administrator (i.e users with the SECURITYADMIN system role) role includes the global MANAGE GRANTS privilege to grant or revoke privileges on objects in the account. The USERADMIN role is a child of this role in the default access control hierarchy. https://docs.snowflake.com/en/user-guide/security-access-control-considerations",
What feature can be used to reorganize a very large table on one or more columns?,multiple-choice,A. Micro-partitions,B. Clustering keys,C. Key partitions,D. Clustered partitions,,,,,,,,,,,,2,https://docs.snowflake.com/en/user-guide/tables-clustering-keys.html,
What is an advantage of using an explain plan instead of the query profiler to evaluate the performance of a query?,multiple-choice,A. The explain plan output is available graphically.,B. An explain plan can be used to conduct performance analysis without executing a query.,C. An explain plan will handle queries with temporary tables and the query profiler will not.,D. An explain plan's output will display automatic data skew optimization information.,,,,,,,,,,,,2,https://docs.snowflake.com/en/sql-reference/sql/explain.html,
Which data types are supported by Snowflake when using semi-structured data? (Choose two.),multi-select,A. VARIANT,B. VARRAY,C. STRUCT,D. ARRAY,E. QUEUE,,,,,,,,,,,"1, 4",https://docs.snowflake.com/en/sql-reference/data-types-semistructured.html,
Why does Snowflake recommend file sizes of 100-250 MB compressed when loading data?,multiple-choice,A. Optimizes the virtual warehouse size and multi-cluster setting to economy mode,B. Allows a user to import the files in a sequential order,C. Increases the latency staging and accuracy when loading the data,D. Allows optimization of parallel operations,,,,,,,,,,,,4,"To optimize the number of parallel operations for a load, we recommend aiming to produce data files roughly 100-250 MB (or larger) in size compressed.
Allows optimization of parallel operations https://docs.snowflake.com/en/user-guide/data-load-considerations-prepare",
Which of the following features are available with the Snowflake Enterprise edition? (Choose two.),multi-select,A. Database replication and failover,B. Automated index management,C. Customer managed keys (Tri-secret secure),D. Extended time travel,E. Native support for geospatial data,,,,,,,,,,,"1, 4","A. Database replication and failover : All Editions B. Automated index management : No index in Snowflake C. Customer managed keys (Tri-secret secure) : Business and VPS D. Extended time travel : Enterprise, Business and VPS E. Native support for geospatial data : All Editions  Answer are : A,D,E  Source : https://docs.snowflake.com/en/user-guide/intro-editions",
What is the default file size when unloading data from Snowflake using the COPY command?,multiple-choice,A. 5 MB,B. 8 GB,C. 16 MB,D. 32 MB,,,,,,,,,,,,3,"By default, COPY INTO location statements separate table data into a set of output files to take advantage of parallel operations. The maximum size for each file is set using the MAX_FILE_SIZE copy option. The default value is 16777216 (16 MB) but can be increased to accommodate larger files.  https://docs.snowflake.com/en/user-guide/data-unload-considerations.html",
What features that are part of the Continuous Data Protection (CDP) feature set in Snowflake do not require additional configuration? (Choose two.),multi-select,A. Row level access policies,B. Data masking policies,C. Data encryption,D. Time Travel,E. External tokenization,,,,,,,,,,,"3, 4","Data encryption Time Travel
correct  https://docs.snowflake.com/en/user-guide/data-cdp.html",
Which Snowflake layer is always leveraged when accessing a query from the result cache?,multiple-choice,A. Metadata,B. Data Storage,C. Compute,D. Cloud Services,,,,,,,,,,,,4,"Cloud Services
correct  https://community.snowflake.com/s/article/Caching-in-Snowflake-Data-Warehouse#:~:text=Snowflake%20Cache%20Layers&text=Result%20Cache%3A%20Which%20holds%20the,underlying%20data%20has%20not%20changed.",
Which connectors are available in the downloads section of the Snowflake web interface (UI)? (Choose two.),multi-select,A. SnowSQL,B. JDBC,C. ODBC,D. HIVE,E. Scala,,,,,,,,,,,"2, 3","Moved to https://developers.snowflake.com/drivers-and-libraries/, not available now in Snowsight. SnowSQL, SnowCD, Snowpark + ODBC - from Snowflake site Others - from external providers (Github, Maven, nuget, pip, npm)",
"A Snowflake Administrator needs to ensure that sensitive corporate data in Snowflake tables is not visible to end users, but is partially visible to functional managers.

How can this requirement be met?",multiple-choice,A. Use data encryption.,B. Use dynamic data masking.,C. Use secure materialized views.,D. Revoke all roles for functional managers and end users.,,,,,,,,,,,,2,"Correct
Masking policy administrators can implement a masking policy such that analysts (i.e. users with the custom ANALYST role) can only view the last four digits of a phone number and none of the social security number, while customer support representatives (i.e. users with the custom SUPPORT role) can view the entire phone number and social security number for customer verification use cases.  https://docs.snowflake.com/en/user-guide/security-column-intro.html#what-are-masking-policies",
Users are responsible for data storage costs until what occurs?,multiple-choice,A. Data expires from Time Travel,B. Data expires from Fail-safe,C. Data is deleted from a table,D. Data is truncated from a table,,,,,,,,,,,,2,"Actually I feel the meaning of the question is what is event that incurs extra cost, in that case the table where data modifications are more incur more cost in that case truncating is churning the entire table data will incur maximum cost so I feel the right one is D
Storage fees are incurred for maintaining historical data during both the Time Travel and Fail-safe periods.  https://docs.snowflake.com/en/user-guide/data-cdp-storage-costs.html",
"A user has an application that writes a new file to a cloud storage location every 5 minutes.

What would be the MOST efficient way to get the files into Snowflake?",multiple-choice,A. Create a task that runs a COPY INTO operation from an external stage every 5 minutes.,B. Create a task that PUTS the files in an internal stage and automate the data loading wizard.,C. Create a task that runs a GET operation to intermittently check for new files.,D. Set up cloud provider notifications on the file location and use Snowpipe with auto-ingest.,,,,,,,,,,,,4,"D. Set up cloud provider notifications on the file location and use Snowpipe with auto-ingest.
",
What affects whether the query results cache can be used?,multiple-choice,A. If the query contains a deterministic function,B. If the virtual warehouse has been suspended,C. If the referenced data in the table has changed,D. If multiple users are using the same virtual warehouse,,,,,,,,,,,,3,"Answer: C Result Cache: Which holds the results of every query executed in the past 24 hours. These are available across virtual warehouses, so query results returned to one user is available to any other user on the system who executes the same query, provided the underlying data has not changed.
answer correct is C https://community.snowflake.com/s/article/Understanding-Result-Caching",
"Which of the following is an example of an operation that can be completed without requiring compute, assuming no queries have been executed previously?",multiple-choice,A. SELECT SUM (ORDER_AMT) FROM SALES;,B. SELECT AVG(ORDER_QTY) FROM SALES;,C. SELECT MIN(ORDER_AMT) FROM SALES;,D. SELECT ORDER_AMT * ORDER_QTY FROM SALES;,,,,,,,,,,,,3,"I believe it's C, since once the METADATA stores it, it will know what's the DETERMINISTIC value without having to perform any calculation as suggested by A and B or run over all micro-partitions as it would occur in D.
",
How many days is load history for Snowpipe retained?,multiple-choice,A. 1 day,B. 7 days,C. 14 days,D. 64 days,,,,,,,,,,,,3,"COPY INTO - Stored in the metadata of the target table for 64 days SNOWPIPE - Stored in the metadata of the pipe for 14 days
Bulk data load Stored in the metadata of the target table for 64 days. Available upon completion of the COPY statement as the statement output.  Snowpipe Stored in the metadata of the pipe for 14 days. Must be requested from Snowflake via a REST endpoint, SQL table function, or ACCOUNT_USAGE view.  source : https://docs.snowflake.com/en/user-guide/data-load-snowpipe-intro",
What Snowflake features allow virtual warehouses to handle high concurrency workloads? (Choose two.),multi-select,A. The ability to scale up warehouses,B. The use of warehouse auto scaling,C. The ability to resize warehouses,D. Use of multi-clustered warehouses,E. The use of warehouse indexing,,,,,,,,,,,"2, 4","Auto-scaling Multicluster warehouse
I think BD https://docs.snowflake.com/en/sql-reference/parameters.html#max-concurrency-level https://docs.snowflake.com/en/sql-reference/parameters.html#max-concurrency-level",
Query compilation occurs in which architecture layer of the Snowflake Cloud Data Platform?,multiple-choice,A. Compute layer,B. Storage layer,C. Cloud infrastructure layer,D. Cloud services layer,,,,,,,,,,,,4,"Ans - D. Query execution is different from Query processing. Query execution is performed in the processing layer. While The services layer for Snowflake authenticates user sessions, provides management, enforces security functions, performs query compilation and optimization, results cache and coordinates all transactions
D. Cloud services layer https://community.snowflake.com/s/article/Snowflake-Additional-Billing-Cloud-Services-Layer-Impact#:~:text=The%20services%20layer%20for%20Snowflake,cache%20and%20coordinates%20all%20transactions.",
"If a size Small virtual warehouse is made up of two servers, how many servers make up a Large warehouse?",multiple-choice,A. 4,B. 8,C. 16,D. 32,,,,,,,,,,,,2,Small 2; Medium 4; Large 8; X-Large 16;  https://docs.snowflake.com/en/user-guide/warehouses-overview.html#warehouse-size,
What is a core benefit of clustering?,multiple-choice,A. To guarantee uniquely identifiable records in the database,B. To increase scan efficiency in queries by improving pruning,C. To improve performance by creating a separate file for point lookups,D. To provide data redundancy by duplicating micro-partitions,,,,,,,,,,,,2,"correct answer
B is correct  https://docs.snowflake.com/en/user-guide/tables-clustering-keys.html#:~:text=Using%20a%20clustering%20key%20to,in%20tables%20with%20no%20clustering.",
Which statement is true about Multi-Factor Authentication (MFA) in Snowflake?,multiple-choice,A. MFA can be enforced or applied for a given role.,B. Snowflake users are automatically enrolled in MFA.,C. Users enroll in MFA by submitting a request to Snowflake Support.,D. MFA is an integrated Snowflake feature.,,,,,,,,,,,,1,"MFA is enabled on a per-user basis; however, at this time, users are not automatically enrolled in MFA. To use MFA, users must enroll themselves.
D is right  https://docs.snowflake.com/en/user-guide/security-mfa.html#:~:text=Snowflake%20supports%20multi%2Dfactor%20authentication,is%20managed%20completely%20by%20Snowflake.",
What data type should be used to store JSON data natively in Snowflake?,multiple-choice,A. JSON,B. String,C. Object,D. VARIANT,,,,,,,,,,,,4,"D is the correct answer
Why not OBJECT? A Snowflake OBJECT is analogous to a JSON “object”. In other programming languages, the corresponding data type is often called a “dictionary”, “hash”, or “map”. An OBJECT contains key-value pairs. https://docs.snowflake.com/en/sql-reference/data-types-semistructured#object",
What should be considered when deciding to use a Secure View? (Choose two.),multi-select,A. No details of the query execution plan will be available in the query profiler.,B. Once created there is no way to determine if a view is secure or not.,C. Secure views do not take advantage of the same internal optimizations as standard views.,D. It is not possible to create secure materialized views.,E. The view definition of a secure view is still visible to users by way of the information schema.,,,,,,,,,,,"3, 5","Some of the internal optimizations for views require access to the underlying data in the base tables for the view. This access might allow data that is hidden from users of the view to be exposed through user code, such as user-defined functions, or other programmatic methods. Secure views do not utilize these optimizations, ensuring that users have no access to the underlying data.
https://alexandersks.medium.com/views-in-snowflake-part-3-secure-view-8bbd8832b3af",
The information schema provides storage information for which of the following objects? (Choose two.),multi-select,A. Users,B. Databases,C. Internal stages,D. Resource monitors,E. Pipes,,,,,,,,,,,"2, 3","Each database created in your account automatically includes a built-in, read-only schema named INFORMATION_SCHEMA. The schema contains the following objects:   Views for all the objects contained in the database, as well as views for account-level objects (i.e. non-database objects such as roles, warehouses, and databases)   Table functions for historical and usage data across your account.
The answer is B & E https://docs.snowflake.com/en/sql-reference/info-schema information_schema contains views that hold metadata for - Databases, Stages(not Internal stages even though internal stage are examples of stages) and pipes. Therefore Databases and Pipes are the correct options.",
What is a responsibility of Snowflake’s virtual warehouses?,multiple-choice,A. Infrastructure management,B. Metadata management,C. Query execution,D. Query parsing and optimization,E. Management of the storage layer,,,,,,,,,,,3,"C. Query execution
",
Which data type is supported by Snowflake data classification?,multiple-choice,A. Binary,B. Float,C. Geography,D. Variant,,,,,,,,,,,,2,"As per the below link, answer should be Float. Please confirm. https://docs.snowflake.com/en/user-guide/governance-classify-concepts.html",
"When unloading data to an external stage, which compression format can be used for Parquet files with the COPY INTO command?",multiple-choice,A. BROTLI,B. GZIP,C. LZO,D. ZSTD,,,,,,,,,,,,2,"https://docs.snowflake.com/en/user-guide/intro-summary-unloading.html  Compression of Output Data Files The following table describes how Snowflake handles compression for the output files generated by Snowflake when unloading data:  Location of Files  Supported  Notes  Internal or external location  gzip  By default, all unloaded data files are compressed using gzip, unless compression is explicitly disabled or one of the other supported compression methods is explicitly specified.  bzip2  Brotli  Zstandard",
Which SQL command can be used to verify the privileges that are granted to a role?,multiple-choice,A. SHOW GRANTS ON ROLE,B. SHOW ROLES,C. SHOW GRANTS TO ROLE,D. SHOW GRANTS FOR ROLE,,,,,,,,,,,,3,"SHOW GRANTS TO ...  ROLE role_name Lists all privileges and roles granted to the role.
Answer shown does not even exist.  Show grants to role: List all privileges granted https://docs.snowflake.com/en/sql-reference/sql/show-grants.html#show-grants",
Which Query Profile result indicates that a warehouse is sized too small?,multiple-choice,A. There are a lot of filter nodes.,B. Bytes are spilling to external storage.,C. The number of processed rows is very high.,D. The number of partitions scanned is the same as partitions total.,,,,,,,,,,,,2,"This questions has come before
https://community.snowflake.com/s/article/Performance-impact-from-local-and-remote-disk-spilling",
What is the default Time Travel retention period?,multiple-choice,A. 1 day,B. 7 days,C. 45 days,D. 90 days,,,,,,,,,,,,1,"No tasks are required to enable Time Travel. It is automatically enabled with the standard, 1-day retention period. However, you may wish to upgrade to Snowflake Enterprise Edition to enable configuring longer data retention periods of up to 90 days for databases, schemas, and tables.
default of 1 day https://docs.snowflake.com/en/user-guide/data-time-travel.html#data-retention-period",
Which of the following are best practice recommendations that should be considered when loading data into Snowflake? (Choose two.),multi-select,A. Load files that are approximately 25 MB or smaller.,B. Remove all dates and timestamps.,C. Load files that are approximately 100-250 MB (or larger).,D. Avoid using embedded characters such as commas for numeric data types.,E. Remove semi-structured data types.,,,,,,,,,,,"3, 4","Avoid embedded characters, such as commas (e.g. 123,456).  https://docs.snowflake.com/en/user-guide/data-load-considerations-prepare.html#preparing-delimited-text-files",
Which schema has the RESOURCE_MONITORS view?,multiple-choice,A. ACCOUNT_USAGE,B. READER_ACCOUNT_USAGE,C. INFORMATION_SCHEMA,D. WAREHOUSE_USAGE_SCHEMA,,,,,,,,,,,,2,RESOURCE_MONITORS View This Account Usage view displays the resource monitors that have been created in the reader accounts managed by the account.  Note: This view is only available in the READER_ACCOUNT_USAGE schema. REF: https://docs.snowflake.com/en/sql-reference/account-usage/resource_monitors#,
What is the purpose of enabling Federated Authentication on a Snowflake account?,multiple-choice,"A. Disables the ability to use key pair and basic authentication (e.g., username/password) when connecting",B. Allows dual Multi-Factor Authentication (MFA) when connecting to Snowflake,C. Forces users to connect through a secure network proxy,D. Allows users to connect using secure single sign-on (SSO) through an external identity provider,,,,,,,,,,,,4,"In a federated environment, user authentication is separated from user access through the use of one or more external entities that provide independent authentication of user credentials. The authentication is then passed to one or more services, enabling users to access the services through SSO. A federated environment consists of the following components:
https://docs.snowflake.com/en/user-guide/admin-security-fed-auth.html",
Which Snowflake partner category is represented at the top of this diagram (labeled 1)?,multiple-choice,A. Business Intelligence,B. Machine Learning and Data Science,C. Security and Governance,D. Data Integration,,,,,,,,,,,,4,"D. Data Integration
https://docs.snowflake.com/en/user-guide/ecosystem-security.html",
Which object types are protected by Fail-safe? (Choose two.),multi-select,A. Permanent Tables,B. Temporary Tables,C. External Tables,D. Materialized Views,E. Transient Tables,,,,,,,,,,,"1, 4","Answers seem to be correct. Temporary and Transient tables are not protected by fail-safe feature. External table is basically a file, so doesn't make sense for fail-safe.
Snowflake documentation only mentions fail-safe for permanent tables. No mention of materialized views of external tables. Don't know how to pick 2 answers here.  https://docs.snowflake.com/en/user-guide/data-failsafe.html",
Snowflake's approach to the management of system access combines which of the following models? (Choose two.),multiple-choice,A. Security Assertion Markup Language (SAML),B. Role-Based Access Control (RBAC),C. Identity Access Management (AM),"D. Create, Read, Update, and Delete (CRUD)",E. Discretionary Access Control (DAC),F. Mandatory Access Control (MAC),,,,,,,,,,"2, 5","Access Control Framework Snowflake’s approach to access control combines aspects from both of the following models:  Discretionary Access Control (DAC): Each object has an owner, who can in turn grant access to that object.  Role-based Access Control (RBAC): Access privileges are assigned to roles, which are in turn assigned to users.
",
"According to Snowflake best practice recommendations, which role should be used to create databases?",multiple-choice,A. ACCOUNTADMIN,B. SYSADMIN,C. SECURITYADMIN,D. USERADMIN,,,,,,,,,,,,2,"The system administrator (SYSADMIN) role includes the privileges to create warehouses, databases, and all database objects (schemas, tables, etc.).  https://docs.snowflake.com/en/user-guide/security-access-control-considerations.html#:~:text=The%20system%20administrator%20(SYSADMIN)%20role,%2C%20tables%2C%20etc.).",
"To add or remove search optimization for a table, a user must have which of the following privileges or roles? (Choose two.)",multi-select,A. The MODIFY privilege on the table,B. The OWNERSHIP privilege on the table,C. A SECURITYADMIN role,D. The ADD SEARCH OPTIMIZATION privilege on the schema that contains the table,E. The SELECT privilege on the table,,,,,,,,,,,"2, 4","To add, configure, or remove search optimization for a table, you must have the following privileges:  You must have OWNERSHIP privilege on the table. You must have ADD SEARCH OPTIMIZATION privilege on the schema that contains the table.  https://docs.snowflake.com/en/user-guide/search-optimization-service.html#what-access-control-privileges-are-needed-for-the-search-optimization-service",
"While using a COPY command with a Validation_mode parameter, which of the following statements will return an error?",multiple-choice,A. Statements that insert a duplicate record during a load,B. Statements that have a specific data type in the source,C. Statements that have duplicate file names,D. Statements that transform data during a load,,,,,,,,,,,,4,Answer D  https://docs.snowflake.com/en/user-guide/data-load-transform.html#validation-mode-parameter,
When is the result set cache no longer available? (Choose two.),multiple-choice,A. When another warehouse is used to execute the query,B. When another user executes the query,C. When the underlying data has changed,D. When the warehouse used to execute the query is suspended,E. When it has been 24 hours since the last query,,,,,,,,,,,"3, 5","Using Persisted Query Results Snowflake uses persisted query results to avoid re-generating results when nothing has changed  For persisted query results of all sizes, the cache expires after 24 hours.
C and E https://docs.snowflake.com/en/user-guide/querying-persisted-results",
What is the recommended file sizing for data loading using Snowpipe?,multiple-choice,"A. A compressed file size greater than 100 MB, and up to 250 MB","B. A compressed file size greater than 100 GB, and up to 250 GB","C. A compressed file size greater than 10 MB, and up to 100 MB","D. A compressed file size greater than 1 GB, and up to 2 GB",,,,,,,,,,,,1,"Loading data files roughly 100-250 MB in size or larger reduces the overhead charge relative to the amount of total data loaded to the point where the overhead cost is immaterial.
A https://www.snowflake.com/blog/best-practices-for-data-ingestion/#:~:text=Recommended%20file%20size%20for%20Snowpipe%20and%20cost%20considerations&text=We%20recommend%20files%20at%20least,cost%2Dto%2Dperformance%20ratio.",
"A user unloaded a Snowflake table called mytable to an internal stage called mystage.

Which command can be used to view the list of files that has been uploaded to the stage?",multiple-choice,A. list @mytable;,B. list @%mytable;,C. list @%mystage;,D. list @mystage;,,,,,,,,,,,,4,"B. list @%mytable; -- copy into @%mytable FROM mytable; D. list @mystage; -- copy into @mystage FROM mytable;
https://docs.snowflake.com/en/sql-reference/sql/list.html",
What is a best practice after creating a custom role?,multiple-choice,A. Create the custom role using the SYSADMIN role.,B. Assign the custom role to the SYSADMIN role.,C. Assign the custom role to the PUBLIC role.,D. Add _CUSTOM to all custom role names.,,,,,,,,,,,,2,"answer is B Custom roles (i.e. any roles other than the system-defined roles) can be created by the USERADMIN role (or a higher role) as well as by any role to which the CREATE ROLE privilege has been granted. By default, a newly-created role is not assigned to any user, nor granted to any other role.  When creating roles that will serve as the owners of securable objects in the system, Snowflake recommends creating a hierarchy of custom roles, with the top-most custom role assigned to the system role SYSADMIN.
https://docs.snowflake.com/en/user-guide/security-access-control-overview.html#role-hierarchy-and-privilege-inheritance  https://docs.snowflake.com/en/user-guide/security-access-control-overview.html#role-hierarchy-and-privilege-inheritance",
Which is the MINIMUM required Snowflake edition that a user must have if they want to use AWS/Azure Privatelink or Google Cloud Private Service Connect?,multiple-choice,A. Standard,B. Premium,C. Enterprise,D. Business Critical,,,,,,,,,,,,4,Private connectivity to the Snowflake service requires Business Critical (or higher). https://docs.snowflake.com/en/user-guide/private-snowflake-service.html#private-connectivity-to-the-snowflake-service,
Which of the following query profiler variables will indicate that a virtual warehouse is not sized correctly for the query being executed?,multiple-choice,A. Bytes sent over the network,B. Synchronization,C. Initialization,D. Remote spillage,,,,,,,,,,,,4,"D is correct
For some operations (e.g. duplicate elimination for a huge data set), the amount of memory available for the compute resources used to execute the operation might not be sufficient to hold intermediate results. As a result, the query processing engine will start spilling the data to local disk. If the local disk space is not sufficient, the spilled data is then saved to remote disks.  https://docs.snowflake.com/en/user-guide/ui-query-profile",
Which of the following Snowflake capabilities are available in all Snowflake editions? (Choose two.),multiple-choice,A. Customer-managed encryption keys through Tri-Secret Secure,B. Automatic encryption of all data,C. Up to 90 days of data recovery through Time Travel,D. Object-level access control,E. Column-level security to apply data masking policies to tables and views,,,,,,,,,,,"2, 4","Busines Critical and VPS  A. Customer-managed encryption keys through Tri-Secret Secure     Enterprise:  C. Up to 90 days of data recovery through Time Travel   E. Column-level security to apply data masking policies to tables and views     All:  B. Automatic encryption of all data   D. Object-level access control
B and D https://docs.snowflake.com/en/user-guide/intro-editions#security-governance-data-protection",
A PUT command can be used to stage local files from which Snowflake interface?,multiple-choice,A. SnowSQL,B. Snowflake classic web interface (UI),C. Snowsight,D. .NET driver,,,,,,,,,,,,1,"correct answer
PUT command Usage  The command cannot be executed from the Worksheets page in the Snowflake web interface; instead, use the SnowSQL client to upload data files, or check the documentation for the specific Snowflake client to verify support for this command. https://roboquery.com/app/syntax-put-command-snowflake",
Which of the following indicates that it may be appropriate to use a clustering key for a table? (Choose two.),multi-select,A. The table contains a column that has very low cardinality.,B. DML statements that are being issued against the table are blocked.,C. The table has a small number of micro-partitions.,D. Queries on the table are running slower than expected.,E. The clustering depth for the table is large.,,,,,,,,,,,"4, 5",DE  Queries on the table are running slower than expected or have noticeably degraded over time. The clustering depth for the table is large.  https://docs.snowflake.com/en/user-guide/tables-clustering-keys#label-considerations-for-choosing-clustering,
Which cache type is used to cache data output from SQL queries?,multiple-choice,A. Metadata cache,B. Result cache,C. Remote cache,D. Local file cache,,,,,,,,,,,,2,"Result Cache:  Which holds the results of every query executed in the past 24 hours. These are available across virtual warehouses, so query results returned to one user is available to any other user on the system who executes the same query, provided the underlying data has not changed. Local Disk Cache:  Which is used to cache data used by SQL queries. Whenever data is needed for a given query it's retrieved from the Remote Disk storage, and cached in SSD and memory.
",
Which of the following describes how clustering keys work in Snowflake?,multiple-choice,"A. Clustering keys update the micro-partitions in place with a full sort, and impact the DML operations.","B. Clustering keys sort the designated columns over time, without blocking DML operations.","C. Clustering keys create a distributed, parallel data structure of pointers to a table's rows and columns.",D. Clustering keys establish a hashed key on each node of a virtual warehouse to optimize joins at run-time.,,,,,,,,,,,,2,"correct answer is B
B https://docs.snowflake.com/en/user-guide/tables-clustering-keys#what-is-a-clustering-key",
Which of the following operations require the use of a running virtual warehouse? (Choose two.),multi-select,A. Downloading data from an internal stage,B. Listing files in a stage,C. Executing a stored procedure,D. Altering a table,E. Querying data from a materialized view,,,,,,,,,,,"3, 5","Performing DML operations, such as: Updating rows in tables (DELETE , INSERT , UPDATE). (Answer D) Loading data into tables (COPY INTO <table>). Unloading data from tables (COPY INTO <location>). (Answer A) a warehouse must be running and in use for the session.
C & E https://docs.snowflake.com/en/user-guide/warehouses.html",
What is used to limit the credit usage of a virtual warehouse within a Snowflake account?,multiple-choice,A. Load monitor,B. Resource monitor,C. Query Profile,D. Stream,,,,,,,,,,,,2,"ressource monitor of course
https://docs.snowflake.com/en/user-guide/resource-monitors.html#:~:text=A%20resource%20monitor%20can%20be,and%20how%20long%20it%20runs.",
What are the benefits of the replication feature in Snowflake? (Choose two.),multi-select,A. Disaster recovery,B. Time Travel,C. Fail-safe,D. Database failover and failback,E. Data security,,,,,,,,,,,"1, 4","Replication is not a security model infact it increases risk exposure, its for business continuity.
https://www.snowflake.com/trending/what-is-data-replication#:~:text=DATABASE%20REPLICATION%20SOLUTIONS&text=Customers%20using%20Snowflake%20Standard%20edition,portability%20to%20facilitate%20account%20migrations  so I think D and E are correct",
Which data type can be used to store geospatial data in Snowflake?,multiple-choice,A. Variant,B. Object,C. Geometry,D. Geography,,,,,,,,,,,,4,"Snowflake provides the following data types for geospatial data: The GEOGRAPHY data type, which models Earth as though it were a perfect sphere. The GEOMETRY data type, which represents features in a planar (Euclidean, Cartesian) coordinate system.
",
"If all virtual warehouse resources are maximized while processing a query workload, what will happen to new queries that are submitted to the warehouse?",multiple-choice,A. All queries will terminate when the resources are maximized.,B. The warehouse will scale out automatically,C. The warehouse will move to a suspended state.,D. New queries will be queued and executed when capacity is available.,,,,,,,,,,,,4,"D is correct
",
Masking policies can be applied to which of the following Snowflake objects? (Choose two.),multi-select,A. A materialized view,B. A stored procedure,C. A table,D. A stream,"E. A pipe -
E. A User-Defined Function (UDF)",,,,,,,,,,,"1, 3","A&C I think
",
What actions are supported by Snowflake resource monitors? (Choose two.),multi-select,A. Alert,B. Notify,C. Notify and suspend,D. Abort,E. Suspend immediately,,,,,,,,,,,"1, 3","B&C https://docs.snowflake.com/en/user-guide/resource-monitors.html#actions Notify & Suspend Notify & Suspend Immediately Notify
",
"A user executes the following SQL query:

create table SALES_BKP like SALES;

What are the cost implications for processing this query?",multiple-choice,A. Processing costs will be generated based on how long the query takes.,B. Storage costs will be generated based on the size of the data.,C. No costs will be incurred as the query will use metadata.,D. The cost for running the virtual warehouse will be charged by the second.,,,,,,,,,,,,3,"C is right.
",
What is the maximum length of time travel available in the Snowflake Standard Edition?,multiple-choice,A. 1 Day,B. 7 Days,C. 30 Days,D. 90 Days,,,,,,,,,,,,1,"Only 1 day
",
What happens when an external or an internal stage is dropped? (Choose two.),multi-select,"A. When dropping an external stage, the files are not removed and only the stage is dropped.","B. When dropping an external stage, both the stage and the files within the stage are removed.","C. When dropping an internal stage, the files are deleted with the stage and the files are recoverable.","D. When dropping an internal stage, the files are deleted with the stage and the files are not recoverable.","E. When dropping an internal stage, only selected files are deleted with the stage and are not recoverable.",,,,,,,,,,,"1, 4","per the docs explain
",
"A user has 10 files in a stage containing new customer data. The ingest operation completes with no errors, using the following command:

COPY INTO my_table FROM @my_stage;

The next day the user adds 10 files to the stage so that now the stage contains a mixture of new customer data and updates to the previous data. The user did not remove the 10 original files.

If the user runs the same COPY INTO command what will happen?",multiple-choice,A. All data from all of the files on the stage will be appended to the table.,B. Only data about new customers from the new files will be appended to the table.,C. The operation will fail with the error UNCERTAIN FILES IN STAGE.,D. All data from only the newly-added files will be appended to the table.,,,,,,,,,,,,4,"D - only the new files will be appended B - SF doesn't know which customer is new (COPY doesn't care about the meaning of data, care about files (file names) which are new (no kept in metadata as loaded)
",
Which parameter can be used to instruct a COPY command to verify data files instead of loading them into a specified table?,multiple-choice,A. STRIP_NULL_VALUES,B. SKIP_BYTE_ORDER_MARK,C. REPLACE_INVALID_CHARACTERS,D. VALIDATION_MODE,,,,,,,,,,,,4,"VALIDATION_MODE: This instructs the command to validate the data files instead of loading them into target tables and allows you to perform the dry run to ensure the fail-safe delivery of data.Dec
",
Which of the following SQL statements will list the version of the drivers currently being used?,multiple-choice,A. Execute SELECT CURRENT_ODBC_CLIENT(); from the Web UI,B. Execute SELECT CURRENT_JDBC_VERSION(); from SnowSQL,C. Execute SELECT CURRENT_CLIENT(); from an application,D. Execute SELECT CURRENT_VERSION(); from the Python Connector,,,,,,,,,,,,3,"C is the correct answer. Just checked it.
",
Which Snowflake technique can be used to improve the performance of a query?,multiple-choice,A. Clustering,B. Indexing,C. Fragmenting,D. Using INDEX_HINTS,,,,,,,,,,,,1,"Answer A , Clustering
",
"What happens to the shared objects for users in a consumer account from a share, once a database has been created in that account?",multiple-choice,A. The shared objects are transferred.,B. The shared objects are copied.,C. The shared objects become accessible.,D. The shared objects can be re-shared.,,,,,,,,,,,,3,"Database become accessible
",
Using variables in Snowflake is denoted by using which SQL character?,multiple-choice,A. @,B. &,C. $,D. #,,,,,,,,,,,,3,"Selected Answer: C
",
Which commands should be used to grant the privilege allowing a role to select data from all current tables and any tables that will be created later in a schema? (Choose two.),multi-select,A. grant USAGE on all tables in schema DB1.SCHEMA to role MYROLE;,B. grant USAGE on future tables in schema DB1.SCHEMA to role MYROLE;,C. grant SELECT on all tables in schema DB1.SCHEMA to role MYROLE;,D. grant SELECT on future tables in schema DB1.SCHEMA to role MYROLE;,E. grant SELECT on all tables in database DB1 to role MYROLE;,F. grant SELECT on future tables in database DB1 to role MYROLE;,,,,,,,,,,"3, 4","Changing to C,D
",
How can a user change which columns are referenced in a view?,multiple-choice,A. Modify the columns in the underlying table,B. Use the ALTER VIEW command to update the view,C. Recreate the view with the required changes,D. Materialize the view to perform the changes,,,,,,,,,,,,3,"Answer is C: https://docs.snowflake.com/en/sql-reference/sql/alter-view.html#alter-view
",
Which statement describes pruning?,multiple-choice,A. The filtering or disregarding of micro-partitions that are not needed to return a query.,B. The return of micro-partitions values that overlap with each other to reduce a query's runtime.,C. A service that is handled by the Snowflake Cloud Services layer to optimize caching.,D. The ability to allow the result of a query to be accessed as if it were a table.,,,,,,,,,,,,1,"A is correct
",
What do temporary and transient tables have in common in Snowflake? (Choose two.),multi-select,A. Both tables have no Fail-safe period.,B. Both tables have data retention period maximums of one day.,C. Both tables are visible only to a single user session.,"D. For both tables, the retention period ends when the tables are dropped.","E. For both tables, the retention period does not end when the session ends.",,,,,,,,,,,"1, 2","A and B are correct.  https://docs.snowflake.com/user-guide/tables-temp-transient#comparison-of-table-types
B is correct too https://docs.snowflake.com/en/user-guide/tables-temp-transient#comparison-of-table-types",
What are the least privileges needed to view and modify resource monitors? (Choose two.),multi-select,A. SELECT,B. OWNERSHIP,C. MONITOR,D. MODIFY,E. USAGE,,,,,,,,,,,"3, 4","CD is correct  https://docs.snowflake.com/en/user-guide/resource-monitors
CD is correct   roles that have been granted the following privileges on specific resource monitors can view and modify the resource monitor as needed using SQL:  - MONITOR - MODIFY  https://docs.snowflake.com/en/user-guide/resource-monitors",
When does a materialized view get suspended in Snowflake?,multiple-choice,A. When a column is added to the base table,B. When a column is dropped from the base table,C. When a DML operation is run on the base table,D. When the base table is reclustered,,,,,,,,,,,,2,"https://docs.snowflake.com/en/user-guide/views-materialized#dropping-the-base-table
B (""If a base table is altered so that existing columns are changed or dropped, then all materialized views on that base table are suspended; the materialized views cannot be used or maintained. (This is true even if the modified or dropped column was not part of the materialized view.)"")",
What happens when a Snowflake user changes the data retention period at the schema level?,multiple-choice,A. All child objects will retain data for the new retention period.,B. All child objects that do not have an explicit retention period will automatically inherit the new retention period.,C. All child objects with an explicit retention period will be overridden with the new retention period.,D. All explicit child object retention periods will remain unchanged.,,,,,,,,,,,,2,"BD are correct
Also D is correct. But B includes D, since just one answer is requested, B is the one
Correct answer is B.  -------------------------------------------------------- If you change the data retention period for a database or schema, the change only affects active objects contained within the database or schema. Any objects that have been dropped (for example, tables) remain unaffected.  For example, if you have a schema s1 with a 90-day retention period and table t1 is in schema s1, table t1 inherits the 90-day retention period. If you drop table s1.t1, t1 is retained in Time Travel for 90 days. Later, if you change the schema’s data retention period to 1 day, the retention period for the dropped table t1 is unchanged. Table t1 will still be retained in Time Travel for 90 days. -------------------------------------------------------- https://docs.snowflake.com/en/user-guide/data-time-travel#specifying-the-data-retention-period-for-an-object:~:text=through%20Time%20Travel.-,Note,-If%20you%20change
BD are both correct, confirmed by testing below. https://docs.snowflake.com/en/user-guide/data-time-travel -- 902  USE ROLE SYSADMIN; CREATE DATABASE TIME_TRAVEL_TEST; USE SCHEMA PUBLIC; CREATE TABLE T_A AS SELECT 1 ID; CREATE TABLE T_B AS SELECT 2 ID;  ALTER TABLE T_B SET DATA_RETENTION_TIME_IN_DAYS=90;  ALTER SCHEMA PUBLIC SET DATA_RETENTION_TIME_IN_DAYS=30;  -- PUBLIC - explicitly set at 30   --T_A - not set explicitly, but was inherited from parent   --T_B - explicitly set at 90  SHOW PARAMETERS like '%DATA_RETENTION_TIME_IN_DAYS%' in schema PUBLIC; --30 SHOW PARAMETERS like '%DATA_RETENTION_TIME_IN_DAYS%' in table T_A; --30 inherited from parent  SHOW PARAMETERS like '%DATA_RETENTION_TIME_IN_DAYS%' in table T_B; --90 remained explicitly set",
Snowpark provides libraries for which programming languages? (Choose two.),multi-select,A. JavaScript,B. Python,C. Scala,D. R,E. C++,,,,,,,,,,,"2, 3","BC is correct.  Snowpark provide libs for Java  Python Scala https://docs.snowflake.com/en/developer-guide/snowpark/index#developer-guides
Confirmed, BC",
How can a Snowflake user sample 10 rows from a table named SNOWPRO? (Choose two.),multi-select,A. SELECT * FROM SNOWPRO SAMPLE SYSTEM (10),B. SELECT * FROM SNOWPRO TABLESAMPLE (10 ROWS),C. SELECT * FROM SNOWPRO TABLESAMPLE BLOCK (10),D. SELECT * FROM SNOWPRO TABLESAMPLE BLOCK (10 ROWS),E. SELECT * FROM SNOWPRO SAMPLE BERNOULLI (10 ROWS),,,,,,,,,,,"2, 5","SELECT COUNT(*) FROM SNOWFLAKE_SAMPLE_DATA.TPCDS_SF100TCL.CALL_CENTER; --60  -- A - not correct -- showing different results each time   -- 5, 8, 7 SELECT COUNT(*) FROM SNOWFLAKE_SAMPLE_DATA.TPCDS_SF100TCL.CALL_CENTER TABLESAMPLE SYSTEM (10);  -- B - correct --10 SELECT COUNT(*) FROM SNOWFLAKE_SAMPLE_DATA.TPCDS_SF100TCL.CALL_CENTER TABLESAMPLE (10 ROWS);   -- C - not correct --9,6,11 SELECT COUNT(*) FROM SNOWFLAKE_SAMPLE_DATA.TPCDS_SF100TCL.CALL_CENTER TABLESAMPLE BLOCK (10);   -- D - not working --Sampling with a fixed size does not support using block sampling method. SELECT COUNT(*) FROM SNOWFLAKE_SAMPLE_DATA.TPCDS_SF100TCL.CALL_CENTER TABLESAMPLE BLOCK (10 ROWS);   -- E - correct -- 10 SELECT COUNT(*) FROM SNOWFLAKE_SAMPLE_DATA.TPCDS_SF100TCL.CALL_CENTER TABLESAMPLE BERNOULLI (10 ROWS);
BE is the correct answer. System or Block do not support fixed rows.  https://docs.snowflake.com/en/sql-reference/constructs/sample#:~:text=BERNOULLI%20%7C%20ROW%20or%20SYSTEM%20%7C%20BLOCK",
Why would a Snowflake user choose to use a transient table?,multiple-choice,A. To store data for long-term analysis,B. To store large data files that are used frequently,C. To create a permanent table for ongoing use in ELT,D. To store transitory data that needs to be maintained beyond the session,,,,,,,,,,,,4,"D is the correct answer.  transient tables are specifically designed for transitory data that needs to be maintained beyond each session https://docs.snowflake.com/en/user-guide/tables-temp-transient#transient-tables
D is correct",
What does a masking policy consist of in Snowflake?,multiple-choice,"A. A single data type, with one or more conditions, and one or more masking functions","B. A single data type, with only one condition, and only one masking function","C. Multiple data types, with only one condition, and one or more masking functions","D. Multiple data types, with one or more conditions, and one or more masking functions",,,,,,,,,,,,1,"A ""A masking policy consists of a single data type, one or more conditions, and one or more masking functions."" https://docs.snowflake.com/en/user-guide/security-column-intro
A masking policy consists of a single data type, one or more conditions, and one or more masking functions",
What actions can be performed by a consumer account on a shared database? (Choose two.),multi-select,A. Cloning a shared table,B. Modifying the data in a shared table,C. Using Time Travel on a shared table,D. Executing the SELECT statement on a shared table,E. Joining the data from a shared table with another table,,,,,,,,,,,"4, 5","Agreed
DE is right
DE is correct",
What data type is used to ingest semi-structured data into a Snowflake table?,multiple-choice,A. BOOLEAN,B. NUMBER,C. VARBINARY,D. VARIANT,,,,,,,,,,,,4,D is correct,
Which security feature is used to connect or log in to a Snowflake account?,multiple-choice,A. Network policy,B. SCIM,C. Role-Based Access Control (RBAC),D. Key pair authentication,,,,,,,,,,,,4,"D. https://docs.snowflake.com/en/user-guide/key-pair-auth
D is correct
correct answer B - https://docs.snowflake.com/en/user-guide/scim-intro",
Which Snowflake feature or tool helps troubleshoot issues in SQL query expressions that commonly cause performance bottlenecks?,multiple-choice,A. Persisted query results,B. QUERY_HISTORY view,C. Query acceleration service,D. Query Profile,,,,,,,,,,,,4,"Analyze and optimize SQL queries by examining execution plans and identifying potential bottlenecks. Use Snowflake's query profiling tools to understand query performance characteristics and optimize accordingly. Consider breaking down complex queries into smaller, more manageable steps to improve performance. https://www.linkedin.com/advice/1/how-can-you-optimize-performance-snowflake-data-5jhec
Correct Answer : D",
What is a non-configurable feature that provides historical data that Snowflake may recover during a 7-day period?,multiple-choice,A. Fail-safe,B. Time Travel,C. Cloning,D. Account replication,,,,,,,,,,,,1,"Fail-safe
correct Answer - A",
Which function should be used to authorize users to access rows in a base table when using secure views with Secure Data Sharing?,multiple-choice,A. CURRENT_ACCOUNT(),B. CURRENT_ROLE(),C. CURRENT_SESSION(),D. CURRENT_USER(),,,,,,,,,,,,1,"The correct answer is A. CURRENT_ACCOUNT()  Secure Views and Data Sharing When using secure views with Secure Data Sharing, use the CURRENT_ACCOUNT function to authorize users from a specific account to access rows in a base table. ------------------------------------------------------------------------------------------------------------------------------- Note: When using the CURRENT_ROLE and CURRENT_USER functions with secure views that will be shared to other Snowflake accounts, Snowflake returns a NULL value for these functions. The reason is that the owner of the data being shared does not typically control the users or roles in the account with which the view is being shared.  https://docs.snowflake.com/en/user-guide/views-secure#secure-views-and-data-sharing
https://docs.snowflake.com/en/user-guide/views-secure#secure-views-and-data-sharing",
What is the purpose of collecting statistics on data in Snowflake?,multiple-choice,A. To identify data storage order correlations,B. To enable efficient pruning based on query filters,C. To reduce the total number of micro-partitions in a table,D. To optimize query performance by reading all data in a table,,,,,,,,,,,,2,B. Stats help with partition pruning telling optimizer what micro-partitions to skip.,
What type of function returns one value for each invocation?,multiple-choice,A. Aggregate,B. Scalar,C. Table,D. Window,,,,,,,,,,,,2,"A scalar function is a function that returns one value per invocation; in most cases, you can think of this as returning one value per row. This contrasts with Aggregate Functions, which return one value per group of rows.
B is correct  https://docs.snowflake.com/en/sql-reference/functions",
Which file formats support unloading semi-structured data? (Choose two.),multi-select,A. Avro,B. JSON,C. ORC,D. Parquet,E. XML,,,,,,,,,,,"2, 4","https://docs.snowflake.com/en/user-guide/data-unload-prepare The following file formats are supported: Semi-structured JSON, Parquet
Correct
Snowflake provides built-in support for importing data from (and exporting data to) the following semi-structured data formats:  -JSON -Avro -ORC -Parquet -XML  https://docs.snowflake.com/en/user-guide/semistructured-concepts",
Which system-defined Snowflake role has permission to rename an account and specify whether the original URL can be used to access the renamed account?,multiple-choice,A. ACCOUNTADMIN,B. SECURITYADMIN,C. SYSADMIN,D. ORGADMIN,,,,,,,,,,,,4,"Allows organization administrators (that is, users with the ORGADMIN role) to modify core characteristics of an account. For example, the organization administrator can rename an account. ALTER ACCOUNT <name> RENAME TO <new_name> [ SAVE_OLD_URL = { TRUE | FALSE } ]
D is correct
https://docs.snowflake.com/en/sql-reference/sql/alter-account  Organization administrators (i.e. users with the ORGADMIN role) to: Rename an account and specify whether the original URL can be used to access the account.
Answer- D https://docs.snowflake.com/en/sql-reference/sql/alter-account",
How can a user get the MOST detailed information about individual table storage details in Snowflake?,multiple-choice,A. SHOW TABLES command,B. SHOW EXTERNAL TABLES command,C. TABLES view,D. TABLE_STORAGE_METRICS view,,,,,,,,,,,,4,"D - table_storage_metrics view
it's correct. https://docs.snowflake.com/en/sql-reference/account-usage/table_storage_metrics",
What type of account can be used to share data with a consumer who does not have a Snowflake account?,multiple-choice,A. Data provider,B. Data consumer,C. Reader,D. Organization,,,,,,,,,,,,3,"As a data provider, you might want to share data with a consumer who does not already have a Snowflake account or is not ready to become a licensed Snowflake customer.  To facilitate sharing data with these consumers, you can create reader accounts. Reader accounts (formerly known as “read-only accounts”) provide a quick, easy, and cost-effective way to share data without requiring the consumer to become a Snowflake customer.
Selected Answer: C Reader Account
https://docs.snowflake.com/en/user-guide/data-sharing-intro",
"By default, which role has access to the SYSTEM$GLOBAL_ACCOUNT_SET_PARAMETER function?",multiple-choice,A. ACCOUNTADMIN,B. SECURITYADMIN,C. SYSADMIN,D. ORGADMIN,,,,,,,,,,,,4,"The function enables replication and failover features for a specified account in an organization.  Once an organization administrator (a user with the ORGADMIN role) has called this function,   the following features are enabled for the account:  Replication  Client Redirect
https://docs.snowflake.com/en/sql-reference/functions/system_global_account_set_parameter  Only organization administrators (i.e. users with the ORGADMIN role) can call this SQL function.",
"If a virtual warehouse is suspended, what happens to the warehouse cache?",multiple-choice,A. The cache is dropped when the warehouse is suspended and is no longer available upon restart.,"B. The warehouse cache persists for as long as the warehouse exists, regardless of its suspension status.",C. The cache is maintained for up to two hours and can be restored if the warehouse is restarted within this limit.,D. The cache is maintained for the auto_suspend duration and can be restored if the warehouse is restarted within this limit.,,,,,,,,,,,,1,"Agreed
A is correct
https://docs.snowflake.com/en/user-guide/warehouses-considerations This cache is dropped when the warehouse is suspended, which may result in slower initial performance for some queries after the warehouse is resumed.  https://docs.snowflake.com/en/user-guide/performance-query-warehouse-cache The auto-suspension setting of the warehouse can have a direct impact on query performance because the cache is dropped when the warehouse is suspended.",
What are the primary authentication methods that Snowflake supports for securing REST API interactions? (Choose two.),multi-select,A. OAuth,B. Key pair authentication,C. Federated authentication,D. Multi-Factor Authentication (MFA),E. Username and password authentication,,,,,,,,,,,"1, 5","""Snowflake supports basic authentication (i.e. username and password) in the API request header as specified in RFC 7617, where the authentication credentials are encoded using Base64. Similarly, Snowflake supports OAuth 2.0 as specified in RFC 6749.""
https://docs.snowflake.com/en/user-guide/api-authentication
A, E https://docs.snowflake.com/en/user-guide/api-authentication",
"A Snowflake user is trying to load a 125 GB file using SnowSQL. The file continues to load for almost an entire day.

What will happen at the 24-hour mark?",multiple-choice,A. The file will continue to load until all contents are loaded.,B. The file will stop loading and all data up to that point will be committed.,C. The file loading could be aborted without any portion of the file being committed.,D. The file’s number of allowable hours to load can be programmatically controlled to load easily into Snowflake.,,,,,,,,,,,,3,"https://docs.snowflake.com/en/user-guide/data-load-considerations-prepare Note Loading very large files (e.g. 100 GB or larger) is not recommended.  If you must load a large file, carefully consider the ON_ERROR copy option value. Aborting or skipping a file due to a small number of errors could result in delays and wasted credits. In addition, if a data loading operation continues beyond the maximum allowed duration of 24 hours, it could be aborted without any portion of the file being committed. https://docs.snowflake.com/en/user-guide/data-load-considerations-prepare
https://docs.snowflake.com/en/user-guide/data-load-considerations-prepare",
What information does the Query Profile provide?,multiple-choice,A. Graphical representation of the data model,B. Statistics for each component of the processing plan,C. Detailed information about the database schema,D. Real-time monitoring of the database operations,,,,,,,,,,,,2,"The Snowflake query profile provides execution details for a query, offering a graphical representation of the processing plan's components, along with statistics for each component and the overall query.
The correct answer is B",
Which sequence (order) of object privileges should be used to grant a custom role read-only access on a table?,multiple-choice,A.,B.,C.,D.,,,,,,,,,,,,3,"In Snowflake, the USAGE privilege alone does not grant read-only access to a table. The USAGE privilege allows a role to see the database and schema, but it does not provide access to the data within the tables.  To grant read-only access to a table, you need to combine the USAGE privilege with the SELECT privilege. Here’s how you can do it:
Answer- C",
Which command removes a role from another role or a user in Snowflake?,multiple-choice,A. ALTER ROLE,B. REVOKE ROLE,C. USE ROLE,D. USE SECONDARY ROLES,,,,,,,,,,,,2,"https://docs.snowflake.com/en/sql-reference/sql/revoke-role
Answer - B",
In which hierarchy is tag inheritance possible?,multiple-choice,A. Organization » Account » Role,B. Account » User » Schema,C. Database » View » Column,D. Schema » Table » Column,,,,,,,,,,,,4,"Complete Path  Organization >> ACCOUNT >> Database >> Schema >> Table >> Column
D makes most sense and it's possible. However, A also appears possible based on docs. https://docs.snowflake.com/en/user-guide/object-tagging
A https://docs.snowflake.com/en/user-guide/object-tagging",
What happens when a network policy includes values that appear in both the allowed and blocked IP address lists?,multiple-choice,A. Those IP addresses are allowed access to the Snowflake account as Snowflake applies the allowed IP address list first.,B. Those IP addresses are denied access to the Snowflake account as Snowflake applies the blocked IP address list first.,C. Snowflake issues an alert message and adds the duplicate IP address values to both the allowed and blocked IP address lists.,D. Snowflake issues an error message and adds the duplicate IP address values to both the allowed and blocked IP address lists.,,,,,,,,,,,,2,"It's B - https://docs.snowflake.com/en/user-guide/network-policies ""When a network policy includes values in both the allowed and blocked IP address lists, Snowflake applies the blocked IP address list first.""
B. When a network policy includes values in both the allowed and blocked IP address lists, Snowflake applies the blocked IP address list first. https://docs.snowflake.com/en/user-guide/network-policies
A. Those IP addresses are allowed access to the Snowflake account as Snowflake applies the allowed IP address list first.  Explanation:  In Snowflake's network policy configuration, the allowed IP address list takes precedence over the blocked IP address list. If an IP address is listed in both the allowed and blocked lists, Snowflake applies the rule from the allowed list, allowing access. The allowed list is processed before the blocked list, and if a match is found in the allowed list, the access is granted.  So, the correct answer is A. Those IP addresses are allowed access to the Snowflake account as Snowflake applies the allowed IP address list first.",
"For directory tables, what stage allows for automatic refreshing of metadata?",multiple-choice,A. User stage,B. Table stage,C. Named internal stage,D. Named external stage,,,,,,,,,,,,4,"https://docs.snowflake.com/en/user-guide/data-load-dirtables-auto
Answer D https://docs.snowflake.com/en/user-guide/data-load-dirtables",
Which command is used to unload data from a Snowflake database table into one or more files in a Snowflake stage?,multiple-choice,A. CREATE STAGE,B. COPY INTO [table],C. COPY INTO [location],D. CREATE PIPE,,,,,,,,,,,,3,"It's C - https://docs.snowflake.com/en/sql-reference/sql/copy-into-location  COPY INTO <location> Unloads data from a table (or query) into one or more files in one of the following locations:  Named internal stage (or table/user stage). The files can then be downloaded from the stage/location using the GET command.  Named external stage that references an external location (Amazon S3, Google Cloud Storage, or Microsoft Azure).  External location (Amazon S3, Google Cloud Storage, or Microsoft Azure).
copy into command",
Any user with the appropriate privileges can view data storage for individual tables by using which queries? (Choose two.),multi-select,A. METERING_HISTORY view in the ACCOUNT_USAGE schema,B. TABLE_STORAGE_METRICS view in the ACCOUNT_USAGE schema,C. STORAGE_USAGE view in the ACCOUNT_USAGE schema,D. TABLE_STORAGE_METRICS view in the INFORMATION_SCHEMA schema,E. METERING_DAILY_HISTORY view in the ORGANIZATION_USAGE schema,,,,,,,,,,,"2, 4","https://docs.snowflake.com/en/user-guide/tables-storage-considerations
Answer B,D - https://docs.snowflake.com/en/user-guide/tables-storage-considerations",
"A user created a database and set the DATA_RETENTION_TIME_IN_DAYS to 30, but did not set the DATA_RETENTION_TIME_IN_DAYS in table T1. After 5 days, the user accidentally drops table T1.

What are the considerations for recovering table T1?",multiple-choice,A. The user can recover the table T1 after 30 days.,B. The table can be recovered because the table retention period default is at the database level.,C. The table can only be recovered by contacting Snowflake Support to recover the table from Fail-safe.,D. The table cannot be recovered because the DATA_RETENTION_TIME_IN_DAYS was not set for table T1.,,,,,,,,,,,,1," 
Answer A https://docs.snowflake.com/en/user-guide/data-time-travel#specifying-the-data-retention-period-for-an-object Changing the retention period for your account or individual objects changes the value for all lower-level objects that do not have a retention period explicitly set. For example: If you change the retention period at the schema level, all tables in the schema that do not have an explicit retention period inherit the new retention period.",
What table functions in the Snowflake Information Schema can be queried to retrieve information about directory tables? (Choose two.),multi-select,A. AUTO_REFRESH_REGISTRATION_HISTORY,B. EXTERNAL_TABLE_FILE_REGISTRATION_HISTORY,C. EXTERNAL_TABLE_FILES,D. MATERIALIZED_VIEW_REFRESH_HISTORY,E. STAGE_DIRECTORY_FILE_REGISTRATION_HISTORY,,,,,,,,,,,"1, 5","i checked it
Information Schema The Snowflake Snowflake Information Schema includes table functions you can query to retrieve information about your directory tables.  Table functions AUTO_REFRESH_REGISTRATION_HISTORY Retrieve the history of data files registered in the metadata of specified objects and the credits billed for these operations.  STAGE_DIRECTORY_FILE_REGISTRATION_HISTORY Retrieve information about the metadata history for a directory table, including any errors found when refreshing the metadata.
AUTO_REFRESH_REGISTRATION_HISTORY: Retrieve the history of data files registered in the metadata of specified objects and the credits billed for these operations. STAGE_DIRECTORY_FILE_REGISTRATION_HISTORY: Retrieve information about the metadata history for a directory table, including any errors found when refreshing the metadata.
https://docs.snowflake.com/en/sql-reference/functions/stage_directory_file_registration_history  https://docs.snowflake.com/en/sql-reference/functions/external_table_files",
"Which Snowflake table type persists until it is explicitly dropped, is available for all users with relevant privileges (across sessions), and has no Fail-safe period?",multiple-choice,A. External,B. Permanent,C. Temporary,D. Transient,,,,,,,,,,,,4,It's correct,
Snowflake’s access control framework combines which models for securing data? (Choose two.),multi-select,A. Attribute-based Access Control (ABAC),B. Discretionary Access Control (DAC),C. Access Control List (ACL),D. Role-based Access Control (RBAC),E. Rule-based Access Control (RuBAC),,,,,,,,,,,"2, 4",It's correct,
"Which semi-structured file format is a compressed, efficient, columnar data representation?",multiple-choice,A. Avro,B. JSON,C. TSV,D. Parquet,,,,,,,,,,,,4,"Apache Parquet is an open source, column-oriented data file format designed for efficient data storage and retrieval.",
How does Snowflake describe its unique architecture?,multiple-choice,A. A single-cluster shared data architecture using a central data repository and massively parallel processing (MPP),B. A multi-cluster shared data architecture using a central data repository and massively parallel processing (MPP),C. A single-cluster shared nothing architecture using a siloed data repository and symmetric multiprocessing (SMP),D. A multi-cluster shared nothing architecture using a siloed data repository and symmetric multiprocessing (SMP),,,,,,,,,,,,2,"B - https://docs.snowflake.com/en/user-guide/intro-key-concepts#snowflake-architecture
Answer B",
"Which data type can be used to load semi-structured data files directly, without explicitly describing the hierarchical structure of the data?",multiple-choice,A. TEXT,B. VARIANT,C. VARCHAR,D. VARBINARY,,,,,,,,,,,,2,"The VARIANT data type in Snowflake is specifically designed to handle semi-structured data files directly, without the need to explicitly describe the hierarchical structure of the data. This makes it ideal for loading and querying JSON, Avro, Parquet, ORC, and XML data.
Answer B",
"The following settings are configured:

THE MIN_DATA_RETENTION_TIME_IN_DAYS is set to 5 at the account level.
THE DATA_RETENTION_TIME_IN_DAYS is set to 2 at the object level.

For how many days will the data be retained at the object level?",multiple-choice,A. 2,B. 3,C. 5,D. 7,,,,,,,,,,,,3,"C is correct, as the retention time is set on the account level.
c is correct
If there is a minimum retention time set for the account, and a retention time explicitly set on an object, the effective retention time is the greater of the two: MAX(DATA_RETENTION_TIME_IN_DAYS, MIN_DATA_RETENTION_TIME_IN_DAYS).  https://docs.snowflake.com/en/release-notes/bcr-bundles/2023_04/bcr-928?utm_source=legacy&utm_medium=serp&utm_term=MIN_DATA_RETENTION_TIME_IN_DAYS",
Which key access control concept does Snowflake describe as a defined level of access to an object?,multiple-choice,A. Grant,B. Privilege,C. Role,D. Session,,,,,,,,,,,,2,"Privilege: A defined level of access to an object. Multiple distinct privileges may be used to control the granularity of access granted.
B.  see: https://docs.snowflake.com/en/user-guide/security-access-control-overview",
Which Snowflake object uses credits for maintenance?,multiple-choice,A. Regular table,B. Regular view,C. Materialized view,D. Cached query result,,,,,,,,,,,,3,"The automatic maintenance of materialized views consumes credits. For more details, see Materialized Views Cost (in this topic).
Answer C",
How many credits does a size 3X-Large virtual warehouse consume if it runs continuously for 2 hours?,multiple-choice,A. 32,B. 64,C. 128,D. 256,,,,,,,,,,,,3,"Cred per hour-Size 1-Xs 2-S 4-M 8-L 16-Xl 32-2xl 64-3xl 64 per hours for 2 hours = 128
https://docs.snowflake.com/en/user-guide/cost-understanding-compute 3x = 64*2 = 128",
What is the purpose of a Query Profile?,multiple-choice,A. To profile how many times a particular query was executed and analyze its usage statistics over time.,"B. To profile a particular query to understand the mechanics of the query, its behavior, and performance.",C. To profile the user and/or executing role of a query and all privileges and policies applied on the objects within the query.,D. To profile which queries are running in each warehouse and identify proper warehouse utilization and sizing for better performance and cost balancing.,,,,,,,,,,,,2,"Query Profile is a powerful tool for understanding the mechanics of queries. It can be used whenever you want or need to know more about the performance or behavior of a particular query
Answer B",
Which common query problems are identified by the Query Profile? (Choose two.),multi-select,A. Syntax error,B. Inefficient pruning,C. Ambiguous column names,D. Queries too large to fit in memory,E. Object does not exist or not authorized,,,,,,,,,,,"2, 4","https://docs.snowflake.com/en/user-guide/ui-query-profile#statistics B Pruning and D Spilling  Please stop quoting Chat GPT without verifying
Choose two. So best two. From https://docs.snowflake.com/en/user-guide/ui-query-profile. Pruning - information on the effects of table pruning. Spilling — information about disk usage for operations where intermediate results do not fit in memory.
B. Inefficient pruning E. Object does not exist or not authorized  Explanation:  A Query Profile in Snowflake is designed to provide insights into the performance characteristics of a specific query. Common query problems that can be identified by the Query Profile include:  B. Inefficient pruning: It can reveal whether pruning (filtering) of data during query execution is being performed efficiently. Inefficient pruning may result in the query scanning more data than necessary.  E. Object does not exist or not authorized: The Query Profile can identify issues related to missing or unauthorized objects in the query. This includes situations where tables or columns referenced in the query do not exist or the user does not have the necessary privileges.  Syntax errors (A), ambiguous column names (C), and queries too large to fit in memory (D) are typically identified during the parsing and compilation phases and may not be specifically addressed by the Query Profile.",
"While running a query on a virtual warehouse in auto-scale mode, additional clusters are started immediately if which setting is configured?",multiple-choice,A. MAX_CLUSTER_COUNT is increased and new_max_clusters is greater than running_clusters,B. MAX_CLUSTER_COUNT is decreased and new_max_clusters is less than running_clusters,C. MIN_CLUSTER_COUNT is increased and new_min_clusters is greater than running_clusters,D. MIN_CLUSTER_COUNT is decreased and new_min_clusters is less than running_clusters,,,,,,,,,,,,3,"Auto-scale: ↑ max If new_max_clusters > running_clusters, no changes until additional clusters are needed. ↓ max If new_max_clusters < running_clusters, excess clusters shut down when they finish executing statements and the scaling policy conditions are met. ↑ min If new_min_clusters > running_clusters, additional clusters immediately started to meet the minimum. ↓ min If new_min_clusters < running_clusters, excess clusters shut down when they finish executing statements and the scaling policy conditions are met.
C.   https://docs.snowflake.com/en/user-guide/warehouses-multicluster#increasing-or-decreasing-clusters-for-a-multi-cluster-warehouse",
"Which Snowflake role can manage any object grant globally, including modifying and revoking grants?",multiple-choice,A. USERADMIN,B. ORGADMIN,C. SYSADMIN,D. SECURITYADMIN,,,,,,,,,,,,4,"SECURITYADMIN (Security Administrator):  -This role can manage any object grant globally. -It has the ability to create, monitor, and manage users and roles. -It is granted the MANAGE GRANTS security privilege to be able to modify any grant, including revoking it. -It inherits the privileges of the USERADMIN role via the system role hierarchy.
https://docs.snowflake.com/en/user-guide/security-access-control-considerations",
What is the MINIMUM permission needed to access a file URL from an external stage?,multiple-choice,A. MODIFY,B. READ,C. SELECT,D. USAGE,,,,,,,,,,,,4,"USAGE (external stage) or READ (internal stage)
https://docs.snowflake.com/en/sql-reference/functions/build_stage_file_url",
"In the Data Exchange, who can get or request data from the listings? (Choose two.)",multi-select,A. Users with ACCOUNTADMIN role,B. Users with SYSADMIN role,C. Users with ORGADMIN role,D. Users with IMPORT SHARE privilege,E. Users with MANAGE GRANTS privilege,,,,,,,,,,,"1, 4","All users can browse listings in the Data Exchange, but only users with the ACCOUNTADMIN role or the IMPORT SHARE privilege can get or request data.
https://docs.snowflake.com/en/user-guide/data-exchange-using",
What does Snowflake attempt to do if any of the compute resources for a virtual warehouse fail to provision during start-up?,multiple-choice,A. Repair the failed resources.,B. Restart the failed resources.,C. Queue the failed resources.,D. Provision the failed resources.,,,,,,,,,,,,1,"https://docs.snowflake.com/en/user-guide/warehouses-tasks#starting-or-resuming-a-warehouse
A. Repair the failed resources.
Answer A If any of the compute resources for the warehouse fail to provision during start-up, Snowflake attempts to repair the failed resources.  https://docs.snowflake.com/en/user-guide/warehouses-tasks",
Which command is used to take away staged files from a Snowflake stage after a successful data ingestion?,multiple-choice,A. DELETE,B. DROP,C. REMOVE,D. TRUNCATE,,,,,,,,,,,,3,"Answer C. https://docs.snowflake.com/en/user-guide/data-load-considerations-manage and https://docs.snowflake.com/en/sql-reference/sql/remove
Answer C",
The Snowflake VARIANT data type imposes a 16 MB size limit on what?,multiple-choice,A. An individual row,B. An individual column,C. A view,D. A file in a stage,,,,,,,,,,,,1,"A us correct
https://docs.snowflake.com/en/user-guide/semistructured-considerations The VARIANT data type imposes a 16 MB size limit on individual rows.
A is the correct Answer",
Which Snowflake feature records changes made to a table so actions can be taken using that change data capture?,multiple-choice,A. Materialized View,B. Pipe,C. Stream,D. Task,,,,,,,,,,,,3,"Answer C
c correct",
"Which system-defined, read-only view displays information on column lineage that specifies how data flows from source to target in a SQL write operation?",multiple-choice,A. ACCESS_HISTORY,B. LOAD_HISTORY,C. QUERY_HISTORY,D. COPY_HISTORY,,,,,,,,,,,,1,"Access History in Snowflake refers to when the user query reads data and when the SQL statement performs a data write operation, such as INSERT, UPDATE, and DELETE along with variations of the COPY command, from the source data object to the target data object. The user access history can be found by querying the Account Usage ACCESS_HISTORY view.
it's correct see: https://docs.snowflake.com/en/user-guide/access-history
It's A  ""Column lineage Column lineage (i.e. access history for columns) extends the Account Usage ACCESS_HISTORY view to specify how data flows from the source column to the target column in a write operation. Snowflake tracks the data from the source columns through all subsequent table objects that reference data from the source columns (e.g. INSERT, MERGE, CTAS) provided that objects in the lineage chain are not dropped. Snowflake makes column lineage accessible by enhancing the objects_modified column in the ACCESS_HISTORY view."" --> https://docs.snowflake.com/en/user-guide/access-history",
Who can create network policies within Snowflake? (Choose two.),multi-select,A. SYSADMIN only,B. ORGADMIN only,C. SECURITYADMIN or higher roles,D. A role with the CREATE NETWORK POLICY privilege,E. A role with the CREATE SECURITY INTEGRATION privilege,,,,,,,,,,,"3, 4","https://docs.snowflake.com/en/sql-reference/sql/create-network-policy
C & D see: https://docs.snowflake.com/en/user-guide/network-policies",
Who can grant object privileges in a regular schema?,multiple-choice,A. Object owner,B. Schema owner,C. Database owner,D. SYSADMIN,,,,,,,,,,,,1,"A because it's not managed schema.  For managed Schema Schema Owner can grant Previleges.
https://docs.snowflake.com/en/user-guide/security-access-control-configure#label-managed-access-schemas  Managed access schemas improve security by locking down privilege management on objects.  In regular (i.e. non-managed) schemas, object owners (i.e. a role with the OWNERSHIP privilege on an object) can grant access on their objects to other roles, with the option to further grant those roles the ability to manage object grants.  With managed access schemas, object owners lose the ability to make grant decisions. Only the schema owner (i.e. the role with the OWNERSHIP privilege on the schema) or a role with the MANAGE GRANTS privilege can grant privileges on objects in the schema, including future grants, centralizing privilege management.
In regular (i.e. non-managed) schemas, object owners (i.e. a role with the OWNERSHIP privilege on an object) can grant access on their objects to other roles https://docs.snowflake.com/en/user-guide/security-access-control-configure#label-managed-access-schemas",
Which command can be used to list all the file formats for which a user has access privileges?,multiple-choice,A. LIST,B. ALTER FILE FORMAT,C. DESCRIBE FILE FORMAT,D. SHOW FILE FORMATS,,,,,,,,,,,,4,"need discussion on 930 934 938 939 940 943 945 951 952 953 955 960-1024 Thanks.
it's correct see: https://docs.snowflake.com/en/sql-reference/sql/show-file-formats",
"A Snowflake user runs a query for 36 seconds on a size 2XL virtual warehouse.

What would be the credit consumption?",multiple-choice,A. Snowflake will charge for 36 seconds at the rate of 32 credits per hour.,B. Snowflake will charge for 36 seconds at the rate of 64 credits per hour.,C. Snowflake will charge for 60 seconds at the rate of 32 credits per hour.,D. Snowflake will charge for 60 seconds at the rate of 64 credits per hour.,,,,,,,,,,,,3,"The rate of 64 credits per hour is based on the size of the virtual warehouse. In Snowflake, the credit consumption rate for a virtual warehouse is determined by its size. A 2XL virtual warehouse consumes 64 credits per hour
L 8/ XL 16/2XL 32
https://docs.snowflake.com/en/user-guide/warehouses-overview#warehouse-size  2X -> 32 credit /hour considering min 60 seconds a VM runs",
What value provides information about disk usage for operations where intermediate results do not fit in memory in a Query Profile?,multiple-choice,A. IO,B. Network,C. Pruning,D. Spilling,,,,,,,,,,,,4,"D  https://community.snowflake.com/s/article/Performance-impact-from-local-and-remote-disk-spilling
D is correct",
"Regardless of which notation is used, what are considerations for writing the column name and element names when traversing semi-structured data?",multiple-choice,A. The column name and element names are both case-sensitive.,B. The column name and element names are both case-insensitive.,C. The column name is case-sensitive but element names are case-insensitive.,D. The column name is case-insensitive but element names are case-sensitive.,,,,,,,,,,,,4,"Regardless of which notation you use, the column name is case-insensitive but element names are case-sensitive. For example, (src is a column name) in the following list, the first two paths are equivalent, but the third is not: src:salesperson.name SRC:salesperson.name SRC:Salesperson.Name
D is correct; https://docs.snowflake.com/en/user-guide/querying-semistructured",
Which Snowflake data type is used to store JSON key value pairs?,multiple-choice,A. TEXT,B. BINARY,C. STRING,D. VARIANT,,,,,,,,,,,,4,D is correct https://docs.snowflake.com/en/sql-reference/data-types-semistructured VARIANT and OBJECT can contain key-value pairs,
How are network policies defined in Snowflake?,multiple-choice,A. They are a set of rules that define the network routes within Snowflake.,B. They are a set of rules that dictate how Snowflake accounts can be used between multiple users.,C. They are a set of rules that define how data can be transferred between different Snowflake accounts within an organization.,D. They are a set of rules that control access to Snowflake accounts by specifying the IP addresses or ranges of IP addresses that are allowed to connect to Snowflake.,,,,,,,,,,,,4,"Snowflake recommends using network rules in conjunction with network policies rather using this parameter. Use the BLOCKED_NETWORK_RULE_LIST parameter to specify network rules that contain IPv4 addresses.  Specifies a list of IPv4 addresses that are denied access to your Snowflake account. This is referred to as the blocked list.  Set this parameter only when you are allowing access to a range of IP addresses (specified in ALLOWED_IP_LIST), but want to deny access to one or more IP addresses within the range.",
What is the only supported character set for loading and unloading data from all supported file formats?,multiple-choice,A. UTF-8,B. UTF-16,C. ISO-8859-1,D. WINDOWS-1253,,,,,,,,,,,,1,"For loading data from delimited files (CSV, TSV, etc.), UTF-8 is the default.   For loading data from all other supported file formats (JSON, Avro, etc.), as well as unloading data, UTF-8 is the only supported character set.
A.  https://docs.snowflake.com/en/sql-reference/sql/create-file-format",
Which function is used to convert rows in a relational table to a single VARIANT column?,multiple-choice,A. ARRAY_AGG,B. OBJECT_AGG,C. ARRAY_CONSTRUCT,D. OBJECT_CONSTRUCT,,,,,,,,,,,,4,D is correct. https://docs.snowflake.com/en/user-guide/data-unload-considerations,
Which command can be used to delete staged files from a Snowflake stage when the files are no longer needed?,multiple-choice,A. DELETE,B. DROP,C. REMOVE,D. TRUNCATE TABLE,,,,,,,,,,,,3,"REMOVE Removes files from either an external (external cloud storage) or internal (i.e. Snowflake) stage. https://docs.snowflake.com/en/sql-reference/sql/remove  Staged files can be deleted from a Snowflake stage (user stage, table stage, or named stage) using the following methods:  Files that were loaded successfully can be deleted from the stage during a load by specifying the PURGE copy option in the COPY INTO <table> command.  After the load completes, use the REMOVE command to remove the files in the stage. https://docs.snowflake.com/en/user-guide/data-load-considerations-manage",
"A virtual warehouse initially suffers from poor performance as a result of queries from multiple concurrent processes that are queuing. Over time, the problem resolved.

What action can be taken to prevent this from happening again?",multiple-choice,A. Increase the size of the virtual warehouse.,B. Add a cluster key to the most used JOIN key.,C. Change the multi-cluster settings to add additional clusters.,D. Enable the search optimization service for the underlying tables.,,,,,,,,,,,,3,"Multi-cluster warehouses are designed specifically for handling queuing and performance issues related to large numbers of concurrent users and/or queries. In addition, multi-cluster warehouses can help automate this process if your number of users/queries tend to fluctuate. https://docs.snowflake.com/en/user-guide/warehouses-considerations#multi-cluster-warehouses-improve-concurrency
C is correct",
What action can be performed using the GET command in Snowflake?,multiple-choice,A. Automatically rename downloaded files.,B. Automatically decrypt downloaded data on a client machine.,C. Download data files from Snowflake internal stages to a local directory/folder.,D. Download data files from Snowflake external stages to a local directory/folder.,,,,,,,,,,,,3,"GET Downloads data files from one of the following Snowflake stages to a local directory/folder on a client machine: Named internal stage. Internal stage for a specified table. Internal stage for the current user. GET does not support downloading files from external stages. To download files from external stages, use the utilities provided by the cloud service. PUT has the same limitation: doesn't support uploading files to an external stage: https://docs.snowflake.com/en/sql-reference/sql/put
C is ok",
Which validation option is the only one that supports the COPY INTO [location] command?,multiple-choice,A. RETURN_ROWS,B. RETURN_[n]_ROWS,C. RETURN_ERRORS,D. RETURN_ALL_ERRORS,,,,,,,,,,,,1,"For sure, those who designed these questions did not have complete intellectual and mental health. Also, I believe that it will be a big problem for the Snowflake company over time because the way the questions are designed and the content is very stereotyped and memory-oriented. Answer these questions correctly
A. https://docs.snowflake.com/en/sql-reference/sql/copy-into-location",
"What are the correct settings for column and element names, regardless of which notation is used while accessing elements in a JSON object?",multiple-choice,A. Both the column name and the element name are case-insensitive.,B. Both the column name and the element name are case-sensitive.,C. The column name is case-sensitive and the element names are case-insensitive.,D. The column name is case-insensitive and the element name is case-sensitive.,,,,,,,,,,,,4,"D. The column name is case-insensitive and the element name is case-sensitive. https://docs.snowflake.com/en/user-guide/querying-semistructured Important Regardless of which notation you use, the column name is case-insensitive but element names are case-sensitive. For example, in the following list, the first two paths are equivalent, but the third is not: src:salesperson.name SRC:salesperson.name SRC:Salesperson.Name
https://docs.snowflake.com/en/user-guide/json-basics-tutorial-query",
How can the Query Profile be used to identify the costliest operator of a query?,multiple-choice,A. Select any node in the operator tree and look at the number of micro-partitions scanned.,B. Find the operator node with the highest fraction of time or percentage of total time.,C. Select the TableScan operator node and look at the percentage scanned from cache.,D. Look at the number of rows between operator nodes across the operator tree.,,,,,,,,,,,,2,"Answer B :  Operator Nodes by Execution Time:  A collapsible panel in the operator tree pane lists nodes by execution time in descending order, enabling users to quickly locate the costliest operator nodes in terms of execution time. The panel lists all nodes that lasted for 1% or longer of the total execution time of the query (or the execution time for the displayed query step, if the query was executed in multiple processing steps).  https://docs.snowflake.com/en/user-guide/ui-query-profile
B is correct https://docs.snowflake.com/en/user-guide/ui-query-profile",
"In order to access Snowflake Marketplace listings, who needs to accept the Snowflake Consumer Terms of Service?",multiple-choice,A. SYSADMIN,B. SECURITYADMIN,C. ACCOUNTADMIN,D. ORGADMIN,,,,,,,,,,,,4,"You must be an organization administrator (i.e. a user granted the ORGADMIN role) to accept the terms
D. ORGADMIN https://other-docs.snowflake.com/en/collaboration/consumer-becoming The organization administrator only needs to accept the Snowflake Provider and Consumer Terms once for your organization. After the terms have been accepted, anyone in your organization that has a role with the necessary privileges can become a consumer of listings.  Note  You must be an organization administrator (i.e. a user granted the ORGADMIN role) to accept the terms.",
Which statistics are displayed in a Query Profile that indicate that intermediate results do not fit in memory? (Choose two.),multi-select,A. Bytes scanned,B. Partitions scanned,C. Bytes spilled to local storage,D. Bytes spilled to remote storage,E. Percentage scanned from cache,,,,,,,,,,,"3, 4","https://docs.snowflake.com/en/user-guide/ui-query-profile
correct",
How can a dropped internal stage be restored?,multiple-choice,A. Enable Time Travel.,B. Clone the dropped stage.,C. Execute the UNDROP command.,D. Recreate the dropped stage.,,,,,,,,,,,,4,"From docs  https://docs.snowflake.com/en/sql-reference/sql/drop-stage#:~:text=Usage%20notes,must%20be%20recreated.
https://docs.snowflake.com/en/sql-reference/sql/undrop You can undrop DB, SCHEMA, TABLE, also ACCOUNT and TAG
D. Recreate the dropped stage. https://docs.snowflake.com/en/user-guide/data-time-travel#introduction-to-time-travel Using Time Travel, you can perform the following actions within a defined period of time:  Query data in the past that has since been updated or deleted.  Create clones of entire tables, schemas, and databases at or before specific points in the past.  Restore tables, schemas, and databases that have been dropped.  Doesn't look like you can restore a dropped stage using UNDROP and time travel. Looks like you just need to recreate it using your SQL definition.",
Which command line flags can be used to log into a Snowflake account using SnowSQL? (Choose two.),multi-select,A. -d,B. -o,C. -e,D. -a,E. -c,,,,,,,,,,,"1, 4","-a, --accountname TEXT Your account identifier. Honors $SNOWSQL_ACCOUNT. -d, --dbname TEXT  Database to use. Honors $SNOWSQL_DATABASE. https://docs.snowflake.com/en/user-guide/snowsql-start
AD. https://docs.snowflake.com/en/user-guide/snowsql-use",
What is a key benefit of using organizations in Snowflake?,multiple-choice,A. Ability to use ACCOUNT_USAGE views,B. Ability to use zero-copy cloning across accounts,C. Ability to consolidate account management and billing,D. Ability to access new releases for testing and validation purposes,,,,,,,,,,,,3,"An organization is a first-class Snowflake object that links the accounts owned by your business entity. Organizations simplify account management and billing, Replication and Failover/Failback, Snowflake Secure Data Sharing, and other account administration tasks.
https://docs.snowflake.com/en/user-guide/organizations",
Which privilege is required on a virtual warehouse to abort any existing executing queries?,multiple-choice,A. USAGE,B. OPERATE,C. MODIFY,D. MONITOR,,,,,,,,,,,,2,"B is correct OPERATE Enables changing the state of a warehouse (stop, start, suspend, resume). In addition, enables viewing current and past queries executed on a warehouse and aborting any executing queries. https://docs.snowflake.com/en/user-guide/security-access-control-privileges#virtual-warehouse-privileges",
Which command should be used to look into the validity of an XML object in Snowflake?,multiple-choice,A. XMLGET,B. TO_XML,C. PARSE_XML,D. CHECK_XML,,,,,,,,,,,,3,"https://docs.snowflake.com/en/sql-reference/functions/check_xml PREVIEW FEATURE — OPEN  Enabled for all accounts.  Checks the validity of an XML document. If the input string is NULL or a valid XML document, the output is NULL. In case of an XML parsing error, the output string contains the error message.
Also see this one, it has a similar purpose, but it's for JSON: https://docs.snowflake.com/en/sql-reference/functions/check_json. Checks the validity of a JSON document. If the input string is a valid JSON document or a NULL, the output is NULL (i.e. no error). If the input cannot be translated to a valid JSON value, the output string contains the error message.",
Who can activate a network policy for users in a Snowflake account? (Choose two.),multi-select,A. ACCOUNTADMIN,B. USERADMIN,C. PUBLIC,D. SYSADMIN,E. Any role that has the global ATTACH POLICY privilege,,,,,,,,,,,"1, 5","AE Only security administrators (i.e. users with the SECURITYADMIN role) or higher or a role with the global ATTACH POLICY privilege can activate a network policy for an account. Once the policy is associated with your account, Snowflake restricts access to your account based on the allowed list and blocked list.
Answer - AE Only security administrators (i.e. users with the SECURITYADMIN role) or higher or a role with the global ATTACH POLICY privilege can activate a network policy for an account. Once the policy is associated with your account, Snowflake restricts access to your account based on the allowed list and blocked list.",
For which use cases is running a virtual warehouse required? (Choose two.),multi-select,A. When creating a table,B. When loading data into a table,C. When unloading data from a table,D. When executing a SHOW command,E. When executing a LIST command,,,,,,,,,,,"2, 3","https://docs.snowflake.com/en/user-guide/warehouses
Executing SQL SELECT statements that require compute resources (e.g. retrieving rows from tables and views).  Performing DML operations, such as:  Updating rows in tables (DELETE , INSERT , UPDATE).  Loading data into tables (COPY INTO <table>).  Unloading data from tables (COPY INTO <location>).",
What action should be taken if a Snowflake user wants to share a newly created object in a database with consumers?,multiple-choice,A. Use the automatic sharing feature for seamless access.,B. Drop the object and then re-add it to the database to trigger sharing.,C. Recreate the object with a different name in the database before sharing.,D. Use the GRANT privilege ... TO SHARE command to grant the necessary privileges.,,,,,,,,,,,,4,"To make a new object available to consumers, you must use the GRANT <privilege> … TO SHARE command to explicitly add the object to the share.
https://docs.snowflake.com/en/user-guide/data-sharing-gs",
Which Snowflake privilege is required on a pipe object to pause or resume pipes?,multiple-choice,A. OPERATE,B. READ,C. SELECT,D. USAGE,,,,,,,,,,,,1,A non-owner role with the OPERATE privilege on the pipe can pause or resume a pipe (using ALTER PIPE … SET PIPE_EXECUTION_PAUSED = TRUE | FALSE).  SQL operations on schema objects also require the USAGE privilege on the database and schema that contain the object.,
Which commands can a Snowflake user execute to specify a cluster key for a table? (Choose two.),multi-select,A. CREATE,B. UPDATE,C. ALTER,D. SET,E. SHOW,,,,,,,,,,,"1, 3","https://docs.snowflake.com/en/user-guide/tables-clustering-keys
A clustering key can be defined at table creation (using the CREATE TABLE command) or afterward (using the ALTER TABLE command).",
Authorization to execute CREATE [object] statements comes only from which role?,multiple-choice,A. Primary role,B. Secondary role,C. Application role,D. Database role,,,,,,,,,,,,1,"A. Primary role Note that authorization to execute CREATE <object> statements to create objects is provided by the primary role. https://docs.snowflake.com/en/sql-reference/sql/use-secondary-roles
Primary role is the correct answer",
"Which VALIDATION_MODE value will return the errors across the files specified in a COPY command, including files that were partially loaded during an earlier load?",multiple-choice,A. RETURN_-1_ROWS,B. RETURN_n_ROWS,C. RETURN_ERRORS,D. RETURN_ALL_ERRORS,,,,,,,,,,,,4,"RETURN_ALL_ERRORS  Returns all errors across all files specified in the COPY statement, including files with errors that were partially loaded during an earlier load because the ON_ERROR copy option was set to CONTINUE during the load. D
D RETURN_ALL_ERRORS Returns all errors across all files specified in the COPY statement, including files with errors that were partially loaded during an earlier load because the ON_ERROR copy option was set to CONTINUE during the load. https://docs.snowflake.com/en/sql-reference/sql/copy-into-table",
"Which command is used to upload data files from a local directory or folder on a client machine to an internal stage, for a specified table?",multiple-choice,A. GET,B. PUT,C. CREATE STREAM,D. COPY INTO [location],,,,,,,,,,,,2,"B is correct https://docs.snowflake.com/en/sql-reference/sql/put Uploads data files from a local file system to one of the following Snowflake stages:  A named internal stage.  A specified table’s internal stage.  The current user’s internal stage.  PUT does not support uploading files to external stages. To upload files to external stages, use the utilities provided by the cloud service.",
Which governance feature is supported by all Snowflake editions?,multiple-choice,A. Object tags,B. Masking policies,C. Row access policies,D. OBJECT_DEPENDENCIES view,,,,,,,,,,,,4,"D. OBJECT_DEPENDENCIES view
Same applies to B & C.  A, B & C all starts from Enterprise. So D is correct answer
A is not correct.  Object tagging is available only from Enterprise Edition.  https://docs.snowflake.com/en/user-guide/object-tagging",
Which chart type is supported in Snowsight for Snowflake users to visualize data with dashboards?,multiple-choice,A. Area chart,B. Box plot,C. Heat grid,D. Pie chart,,,,,,,,,,,,3,Bar charts  Line charts  Scatterplots  Heat grids  Scorecards,
At what level is the MIN_DATA_RETENTION_TIME_IN_DAYS parameter set?,multiple-choice,A. Account,B. Database,C. Schema,D. Table,,,,,,,,,,,,1,MIN_DATA_RETENTION_TIME_IN_DAYS - Account level DATA_RETENTION_TIME_IN_DAYS - Object / Account level  Max of these values apply.,
Which function returns an integer between 0 and 100 when used to calculate the similarity of two strings?,multiple-choice,A. APPROXIMATE_SIMILARITY,B. JAROWINKLER_SIMILARITY,C. APPROXIMATE_JACCARD_INDEX,D. MINHASH_COMBINE,,,,,,,,,,,,2,"Computes the Jaro-Winkler similarity between two input strings. The function returns an integer between 0 and 100, where 0 indicates no similarity and 100 indicates an exact match.
https://docs.snowflake.com/en/sql-reference/functions/jarowinkler_similarity",
Which Snowflake data governance feature can support auditing when a user query reads column data?,multiple-choice,A. Access History,B. Data classification,C. Column-level security,D. Object dependencies,,,,,,,,,,,,1,"it's A - Allows the auditing of the user access history through the Account Usage ACCESS_HISTORY View.
B and C https://docs.snowflake.com/en/guides-overview-govern",
Which categories are included in the execution time summary in a Query Profile? (Choose two.),multi-select,A. Pruning,B. Spilling,C. Initialization,D. Local Disk I/O,E. Percentage of data read from cache,,,,,,,,,,,"3, 4","https://docs.snowflake.com/en/user-guide/ui-query-profile Execution Time Execution time provides information about “where the time was spent” during the processing of a query. Time spent can be broken down into the following categories, displayed in the following order:  Processing — time spent on data processing by the CPU.  Local Disk IO — time when the processing was blocked by local disk access.  Remote Disk IO — time when the processing was blocked by remote disk access.  Network Communication — time when the processing was waiting for the network data transfer.  Synchronization — various synchronization activities between participating processes.  Initialization — time spent setting up the query processing.
https://docs.snowflake.com/en/user-guide/ui-query-profile",
Which command can be used to list all network policies available in an account?,multiple-choice,A. DESCRIBE SESSION POLICY,B. DESCRIBE NETWORK POLICY,C. SHOW SESSION POLICIES,D. SHOW NETWORK POLICIES,,,,,,,,,,,,4,https://docs.snowflake.com/en/sql-reference/sql/show-network-policies,
Which type of loop requires a BREAK statement to stop executing?,multiple-choice,A. FOR,B. LOOP,C. REPEAT,D. WHILE,,,,,,,,,,,,2,"https://docs.snowflake.com/en/developer-guide/snowflake-scripting/loops#terminating-a-loop BREAK is required in a LOOP but is not necessary in WHILE, FOR, and REPEAT.
https://docs.snowflake.com/en/developer-guide/snowflake-scripting/loops",
Which virtual warehouse consideration can help lower compute resource credit consumption?,multiple-choice,A. Setting up a multi-cluster virtual warehouse,B. Resizing the virtual warehouse to a larger size,C. Automating the virtual warehouse suspension and resumption settings,D. Increasing the maximum cluster count parameter for a multi-cluster virtual warehouse,,,,,,,,,,,,3,"A - it won't  B - it can, if your queries take a very long time to execute. However, it's more likely to increase  C - it can D - it won't
https://docs.snowflake.com/en/user-guide/warehouses-considerations#automating-warehouse-suspension https://docs.snowflake.com/en/user-guide/warehouses-considerations#automating-warehouse-resumption",
"To use the OVERWRITE option on INSERT, which privilege must be granted to the role?",multiple-choice,A. TRUNCATE,B. DELETE,C. UPDATE,D. SELECT,,,,,,,,,,,,2,"Based on the Snowflake documentation, the INSERT statement with the OVERWRITE option does not require the TRUNCATE privilege. Instead, it requires the DELETE privilege. This allows the role to delete existing rows in the target table before inserting the new data.
Correct.  To use the OVERWRITE option on INSERT, you must use a role that has DELETE privilege on the table because OVERWRITE will delete the existing records in the table.
https://docs.snowflake.com/en/sql-reference/sql/insert",
What happens when a suspended virtual warehouse is resized in Snowflake?,multiple-choice,A. It will return an error.,B. It will return a warning.,C. The suspended warehouse is resumed and new compute resources are provisioned immediately.,D. The additional compute resources are provisioned when the warehouse is resumed.,,,,,,,,,,,,4,https://docs.snowflake.com/en/user-guide/warehouses-tasks,
Which task is supported by the use of Access History in Snowflake?,multiple-choice,A. Data backups,B. Cost monitoring,C. Compliance auditing,D. Performance optimization,,,,,,,,,,,,3,"Agree with C
https://docs.snowflake.com/en/user-guide/access-history",
Which feature of Snowflake’s Continuous Data Protection (CDP) has associated costs?,multiple-choice,A. Fail-safe,B. Network policies,C. End-to-end encryption,D. Multi-Factor Authentication (MFA),,,,,,,,,,,,1,A - fail-safe are part of CDP and have associated storage costs,
"When enabling access to unstructured data, which URL permits temporary access to a staged file without the need to grant privileges to the stage or to issue access tokens?",multiple-choice,A. File URL,B. Scoped URL,C. Relative URL,D. Pre-Signed URL,,,,,,,,,,,,2,"B - Scoped url are for staged files https://docs.snowflake.com/en/user-guide/unstructured-intro#types-of-urls-available-to-access-files
The answer should be D - Pre-signed URL. ScopeURL you need access to stage as well.
Pre Signed URL need Access tokens but Scoped URL doesnt require access token and expires in 24 Hours
Answer is B Scoped URL: Encoded URL that permits temporary access to a staged file without granting privileges to the stage.  The URL expires when the persisted query result period ends (i.e. the results cache expires), which is currently 24 hours. Source: https://docs.snowflake.com/en/user-guide/unstructured-intro#:~:text=Scoped%20URL,granting%20privileges%20to%20the%20stage.",
"Which Snowflake function is maintained separately from the data and helps to support features such as Time Travel, Secure Data Sharing, and pruning?",multiple-choice,A. Column compression,B. Data clustering,C. Micro-partitioning,D. Metadata management,,,,,,,,,,,,4,"D is correct the other answers support these features but they are not maintained separately
Maybe metadata cus it's the only thing which is separate from data  ABC are all about data, not separate from the data D",
"A tag object has been assigned to a table (TABLE_A) in a schema within a Snowflake database.

Which CREATE object statement will automatically assign the TABLE_A tag to a target object?",multiple-choice,A. CREATE TABLE [table_name] LIKE TABLE_A;,B. CREATE VIEW [view_name] AS SELECT * FROM TABLE_A;,C. CREATE TABLE [table_name] AS SELECT * FROM TABLE_A;,D. CREATE MATERIALIZED VIEW [view_name] AS SELECT * FROM TABLE_A;,,,,,,,,,,,,1,"A is correct
it's correct
https://docs.snowflake.com/en/user-guide/object-tagging  With CREATE TABLE … LIKE, tags assigned to the source table are assigned to the target table.",
"In addition to performing all the standard steps to share data, which privilege must be granted on each database referenced by a secure view in order to be shared?",multiple-choice,A. READ,B. REFERENCES,C. REFERENCE_USAGE,D. USAGE,,,,,,,,,,,,3,"https://docs.snowflake.com/en/user-guide/data-sharing-multiple-db  c
it's correct
https://docs.snowflake.com/en/release-notes/bcr-bundles/2023_02/bcr-944",
"Which function can be used with the COPY INTO [LOCATION] statement to convert rows from a relational table to a single VARIANT column, and to unload rows into a JSON file?",multiple-choice,A. FLATTEN,B. OBJECT_AS,C. OBJECT_CONSTRUCT,D. TO_VARIANT,,,,,,,,,,,,3,"C - this type of question comes back often
D is correct D. USAGE: The USAGE privilege on a database allows users to access objects within the database, which is necessary for the users who will be accessing the shared secure view. This privilege is required to ensure that users can resolve references to objects in the database when querying the secure view.",
Which type of role can be granted to a share?,multiple-choice,A. Account role,B. Custom role,C. Database role,D. Secondary role,,,,,,,,,,,,3,"Grant the database role to a share and grant future privileges on an object to the database role:  GRANT DATABASE ROLE dbr1 TO SHARE myshare; GRANT SELECT ON FUTURE TABLES IN SCHEMA sh TO DATABASE ROLE dbr1;
https://docs.snowflake.com/en/sql-reference/sql/grant-database-role-share",
"When unloading data with the COPY INTO [location] command, what is the purpose of the PARTITION BY <expression> parameter option?
							
						</expression>",multiple-choice,A. To sort the contents of the output file by the specified expression.,B. To delimit the records in the output file using the specified expression.,C. To include a new column in the output using the specified window function expression.,"D. To split the output into multiple files, one for each distinct value of the specified expression.",,,,,,,,,,,,4,"https://docs.snowflake.com/en/sql-reference/sql/copy-into-location#optional-parameters
D is correct.  https://docs.snowflake.com/en/user-guide/data-unload-overview",
What are potential impacts of storing non-native values like dates and timestamps in a VARIANT column in Snowflake?,multiple-choice,A. Faster query performance and increased storage consumption,B. Slower query performance and increased storage consumption,C. Faster query performance and decreased storage consumption,D. Slower query performance and decreased storage consumption,,,,,,,,,,,,2,"Non-native values such as dates and timestamps are stored as strings when loaded into a VARIANT column, so operations on these values could be slower and also consume more space than when stored in a relational column with the corresponding data type.
https://docs.snowflake.com/en/sql-reference/data-types-semistructured",
Which views are included in the DATA_SHARING_USAGE schema? (Choose two.),multiple-choice,A. ACCESS_HISTORY,B. DATA_TRANSFER_HISTORY,C. WAREHOUSE_METERING_HISTORY,D. MONETIZED_USAGE_DAILY,E. LISTING_TELEMETRY_DAILY,,,,,,,,,,,"4, 5","DE agreed
It is D and E
D & E  https://docs.snowflake.com/en/sql-reference/data-sharing-usage
Correct Answers: D. MONETIZED_USAGE_DAILY and E. LISTING_TELEMETRY_DAILY MONETIZED_USAGE_DAILY: This view provides daily usage data for monetized data sharing, which is relevant for tracking and analyzing how shared data is being accessed and utilized in a monetized context. LISTING_TELEMETRY_DAILY: This view contains daily telemetry data for data listings, offering insights into the activity and interactions with data listings shared via Snowflake.",
Which Snowflake object contains all the information required to share a database?,multiple-choice,A. Private listing,B. Secure view,C. Sequence,D. Share,,,,,,,,,,,,4,"D - straightforward
D.  https://docs.snowflake.com/en/user-guide/data-sharing-intro",
What is the PRIMARY factor that determines the cost of using a virtual warehouse in Snowflake?,multiple-choice,A. The type of SQL statements executed,B. The number of tables or databases queried,C. The amount of data stored in the warehouse,D. The length of time the compute resources in each cluster run,,,,,,,,,,,,4,"Agree with D every other answers determines costs but D is the main one
D.  https://docs.snowflake.com/en/user-guide/cost-understanding-compute",
"Which function generates a Snowflake-hosted file URL to a staged file using the stage name and relative file path as inputs, with a file URL that does not expire?",multiple-choice,A. BUILD_SCOPED_FILE_URL,B. BUILD_STAGE_FILE_URL,C. GET_ABSOLUTE_PATH,D. GET_PRESIGNED_URL,,,,,,,,,,,,2,B - Scoped and presigned expires and get absolute path isn't working like that,
"When a Snowflake user loads CSV data from a stage, which COPY INTO [table] command guideline should they follow?",multiple-choice,"A. The CSV field delimiter must be a comma character (‘,’).",B. The number of columns in each row should be consistent.,C. The data file in the stage must be in a compressed format.,D. The data file must have the same number of columns as the target table.,,,,,,,,,,,,2,"B: The number of columns in each row should be consistent.
The number of columns in each row should be consistent.
B is correct.   Any valid character can be used as a field delimiter (not A) Snowflake recommends that files be compressed, but it's not required (Not C) You can drop columns from the file to the target table (Not D)  https://docs.snowflake.com/en/user-guide/data-load-considerations-prepare#preparing-delimited-text-files
https://docs.snowflake.com/en/user-guide/data-load-transform",
"A user creates a stage using the following command:


CREATE STAGE mystage -
DIRECTORY = (ENABLE = TRUE)
FILE_FORMAT = myformat;

What will be the outcome?",multiple-choice,A. A stage with a directory table set to automatically refresh will be created.,B. A stage with a directory table that has metadata that must be manually refreshed will be created.,C. An error will be received stating that the storage location for the stage must be identified when creating a stage with a directory table.,D. The command will fail to run because the name of the directory table is not specified.,,,,,,,,,,,,2,"The below command creates a directory table for an internal stage with auto refresh  https://docs.snowflake.com/en/user-guide/data-load-dirtables-auto  CREATE STAGE my_int_stage  DIRECTORY = (  ENABLE = TRUE  AUTO_REFRESH = TRUE  );
Answer is B. https://docs.snowflake.com/en/user-guide/data-load-dirtables-manage#label-directory-table-refreshes Directory tables on internal stages require manual metadata refreshes. This command creates an internal Snowflake stage since it doesn't specify an external cloud storage location. I ran this command in Snowflake and it was valid and using SHOW STAGES; I validated that it was an internal stage, so the answer is B
B. https://docs.snowflake.com/en/user-guide/data-load-dirtables-manage ""Directory tables on internal stages require manual metadata refreshes.""  https://docs.snowflake.com/en/user-guide/data-load-dirtables-manage#label-directory-table-auto-refreshes ""You can automatically refresh the metadata for a directory table by using the event messaging service for your cloud storage service.""",
Which statistics on a Query Profile reflect the efficiency of the query pruning? (Choose two.),multi-select,A. Partitions scanned,B. Partitions total,C. Bytes scanned,D. Bytes spilled,E. Bytes written,,,,,,,,,,,"1, 2","Statistics  A major source of information provided in the detail pane is the various statistics, grouped in the following sections:   Pruning — information on the effects of table pruning:   Partitions scanned — number of partitions scanned so far.  Partitions total — total number of partitions in a given table.  https://docs.snowflake.com/en/user-guide/ui-query-profile",
"When cloning a schema, which Snowflake object will not be included in the clone?",multiple-choice,A. An external stage,B. A named internal stage,C. A task,D. A User-Defined Function (UDF),,,,,,,,,,,,2,"UDF cannot be cloned in snowflake. We need to copy definition and recreate it
A is correct https://docs.snowflake.com/en/sql-reference/sql/create-clone#:~:text=statement%20is%20executed.-,Not%20cloned,Internal%20(Snowflake)%20stages,-Pipes",
Which role has the privileges to describe a share?,multiple-choice,A. ORGADMIN,B. SECURITYADMIN,C. SYSADMIN,D. ACCOUNTADMIN,,,,,,,,,,,,2,"Based on doc answer is D - https://docs.snowflake.com/en/sql-reference/sql/desc-share#usage-notes
I think D
https://docs.snowflake.com/en/sql-reference/sql/desc-share Only the ACCOUNTADMIN role has the privileges to describe a share. Executing this command with any role other than ACCOUNTADMIN returns an error.  To post-process the output of this command, you can use the RESULT_SCAN function, which treats the output as a table that can be queried. The ANSWER is D",
"This command is executed:

CREATE TABLE new_table CLONE existing_table COPY GRANT;

What will happen to the privileges of any cloned objects?",multiple-choice,A. The clone will only inherit SELECT privileges from the source object.,"B. The clone will inherit all privileges, including OWNERSHIP, from the source object.",C. The clone will inherit all privileges except OWNERSHIP from the source object.,D. The clone will not inherit any privileges from the source object.,,,,,,,,,,,,3,"When you use the COPY GRANTS clause in a CREATE … CLONE statement, Snowflake copies all explicit access privileges that were granted on the source object to the new clone, but does not copy the OWNERSHIP privilege. The clone’s ownership is assigned to the role executing the CLONE command, and any future grants defined at the schema level are not applied to that clone.
I think B is correct unless OWNERSHIP is not an ""explicit"" privilege https://docs.snowflake.com/en/sql-reference/sql/create-clone#:~:text=If%20the%20COPY%20GRANTS%20parameter%20is%20used%2C%20then%20the%20new%20object%20inherits%20any%20explicit%20access%20privileges%20granted%20on%20the%20original%20table",
What is the default authenticator while using the JDBC driver connection in Snowflake?,multiple-choice,A. externalbrowser,B. snowlake,C. username_password_mfa,D. snowflake_jwt,,,,,,,,,,,,2,"C and D are correct. based on the link from bor4un, but it seems that they are noy by default. By default, seems to be ""snowflake"", maybe the ""f"" was missed. Hence, I propose B.
https://docs.snowflake.com/en/developer-guide/jdbc/jdbc-parameters#authenticator",
When will Snowflake charge credits for the use of the Cloud Services layer?,multiple-choice,A. Credits will be charged whenever the Cloud Services layer is used.,B. Credits will be charged only when running a Snowflake-provisioned compute warehouse COMPUTE_WH.,C. Credits will be charged when the daily consumption of cloud services resources exceeds 10% of the daily warehouse usage.,D. Credits will be charged only when a virtual warehouse consumes serverless compute services.,,,,,,,,,,,,3,"In the courses it is not specified if it is about ""daily"", but for sure A is not correct, because the 10% have to be exceeded. Hence, it remains to be C.",
What are the recommended alternative data types in Snowflake for unsupported large object data types such as BLOB and CLOB? (Choose two.),multi-select,A. VARIANT,B. ARRAY,C. BINARY,D. OBJECT,E. VARCHAR,,,,,,,,,,,"3, 5","Agree with CE https://docs.snowflake.com/en/sql-reference/data-types-unsupported
C & E are correct",
A network policy set at which level will override all other network policies?,multiple-choice,A. Account,B. User,C. Security integration,D. Database,,,,,,,,,,,,2,B is correct,
"A company needs to share sales data with multiple marketing agency partners.

Which Snowflake data share mechanism is recommended for this use case?",multiple-choice,A. A shared Amazon S3 bucket,B. Direct share,C. A reader account,D. Data Exchange,,,,,,,,,,,,3,"For securely sharing data with multiple external partners—especially if they may not already have Snowflake accounts—the Reader Account feature is the preferred approach.  Reader accounts let you provision and manage Snowflake accounts on behalf of external consumers. Those consumers connect to a fully managed account that exists under your control, but they only incur compute costs when they query the shared data.  Unlike a Direct Share, which requires each partner to have their own Snowflake account in the same region, Reader Accounts remove that prerequisite and simplify onboarding. Using Reader Accounts also centralizes billing and governance: you control compute warehouses, roles, and access, while partners get read‑only visibility into your sales data.",
Which security feature is available in all Snowflake editions?,multiple-choice,A. Data masking policies,B. Object-level access control,C. Object tagging,D. Customer-managed encryption keys,,,,,,,,,,,,2,"B seems to be correct. C, object tagging may is also correct, though some tagging features require Enterprise or higher",
Which strings will be converted to TRUE using the TO_BOOLEAN() or CAST() functions when unloading data? (Choose two.),multi-select,A. 0,B. n,C. no,D. on,E. yes,,,,,,,,,,,"4, 5","https://docs.snowflake.com/en/sql-reference/functions/to_boolean Returns Returns a BOOLEAN value or NULL. Returns TRUE if string_or_numeric_expr evaluates to TRUE. Usage notes For a string expression: 'true', 't', 'yes', 'y', 'on', '1' return TRUE.",
Which authentication method requires access to a secure file that is only stored on the user's local device?,multiple-choice,A. Password authentication,B. Key-pair authentication,C. Multi-Factor Authentication (MFA),D. Federated authentication,,,,,,,,,,,,2,Answer is B - Key-pair authentication (Public/Private Key Pair Authentication),
Which drivers or connectors are supported by Snowflake? (Choose two.),multi-select,A. Perl Connector,B. MongoDB Rust Driver,C. Go Snowflake Driver,D. Cobol Driver,E. Snowflake Connector for Python,,,,,,,,,,,"3, 5",https://www.snowflake.com/en/developers/downloads/drivers-and-libraries/,
"If a source table is updated while cloning is in progress, what data will be included in the cloned table?",multiple-choice,A. All data from the timestamp when the user runs the query.,B. All data from the timestamp when the user session was created.,C. All data from the timestamp when the clone statement was initiated.,D. All data from the timestamp when the clone statement was completed.,,,,,,,,,,,,3,"Cloning considerations | Snowflake Documentation - During this period, DML transactions can alter the data in a source table. Subsequently, Snowflake attempts to clone the table data as it existed when the operation began.
Please, disregard mt previous reply from above. Take in consideration the below presentation: I am reanalyzing. Link is: https://docs.snowflake.com/en/user-guide/object-clone Cloning and foreign key constraints  Cloning operations require time to complete, particularly for large tables. During this period, DML transactions can alter the data in a source table. Subsequently, Snowflake attempts to clone the table data as it existed when the operation began. My comment: the key word in the message from SNOW FLAKE link is the word ""operation"". Cloning is the ""operation"". Hence, it seems that in the second phrase, ""when the operation began"" is referring to ""when the cloning operation began"". Hence, Snowflake tries (attempts) to clone without the DML changes occurring during cloning. But, will Snowflake do it?  Apparently YES, if we take in consdieration the proposed answer as C.",
"The CUSTOMER table in the T1 database is accidentally dropped.

Which privileges are required to restore this table? (Choose two.)",multiple-choice,A. SELECT privilege on the CUSTOMER table,B. OWNERSHIP privilege on the CUSTOMER table,C. All privileges on the CUSTOMER table,D. All privileges on the T1 database,E. CREATE TABLE privilege on the T1 database,,,,,,,,,,,"2, 5","B and E
I think it should be B and E",
A stream object will advance its offset when it is used in which statement?,multiple-choice,A. SELECT,B. INSERT,C. CREATE,D. COPY INTO [location],,,,,,,,,,,,2,"A stream object's offset in Snowflake advances when it's used in a DML (Data Manipulation Language) statement, like INSERT, UPDATE, or DELETE. Specifically, it advances when the DML operation is part of a transaction that either commits or is rolled back.
https://docs.snowflake.com/en/user-guide/streams-intro Note  To advance the offset of a stream to the current table version without consuming the change data in a DML operation, complete either of the following actions: Recreate the stream (using the CREATE OR REPLACE STREAM syntax).  Insert the current change data into a temporary table. In the INSERT statement, query the stream but include a WHERE clause that filters out all of the change data (e.g. WHERE 0 = 1).",
What does an integration between Snowflake and Microsoft Private Link or AWS PrivateLink support?,multiple-choice,A. The isolation of data within a Snowflake account.,B. The use of Secure Data Sharing among Snowflake accounts.,C. A Virtual Private Network (VPN) between a user and Snowflake.,"D. A secure, direct connection to Snowflake that does not use the internet.",,,,,,,,,,,,4,"AWS PrivateLink is an AWS service for creating private VPC endpoints that allow direct, secure connectivity between your AWS VPCs and the Snowflake VPC without traversing the public Internet. The connectivity is for AWS VPCs in the same AWS region https://docs.snowflake.com/en/user-guide/admin-security-privatelink Azure Private Link provides private connectivity to Snowflake by ensuring that access to Snowflake is through a private IP address. Traffic can only occur from the customer virtual network (VNet) to the Snowflake VNet using the Microsoft backbone and avoids the public Internet https://docs.snowflake.com/en/user-guide/privatelink-azure",
Which Snowflake data governance feature supports resource usage monitoring?,multiple-choice,A. Data classification,B. Column lineage,C. Access history,D. Object tagging,,,,,,,,,,,,4,"Snowflake’s object tagging lets you assign metadata (e.g. cost‑center, project, environment) to objects like warehouses, databases, and tables, and then track and report on resource usage (credit or data usage) by tag via Snowsight or the ACCOUNT_USAGE views",
Which functions can be used to identify the data type stored in a VARIANT column? (Choose two.),multi-select,A. IS_NULL_VALUE,B. IS_DATE_VALUE,C. IS_GEOGRAPHY,D. IS_XML,E. IS_JSON,,,,,,,,,,,"1, 2","I have checked in SNOWFLAKE documentation. Only the first two are available. My answer is A & B
Snowflake does not have an IS_XML function. While Snowflake can store XML-like structures in VARIANT columns, the format isn't natively checked as XML.",
How can data be shared between two users who have different Snowflake accounts?,multiple-choice,A. Create a share with the same name as the original database.,B. Create a share and ensure the proper role is assigned to the share.,C. Ensure both users’ accounts are using the same cloud provider and region.,D. Use the PUT command to create a shared account.,,,,,,,,,,,,2,"you create a share in the provider account, grant object privileges to that share, and then assign the IMPORT SHARE privilege to the appropriate role in the consumer account so they can CREATE DATABASE … FROM SHARE",
Which view will show the MOST recent information about table-level storage utilization?,multiple-choice,A. The TABLE_STORAGE_METRICS view in a Snowflake data share,B. The TABLE_STORAGE_METRICS view in the ACCOUNT_USAGE schema,C. The TABLE_STORAGE_METRICS view in the INFORMATION_SCHEMA,D. The STORAGE_USAGE_HISTORY view in the INFORMATION_SCHEMA,,,,,,,,,,,,3,"The TABLE_STORAGE_METRICS view in the INFORMATION_SCHEMA  Snowflake’s INFORMATION_SCHEMA views reflect metadata in (near) real time, whereas the corresponding ACCOUNT_USAGE views—including its TABLE_STORAGE_METRICS—have built‑in latency of up to a few hours due to their batch extraction process. The STORAGE_USAGE_HISTORY view is a historical, time‑series log (not current point‑in‑time metrics), and data‑share views also surface the same (lagged) Account Usage data.",
"A user executed a SELECT query in Snowsight which returned a 1 GB result set. The user then downloads the files.

What will occur?",multiple-choice,A. The result set will be successfully downloaded from Snowsight.,B. The result set will be automatically compressed and the data will be downloaded as individual files.,C. The download will fail because the result set needs to be broken up into files no greater than 50 MB before downloading.,D. The download will result in an error because the filters of the SELECT query need to be changed so that Snowsight returns a smaller result set.,,,,,,,,,,,,2,"B - Snowflake apply compression and splits data into multiple files
First of all, 1 GB is not good. It is by default divided in 16 MB files, and compressed, I suppose.",
Which file format option should be used when unloading data into a stage to create a CSV or a JSON file?,multiple-choice,A. PARSE_HEADER,B. TRIM_SPACE,C. FILE_EXTENSION,D. SKIP_HEADER,,,,,,,,,,,,3,"When unloading data into a stage in Snowflake, the FILE_EXTENSION file format option specifies the extension for the output files (e.g., .csv for CSV files or .json for JSON files). While the TYPE parameter (e.g., CSV or JSON) defines the format itself, FILE_EXTENSION explicitly controls the file extension. This ensures the output files are saved with the correct format-specific suffix.  Why the other options are incorrect:   A. PARSE_HEADER: Used during data loading (not unloading) to parse headers in CSV files.   B. TRIM_SPACE: Trims whitespace during data loading, irrelevant to unloading.   D. SKIP_HEADER: Skips header rows during loading, not applicable to unloading.  FILE_EXTENSION is the only option directly tied to defining the output file format when unloading data.",
"When creating a virtual warehouse, what setting should be used to avoid both over-provisioning resources and auto-scaling when there is increased concurrency?",multiple-choice,A. WAREHOUSE_SIZE = LARGE,B. WAREHOUSE_TYPE = SNOWPARK-OPTIMIZED,C. MAX_CLUSTER_COUNT =10,D. ENABLE_QUERY_ACCELERATION = TRUE,,,,,,,,,,,,3,"set MAX_CLUSTER_COUNT = 1, not 10
https://docs.snowflake.com/en/user-guide/query-acceleration-service  ENABLE_QUERY_ACCELERATION is designed to improve performance for queries that experience high concurrency or large data scans without requiring additional manual scaling of resources. This feature dynamically allocates additional resources as needed for certain queries, avoiding both over-provisioning (which wastes resources) and scaling the number of clusters.",
What is the MINIMUM Snowflake edition required to add masking policies to selectively mask plain-text data in a table or in view columns at query time?,multiple-choice,A. Standard,B. Enterprise,C. Business Critical,D. Virtual Private Snowflake (VPS),,,,,,,,,,,,2,"To add masking policies and selectively mask plain-text data in a table or view column at query time in Snowflake, you need at least the Enterprise Edition. Explanation: This feature, known as ""Dynamic Data Masking"", is only available on the Enterprise Edition and higher tiers of Snowflake. Key points about Snowflake masking policies: Feature: Dynamic Data Masking Required Edition: Enterprise Edition or higher Functionality: Allows you to create masking policies that selectively hide sensitive data in columns when queried, without modifying the underlying data.",
Which command can be used to determine if data from a file has been previously loaded?,multiple-choice,A. COPY_HISTORY,B. DATA_TRANSFER_HISTORY,C. WAREHOUSE_LOAD_HISTORY,D. STAGE_STORAGE_USAGE_HISTORY,,,,,,,,,,,,1,"Snowflake’s COPY_HISTORY table function (or the COPY_HISTORY view in ACCOUNT_USAGE) lets you query recent load activity—including file names and statuses—to determine if a given staged file has already been loaded into a table  SELECT * FROM TABLE(  INFORMATION_SCHEMA.COPY_HISTORY(  TABLE_NAME => 'ORDERS',  START_TIME => DATEADD(DAY, -1, CURRENT_TIMESTAMP())  ) ) WHERE FILE_NAME = 'orders_20250419.csv';",
What does Snowflake recommend when configuring the auto-suspend parameter for a virtual warehouse?,multiple-choice,A. Set auto-suspend to the maximum possible duration for optimal resource utilization.,B. Enable auto-suspend to a high value to maximize warehouse availability.,C. Enable auto-suspend to a low value to minimize credit consumption during inactivity.,D. Disable auto-suspend to ensure continuous availability of the warehouse.,,,,,,,,,,,,3,"Snowflake’s best practice is to enable auto‑suspend and set it to a low value (for example, 5–10 minutes or less) so that warehouses don’t remain running—and incurring credits—when idle.
i think C is correct",
"Which URL identifies the database, schema, stage, and file path to a set of files for accessing the unstructured data files in Snowflake?",multiple-choice,A. Scoped URL,B. File URL,C. Pre-signed URL,D. HTTPS URL,,,,,,,,,,,,2,"The File URL is the Snowflake URL type that permanently encodes the database, schema, stage, and file path for a set of staged files, allowing any role with appropriate stage privileges to access them directly.",
Which URL type should be used for custom applications that need to access unstructured data files?,multiple-choice,A. Scoped URL,B. File URL,C. Pre-signed URL,D. Relative URL,,,,,,,,,,,,2,"For custom applications that need reliable, long‑lived access to unstructured data files, Snowflake recommends using the File URL. Unlike scoped or pre‑signed URLs, File URLs do not expire and precisely identify the object location (database, schema, stage, and path), ensuring your application can fetch files consistently without needing to regenerate links.
The problem is that to the same link, https://docs.snowflake.com/en/user-guide/unstructured-intro, it says the same about Scoped URL: Ideal for use in custom applications, for providing unstructured data to other accounts through a share, or for downloading and analysis of unstructured data in Snowsight. Hence, A could be good, as well. But, since the access is a little more restrictive:  Recommended for file administrators to give scoped access to data files to specific roles in the same account. Provide access to the files with a view that retrieves scoped URLs. Only roles that have privileges on the view can access the files. Snowflake records information in the query history about who uses a scoped URL to access a file, and when.  And, since in the question, we do not have any mention related to the access, I still keep B as answer.",
"When using a direct share, what privileges does a role need to control access to the objects that are in a share that is using database roles? (Choose two.)",multi-select,A. CREATE PIPE,B. CREATE STREAM,C. CREATE TASK,D. CREATE SHARE,E. CREATE DATABASE,,,,,,,,,,,"4, 5",correct,
What actions can be performed by consumers of shared databases? (Choose two.),multiple-choice,A. Create a clone of the database.,B. Edit the comments for the database.,C. Query Time Travel data on the database.,D. Create streams on objects in the database.,E. Query data from the objects in the database.,,,,,,,,,,,"4, 5","DE Users in a consumer account can view/query data, but cannot insert or update data, or create any objects in the database. The following actions are not supported: Creating a clone of an imported database or any schemas/tables in the database.
Answer D and E.  https://docs.snowflake.com/en/user-guide/data-share-consumers#creating-streams-on-shared-views-or-tables  https://docs.snowflake.com/en/user-guide/data-share-consumers#general-limitations-for-imported-databases
Answer is Cand E  https://docs.snowflake.com/en/user-guide/data-share-consumers",
"A Snowflake user is actively logged into Snowflake when a user-level network policy is assigned to that user.

What will Snowflake do if the user's IP address does not match the user-level network policy rules?",multiple-choice,A. Log the user out.,B. Deactivate the network policy.,C. Prevent the user from executing additional queries.,D. Allow the user to continue until the session or login token expires.,,,,,,,,,,,,3,"For a user‑level network policy applied to an already‑logged‑in session, if the user’s IP address no longer matches the policy’s allowed rules, Snowflake prevents the user from executing any further queries
I checked the link from c561a14.
Per Snowflake's documentation - In addition, when a user-level network policy is associated with the user and the user is already logged into Snowflake, if the user’s network location does not match the user-level network policy rules, Snowflake prevents the user from executing further queries. - https://docs.snowflake.com/en/user-guide/network-policies",
At what level is the ALLOW_CLIENT_MFA_CACHING parameter configurable in Snowflake?,multiple-choice,A. User,B. Session,C. Account,D. Virtual warehouse,,,,,,,,,,,,3,"As an account administrator (i.e. a user with the ACCOUNTADMIN system role), set the ALLOW_CLIENT_MFA_CACHING parameter to true for an account using the ALTER ACCOUNT command.
https://docs.snowflake.com/en/user-guide/security-mfa To enable MFA token caching, complete the following steps:  As an account administrator (i.e. a user with the ACCOUNTADMIN system role), set the ALLOW_CLIENT_MFA_CACHING parameter to true for an account using the ALTER ACCOUNT command.",
"A size X-Small virtual warehouse ran for 90 seconds, and was shut down. The warehouse was then run for another 30 seconds before being shut down again.

How many seconds will be billed?",multiple-choice,A. 90 seconds,B. 120 seconds,C. 150 seconds,D. 180 seconds,,,,,,,,,,,,3,"Correct
The answer is C as anytime less then the first min is billed to the first min and then anytime beyond that is billed to second. https://docs.snowflake.com/en/user-guide/cost-understanding-overall
https://docs.snowflake.com/en/user-guide/cost-understanding-overall",
"This statement is run:

SELECT { 'key' : { 'subkey': 'value' }} mycolumn;

What notations will retrieve the 'value' from the VARIANT column? (Choose two.)",multi-select,A. mycolumn.key.subkey,B. mycolumn.key:subkey,C. mycolumn:key.subkey,D. mycolumn['key'].subkey,E. mycolumn:key:subkey,,,,,,,,,,,"1, 5","C and E,using :
I have checked, as well, in snowflake, all C,D,E are working. For me, D was a surprise. I shall select C and E
Unfortunately C,D,E will work in Snowflake:  At the same time accorting to documentation Snowflake separates Dot and Bracket Notation, thst's why voting for C and E.  https://docs.snowflake.com/en/user-guide/querying-semistructured#traversing-semi-structured-data",
Which table type is used in the file processing pipeline to process unstructured data in Snowflake?,multiple-choice,A. Temporary,B. Directory,C. Standard,D. Transient,,,,,,,,,,,,2,"intended selecting Directory table
Snowflake’s directory tables are the specialized table type designed for building file processing pipelines over unstructured data. Unlike standard, temporary, or transient tables—which manage structured row‑column data—directory tables track and expose file‑level metadata (file names, sizes, timestamps, URLs) for files in internal or external stages, enabling streams and tasks to detect new or changed files and invoke Snowpark UDFs or external functions for processing.",
Which metrics in the QUERY_HISTORY Account _Usage View can be used to assess the pruning efficiency of a query? (Choose two.),multi-select,A. EXECUTION_TIME,B. PARTITIONS_TOTAL,C. COMPILATION_TIME,D. TOTAL_ELAPSED_TIME,E. PARTITIONS_SCANNED,,,,,,,,,,,"2, 5",BE : pruning efficiency = partitions_scanned / partitions_total ratio,
How should a data provider securely share Snowflake objects with a data consumer who does not have a Snowflake account?,multiple-choice,A. Give the consumer owner's rights on the provider's Snowflake account.,B. Unload the data into the consumer's cloud storage.,C. Create a reader account for the consumer.,"D. Create and replicate a share, then give the consumer access to the replication.",,,,,,,,,,,,3,"Snowflake’s secure data sharing framework allows providers to share database objects (tables, views, UDFs, etc.) with other Snowflake accounts without copying data or incurring storage costs in the consumer account. For consumers who do not already have a Snowflake account, the recommended and secure mechanism is to create a Reader Account, which the provider fully owns and bills. This Reader Account lets the consumer log in, query the shared objects in a read‑only fashion, and requires no separate Snowflake subscription for the consumer.",
"When unloading Snowflake relational data to a Parquet file format, why should the PARTITION BY clause be used?",multiple-choice,A. It will provide a mechanism to encrypt each micro-partition with a unique key.,"B. It will guarantee data integrity by splitting the data into smaller, manageable chunks.",C. It will increase storage efficiency by automatically compressing data based on access patterns.,D. It will optimize query performance by filtering relevant partitions without scanning the entire dataset.,,,,,,,,,,,,4,"Using the PARTITION BY clause when unloading Snowflake data to Parquet organizes the output into directory‑based partitions based on your chosen expression. This layout enables downstream query engines or Snowflake external tables to prune partitions—scanning only the relevant subset of files—rather than reading every file in the dataset, thereby optimizing query performance without extra cost or complexity.
Here is the real reply for question 1285: https://www.snowflake.com/guides/what-parquet/#:~:text=Parquet%20is%20an%20open%20source,wide%20variety%20of%20encoding%20types. ""Parquet is an open source file format built to handle flat columnar storage data formats. Parquet operates well with complex data in large volumes.It is known for its both performant data compression and its ability to handle a wide variety of encoding types."" Based on this I propose C.",
How can a user access information about a query execution plan without consuming virtual warehouse compute resources?,multiple-choice,A. Use the EXPLAIN function.,B. Review the Query Profile metrics.,C. Review the data in the Account_Usage view.,D. Use the Snowsight dashboard.,,,,,,,,,,,,2,"EXPLAIN compiles the SQL statement, but does not execute it, so EXPLAIN does not require a running warehouse.  https://docs.snowflake.com/en/sql-reference/sql/explain
https://docs.snowflake.com/en/sql-reference/sql/explain ""EXPLAIN compiles the SQL statement, but does not execute it, so EXPLAIN does not require a running warehouse.  Although EXPLAIN does not consume any compute credits, the compilation of the query does consume Cloud Service credits, just as other metadata operations do.""  The EXPLAIN plan is the “logical” explain plan. It shows the operations that will be performed, and their logical relationship to each other. The actual execution order of the operations in the plan does not necessarily match the logical order shown by the plan. Hence, it is not clear 100%. Let's say A., not B.",
"If a query is being used to unload a 1 TB table into a stage, which DML operator will be shown in the Query Profile?",multiple-choice,A. INSERT,B. UNLOAD,C. COPY,D. UPDATE,,,,,,,,,,,,3,"Answer is C. When unloading data from a Snowflake table into a stage (internal or external), the operation is performed using the COPY INTO <location> command. In the Query Profile, this is represented by the COPY operator.  Even though you're not inserting or updating data, COPY INTO is classified as a Data Manipulation Language (DML) operation in Snowflake and appears as such in query profiles.",
At what levels can network policies be defined in Snowflake? (Choose two.),multi-select,A. User,B. Account,C. Table,D. Schema,E. Database,,,,,,,,,,,"1, 2",repeated many times,
A Snowflake table that is loaded using a Kafka connector has a schema consisting of which two VARIANT columns? (Choose two.),multi-select,A. RECORD_TIMESTAMP,B. RECORD_CONTENT,C. RECORD_KEY,D. RECORD_SESSION,E. RECORD_METADATA,,,,,,,,,,,"2, 5","The two VARIANT columns are:   RECORD_CONTENT   RECORD_METADATA  Every Snowflake table loaded by the Kafka connector (via Snowpipe or Snowpipe Streaming) uses exactly these two VARIANT columns by default.
https://docs.snowflake.com/en/user-guide/kafka-connector-overview ""RECORD_CONTENT. This contains the Kafka message.  RECORD_METADATA. This contains metadata about the message, for example, the topic from which the message was read."" No RECORD_KEY mentioned. Answer is B and E.",
"When working with table MY_TABLE that contains 10 rows, which sampling query will always return exactly 5 rows?",multiple-choice,A. SELECT * FROM MY_TABLE SAMPLE SYSTEM (5);,B. SELECT * FROM MY_TABLE SAMPLE BERNOULLI (5);,C. SELECT * FROM MY_TABLE SAMPLE (5 ROWS);,D. SELECT * FROM MY_TABLE SAMPLE SYSTEM (1) SEED (5);,,,,,,,,,,,,3,SELECT * FROM MY_TABLE SAMPLE (5 ROWS);,
How should a Snowflake user access a third-party SaaS service to process unstructured data?,multiple-choice,A. Use internal functions.,B. Use external functions.,C. Use process functions.,D. Use an API gateway.,,,,,,,,,,,,4,"To integrate a third‑party SaaS service for processing unstructured data in Snowflake—such as using Amazon Textract, Google Document AI, or Azure Computer Vision—the user should leverage External Functions. External Functions are Snowflake UDFs that call code executed outside of the Snowflake engine via a secure proxy (e.g., Amazon API Gateway), enabling seamless invocation of external HTTP‑based services without unloading data or moving it out of Snowflake’s environment.",
Which command will list all of the dropped accounts in an organization that have not been deleted?,multiple-choice,A. SHOW MANAGED ACCOUNTS;,B. SHOW ORGANIZATION ACCOUNTS;,C. SHOW ORGANIZATION ACCOUNTS HISTORY;,D. SHOW ORGANIZATION ACCOUNTS LIKE 'myaccounts%';,,,,,,,,,,,,3,"Here it is a long explanation.  1. C and D do not exist, or I cannot find them. 2. A. SHOW MANAGED ACCOUNTS does not refer to all accounts in an organization, only to the managed accounts. 3. B SHOW ORGANIZATION ACCOUNTS is showing an error, when executed, and pulls us to SHOW ACCOUNTS https://docs.snowflake.com/en/release-notes/bcr-bundles/2024_06/bcr-1712. And, this SHOW ACCOUNTS: ""Optionally includes dropped accounts that have not yet been deleted. The output of SHOW ACCOUNTS HISTORY includes additional columns related to dropped accounts.""",
How does Snowflake use Multi-Factor Authentication (MFA)?,multiple-choice,A. MFA is an integrated feature powered by the Duo Security service.,B. MFA is enabled by default for any user having the ACCOUNTADMIN role.,C. An MFA login is designed to log in to Snowflake only through Snowsight.,D. MFA is enabled by default for each user and does not require activation.,,,,,,,,,,,,1,"Why the Other Options Are Incorrect   B. Enabled by default for ACCOUNTADMIN:  MFA for ACCOUNTADMIN is only recommended, not automatically on.   C. Only through Snowsight:  MFA is fully supported by CLI and all drivers, not just the web UI.   D. Enabled by default for every user:  Users must enroll themselves; MFA is not on by default in existing accounts.",
Which command is used to download data from Snowflake to a client machine?,multiple-choice,A. COPY INTO [location],B. PUT,C. DROP,D. GET,,,,,,,,,,,,4,"GET  The SnowSQL GET command downloads data files from an internal stage (named, table, or user stage) to a local directory on a client machine. It is specifically designed to retrieve files that were previously unloaded into a stage (for example, via COPY INTO <location>).   COPY INTO [location]  While COPY INTO can unload table data into files (such as Parquet or CSV) in an internal or external stage, it does not directly deliver files to the client’s local filesystem. Instead, you first run COPY INTO to stage the files, then use GET to fetch them.   PUT  The PUT command is the inverse of GET: it uploads local files from the client machine to an internal stage. It cannot be used to download data.   DROP  DROP is unrelated to file transfer; it removes database objects (tables, stages, etc.) and is not used for data loading or unloading.  Thus, to download staged data files from Snowflake to your local environment, you must use the GET command.",
"Which Snowflake data governance feature supports the tracking of sensitive data for compliance, discovery, protection, and resource usage?",multiple-choice,A. Row access policies,B. Data classification,C. Object dependencies,D. Object tagging,,,,,,,,,,,,4,Object Tagging,
Which query metric can be used to monitor the health of a large table?,multiple-choice,A. Clustering depth,B. Clustering key,C. Total partition count,D. Total number of rows,,,,,,,,,,,,1,"The key metric for monitoring the “health” of a large table in Snowflake is clustering depth. Clustering depth measures the average number of micro‑partition overlaps for the specified clustering key (or any set of columns), and a lower value indicates more effective clustering and thus better query pruning and performance. Tracking clustering depth over time as DML operations occur helps you detect when a table’s physical data layout degrades and may require reclustering.",
What function should be used to convert JSON NULL values to SQL NULL values when loading data into a Snowflake table?,multiple-choice,A. STRIP_OUTER_ARRAYS,B. STRIP_NULL_VALUE,C. FLATTEN,D. PARSE_JSON,,,,,,,,,,,,2,"SELECT STRIP_NULL_VALUE(PARSE_JSON('{""a"": 1, ""b"": null, ""c"": ""value""}'));
When loading JSON data into a Snowflake table, the PARSE_JSON function can be used to convert JSON NULL values to SQL NULL values. This function parses a string containing JSON data into a Snowflake JSON data type (VARIANT). During this parsing process, JSON null values are interpreted as SQL NULL values.",
What is the recommended way to insert a VARIANT value into a Snowflake table?,multiple-choice,A. Use a SELECT statement to convert data to a VARIANT data type before inserting it.,B. Use the TO_VARIANT function in the INSERT statement.,C. Cast the data to a VARIANT data type within the INSERT statement.,D. Use a subquery to convert the data to a VARIANT data type and then insert it.,,,,,,,,,,,,2,"TO_VARIANT Cannot Be Used Directly in VALUES  The TO_VARIANT function cannot appear directly inside a VALUES clause in an INSERT; instead, you must select from it: Explicit Casting and JSON Parsing  Snowflake supports multiple ways to produce VARIANT values in the SELECT:   TO_VARIANT(<expr>) converts any SQL expression to VARIANT.  <expr>::VARIANT or CAST(<expr> AS VARIANT) for explicit casting.  PARSE_JSON('<json>') to turn a JSON string into VARIANT.   INSERT INTO to_variant_example (v_varchar, v_object)  SELECT  TO_VARIANT('Hello'),   PARSE_JSON('{""key"":""value""}');
https://docs.snowflake.com/en/sql-reference/functions/to_variant ""The TO_VARIANT function cannot be used directly in an INSERT statement. Instead, use INSERT INTO ... SELECT....  Hence, ANSWER B is not correct.  As per the right answer, or A, or D. I am saying D, only because I have to select an answer. Please, see below syntax, for JSON: INSERT INTO to_variant_example (v_varchar, v_number, v_timestamp, v_array, v_object)  SELECT  TO_VARIANT('Skiing is fun!'),  TO_VARIANT(3.14),  TO_VARIANT('2024-01-25 01:02:03'),  TO_VARIANT(ARRAY_CONSTRUCT('San Mateo', 'Seattle', 'Berlin')),  PARSE_JSON(' { ""key1"": ""value1"", ""key2"": ""value2"" } ');  SELECT * FROM to_variant_example; Not very confident that this will help here.
I have analyzed more on the info from my previous email. My answer is A.",
Which process does Snowflake follow when a stored procedure with owner's rights is called within a session?,multiple-choice,A. The procedure will be run with the privileges of the caller.,B. The owner can set the caller's session variables.,C. The owner will inherit the caller's current virtual warehouse.,D. The owner can view the caller's session variables.,,,,,,,,,,,,2,"""Inherit the current warehouse of the caller.""https://docs.snowflake.com/en/developer-guide/stored-procedure/stored-procedures-rights
It is exactly what we can see in docs.snowflake when it is about owner's rights",
Which view can be used to track the read and write operations that have been performed on a table?,multiple-choice,A. COPY_HISTORY,B. ACCESS_HISTORY,C. QUERY_HISTORY,D. TASK_HISTORY,,,,,,,,,,,,2,"Snowflake provides the ACCESS_HISTORY view to track both read and write operations performed on tables (and other objects) within your account.  ACCESS_HISTORY records every query’s access details, including reads (direct_objects_accessed and base_objects_accessed) and writes (objects_modified) for operations such as INSERT, UPDATE, DELETE, and COPY.  It retains up to 365 days of history in the ACCOUNT_USAGE schema (Enterprise Edition or higher), enabling auditing and compliance reporting on who accessed or modified your data.",
"While preparing to unload data in Snowflake, the file format option can be specified in which commands? (Choose two.)",multi-select,A. GET,B. CREATE STAGE,C. PUT,D. COPY INTO [location],E. CREATE PIPE,,,,,,,,,,,"2, 4","The correct answers are B. CREATE STAGE and D. COPY INTO [location].  Explanation: CREATE STAGE: When creating a stage in Snowflake, you can define the file format options that will be used when data is unloaded to that stage. COPY INTO [location]: The COPY INTO command is used to unload data from a table to a stage. You can specify the file format directly within the COPY INTO command if you don't want to use the pre-defined format on the stage",
Which Query Profile operator provides information on pruning efficiency?,multiple-choice,A. TableScan,B. ExternalScan,C. InternalObject,D. Generator,,,,,,,,,,,,1,"https://docs.snowflake.com/en/sql-reference/functions/get_query_operator_stats#retrieving-data-about-a-single-query  example shows tablescan contains pruning information
I do not see the well known answers, from previous 1167 questions:  Partition Total Partition Scanned.  I do not see any connection with Table Scan. Any help, please!? I do not think that A is the answer. I select B, because I have to select something.",
What is a fundamental characteristic of Snowflake micro-partitions?,multiple-choice,A. They can be read directly as files.,B. They serve as an index for Snowflake tables.,C. They are sized based on Time Travel requirements.,"D. Once established, they cannot be changed.",,,,,,,,,,,,4,"Snowflake micro‑partitions are immutable, contiguous units of storage that, once written, are never modified in place—any updates or deletes result in new micro‑partitions being created and the old ones retained (e.g., for Time Travel). This immutability underpins Snowflake’s architecture, enabling reliable metadata management, efficient pruning, and snapshot isolation.",
Which Snowflake objects use storage? (Choose two.),multi-select,A. Regular table,B. Regular view,C. Cached query result,D. Materialized view,E. External table,,,,,,,,,,,"1, 4","AD is correct, nothing mentions cached query result using storage in the documentation https://docs.snowflake.com/en/user-guide/cost-understanding-data-storage
Lind update: Regular tables are logical representation of the data. They do not store data. Views are interrogations, they do not store data. External Tables point to External Stages which contains only metadata and a pointer to the location from Cloud Storage, where the data are maintained. It remains Cached query result and Materialized Views. Materialized views are clear, Cash Query Result is the key. Or the question is wrong and it has one correct answer, or the term Cash refers exactly to data storage.",
Which default warehouse configuration has the highest precedence whenever a new session is created by a user?,multiple-choice,A. Default warehouse for the user,B. Default warehouse in the configuration file of the client utilities,C. Default warehouse specified on a CLI or in drivers/connectors parameters,D. Default warehouse of the role assigned to the user,,,,,,,,,,,,3,"https://docs.snowflake.com/en/user-guide/warehouses-overview Precedence for warehouse defaults When a user connects to Snowflake and start a session, Snowflake determines the default warehouse for the session in the following order:  Default warehouse for the user,  » overridden by…  Default warehouse in the configuration file for the client utility (SnowSQL, JDBC driver, etc.) used to connect to Snowflake (if the client supports configuration files),  » overridden by…  Default warehouse specified on the client command line or through the driver/connector parameters passed to Snowflake.",
Which type of query would benefit from enabling the query acceleration service on the virtual warehouse?,multiple-choice,A. Queries with no filters or aggregation,B. Queries that are queued in the warehouse,C. Queries that use more resources than the typical query,D. Queries that contain a high cardinality GROUP BY expression,,,,,,,,,,,,3,"It is not D. In docs.snowflake, there is exactly the text from Answer C. My answer is C",
Which table function will return the output of a previously-run command?,multiple-choice,A. FLATTEN,B. QUERY_HISTORY,C. TASK_HISTORY,D. RESULT_SCAN,,,,,,,,,,,,4,RESULT_SCAN can be used to access the results of a query executed within the last 24 hours,
How can a relational table be unloaded into a JSON file?,multiple-choice,A. Use the OBJECT_CONSTRUCT function in conjunction with the COPY INTO [location] command.,B. Use the COPY INTO [location] command with the file_format set as JSON.,C. Use the PUT command with the file_format set as JSON.,D. Use the GET command with the file_format set as JSON.,,,,,,,,,,,,1,"Unloading a relational table to JSON You can use the OBJECT_CONSTRUCT function combined with the COPY command to convert the rows in a relational table to a single VARIANT column and unload the rows into a file. https://docs.snowflake.com/en/user-guide/data-unload-considerations
The question does not say anything about an Object_Construct. Right answer is B.
https://docs.snowflake.com/en/user-guide/data-unload-considerations#unloading-a-relational-table-to-json",
Which JSON paths are considered to be equivalent in Snowflake? (Choose two.),multi-select,A. src['customer']['EMAIL'],B. src['CUSTOMER']['Email'],C. SRC:Customer.Email,D. src:customer.email,E. SRC:customer.email,,,,,,,,,,,"4, 5","DE - Column name (customer) and element key are case sensistive
Element key (Email) should be case sensitives whilst the objects are case insensitive.",
"Based on a review of a Query Profile, which scenarios will benefit the MOST from the use of a data clustering key? (Choose two.)",multi-select,A. A column that appears most frequently in ORDER BY operations,B. A column that appears most frequently in WHERE operations,C. A column that appears most frequently in GROUP BY operations,D. A column that appears most frequently in AGGREGATE operations,E. A column that appears most frequently in JOIN operations,,,,,,,,,,,"2, 5","From the documentation at ( https://docs.snowflake.com/en/user-guide/tables-clustering-keys ):   Snowflake recommends prioritizing keys in the order below:  Cluster columns that are most actively used in selective filters. For many fact tables involved in date-based queries (for example “WHERE invoice_date > x AND invoice date <= y”), choosing the date column is a good idea.[...]  If there is room for additional cluster keys, then consider columns frequently used in join predicates, for example “FROM table1 JOIN table2 ON table2.column_A = table1.column_B”.
https://docs.snowflake.com/en/user-guide/tables-clustering-keys",
What Snowflake privilege should be granted to allow a non-ACCOUNTADMIN access to billing information?,multiple-choice,A. OPERATE,B. MONITOR USAGE,C. OWNERSHIP,D. USAGE,,,,,,,,,,,,2,"https://community.snowflake.com/s/article/Snowflake-UI-displays-all-databases-and-all-database-objects-even-without-any-privilege-granted-on-those-databases-and-its-objects ""The MONITOR USAGE privilege provides the ability to monitor account-level usage and historical information for databases and warehouses. This privilege enables non-account administrators to monitor usage and billing history in the classic web interface.""
Not in English language, of course, but in it.",
Which operation can be performed on Snowflake external tables?,multiple-choice,A. INSERT,B. JOIN,C. RENAME,D. ALTER,,,,,,,,,,,,2,"Both options seem to be valid. As others mentioned: B). https://docs.snowflake.com/en/user-guide/tables-external-intro. External tables are read-only. You cannot perform data manipulation language (DML) operations on them. However, you can use external tables for query and join operations. You can also create views against external tables. D). https://docs.snowflake.com/en/sql-reference/sql/alter-external-table
B. JOIN External tables in Snowflake can participate in JOIN operations with other tables, whether they are external or internal.
Option B is the answer. Kindly read the question ""Which Operation can be performed""  Join is an operation in database but not alter.
Answer ""B"" is correct. External tables are read-only. You cannot perform data manipulation language (DML) operations on them. However, you can use external tables for query and join operations. You can also create views against external tables.",
Which table function is used to view all errors encountered during a previous data load?,multiple-choice,A. VALIDATE,B. INFER_SCHEMA,C. GENERATOR,D. QUERY_HISTORY,,,,,,,,,,,,1,"A - That's the purpose of VALIDATE function
A  https://docs.snowflake.com/en/sql-reference/functions/validate",
What is the MINIMUM size requirement when creating a Snowpark-optimized virtual warehouse?,multiple-choice,A. X-Small,B. Small,C. Medium,D. Large,,,,,,,,,,,,3,"XS seems to be the minimum size mentioned in the table (memory 16GB, CPU Default or x86, minimum warehouse size required XSMALL): https://docs.snowflake.com/en/user-guide/warehouses-snowpark-optimized
Tried creating a new warehouse in Snowflake, as well as tried altering an existing one- Either cases, I was able to set 'snowpark optimised' for X-small !
C  https://docs.snowflake.com/en/user-guide/warehouses-snowpark-optimized",
Which role has the ability to create and manage users and roles?,multiple-choice,A. ORGADMIN,B. USERADMIN,C. SYSADMIN,D. SECURITYADMIN,,,,,,,,,,,,2,"USERADMIN can create Users but not Roles. SECURITYADMIN is the right answer
https://docs.snowflake.com/en/user-guide/admin-user-management
d. security admin https://community.snowflake.com/s/article/Users-with-securityadmin-role-can-grant-accountadmin-role-to-any-other-user-or-role",
What issues can be identified and troubleshooted using the Query Profile? (Choose two.),multi-select,A. Full index scans,B. Cartesian products,C. Insufficient privileges,D. Queries too large to fit in memory,E. Virtual warehouse credit consumption,,,,,,,,,,,"2, 4","B & D https://docs.snowflake.com/en/user-guide/ui-query-profile
Correct Answers: B. Cartesian products and E. Virtual warehouse credit consumption Cartesian products: The Query Profile can help identify inefficient joins or joins without proper join conditions that result in Cartesian products (i.e., when each row from one table is joined with all rows of another table). This can significantly impact query performance.  Virtual warehouse credit consumption: The Query Profile provides insights into the resources used by a query, including the credits consumed by the virtual warehouse executing the query. This helps in analyzing and optimizing resource usage.
B & D  Cartesian product is the same as Eploding JOINs https://docs.snowflake.com/en/user-guide/ui-query-profile",
What happens to the objects in a reader account when the DROP MANAGED ACCOUNT command is executed?,multiple-choice,A. The objects are dropped.,B. The objects enter the Fail-safe period.,C. The objects enter the Time Travel period.,D. The objects are immediately moved to the provider account.,,,,,,,,,,,,1,"Answer A - https://docs.snowflake.com/en/sql-reference/sql/drop-managed-account
A  https://docs.snowflake.com/en/sql-reference/sql/drop-managed-account",
What function can be used with the recursive argument to return a list of distinct key names in all nested elements in an object?,multiple-choice,A. FLATTEN,B. GET_PATH,C. CHECK_JSON,D. PARSE_JSON,,,,,,,,,,,,1,"Agree with A
""Related to Using FLATTEN to List Distinct Key Names, you can use the FLATTEN function with the RECURSIVE argument to retrieve all keys and paths in an OBJECT."" https://docs.snowflake.com/en/user-guide/querying-semistructured#using-flatten-to-list-paths-in-an-object
A  https://docs.snowflake.com/en/sql-reference/functions/flatten",
What does Snowflake recommend when planning virtual warehouse usage for a data load?,multiple-choice,A. Load the fewest possible number of large files.,B. Dedicate a separate warehouse for loading data.,C. Increase the size of the warehouse used.,D. Use several single-cluster warehouses.,,,,,,,,,,,,2,"Agree with B other answers makes no sense especially A and D
https://docs.snowflake.com/user-guide/data-load-considerations-plan
Dedicating separate warehouses to load and query operations:  Loading large data sets can affect query performance. We recommend dedicating separate warehouses for loading and querying operations to optimize performance for each.",
Which Snowflake database object can be used to track data changes made to table data?,multiple-choice,A. Tag,B. Task,C. Stream,D. Stored procedure,,,,,,,,,,,,3,C  https://docs.snowflake.com/en/user-guide/streams-intro,
Who can activate and enforce a network policy for all users in a Snowflake account? (Choose two.),multi-select,A. A user with an USERADMIN or higher role,B. A user with a SECURITYADMIN or higher role,C. A role that has been granted the ATTACH POLICY privilege,D. A role that has the NETWORK_POLICY account parameter set,E. A role that has the OWNERSHIP of the network policy,,,,,,,,,,,"2, 3","BC - https://docs.snowflake.com/en/user-guide/network-policies
B & C  https://docs.snowflake.com/en/sql-reference/sql/create-network-policy
Agree with your answer B+C , but the link should be  https://docs.snowflake.com/en/user-guide/network-policies Activating a network policy for an account enforces the policy for all users in the account.  Only security administrators (i.e. users with the SECURITYADMIN role) or higher or a role with the global ATTACH POLICY privilege can activate a network policy for an account.",
How can a data provider share their Snowflake data? (Choose two.),multi-select,A. External table,B. Snowpark API,C. Direct share,D. External function,E. Snowflake Marketplace listing,,,,,,,,,,,"3, 5","CE - marketplace and direct share
https://medium.com/clouddataplatform/snowflake-data-sharing-approach-9e490b5fb7c8",
What will prevent unauthorized access to a Snowflake account from an unknown source?,multiple-choice,A. Network policy,B. End-to-end encryption,C. Multi-Factor Authentication (MFA),D. Role-Based Access Control (RBAC),,,,,,,,,,,,3,"I think the correct answer is A but I agree that without much context C might be an option
Both options (A) Network policy and (C) Multi-Factor Authentication (MFA) contribute to preventing unauthorized access, but MFA is specifically designed to provide an additional layer of security by requiring users to provide multiple forms of verification before gaining access, making it harder for unauthorized users to access the account even if they manage to bypass network policies. So, while network policies play a role in access control, MFA is typically considered a more effective measure against unauthorized access from unknown sources.",
Which query type is supported for implementing the search optimization service?,multiple-choice,A. Queries with column concatenation,B. Substring search queries on external tables,C. String searches on columns using the COLLATE function,D. Geography value column searches using geospatial functions,,,,,,,,,,,,4,"Queries that use selected geospatial functions with GEOGRAPHY values
D  https://docs.snowflake.com/en/user-guide/search-optimization-service",
"What Snowflake feature provides a data hub for secure data collaboration, with a selected group of invited members?",multiple-choice,A. Data Replication,B. Secure Data Sharing,C. Data Exchange,D. Snowflake Marketplace,,,,,,,,,,,,3,"Data Exchange provides a data hub for securely collaborating around data with a selected group of members that you invite.
C  https://docs.snowflake.com/en/user-guide/data-exchange",
Which semi-structured data function interprets an input string as a JSON document that produces a VARIANT value?,multiple-choice,A. PARSE_JSON,B. CHECK_JSON,C. JSON_EXTRACT_PATH_TEXT,D. PARSE_XML,,,,,,,,,,,,1,"PARSE_JSON Interprets an input string as a JSON document, producing a VARIANT value.
A  https://docs.snowflake.com/en/sql-reference/functions/parse_json",
Which Snowflake data types can be used to build nested hierarchical data? (Choose two.),multi-select,A. INTEGER,B. OBJECT,C. VARIANT,D. VARCHAR,E. LIST,,,,,,,,,,,"2, 3","Agree with BC
B & C  https://docs.snowflake.com/en/user-guide/semistructured-intro#:~:text=The%20ARRAY%2C%20OBJECT%2C%20and%20VARIANT,store%20it%20in%20a%20VARIANT.",
Which statistics can be used to identify queries that have inefficient pruning? (Choose two.),multi-select,A. Bytes scanned,B. Bytes written to result,C. Partitions scanned,D. Partitions total,E. Percentage scanned from cache,,,,,,,,,,,"3, 4","CD - efficient pruning is when the number of partition scanned is way lower than the total number of partitions so if you compare the two you can telle if your pruning is efficient or not.
https://select.dev/posts/snowflake-micro-partitions
""The efficiency of pruning can be observed by comparing Partitions scanned and Partitions total statistics in the TableScan operators. If the former is a small fraction of the latter, pruning is efficient. If not, the pruning did not have an effect."" https://docs.snowflake.com/en/user-guide/ui-query-profile#inefficient-pruning",
Which element in the Query Profile interface shows the relationship between the nodes in the execution of a query?,multiple-choice,A. Node List,B. Steps,C. Overview,D. Operator Tree,,,,,,,,,,,,4,"https://docs.snowflake.com/en/user-guide/ui-query-profile Operator tree The middle pane displays a graphical representation of all the operator nodes for the selected step, including the relationships between each operator node.",
What will happen if a Snowflake user suspends the updates to a materialized view?,multiple-choice,A. The queries on that view will generate an error message.,B. The queries on that view will return the last stored data.,C. The queries on that view will return the data using Time Travel.,D. The queries on that view will return the data with a warning message.,,,,,,,,,,,,1,"A  https://docs.snowflake.com/en/user-guide/views-materialized#label-materialized-view-suspend-example
A is correct
A  https://docs.snowflake.com/en/user-guide/views-materialized#:~:text=ALTER%20MATERIALIZED%20VIEW%20%3Cname%3E%20SUSPEND",
Which Snowflake function will parse a JSON-null into a SQL-null?,multiple-choice,A. TO_CHAR,B. TO_VARIANT,C. TO_VARCHAR,D. STRIP_NULL_VALUE,,,,,,,,,,,,4,"STRIP_NULL_VALUE: Converts a JSON null value to a SQL NULL value. All other variant values are passed unchanged.
B  https://docs.snowflake.com/en/sql-reference/functions/to_variant",
Which Snowflake command can be used to unload the result of a query to a single file?,multiple-choice,A. Use COPY INTO [external stage] followed by a GET command to download the file.,B. Use COPY INTO [internal stage] followed by a PUT command to download the file.,C. Use COPY INTO [internal stage] with SINGLE = TRUE followed by a GET command to download the file.,D. Use COPY INTO [external stage] with SINGLE = TRUE followed by a PUT command to download the file.,,,,,,,,,,,,3,"Answer is C : We need to set the parameter SINGLE = TRUE or else data will be unloaded to multiple files and the GET command is for unloading.
https://docs.snowflake.com/en/user-guide/data-unload-considerations",
How are micro-partitions enabled on Snowflake tables?,multiple-choice,A. Micro-partitioning requires a cluster key on a table.,B. Micro-partitioning is automatically performed on a table.,C. Micro-partitioning requires the use of the search optimization service.,D. Micro-partitioning is defined by the user when a table is created.,,,,,,,,,,,,2,B  https://docs.snowflake.com/en/user-guide/tables-clustering-micropartitions#:~:text=Micro%2Dpartitioning%20is%20automatically%20performed%20on%20all%20Snowflake%20tables.%20Tables%20are%20transparently%20partitioned%20using%20the%20ordering%20of%20the%20data%20as%20it%20is%20inserted/loaded.,
What persistent data structures are used by the search optimization service to improve the performance of point lookups?,multiple-choice,A. Micro-partitions,B. Clustering keys,C. Equality searches,D. Search access paths,,,,,,,,,,,,4,"D - that's what search access paths do
https://docs.snowflake.com/en/user-guide/search-optimization-service#how-the-search-optimization-service-works
To improve performance of search queries, the search optimization service creates and maintains a persistent data structure called a search access path. The search access path keeps track of which values of the table’s columns might be found in each of its micro-partitions, allowing some micro-partitions to be skipped when scanning the table.",
Which Snowflake feature provides increased login security for users connecting to Snowflake that is powered by Duo Security service?,multiple-choice,A. OAuth,B. Network policies,C. Single Sign-On (SSO),D. Multi-Factor Authentication (MFA),,,,,,,,,,,,4,"D - MFA does that
https://docs.snowflake.com/en/user-guide/ui-snowsight-profile#enroll-in-multi-factor-authentication-mfa
Snowflake supports multi-factor authentication (i.e. MFA) to provide increased login security for users connecting to Snowflake. MFA support is provided as an integrated Snowflake feature, powered by the Duo Security service, which is managed completely by Snowflake.",
A user with which privileges can create or manage other users in a Snowflake account? (Choose two.),multi-select,A. GRANT,B. SELECT,C. MODIFY,D. OWNERSHIP,E. CREATE USER,,,,,,,,,,,"4, 5","D& E  Create users The USERADMIN system role can create users using SQL (CREATE USER).  If you prefer to use a custom role for this purpose, grant the CREATE USER privilege on the account to this role.  Modify users Only the role with the OWNERSHIP privilege on a user, or a higher role, can modify most user properties using SQL (ALTER USER). In addition, the role must have the global CREATE USER privilege.  https://docs.snowflake.com/en/user-guide/admin-user-management
Create users: The USERADMIN system role can create users using SQL (CREATE USER). If you prefer to use a custom role for this purpose, grant the CREATE USER privilege on the account to this role.  https://docs.snowflake.com/en/user-guide/admin-user-management",
Which items are considered schema objects in Snowflake? (Choose two.),multi-select,A. Pipe,B. File format,C. Resource monitor,D. Storage integration,E. Virtual warehouse,,,,,,,,,,,"1, 2","AB - agreed
https://www.tutorialspoint.com/snowflake/snowflake_objects.htm",
What does SnowCD help Snowflake users to do?,multiple-choice,A. Copy data into files.,B. Manage different databases and schemas.,C. Troubleshoot network connections to Snowflake.,D. Write SELECT queries to retrieve data from external tables.,,,,,,,,,,,,3,"C - straightforward
https://docs.snowflake.com/en/user-guide/snowcd
C https://docs.snowflake.com/en/user-guide/snowcd",
"A Snowflake account has activated federated authentication.

What will occur when a user with a password that was defined by Snowflake attempts to log in to Snowflake?",multiple-choice,A. The user will be unable to enter a password.,"B. The user will encounter an error, and will not be able to log in.",C. The user will be able to log into Snowflake successfully.,"D. After entering the username and password, the user will be redirected to an Identity Provider (IdP) login page.",,,,,,,,,,,,3,"I think C is correct, the doc says that when activating fedrated authentication you choose either IdP or Snowflake. In that case I think we're using Snowflake so it should be C
It's D : https://docs.snowflake.com/en/user-guide/admin-security-fed-auth-overview  ""Note  For Snowflake-initiated login, the Snowflake login page provides two options for authentication (IdP or Snowflake). To use federated authentication, users must choose the IdP option and then enter their credentials when prompted. Choosing the Snowflake option bypasses federated authentication and logs the user in using Snowflake’s native authentication.""
Quote: ""With federated authentication enabled for your account, Snowflake still allows maintaining and using Snowflake user credentials (login name and password). In other words: - Account and security administrators can still create users with passwords maintained in Snowflake. - Users can still log into Snowflake using their Snowflake credentials.""  https://docs.snowflake.com/en/user-guide/admin-security-fed-auth-use#:~:text=With%20federated%20authentication%20enabled%20for,Snowflake%20using%20their%20Snowflake%20credentials.
https://docs.snowflake.com/en/user-guide/admin-security-fed-auth-overview",
Which solution improves the performance of point lookup queries that return a small number of rows from large tables using highly selective filters?,multiple-choice,A. Automatic clustering,B. Materialized views,C. Query acceleration service,D. Search optimization service,,,,,,,,,,,,4,D  https://docs.snowflake.com/en/user-guide/search-optimization-service#:~:text=Selective%20point%20lookup%20queries%20on%20tables.%20A%20point%20lookup%20query%20returns%20only%20one%20or%20a%20small%20number%20of%20distinct%20rows.%20Use%20case%20examples%20include,
What does a Notify &amp; Suspend action for a resource monitor do?,multiple-choice,A. Send an alert notification to all account users who have notifications enabled.,B. Send an alert notification to all virtual warehouse users when thresholds over 100% have been met.,"C. Send a notification to all account administrators who have notifications enabled, and suspend all assigned warehouses after all statements being executed by the warehouses have completed.","D. Send a notification to all account administrators who have notifications enabled, and suspend all assigned warehouses immediately, canceling any statements being executed by the warehouses.",,,,,,,,,,,,3,"C is correct agree with the others
https://medium.com/@aitor.porcellaburu/snowpro-core-level-up-resource-monitoring-736cc4b13958",
How can a Snowsight user change a Standard virtual warehouse to a Snowpark-optimized virtual warehouse?,multiple-choice,A. Use the ALTER WAREHOUSE command on an active Standard virtual warehouse.,B. Use the ALTER WAREHOUSE command on an active Snowpark-optimized warehouse.,C. Use the ALTER WAREHOUSE command on a suspended Standard virtual warehouse.,D. Use the ALTER WAREHOUSE command on a suspended Snowpark-optimized warehouse.,,,,,,,,,,,,3,"C - warehouse needs to be suspended
C  https://docs.snowflake.com/en/user-guide/warehouses-snowpark-optimized
Changing the warehouse type using the ALTER WAREHOUSE command is only supported for a warehouse in the SUSPENDED state.",
"According to best practices, which table type should be used if the data can be recreated outside of Snowflake?",multiple-choice,A. Permanent table,B. Temporary table,C. Transient table,D. Volatile table,,,,,,,,,,,,3,"Can someone explain why Temporary tables cannot be the answer in this case? They can both be used and I haven't found any docs stating otherwise.
https://docs.snowflake.com/en/sql-reference/sql/create-table
https://hevodata.com/learn/snowflake-temporary-table/",
Which function unloads data from a relational table to JSON?,multiple-choice,A. TO_OBJECT,B. TO_JSON,C. TO_VARIANT,D. OBJECT_CONSTRUCT,,,,,,,,,,,,4,"OBJECT_CONSTRUCT builds the JSON structure from relational data, and TO_JSON converts that structure into the final JSON string for unloading into files. Both answers seem to be steps of the solution, but since the question mentions the table as the source, my guess would be D
d is correct: https://community.snowflake.com/s/article/faq-can-i-unload-a-relational-table-with-multiple-columns-to-json",
What is the purpose of the STRIP_NULL_VALUES file format option when loading semi-structured data files into Snowflake?,multiple-choice,A. It removes null values from all columns in the data.,B. It converts null values to empty strings during loading.,C. It skips rows with null values during the loading process.,D. It removes object or array elements containing null values.,,,,,,,,,,,,4,"D is correct
Alternatively, if the “null” values in your files indicate missing values and have no other special meaning, we recommend setting the file format option STRIP_NULL_VALUES to TRUE when you load the semi-structured data files. This option removes OBJECT elements or ARRAY elements containing “null” values. https://docs.snowflake.com/en/user-guide/semistructured-considerations#label-variant-null",
Which Snowflake edition enables data sharing only through Snowflake Support?,multiple-choice,A. Virtual Private Snowflake,B. Business Critical,C. Enterprise,D. Standard,,,,,,,,,,,,1,"A is correct
A  https://docs.snowflake.com/en/user-guide/intro-editions#:~:text=VPS%20accounts%20do%20not%20share%20any%20resources%20with%20accounts%20outside%20the%20VPS",
What is the primary purpose of partitioning staged data files for regular data loads?,multiple-choice,A. To improve the performance of data loads,B. To compress the data for efficient storage,C. To encrypt the data for enhanced security,D. To organize the data into subfolders for easy browsing,,,,,,,,,,,,1,"https://docs.snowflake.com/en/user-guide/data-load-considerations-manage Note  ""S3 transmits a directory list with each COPY statement used by Snowflake, so reducing the number of files in each directory improves the performance of your COPY statements. You may even consider creating subfolders of 10-15 minute increments within the folders for each hour."" --reducing the number of files in each directory improves the performance of your COPY statements. meaning more partition, better the performance.
When staging regular data sets, we recommend partitioning the data into logical paths that include identifying details such as geographical location or other source identifiers, along with the date when the data was written.  Organizing your data files by path lets you copy any fraction of the partitioned data into Snowflake with a single command. This allows you to execute concurrent COPY statements that match a subset of files, taking advantage of parallel operations. https://docs.snowflake.com/en/user-guide/data-load-considerations-stage#organizing-data-by-path",
What is the minimum Snowflake Edition that supports secure storage of Protected Health Information (PHI) data?,multiple-choice,A. Standard Edition,B. Enterprise Edition,C. Business Critical Edition,D. Virtual Private Snowflake Edition,,,,,,,,,,,,3,"C - seen this question before
""Business Critical Edition, formerly known as Enterprise for Sensitive Data (ESD), offers even higher levels of data protection to support the needs of organizations with extremely sensitive data, particularly PHI data that must comply with HIPAA and HITRUST CSF regulations."" https://docs.snowflake.com/en/user-guide/intro-editions
C  https://docs.snowflake.com/en/user-guide/intro-editions#:~:text=enterprises%20and%20organizations.-,Business%20Critical%20Edition,-%C2%B6",
What can a Snowflake user do to reduce queuing on a multi-cluster virtual warehouse?,multiple-choice,A. Increase the warehouse size.,B. Use an economy scaling policy.,C. Increase the maximum number of clusters.,D. Convert the warehouse to a Snowpark-optimized warehouse.,,,,,,,,,,,,3,"https://docs.snowflake.com/en/user-guide/performance-query-warehouse-queue#options-for-reducing-queues
C https://docs.snowflake.com/en/user-guide/performance-query-warehouse-queue",
What should be used to show the status of partial data loads and loading errors?,multiple-choice,A. The COPY_HISTORY function,B. The QUERY_HISTORY function,C. The ACCESS_HISTORY view,D. The WAREHOUSE_LOAD_HISTORY function,,,,,,,,,,,,1,"A - straigtforward
https://docs.snowflake.com/en/sql-reference/functions/copy_history#output
A  https://docs.snowflake.com/en/sql-reference/functions/copy_history#:~:text=%2C%20Table%20Functions-,COPY_HISTORY,-This%20table%20function  And ChatGPT and Gemini give different answers!!!",
Which object can be used with Secure Data Sharing?,multiple-choice,A. View,B. Materialized view,C. External table,D. User-Defined Function (UDF),,,,,,,,,,,,3,"C - the other 3 can be if they are SECURE, in this case they are not
C  https://docs.snowflake.com/en/user-guide/data-sharing-intro#:~:text=Dynamic%20tables-,External%20tables,-Iceberg%20tables
You can share the following Snowflake objects:  Databases Tables Dynamic tables External tables Iceberg tables Secure views Secure materialized views Secure user-defined functions (UDFs)",
Which parameter can be set at the account level to set the minimum number of days for which Snowflake retains historical data in Time Travel?,multiple-choice,A. DATA_RETENTION_TIME_IN_DAYS,B. MAX_DATA_EXTENSION_TIME_IN_DAYS,C. MIN_DATA_RETENTION_TIME_IN_DAYS,D. MAX_CONCURRENCY_LEVEL,,,,,,,,,,,,3,"C is correct, A is at object level the other two simply don't do that
MIN_DATA_RETENTION_TIME_IN_DAYS:  Used to set the minimum data retention period for retaining historical data for Time Travel operations.  https://docs.snowflake.com/en/sql-reference/parameters
The parameter that can be set at the account level to set the minimum number of days for which Snowflake retains historical data in Time Travel is A. DATA_RETENTION_TIME_IN_DAYS. This parameter allows you to specify how long Snowflake retains the historical data, enabling you to access and query data from past states of tables within the specified time frame.",
Which commands are restricted in owner's rights stored procedures? (Choose two.),multi-select,A. SHOW,B. MERGE,C. INSERT,D. DELETE,E. DESCRIBE,,,,,,,,,,,"1, 5","AE is correct
Owner’s rights stored procedures have several additional restrictions, besides the restrictions related to session variables and session parameters. These restrictions affect the following:  The built-in functions that can be called from inside a stored procedure.  Ability to execute ALTER USER statements.  Monitoring stored procedures at execution time.  SHOW and DESCRIBE commands.  The types of SQL statements that can be called from inside a stored procedure.
A & E  https://docs.snowflake.com/en/developer-guide/stored-procedure/stored-procedures-rights#:~:text=SHOW%20and-,DESCRIBE,-commands.",
What is the relationship between a Query Profile and a virtual warehouse?,multiple-choice,A. A Query Profile can help users right-size virtual warehouses.,B. A Query Profile defines the hardware specifications of the virtual warehouse.,C. A Query Profile can help determine the number of virtual warehouses available.,D. A Query Profile automatically scales the virtual warehouse based on the query complexity.,,,,,,,,,,,,1,"A - nexerSnow explanation is great
A correct
It's crucial to monitor both local and remote disk spillage. In Snowflake, when a warehouse cannot fit an operation in memory, it starts spilling data first to the local disk of a warehouse node, and then to remote storage. This process, called disk spilling, leads to decreased performance and can be seen in the query profile as ""Bytes spilled to local/remote storage.""   https://www.chaosgenius.io/blog/snowflake-warehouse-sizes/",
Which transformation is supported by a COPY INTO [table] command?,multiple-choice,A. Filter using a WHERE clause,B. Filter using a LIMIT keyword,C. Cast using a SELECT statement,D. Order using an ORDER BY Clause,,,,,,,,,,,,3,"Option C is correct, other are not possible when using the COPY INTO statement https://docs.snowflake.com/en/user-guide/data-load-transform
The COPY command supports: Column reordering column omission casts using a SELECT statement https://docs.snowflake.com/en/user-guide/data-load-transform",
How does conditional data masking work in Snowflake?,multiple-choice,A. It selectively masks plain text data.,B. It selectively masks multiple columns.,C. It masks all values in a given column.,D. It selectively masks a column value based on another column.,,,,,,,,,,,,4,"I also thin the right answer is A.
D  https://community.snowflake.com/s/article/How-to-conditionally-mask-a-column-in-a-table-based-on-a-subquery-from-a-different-table
A. It selectively masks plain text data - because conditional data masking does involve selectively masking data based on certain conditions or criteria. However, it's important to clarify that these conditions are often related to user roles or other security measures rather than the content of the data itself. The key feature of conditional data masking is its ability to dynamically display either the original data or a masked version of the data based on the evaluation of these conditions.",
"If a virtual warehouse runs for 61 seconds, shuts down, and then restarts and runs for 30 seconds, for how many seconds is it billed?",multiple-choice,A. 60,B. 91,C. 120,D. 121,,,,,,,,,,,,4,"D - virtual warehouse are always billed for the entire minute after they are started even if they are shut down earlier
D 121=61+60
If a warehouse runs for 30 to 60 seconds, it is billed for 60 seconds.  If a warehouse runs for 61 seconds, it is billed for only 61 seconds.  If a warehouse runs for 61 seconds, shuts down, and then restarts and runs for less than 60 seconds, it is billed for 121 seconds (60 + 1 + 60).
D is correct according to documentation: ""If a warehouse runs for 30 to 60 seconds, it is billed for 60 seconds. If a warehouse runs for 61 seconds, it is billed for only 61 seconds. If a warehouse runs for 61 seconds, shuts down, and then restarts and runs for less than 60 seconds, it is billed for 121 seconds (60 + 1 + 60)."" https://docs.snowflake.com/en/user-guide/warehouses-considerations#how-are-credits-charged-for-warehouses",
"What function, combined with the copy command, should be used to unload data from a relational table into a JSON file?",multiple-choice,A. LATERAL,B. CAST,C. FLATTEN,D. OBJECT_CONSTRUCT,,,,,,,,,,,,4,"D should be ok
correct
D is correct: Unloading a relational table to JSON You can use the OBJECT_CONSTRUCT function combined with the COPY command to convert the rows in a relational table to a single VARIANT column and unload the rows into a file. https://docs.snowflake.com/en/user-guide/data-unload-considerations",
What is the primary purpose of a directory table in Snowflake?,multiple-choice,A. To store actual data from external stages,B. To automatically expire file URLs for security,C. To manage user privileges and access control,D. To store file-level metadata about data files in a stage,,,,,,,,,,,,4,"D is correct that's the purpose of directory tables
A directory table is an implicit object layered on a stage that stores file-level metadata about the data files in the stage, similar conceptually to an external table You can query a directory table to retrieve a list of all the files on a stage. The query output contains information about each file, including the size, last modified timestamp, and the file URL Directory tables store data file metadata  https://docs.snowflake.com/en/user-guide/data-load-dirtablesThe key points are:",
Which Snowflake table objects can be shared with other accounts? (Choose two.),multi-select,A. Temporary tables,B. Permanent tables,C. Transient tables,D. External tables,E. User-Defined Table Functions (UDTFs),,,,,,,,,,,"2, 4","BD - UDTFs must be secure
""Secure Data Sharing lets you share selected objects in a database in your account with other Snowflake accounts. You can share the following Snowflake objects: Databases Tables Dynamic tables External tables Iceberg tables Secure views Secure materialized views Secure user-defined functions (UDFs)""",
Which metadata table will store the storage utilization information even for dropped tables?,multiple-choice,A. DATABASE_STORAGE_USAGE_HISTORY,B. TABLE_STORAGE_METRICS,C. STORAGE_DAILY_HISTORY,D. STAGE_STORAGE_USAGE_HISTORY,,,,,,,,,,,,2,"B is correct https://docs.snowflake.com/en/sql-reference/info-schema/table_storage_metrics
""This view (TABLE_STORAGE_METRICS) displays table-level storage utilization information, which is used to calculate the storage billing for each table in the account, including tables that have been dropped, but are still incurring storage costs.""
B  https://docs.snowflake.com/en/sql-reference/info-schema/table_storage_metrics",
How is role hierarchy established in Snowflake?,multiple-choice,A. By assigning users to roles,B. By default when a role is created,C. By granting one role to another role,D. By transferring ownership of one role to another role,,,,,,,,,,,,3,"C is the principle of parent child
""Granting a role to another role creates a “parent-child” relationship between the roles (also referred to as a role hierarchy).""
C  https://docs.snowflake.com/en/sql-reference/sql/grant-role#:~:text=GRANT%20ROLE-,GRANT%20ROLE,-Assigns%20a%20role",
What commands can be used to see what files are stored in a stage? (Choose two.),multi-select,A. LIST,B. SELECT,C. LS,D. GET,E. DESCRIBE,,,,,,,,,,,"1, 3","AC - both are the same command
LIST, LS Returns a list of files that have been staged (i.e. uploaded from a local file system or unloaded from a table) in one of the following Snowflake stages:",
"Which stages are created by default, with no need to use the CREATE STAGE command? (Choose two.)",multi-select,A. External stage,B. Internal stage,C. Named stage,D. Table stage,E. User stage,,,,,,,,,,,"4, 5","DE are created by default
https://docs.snowflake.com/en/user-guide/data-load-local-file-system-create-stage",
"While working with unstructured data, which file function generates a Snowflake-hosted file URL to a staged file using the stage name and relative file path as inputs?",multiple-choice,A. BUILD_STAGE_FILE_URL,B. GET_ABSOLUTE_PATH,C. BUILD_SCOPED_FILE_URL,D. GET_PRESIGNED_URL,,,,,,,,,,,,1,"Agree with A
https://docs.snowflake.com/en/sql-reference/functions/build_stage_file_url
For this question, answers AC are both correct in my opinion.",
Who can create and manage reader accounts? (Choose two.),multi-select,A. A user with ACCOUNTADMIN role,B. A user with SECURITYADMIN role,C. A user with SYSADMIN role,D. A user with ORGADMIN role,E. A user with CREATE ACCOUNT privilege,,,,,,,,,,,"1, 5","https://docs.snowflake.com/en/user-guide/data-sharing-reader-create
""All tasks described in this topic must be performed using the ACCOUNTADMIN role or a role granted the CREATE ACCOUNT global privilege.""",
Which command allows for continuous loading of data files as soon as they are available in a stage?,multiple-choice,A. COPY INTO [table],B. PUT,C. CREATE PIPE,D. GET,,,,,,,,,,,,3,"C - that's just what pipes does, no further explanation needed
https://docs.snowflake.com/en/sql-reference/sql/create-pipe",
What is an advantage of using database roles instead of granting privileges on objects directly to a share in Snowflake?,multiple-choice,A. Easier management of cross-region data sharing,B. Greater flexibility in including objects from multiple databases,C. More control over object-level access for different user groups,D. Reduction in the number of shares required for different objects in the same database,,,,,,,,,,,,3,But instead granting the shared database role allows the user to access only the subset of shared objects granted to the database role. The shared Database roles allow different groups of users in a data consumer account to access different subsets of the shared objects. https://community.snowflake.com/s/article/How-to-use-Database-Roles-in-a-Data-Share,
"What is the order of precedence (highest to lowest) of network policies when applied at the account, user, and security integrations layers?",multiple-choice,"A. Account, user, security integration","B. Account, security integration, user","C. User, security integration, account","D. User, account, security integration",,,,,,,,,,,,3,"Account is overriden by Security Integration, that is overriden by User  https://docs.snowflake.com/en/user-guide/network-policies#:~:text=%27block_access_rule%27)%3B-,Network%20policy%20precedence,-%C2%B6
It's B : https://docs.snowflake.com/en/user-guide/network-policies The following summarizes the order of precedence:  Account Network policies applied to an account are the most general network policies. They are overridden by network policies applied to a security integration or user.  Security Integration Network policies applied to a security integration override network policies applied to the account, but are overridden by a network policy applied to a user.  User Network policies applied to a user are the most specific network policies. They override both accounts and security integrations.",
"Which type of Snowflake virtual warehouse provides 16 times the memory for each node, and is recommended for larger workloads like Machine Learning (ML) training?",multiple-choice,A. A size 6XL warehouse,B. A standard warehouse,C. A multi-cluster warehouse,D. A Snowpark-optimized warehouse,,,,,,,,,,,,4,"Agree with D
SnowPark-optimized virtual warehouse is designed for high memory requirements, such as ML workloads, ML training datasets, and other memory-intensive tasks. It provides 16 times more memory per node than a standard virtual warehouse, making it an excellent choice for handling such workloads on a single virtual warehouse.",
Which common query issues can be identified by the Query Profile? (Choose two.),multi-select,A. Insufficient credit quota,B. Inefficient query pruning,C. Excessive query pruning,D. Exploding joins,E. Credit usage that exceeds a set threshold,,,,,,,,,,,"2, 4","Agre with BD
It's B D : https://docs.snowflake.com/en/user-guide/ui-query-profile#common-query-problems-identified-by-query-profile",
"In Snowflake, what allows users to perform recursive queries?",multiple-choice,A. QUALIFY,B. LATERAL,C. PIVOT,D. CONNECT BY,,,,,,,,,,,,4,D  https://docs.snowflake.com/en/sql-reference/constructs/connect-by,
"A user wants to create objects within a schema but wants to restrict other users’ ability to grant privileges on these objects.

What configuration should be used to create the schema?",multiple-choice,A. Use a regular (non-managed) schema.,B. Use a managed access schema.,C. Use a transient schema.,D. Set the Default_DDL_Collation parameter.,,,,,,,,,,,,2,"https://docs.snowflake.com/en/sql-reference/sql/create-schema#optional-parameters
https://docs.snowflake.com/en/user-guide/security-access-control-privileges
In Snowflake, a managed access schema allows the schema owner (or a designated role) to have full control over granting privileges on objects within the schema. In this configuration, only the schema owner can grant or revoke privileges on the objects within the schema, preventing other users from doing so.",
What is the MOST cost-effective way to resolve memory spillage in a virtual warehouse?,multiple-choice,A. Enable automatic clustering.,B. Enable the query acceleration service.,C. Enable the search optimization service.,D. Convert to a Snowpark-optimized warehouse.,,,,,,,,,,,,4,"D - others explanation are good
B. Enable the query acceleration service. The query acceleration service dynamically adds additional compute resources (more CPU and memory) to a virtual warehouse when queries require more resources than initially allocated. This can be a cost-effective solution as it only scales up resources temporarily during peak demand, potentially reducing memory spillage without the need to permanently increase the warehouse size.
https://docs.snowflake.com/en/user-guide/performance-query-warehouse-memory",
What objects in Snowflake are supported by Dynamic Data Masking? (Choose two.),multi-select,A. Views,B. Materialized views,C. Tables,D. External tables,E. Future grants,,,,,,,,,,,"1, 3","AC - Data masking is supported on views and tables
""Snowflake supports using Dynamic Data Masking on tables and views.""
https://docs.snowflake.com/en/user-guide/security-column-ddm-intro#:~:text=Snowflake%20supports%20using%20Dynamic%20Data%20Masking%20on%20tables%20and%20views
Dynamic Data Masking is a Column-level Security feature that uses masking policies to selectively mask plain-text data in table and view columns at query time.",
"A user has created a dashboard in Snowflake and wants to share it with colleagues.

How can the dashboard be shared?",multiple-choice,A. By creating a private Data Exchange,B. By using the share option within Snowsight,C. By using a Direct Share with another account,D. By creating a listing on Snowflake Marketplace,,,,,,,,,,,,2,"Agree with B
https://docs.snowflake.com/en/user-guide/ui-snowsight-dashboards#share-dashboards
https://www.chaosgenius.io/blog/snowflake-snowsight-guide/",
When would Snowsight automatically detect if a target account is in a different region and enable cross-cloud auto-fulfillment?,multiple-choice,A. When using a paid listing on the Snowflake Marktetplace,B. When using a private listing on the Snowflake Marketplace,C. When using a personalized listing on the Snowflake Marketplace,D. When using a Direct Share with another account,,,,,,,,,,,,2,"B is correct.
https://other-docs.snowflake.com/en/collaboration/provider-listings-auto-fulfillment#about-cross-cloud-auto-fulfillment  "" If your data product is a share, use auto-fulfillment in most cases. For all listings shared with specific consumer accounts, Snowsight automatically detects whether or not the target account is in a different region and enables auto-fulfillment. You cannot manually replicate private listings to other regions. ""  Listing with specific consumer accounts > B
D  https://other-docs.snowflake.com/en/collaboration/provider-listings-auto-fulfillment#:~:text=When%20you%20share%20a%20private%20listing%2C%20the%20database%20is%20auto%2Dfulfilled%20after%20the%20specified%20consumers%20get%20your%20listing
Direct share works only in the same region: https://docs.snowflake.com/en/user-guide/data-sharing-intro#options-for-sharing-in-snowflake  Thus, D seems not correct.",
Which languages require that User-Defined Function (UDF) handlers be written inline? (Choose two.),multi-select,A. Java,B. Javascript,C. Scala,D. Python,E. SQL,,,,,,,,,,,"2, 5","BE is correct https://docs.snowflake.com/en/developer-guide/udf/udf-overview
It's B & E : https://docs.snowflake.com/en/developer-guide/udf/udf-overview#language-choice
BE  https://docs.snowflake.com/en/developer-guide/udf/udf-overview",
Which task privilege does a Snowflake role need in order to suspend or resume a task?,multiple-choice,A. USAGE,B. OPERATE,C. MONITOR,D. OWNERSHIP,,,,,,,,,,,,2,"B - OPERATE
B  https://docs.snowflake.com/en/sql-reference/sql/alter-task#:~:text=Resuming%20or%20suspending%20a%20task%20(using%20ALTER%20TASK%20%E2%80%A6%20RESUME%20or%20ALTER%20TASK%20%E2%80%A6%20SUSPEND%2C%20respectively)%20requires%20either%20the%20OWNERSHIP%20or%20OPERATE%20privilege%20on%20the%20task
Correct Answer: B. OPERATE The OPERATE privilege allows a role to execute operational actions on a task, such as suspending, resuming, and executing the task. This privilege is necessary for managing the state of tasks within Snowflake.",
What is a directory table in Snowflake?,multiple-choice,A. A separate database object that is used to store file-level metadata.,B. An object layered on a stage that is used to store file-level metadata.,C. A database object with grantable privileges for unstructured data tasks.,D. A Snowflake table specifically designed for storing unstructured files.,,,,,,,,,,,,2,"B is correct
B  https://docs.snowflake.com/en/user-guide/data-load-dirtables#:~:text=using%20directory%20tables.-,What%20is%20a%20directory%20table%3F,-%C2%B6
""A directory table is an implicit object layered on a stage (not a separate database object) and is conceptually similar to an external table because it stores file-level metadata about the data files in the stage.""",
What factors impact storage costs in Snowflake? (Choose two.),multi-select,A. The account type,B. The storage file format,C. The cloud region used by the account,D. The type of data being stored,E. The cloud platform being used,,,,,,,,,,,"1, 3","at the Snowflake billing layer your storage charge is simply a flat $/TB‑month rate, and that published rate only varies by:   Account type (On‑Demand vs Capacity pre‑purchase)   Region (US, EU, APAC, etc.)  All of the “cloud platform” differences are already baked into the single per‑TB list prices Snowflake publishes; you as a customer simply pick On‑Demand or Capacity and a region, and you pay that flat rate. The other choices (file format, data type, underlying provider) don’t change your Snowflake‑billed per‑TB price.
""The amount charged depends on your type of account (Capacity or On Demand) and region (US or EU)""
A,C, E The monthly costs for storing data in Snowflake are based on a flat rate per terabyte (TB) of consumption (after being compressed). The amount charged is determined by your account type (capacity or on demand), Cloud Platform, and the region, whether in the United States, Asia, or Europe.
In this page,  https://docs.snowflake.com/en/user-guide/cost-understanding-data-storage it mentioned that,  > The amount charged depends on your type of account (Capacity or On Demand) and region (US or EU).  So it should be A and C",
Which ACCOUNT_USAGE schema database role provides visibility into policy-related information?,multiple-choice,A. USAGE_VIEWER,B. GOVERNANCE_VIEWER,C. OBJECT_VIEWER,D. SECURITY_VIEWER,,,,,,,,,,,,2,"Agree with B
""The GOVERNANCE_VIEWER role provides visibility into policy related information.""
B  https://docs.snowflake.com/en/sql-reference/snowflake-db-roles",
How should clustering be used to optimize the performance of queries that run on a very large table?,multiple-choice,A. Manually re-cluster the table regularly.,B. Choose one high cardinality column as the clustering key.,C. Use the column that is most-frequently used in query select clauses as the clustering key.,D. Assess the average table depth to identify how clustering is impacting the query.,,,,,,,,,,,,4,"C, having select columns as clustering key may help directly improve a query D- But only accessing the information cant help optimize. Hence C.
D is correct
its D  select clause is the column you choose to select. We dont care about that. We care about the columns being filtered in the WHERE clause.
It's C : https://docs.snowflake.com/en/user-guide/tables-clustering-keys#strategies-for-selecting-clustering-keys ""Selecting the right columns/expressions for a clustering key can dramatically impact query performance. Analysis of your workload will usually yield good clustering key candidates.  Snowflake recommends prioritizing keys in the order below:  Cluster columns that are most actively used in selective filters""",
"Which privilege must be granted by one role to another role, and cannot be revoked?",multiple-choice,A. MONITOR,B. OPERATE,C. OWNERSHIP,D. ALL,,,,,,,,,,,,3,"C OWNERSHIP cannot be revoked
OWNERSHIP is a special type of privilege that can only be granted from one role to another role; it cannot be revoked
C  https://docs.snowflake.com/en/sql-reference/sql/grant-ownership",
How can performance be optimized for a query that returns a small amount of data from a very large base table?,multiple-choice,A. Use clustering keys,B. Create materialized views,C. Use the search optimization service,D. Use the query acceleration service,,,,,,,,,,,,3,"C is correct
""The search optimization service aims to significantly improve the performance of certain types of queries on tables, including: Selective point lookup queries on tables. A point lookup query returns only one or a small number of distinct rows. Use case examples include: Business users who need fast response times for critical dashboards with highly selective filters. Data scientists who are exploring large data volumes and looking for specific subsets of data. Data applications retrieving a small set of results based on an extensive set of filtering predicates.""
C  https://docs.snowflake.com/en/user-guide/search-optimization-service#:~:text=Selective%20point%20lookup%20queries%20on%20tables.%20A%20point%20lookup%20query%20returns%20only%20one%20or%20a%20small%20number%20of%20distinct%20rows
It's C : https://docs.snowflake.com/en/user-guide/search-optimization-service",
Use of which Snowflake function is recommended when unloading data from a relational table into a JSON file?,multiple-choice,A. TO_JSON,B. TO_VARIANT,C. OBJECT_INSERT,D. OBJECT_CONSTRUCT,,,,,,,,,,,,4,"Yes, it is same with 1070. But, there the answer was TO_JSONE Even for this one the answer is TO_JSON. As long as the question does not mention anything related to construct an object, like Variant column, the answer is TO_JSONE",
Which command should be used to generate a single file when unloading data from a Snowflake table into a file?,multiple-choice,A. PARTITION BY [expr],B. MAX_FILE_SIZE = 0,C. SINGLE = TRUE,D. OVERWRITE = TRUE,,,,,,,,,,,,3,C - straightforward,
Which function can be used to convert semi-structured data into rows and columns?,multiple-choice,A. TABLE,B. FLATTEN,C. PARSE_JSON,D. JSON_EXTRACT_PATH_TEXT,,,,,,,,,,,,2,"B that's the purpose of Flatten + there is no mention of JSON in the question
FLATTEN can be used to convert semi-structured data to a relational representation.",
What user setting can be configured to disable Multi-Factor Authentication (MFA) for a Snowflake user? (Choose two.),multi-select,A. DISABLE_MFA,B. MINS_TO_BYPASS_MFA,C. PASSWORD,D. MINS_TO_UNLOCK,E. MUST_CHANGE_PASSWORD,,,,,,,,,,,"1, 2","A and B
A and B.
https://docs.snowflake.com/en/user-guide/security-mfa#managing-mfa-for-an-account-and-users
its A and B",
Which table type has a Fail-safe period of 7 days?,multiple-choice,A. Temporary table,B. Transient table,C. Permanent table,D. External table,,,,,,,,,,,,3,"Agree with C
Answer is C",
How does Snowflake enable OAuth?,multiple-choice,A. By creating an external integration,B. By configuring a security integration,C. By establishing IP allowed lists and IP blocked lists,D. By using SnowSQL to enable an external OAuth using the Snowflake protocol,,,,,,,,,,,,2,"B - explained here https://docs.snowflake.com/en/user-guide/oauth-intro
Correct Answer: B. By configuring a security integration Configuring a security integration: In Snowflake, OAuth is enabled by creating and configuring a security integration. This integration defines the settings and parameters required for Snowflake to interact with an OAuth 2.0 authorization server, allowing users to authenticate and authorize access to Snowflake resources using OAuth tokens.
https://docs.snowflake.com/en/user-guide/oauth-intro  Administrators configure OAuth using a Security integration, which enables clients that support OAuth to redirect users to an authorization page and generate access tokens (and optionally, refresh tokens) for accessing Snowflake.",
Which type of workload traditionally benefits from the use of the query acceleration service?,multiple-choice,A. Workloads with a predictable data volume for each query,B. Workloads that include on-demand data analyses,C. Queries with small scans and non-selective filters,D. Queries that do not have filters or aggregation,,,,,,,,,,,,2,"B is correct
Correct Answer: B. Workloads that include on-demand data analyses Workloads that include on-demand data analyses: These types of workloads often involve complex queries that need to be executed quickly and efficiently. The query acceleration service is designed to speed up query processing for such workloads by allocating additional resources, thus reducing query response times and improving performance for ad-hoc and interactive queries.",
"When unloading data, which combination of parameters should be used to differentiate between empty strings and NULL values? (Choose two.)",multi-select,A. ESCAPE_UNENCLOSED_FIELD,B. REPLACE_INVALID_CHARACTERS,C. FIELD_OPTIONALLY_ENCLOSED_BY,D. EMPTY_FIELD_AS_NULL,E. SKIP_BLANK_LINES,,,,,,,,,,,"3, 4","Agree with cybe explanation
Correct Answers: C. FIELD_OPTIONALLY_ENCLOSED_BY and D. EMPTY_FIELD_AS_NULL FIELD_OPTIONALLY_ENCLOSED_BY: This parameter specifies a character that encloses the field. By using this parameter, you can ensure that empty strings are enclosed within the specified character (e.g., double quotes), allowing them to be differentiated from NULL values. EMPTY_FIELD_AS_NULL: This parameter determines how to handle empty fields during the unload operation. When set to TRUE, empty fields are treated as NULL values. This helps in distinguishing between actual empty strings and NULLs in the unloaded data.
https://docs.snowflake.com/en/user-guide/data-unload-considerations",
Which role must be used to create resource monitors?,multiple-choice,A. SECURITYADMIN,B. ACCOUNTADMIN,C. SYSADMIN,D. ORGADMIN,,,,,,,,,,,,2,"Agree with B
Correct Answer: B. ACCOUNTADMIN ACCOUNTADMIN: The ACCOUNTADMIN role in Snowflake has the necessary privileges to create and manage resource monitors. Resource monitors are used to manage and monitor the usage of resources (such as compute credits) within the Snowflake account. The ACCOUNTADMIN role has the highest level of administrative privileges required to perform this task.",
What step does Snowflake recommend when loading data from a stage?,multiple-choice,A. Use PURGE when using the COPY INTO [table] command.,B. Use REMOVE when using the COPY INTO [table] command.,C. Use the LOAD HISTORY function to view the status of loaded files.,D. Use the COPY HISTORY function to update the status of loaded files.,,,,,,,,,,,,3,"Answer C seems correct
Answer for Q #1116 is C external function https://docs.snowflake.com/en/user-guide/unstructured-intro",
"How can a user MINIMIZE Continuous Data Protection costs when using large, high-churn, dimension tables?",multiple-choice,A. Create transient tables and periodically copy them to permanent tables.,B. Create temporary tables and periodically copy them to permanent tables.,C. Create regular tables with extended Time Travel and Fail-safe settings.,D. Create regular tables with default Time Travel and Fail-safe settings.,,,,,,,,,,,,1,"A - transient table are basically the same as regular table but do not utilize fail safe hence reducing the storage cost involved with them https://docs.snowflake.com/en/user-guide/tables-temp-transient#transient-tables
For large, high-churn dimension tables that incur overly-excessive CDP costs, the solution is to create these tables as transient with zero Time Travel retention (i.e. DATA_RETENTION_TIME_IN_DAYS=0) and then copy these tables on a periodic basis into a permanent table.
https://docs.snowflake.com/en/user-guide/tables-storage-considerations",
Which Snowsight feature can be used to perform data manipulations and transformations using a programming language?,multiple-choice,A. SnowSQL,B. Dashboards,C. Python worksheets,D. Provider Studio,,,,,,,,,,,,3,"C - SnowSQL is a command line tool and BD makes no sense
It's the only answer",
"In Snowflake's data security framework, how does column-level security contribute to the protection of sensitive information? (Choose two.)",multi-select,A. Implementation of column-level security will optimize query performance.,B. Column-level security supports encryption of the entire database.,C. Column-level security ensures that only the table owner can access the data.,D. Column-level security limits access to specific columns within a table based on user privileges.,E. Column-level security allows the application of a masking policy to a column within a table or view.,,,,,,,,,,,"4, 5",Agree with DE,
How does Snowflake utilize clustering information to improve query performance?,multiple-choice,A. It prunes unnecessary micro-partitions based on clustering metadata.,B. It compresses the data within micro-partitions for faster querying.,C. It automatically allocates additional resources to improve query execution.,D. It organizes clustering information to speed-up data retrieval from storage.,,,,,,,,,,,,1,"A. It prunes unnecessary micro-partitions based on clustering metadata. This accurately describes the core mechanism. By using clustering metadata, Snowflake avoids scanning micro-partitions that do not contain the relevant data, leading to faster query execution.",
How can staged files be removed during data loading once the files have loaded successfully?,multiple-choice,A. Use the DROP command.,B. Use the PURGE copy option.,C. Use the FORCE = TRUE parameter.,D. Use the LOAD_UNCERTAIN_FILES copy option.,,,,,,,,,,,,2,"B - that's what purge does :)
Answer is B",
What objects can be cloned within Snowflake? (Choose two.),multi-select,A. Schemas,B. Users,C. External tables,D. Internal named stages,E. External named stages,,,,,,,,,,,"1, 4","https://docs.snowflake.com/en/user-guide/object-clone#cloning-and-stages
CREATE <object> … CLONE Creates a copy of an existing object in the system. This command is primarily used for creating zero-copy clones of databases, schemas, and tables; however, it can also be used to quickly/easily create clones of other schema objects , such as external stages, file formats, and sequences, and database roles.  https://docs.snowflake.com/en/user-guide/object-clone",
What can be used to process unstructured data?,multiple-choice,A. External tables,B. The COPY INTO [table] command,C. External functions,D. Snowpipe,,,,,,,,,,,,1,"C is the correct answer
C is correct
External functions allow you to call external services/APIs to process unstructured data Useful for tasks like text analysis, image processing, or other complex transformations",
Which type of workload is recommended for Snowpark-optimized virtual warehouses?,multiple-choice,A. Workloads with ad hoc analytics,B. Workloads that have large memory requirements,C. Workloads with unpredictable data volumes for each query,D. Workloads that are queried with small table scans and selective filters,,,,,,,,,,,,2,"https://docs.snowflake.com/en/user-guide/warehouses-snowpark-optimized#when-to-use-a-snowpark-optimized-warehouse
B is the right answer",
What is the benefit of using the STRIP_OUTER_ARRAY parameter with the COPY INTO [table] command when loading data from a JSON file into a table?,multiple-choice,A. It flattens multiple arrays into a single array.,B. It removes the outer array structure and loads separate rows of data.,C. It transforms a pivoted table into an array.,D. It tokenizes each data string using the defined delimiters.,,,,,,,,,,,,2,,
"A query containing a WHERE clause is running longer than expected. The Query Profile shows that all micro-partitions being scanned.

How should this query be optimized?",multiple-choice,A. Create a view on the table.,B. Add a clustering key to the table.,C. Add a LIMIT clause to the query.,D. Add a Dynamic Data Masking policy to the table.,,,,,,,,,,,,2,"Adding a clustering key would improve the depth and, in turn, pruning efficiency.",
Which access control entity in Snowflake can be created as part of a hierarchy within an account?,multiple-choice,A. Securable object,B. Role,C. Privilege,D. User,,,,,,,,,,,,2,B role is hierarchic,
"When an object is created in Snowflake, who owns the object?",multiple-choice,A. The public role,B. The user's default role,C. The current active primary role,D. The owner of the parent schema,,,,,,,,,,,,3,,
What is the MINIMUM Snowflake edition that must be used in order to see the ACCESS_HISTORY view?,multiple-choice,A. Standard,B. Enterprise,C. Business Critical,D. Virtual Private Snowflake (VPS),,,,,,,,,,,,2,"Agree with B
Access History requires Enterprise Edition (or higher). To inquire about upgrading, please contact Snowflake Support. This Account Usage view can be used to query the access history of Snowflake objects (e.g. table, view, column) within the last 365 days (1 year).",
Which role is responsible for managing the billing and credit data within Snowflake?,multiple-choice,A. ORGADMIN,B. ACCOUNTADMIN,C. SYSADMIN,D. SECURITYADMIN,,,,,,,,,,,,2,"https://docs.snowflake.com/en/user-guide/security-access-control-considerations#using-the-accountadmin-role
The account administrator (i.e users with the ACCOUNTADMIN system role) role is the most powerful role in the system. This role alone is responsible for configuring parameters at the account level. Users with the ACCOUNTADMIN role can view and manage Snowflake billing and credit data, and can stop any running SQL statements.",
"What can be used to identify the database, schema, stage, and file path to a set of files, and to allow a role that has sufficient privileges on the stage to access the files?",multiple-choice,A. A scoped URL,B. A file URL,C. A pre-signed URL,D. A directory table,,,,,,,,,,,,2,"https://docs.snowflake.com/en/user-guide/unstructured-intro
It's B, File URL : URL that identifies the database, schema, stage, and file path to a set of files. A role that has sufficient privileges on the stage can access the files",
Which command is used to remove files from either external cloud storage or an internal stage?,multiple-choice,A. DELETE,B. REMOVE,C. TRUNCATE,D. DROP,,,,,,,,,,,,2,B. REMOVE Removes files from either an external (external cloud storage) or internal (i.e. Snowflake) stage. https://docs.snowflake.com/en/sql-reference/sql/remove,
"How does Snowflake recommend defining a clustering key on a high-cardinality column that includes a 15 digit ID numbered column, ID_NUMBER?",multiple-choice,"A. TRUNC(ID_NUMBER, -6)","B. TRUNC(ID_NUMBER, 5)",C. ID_NUMBER*100,D. TO_CHAR(ID_NUMBER),,,,,,,,,,,,1,"A - Using Trunc(ID_NUMBER, -6) we reduce the cardinality of the column by turning the last 6 digits of the ID to zeros https://docs.snowflake.com/fr/sql-reference/functions/trunc",
Which query types will have significant performance improvement when run using the search optimization service? (Choose two.),multi-select,A. Range searches,B. Equality searches,C. Substring searches,D. Queries with IN predicates,E. Queries with aggregation,,,,,,,,,,,"2, 4","Point lookup queries are queries that are expected to return a small number of rows. The search optimization service can improve the performance of point lookup queries that use:  Equality predicates (for example, <column_name> = <constant>).  Predicates that use IN (see example).  Example
B and D
https://docs.snowflake.com/en/user-guide/search-optimization/point-lookup-queries",
Which Query Profile operator is considered a DML operator?,multiple-choice,A. ExternalScan,B. Flatten,C. Merge,D. Sort,,,,,,,,,,,,3,"https://docs.snowflake.com/en/user-guide/ui-snowsight-activity#dml-operators
Insert, Delete, Update, MERGE, and Unload are DML Operator",
Masking policies are created at what level in Snowflake?,multiple-choice,A. Table,B. Column,C. Schema,D. Database,,,,,,,,,,,,3,"https://docs.snowflake.com/en/sql-reference/sql/create-masking-policy
Masking policies are applied to columns to control how sensitive data is displayed
C. schema https://docs.snowflake.com/en/user-guide/security-column-intro  ""What are masking policies? Snowflake supports masking policies as a schema-level object to protect sensitive data....""",
What would cause different results to be returned when running the same query twice?,multiple-choice,A. SAMPLE is used and the seed is set.,B. SAMPLE is used and the seed is not set.,C. Fraction-based sampling is used.,D. Fixed-size sampling is used.,,,,,,,,,,,,2,,
What are type predicates used for?,multiple-choice,A. Extracting data from a VARIANT column,B. Casting a value in a VARIANT column to a particular data type,C. Determining if a value in a VARIANT column is a particular data type,D. Manipulating objects and arrays in a VARIANT column,,,,,,,,,,,,3,"https://docs.snowflake.com/en/sql-reference/functions/is
Type predicates are functions like IS_BOOLEAN, IS_BINARY, etc... They check the type of values in variants  See https://docs.snowflake.com/en/sql-reference/functions-semistructured#list-of-semi-structured-and-structured-data-functions",
Which table function is used to perform additional processing on the results of a previously-run query?,multiple-choice,A. QUERY_HISTORY,B. RESULT_SCAN,C. DESCRIBE_RESULTS,D. QUERY_HISTORY_BY_SESSION,,,,,,,,,,,,2,https://docs.snowflake.com/en/sql-reference/functions/result_scan,
Which actions can be performed using a resource monitor in Snowflake? (Choose two.),multi-select,A. Monitor the performance of individual queries in real-time.,B. Automatically allocate more storage space to a virtual warehouse.,C. Modify the queries being executed within a virtual warehouse.,D. Suspend a virtual warehouse when its credit usage reaches a defined limit.,E. Trigger a notification to account administrators when credit usage reaches a specified threshold.,,,,,,,,,,,"4, 5",D & E options are correct.,
Which Snowflake native tool can be used to diagnose and troubleshoot network connections?,multiple-choice,A. SnowSQL,B. Snowflake Python connector,C. Snowsight,D. SnowCD,,,,,,,,,,,,4,"D. It is litterally the definition of the tool https://docs.snowflake.com/en/user-guide/snowcd
SnowCD
SnowCD is D, not C.",
Why would a Snowflake user load JSON data into a VARIANT column instead of a string column?,multiple-choice,A. A VARIANT column is more secure than a string column.,B. A VARIANT column compresses data and a string column does not.,C. A VARIANT column can be used to create a data hierarchy and a string column cannot.,D. A VARIANT column will have a better query performance than a string column.,,,,,,,,,,,,3,https://docs.snowflake.com/en/user-guide/semistructured-considerations,
How can a 5 GB table be downloaded into a single file MOST efficiently?,multiple-choice,A. Keep the default MAX_FILE_SIZE to 16 MB.,B. Set the default MAX_FILE_SIZE to 5 GB.,C. Set the SINGLE parameter to TRUE.,D. Use a regular expression in the stage specifications of the COPY command.,,,,,,,,,,,,3,,
Which security models are used in Snowflake to manage access control? (Choose two.),multi-select,A. Discretionary Access Control (DAC),B. Identity Access Management (IAM),C. Mandatory Access Control (MAC),D. Role-Based Access Control (RBAC),E. Security Assertion Markup Language (SAML),,,,,,,,,,,"1, 4","https://docs.snowflake.com/en/user-guide/security-access-control-overview  Snowflake’s approach to access control combines aspects from the following models:  Discretionary Access Control (DAC): Each object has an owner, who can in turn grant access to that object.  Role-based Access Control (RBAC): Access privileges are assigned to roles, which are in turn assigned to users.  User-based Access Control (UBAC): Access privileges are assigned directly to users. Access control considers privileges assigned directly to users only when USE SECONDARY ROLE is set to ALL.
It's the same response from Gemini, GPT and Claude ;-)  Be careful, because they often give different answers. They fail a lot of these tests",
Which Snowflake governance feature allows users to assign metadata labels to improve data governance and database access control?,multiple-choice,A. Secure functions,B. Secure views,C. Object tagging,D. Row-level security,,,,,,,,,,,,3,https://docs.snowflake.com/en/user-guide/object-tagging,
What is the MINIMUM Snowflake edition that supports database replication?,multiple-choice,A. Standard,B. Enterprise,C. Business Critical,D. Virtual Private Snowflake (VPS),,,,,,,,,,,,1,"A - Every edition supports features like database replication and time travel
Database replication is supported on all editions, so it's A
https://docs.snowflake.com/en/user-guide/db-replication-intro",
"Which Snowflake function and command combination should be used to convert rows in a relational table to a single VARIANT column, and unload the rows into a file in JSON format? (Choose two.)",multi-select,A. PUT,B. GET,C. COPY,D. EXPORT,E. OBJECT_CONSTRUCT,,,,,,,,,,,"3, 5",CE - seen this question multiple times,
What Snowflake recommendation is designed to ensure that staged data is only loaded once?,multiple-choice,A. Partitioning staged data files,B. Loading only the most recently-staged data files,C. Removing data files after loading,D. Identifying and removing duplicates after each data load,,,,,,,,,,,,3,,
Which privilege grants the ability to set a column-level security masking policy on a table or view column?,multiple-choice,A. APPLY,B. CREATE,C. SET,D. MODIFY,,,,,,,,,,,,1,"https://docs.snowflake.com/en/user-guide/security-column-ddm-intro#dynamic-data-masking-privileges
Go to section Masking policy privileges.  APPLY >>>Enables executing the unset and set operations for a masking policy on a column.  Correct answer- Apply",
"When sharing data in Snowflake, what privileges does a Provider need to grant along with a share? (Choose two.)",multi-select,A. USAGE on the specific tables in the database.,B. MODIFY on the specific tables in the database.,C. SELECT on the specific tables in the database.,D. USAGE on the database and the schema containing the tables to share.,E. OPERATE on the database and the schema containing the tables to share.,,,,,,,,,,,"3, 4","https://docs.snowflake.com/en/user-guide/data-sharing-gs#grant-database-roles-to-a-share
GRANT USAGE ON DATABASE sales_db TO SHARE sales_s; GRANT USAGE ON SCHEMA sales_db.aggregates_eula TO SHARE sales_s;  GRANT SELECT ON TABLE sales_db.aggregates_eula.aggregate_1 TO SHARE sales_s;",
How can the Query Profile be used to troubleshoot a problematic query?,multiple-choice,A. It will indicate if a virtual warehouse memory is too small to run the query.,B. It will indicate if a user lacks the privileges needed to run the query.,C. It will indicate if a virtual warehouse is in auto-scale mode.,D. It will indicate if the user has enough Snowflake credits to run the query.,,,,,,,,,,,,1,,
Which data type can be used for floating-point numbers without losing precision?,multiple-choice,A. BINARY,B. VARIANT,C. INTEGER,D. DOUBLE,,,,,,,,,,,,4,"D is correct DOUBLE is a synonim for FLOAT in data types
https://docs.snowflake.com/en/sql-reference/data-types-numeric",
Which data sharing option allows a Snowflake user to set up and manage a group of accounts and offer a share to that group?,multiple-choice,A. Free listing,B. Paid listing,C. Direct share,D. Data Exchange,,,,,,,,,,,,4,"With a Data Exchange, you can: Create a group of accounts Manage access to this group Offer data shares to the entire group",
What kind of authentication do Snowpipe REST endpoints use?,multiple-choice,A. OAuth,B. Key-based,C. Username and password,D. Single Sign-On (SSO),,,,,,,,,,,,2,,
What are the possible values within a METADATA$ACTION column in a Snowflake stream? (Choose two.),multi-select,A. INSERT,B. UPDATE,C. DELETE,D. TRUNCATE,E. UPSERT,,,,,,,,,,,"1, 3","AC - INSERT and DELETE
INSERT and DELETE
Insert and delete. https://docs.snowflake.com/en/user-guide/streams-intro#:~:text=following%20additional%20columns%3A-,METADATA%24ACTION,-Indicates%20the%20DML",
"What is the MINIMUM Snowflake edition that offers data protection for extremely sensitive data, such as Protected Health Information (PHI)?",multiple-choice,A. Standard,B. Enterprise,C. Business Critical,D. Virtual Private Snowflake (VPS),,,,,,,,,,,,3,"Poorly phrased question... what's the use of adding (PHI) at the end except to spread confusion ? but answer is C
Business Critical Edition, formerly known as Enterprise for Sensitive Data (ESD), offers even higher levels of data protection to support the needs of organizations with extremely sensitive data, particularly PHI data that must comply with HIPAA and HITRUST CSF regulations.",
"What takes the highest precedence in Snowflake file format options, when specified in multiple locations during data loading?",multiple-choice,A. The stage definition,B. The table definition,C. The use of a COPY INTO [table] statement,D. The use of a COPY INTO [location] statement,,,,,,,,,,,,2,"Table has not relevance here.
D :https://docs.snowflake.com/en/sql-reference/functions/validate#:~:text=Validates%20the%20files%20loaded%20in,than%20just%20the%20first%20error.",
Which service or tool is a Command Line Interface (CLI) client used for connecting to Snowflake to execute SQL queries?,multiple-choice,A. Snowsight,B. SnowCD,C. Snowpark,D. SnowSQL,,,,,,,,,,,,4,"correct
SnowSQL D",
What Snowflake objects can contain custom application logic written in JavaScript? (Choose two.),multi-select,A. Stored procedures,B. Stages,C. Tasks,D. Views,E. User-Defined Functions (UDFs),,,,,,,,,,,"1, 5",correct,
What is the MINIMUM Snowflake edition required to use the column-level security feature?,multiple-choice,A. Standard,B. Enterprise,C. Business Critical,D. Virtual Private Snowflake (VPS),,,,,,,,,,,,2,"https://docs.snowflake.com/en/user-guide/intro-editions
This feature requires Enterprise Edition (or higher). To inquire about upgrading, please contact Snowflake Support. https://docs.snowflake.com/en/user-guide/security-column-intro
C. Business Critical  Explanation: Column-level security in Snowflake, such as column masking policies, is available starting from the Business Critical edition, providing more granular control over data access.  Why the others are wrong:   A. Standard: The Standard edition does not support column-level security features.  B. Enterprise: Although the Enterprise edition includes many features, column-level security is not available in this edition.  D. Virtual Private Snowflake (VPS): While VPS includes enhanced security features, it is not the minimum edition for column-level security.",
Which command should be used to assign a key to a Snowflake user who needs to connect using key pair authentication?,multiple-choice,A. ALTER USER jsmith SET RSA_P8_KEY='MIIBIjANBgkqh...';,B. ALTER USER jsmith SET ENCRYPTED_KEY='MIIBIjANBgkqh...';,C. ALTER USER jsmith SET RSA_PRIVATE_KEY='MIIBIjANBgkqh...';,D. ALTER USER jsmith SET RSA_PUBLIC_KEY='MIIBIjANBgkqh...';,,,,,,,,,,,,4,"D, key needs to be public
Correct Answer D https://docs.snowflake.com/en/user-guide/key-pair-auth Go to section Assign the public key to a Snowflake user of above url.",
What optional properties can a Snowflake user set when creating a virtual warehouse? (Choose two.),multi-select,A. Auto-suspend,B. Cache size,C. Default role,D. Resource monitor,E. Storage size,,,,,,,,,,,"1, 4","https://docs.snowflake.com/en/sql-reference/sql/create-warehouse
Based on this it looks correct - https://docs.snowflake.com/en/sql-reference/sql/create-warehouse",
What is the purpose of the use of the VALIDATE command?,multiple-choice,A. To view any queries that encountered an error,B. To verify that a SELECT query will run without error,C. To prevent a PUT statement from running if an error occurs,D. To see all errors from a previously run COPY INTO [table] statement,,,,,,,,,,,,4,"https://docs.snowflake.com/en/sql-reference/functions/validate
D - that's the purpose of VALIDATE no further explanation needed
https://docs.snowflake.com/en/sql-reference/functions/validate
VALIDATE - Validates the files loaded in a past execution of the COPY INTO command - Returns all the errors encountered during the load, rather than just the first error",
Which function is used to unload a relational table into a JSON file?,multiple-choice,A. PARSE_JSON,B. JSON_EXTRACT_PATH_TEXT,C. OBJECT_CONSTRUCT,D. TO_JSON,,,,,,,,,,,,4,"The TO_JSON function in Snowflake is used to convert relational data into a JSON-formatted string. It is the appropriate function to use when unloading a relational table into a JSON file, as it serializes the data into a JSON representation.
D is correct, I think the first two are for unloading json and C needs the COPY INTO [location] to successfully unload json",
How can the ACCESS_HISTORY view in the ACCOUNT_USAGE schema be used to review the data governance settings for an account? (Choose two.),multi-select,A. Identify queries run by a particular user.,B. Identify access to the roles given to a user.,C. Identify SQL statements that failed to run.,D. Identify objects that were modified by a query.,E. Identify object dependencies.,,,,,,,,,,,"1, 4",,
Which command is used to unload data from a Snowflake table into a Snowflake stage?,multiple-choice,A. GET,B. CREATE STAGE,C. COPY INTO [location],D. PUT,,,,,,,,,,,,3,"C is correct
correct
Option : C -- is correct",
"What should an account administrator do to help a user log into Snowflake, if the user cannot authenticate using Multi-Factor Authentication (MFA)?",multiple-choice,A. Set DISABLE_MFA to TRUE for the user.,B. Set MINS_TO_BYPASS_MFA equal to 0 for the user.,C. Set ALLOW_ID_TOKEN to FALSE for the user.,D. Set ALLOW_CLIENT_MFA_CACHING to FALSE for the user.,,,,,,,,,,,,1,The adiminstrator should disable the MFA for the user.,
Which command can be executed from a reader account?,multiple-choice,A. INSERT,B. CREATE SHARE,C. SHOW PROCEDURES,D. COPY INTO [location],,,,,,,,,,,,4,"""However, you can use the COPY INTO <location> command with your connection credentials to unload data into a cloud storage location.  Additionally, you cannot execute the following commands in a reader account: INSERT UPDATE DELETE MERGE CREATE IMAGE REPOSITORY COPY INTO <table> CREATE MASKING POLICY CREATE PIPE CREATE ROW ACCESS POLICY CREATE SERVICE CREATE SHARE CREATE STAGE SHOW PROCEDURES""  https://docs.snowflake.com/en/user-guide/data-sharing-reader-create
None if these can be executed according to docs",
Which command line parameter value can be pre-specified as an environment variable in SnowSQL?,multiple-choice,A. HOST,B. VARIABLE,C. OPTION,D. MFA-PASSCODE,,,,,,,,,,,,1,"""Currently, environment variables can only be used to pre-specify some command line parameter values such as password, host, and database""  https://docs.snowflake.com/en/user-guide/snowsql-start#:~:text=Currently%2C%20environment%20variables%20can%20only%20be%20used%20to%20pre%2Dspecify%20some%20command%20line%20parameter%20values%20such%20as%20password%2C%20host%2C%20and%20database",
Which command is used to determine the file name of each row of data from a staged file?,multiple-choice,A. SHOW FILE FORMATS,B. SELECT METADATA$FILE_CONTENT_KEY,C. SELECT METADATA$FILE_ROW_NUMBER,D. SELECT METADATA$FILENAME,,,,,,,,,,,,4,https://docs.snowflake.com/en/user-guide/querying-metadata,
Which Snowflake feature improves the performance of point lookup queries?,multiple-choice,A. Materialized views,B. Automatic clustering,C. Query acceleration service,D. Search optimization service,,,,,,,,,,,,4,correct,
What is the impact of selecting one Snowflake edition over another? (Choose two.),multi-select,A. The edition will impact the unit costs for storage.,B. The edition will impact which regions can be accessed by the accounts.,C. The edition will determine the unit costs for the compute credits.,D. The edition will impact the total allowed storage space.,E. The edition will set a limit on the number of compute credits that can be consumed.,,,,,,,,,,,"1, 3","AC - unit costs and compute credits
Yes, finally 1167 question finshedcongrats!!! Don't know how many times I Need to go though 1167 question before exam.
https://docs.snowflake.com/en/user-guide/intro-editions",
"In a managed access schema, only the schema owner or a role with what privilege can help centralize privilege management?",multiple-choice,A. USAGE,B. OPERATE,C. MANAGE GRANTS,D. IMPORTED PRIVILEGES,,,,,,,,,,,,3,,
Which command should be used to drop files from an internal or external stage?,multiple-choice,A. DELETE,B. DROP,C. REMOVE,D. TRUNCATE,,,,,,,,,,,,3,correct,
Which parameters can be used together to ensure that a virtual warehouse never has a backlog of queued SQL statements? (Choose two.),multi-select,A. STATEMENT_QUEUED_TIMEOUT_IN_SECONDS,B. STATEMENT_TIMEOUT_IN_SECONDS,C. DATA_RETENTION_TIME_IN_DAYS,D. MAX_CONCURRENCY_LEVEL,E. MAX_DATA_EXTENSION_TIME_IN_DAYS,,,,,,,,,,,"1, 4",,
What action should be taken if a large number of concurrent queries are queued in a virtual warehouse?,multiple-choice,A. Scale-up by resizing the warehouse.,B. Scale-out with a multi-cluster warehouse.,C. Disable auto-suspend on the warehouse.,D. Enable auto-resume on the warehouse.,,,,,,,,,,,,2,correct,
Which feature is supported in column-level security in Snowflake?,multiple-choice,A. Object tagging,B. Data classification,C. External tokenization,D. Tag-based masking policies,,,,,,,,,,,,4,"C is correct
https://docs.snowflake.com/en/user-guide/tag-based-masking-policies A tag-based masking policy combines the object tagging and masking policy features to allow a masking policy to be set on a tag using an ALTER TAG command.  https://docs.snowflake.com/en/user-guide/security-column-intro Column-level Security in Snowflake allows the application of a masking policy to a column within a table or view. Currently, Column-level Security includes two features:  Dynamic Data Masking External Tokenization  I think that both C & D are correct. But, if it is to select one, only, let's say the same: D",
A network policy applied at the user level takes precedence over a network policy applied to what Snowflake object?,multiple-choice,A. A role,B. An account,C. A database,D. An organization,,,,,,,,,,,,2,correct,
Which Snowflake storage object can be used to store data beyond a single session and will not incur Fail-safe costs?,multiple-choice,A. Permanent table,B. External table,C. Temporary table,D. Transient table,,,,,,,,,,,,4,"https://docs.snowflake.com/en/user-guide/data-cdp-storage-costs
correct",
Which data sharing mechanism can be used to share data privately or publicly within the Snowflake Marketplace?,multiple-choice,A. Listing,B. Direct share,C. Reader account,D. Data Exchange,,,,,,,,,,,,1,,
What metrics will the SHOW TABLES command in Snowsight provide?,multiple-choice,A. Time Travel bytes,B. Active bytes,C. Fail-safe bytes,D. Retained for clone bytes,,,,,,,,,,,,2,,
"An external stage, my_stage contains many directories, including one, app_files that contains CSV files.

How can all the CSV files from this directory be moved into table my_table without scanning files that are not needed?",multiple-choice,A. COPY INTO my_table FROM @my_stage PATTERN='.*[.]csv';,B. COPY INTO my_table FROM @my_stage/app_files PATTERN='.*[.]csv';,C. COPY INTO my_table FROM @my_stage/app_files PATTERN='.*[.]txt';,D. COPY INTO my_table FROM @my_stage PATTERN='.*[.]txt';,,,,,,,,,,,,2,,
Using which object-level parameters will help limit query processing and concurrency slowdowns? (Choose two.),multi-select,A. MULTI_STATEMENT_COUNT,B. ENABLE_QUERY_ACCELERATION,C. STATEMENT_TIMEOUT_IN_SECONDS,D. STATEMENT_QUEUED_TIMEOUT_IN_SECONDS,E. QUERY_ACCELERATION_MAX_SCALE_FACTOR,,,,,,,,,,,"2, 5","STATEMENT_TIMEOUT_IN_SECONDS: This parameter sets a limit on the execution time for a SQL statement. If a statement runs longer than the specified time (in seconds), the system automatically aborts it. This helps prevent long-running queries from monopolizing resources and slowing down other processes.  STATEMENT_QUEUED_TIMEOUT_IN_SECONDS: This parameter controls how long a statement will wait in a queue before it's canceled. When there's high concurrency, queries might be queued before they can be executed. Setting a timeout prevents statements from staying in the queue indefinitely, freeing up resources and preventing potential deadlocks.",
Which function will convert semi-structured data to a relational data representation?,multiple-choice,A. PARSE_JSON,B. FLATTEN,C. OBJECT_CONSTRUCT,D. OBJECT_AGG,,,,,,,,,,,,2,"The FLATTEN function in Snowflake is used to convert semi-structured data, such as JSON or XML, into a relational (tabular) representation. It essentially ""explodes"" the data, breaking down nested structures like arrays or objects into multiple rows and columns.",
What triggers the automated maintenance of a table's clustering key after it has been defined?,multiple-choice,A. A scheduled task established by the ORGADMIN.,B. A time-based schedule set by the user.,C. A Snowflake determination based on the table size.,D. A Snowflake determination that the table will benefit from maintenance.,,,,,,,,,,,,4,"Snowflake’s Automatic Clustering service does not run on a fixed schedule or via user‑defined tasks; instead, it monitors each clustered table continuously and automatically triggers maintenance only when the system determines that the table’s clustering will benefit from reclustering.",
How does Snowflake optimize queries on tables by leveraging the sorting and storage of data within micro-partitions?,multiple-choice,"A. The data is pruned by column to eliminate unnecessary micro-partitions, then the rows within the remaining micro-partitions are filtered.","B. The data is pruned by micro-partitions based on column values, then rows within the remaining micro-partitions are filtered.","C. Any micro-partitions that are not needed for the query are pruned, then the data within the remaining micro-partitions is pruned by column.","D. The data within micro-partitions is sorted by rows, then the columns are filtered based on the query conditions.",,,,,,,,,,,,2,"Snowflake organizes table data into immutable micro‑partitions—small (50–500 MB uncompressed, up to 16 MB compressed) columnar files stored in cloud blob storage—where each partition’s columns are sorted and compressed independently. At query compile time, Snowflake uses per‑partition metadata (min/max values, distinct counts, byte offsets) to prune irrelevant partitions and skip unreferenced columns, drastically reducing I/O and network reads.
https://docs.snowflake.com/en/user-guide/tables-clustering-micropartitions The micro-partition metadata maintained by Snowflake enables precise pruning of columns in micro-partitions at query run-time, including columns containing semi-structured data. These being said, it seems that pruning is done by column in micro-partitions, which is against all the questions we solved in this examtopics. I shall say that B, but I am not convinced anymore.",
What role should be used when creating a new user?,multiple-choice,A. ORGADMIN,B. SECURITYADMIN,C. USERADMIN,D. SYSADMIN,,,,,,,,,,,,3,"I really hate these questions because the documentation says both the securityadmin and the useradmin can create, monitor and manage user and roles... but it seems like the best practice is to use useradmin for this task
https://docs.snowflake.com/en/user-guide/admin-user-management#privileges-required-to-create-and-modify-users  https://docs.snowflake.com/en/user-guide/security-access-control-overview#system-defined-roles",
Which ACCOUNT_USAGE view will identify long-running queries?,multiple-choice,A. DATA_TRANSFER_HISTORY,B. TASK_HISTORY,C. QUERY_HISTORY,D. METERING_DAILY_HISTORY,,,,,,,,,,,,3,https://docs.snowflake.com/en/sql-reference/account-usage/query_history,
"When sharing data among multiple Snowflake accounts, what charges are incurred by a data consumer when viewing shared data using their own account?",multiple-choice,A. Cloud services charges,B. Compute charges,C. Data storage charges,D. Data egress charges,,,,,,,,,,,,2,Correct,
Which objects can be cloned in Snowflake? (Choose two.),multi-select,A. Virtual warehouses,B. Internal named stages,C. External named stages,D. Dynamic tables,E. External tables,,,,,,,,,,,"2, 4","CREATE <object> … CLONE Creates a copy of an existing object in the system. This command is primarily used for creating zero-copy clones of databases, schemas, and tables. You can also use this command to create clones of other schema objects, including external stages, file formats, sequences, and database roles. However, the following object types are not cloned:",
What happens to foreign key constraints when a table is cloned to another database?,multiple-choice,A. All referenced tables will be cloned.,B. The cloned table will reference the primary key in the source table.,C. The cloned table will lose all references to the primary key.,D. The cloned table will lose all references to the foreign and primary keys,,,,,,,,,,,,2,"If the database or schema containing both tables is cloned, the cloned table with the foreign key references the primary key in the other cloned table.  If the tables are in separate databases or schemas, the cloned table references the primary key in the source table.
I changed my mind: https://docs.snowflake.com/en/user-guide/object-clone Cloning and foreign key constraints A table can have a foreign key constraint that references a table that includes the primary key. When a table with a foreign key constraint is cloned, the cloned table references the source or cloned table that includes the primary key:  If the database or schema containing both tables is cloned, the cloned table with the foreign key references the primary key in the other cloned table.  If the tables are in separate databases or schemas, the cloned table references the primary key in the source table. Hence, the answer is B, since the question does not mention that the both tables are cloned, within the same cloned database.",
"What step must be taken to ensure that a user can only access Snowsight from a specific location, or when working from home?",multiple-choice,A. Use a company Virtual Private Network (VPN) connection.,B. Use Multi-Factor Authentication (MFA).,C. Use Single Sign-On (SSO).,D. Add the user's IP address to the network policy allowed list.,,,,,,,,,,,,4,https://docs.snowflake.com/en/user-guide/network-policies,
"In a SPLIT_PART function, what will the returned value be if the partNumber is out of range?",multiple-choice,A. −1,B. An empty string,C. The full string,D. An error,,,,,,,,,,,,2,"Usage notes If the partNumber is out of range, the returned value is an empty string.
https://docs.snowflake.com/en/sql-reference/functions/split_part
https://docs.snowflake.com/en/sql-reference/functions/split_part Splits a given string at a specified character and returns the requested part.  In this case, SPLIT will return entire string.",
What Snowflake features are recommended to restrict unauthorized users from accessing Personal Identifiable Information (PI)? (Choose two.),multi-select,A. Dynamic Data Masking,B. Transient tables,C. Secure views,D. Multi-Factor Authentication (MFA),E. Data encryption,,,,,,,,,,,"1, 3",https://community.snowflake.com/s/article/Methods-for-Securing-PII-Data-in-Snowflake,
Which Snowflake keywords help retrieve data without the need to completely scan a table? (Choose two.),multi-select,A. TOP [n],B. LIMIT,C. FETCH,D. SAMPLE,E. TABLESAMPLE,,,,,,,,,,,"4, 5","Both clauses are synonymous and tell Snowflake to perform a probabilistic (Bernoulli or block‑level) or fixed‑size sample before reading all micro‑partitions
Correct answer is DE : SAMPLE and TABLESAMPLE are synonimous https://docs.snowflake.com/en/sql-reference/constructs/sample. LIMIT / FETCH and TOP[n] are also all equivalent and does require a complete scan of the table (plus are eliminated by default since there is 3 of them and the question asks for two answers)
SAMPLE  TABLESAMPLE  Both clauses are synonymous and tell Snowflake to perform a probabilistic (Bernoulli or block‑level) or fixed‑size sample before reading all micro‑partitions, so the engine can skip over large portions of the data store when only a sample is needed",
Which data protection feature should only be used when all other data recovery options have been attempted?,multiple-choice,A. Time Travel,B. Cloning,C. Replication,D. Fail-safe,,,,,,,,,,,,4,"Fail‑Safe, is a non‑configurable, seven‑day, best‑effort recovery period provided solely by Snowflake after the Time Travel window closes, and should only be used when all other recovery options have been attempted",
"A single cluster virtual warehouse has no free resources.

What will happen to new queries that are run against this warehouse?",multiple-choice,A. The queries will be assigned to another virtual warehouse.,B. The queries will be skipped.,C. The queries will be placed in a queue.,D. The warehouse will automatically resize and execute the queries.,,,,,,,,,,,,3,"When there is only single cluster virtual warehouse , it can not SCALE and hence new queries need to wait in the Queue",
How can a Data Exchange Administrator provide a user with account access to a Data Exchange?,multiple-choice,A. Grant the user the USERADMIN role.,B. Add the user to the Data Exchange.,C. Enable the IMPORT SHARE privilege and grant this privilege to the user.,D. Create a new database for the Data Exchange and provide access to the user.,,,,,,,,,,,,3,"Data Exchange Admin responsibilities The Snowflake account that hosts the Data Exchange is the Data Exchange Admin. The Data Exchange Admin is responsible for configuring the Data Exchange and managing members (data providers and data consumers).  A user with the ACCOUNTADMIN role in the account designated as the Data Exchange Admin can:  Add or remove members  Designate members as providers, or consumers, or both  A Data Exchange Admin can delegate these privileges to other roles. For more information, see Granting administrator privileges in a Data Exchange. https://docs.snowflake.com/en/user-guide/data-exchange
https://docs.snowflake.com/en/user-guide/data-exchange-using#access-consumer-listings All users can browse listings in the Data Exchange, but only users with the ACCOUNTADMIN role or the IMPORT SHARE privilege can get or request data. Indeed, the B answer is correct, but I do not think that the question is looking for such simple reply. It is clear that first step for getting access to data in DATA EXCHANGE is the user to be added. I expect that the question assumed that this was already done. Answer is C.
https://docs.snowflake.com/en/user-guide/data-exchange-using#access-consumer-listings",
What identifiers are supported when creating a Snowflake account hostname? (Choose two.),multi-select,A. Cloud region,B. Snowflake domain,C. Account name,D. Account locator,E. Account cloud platform,,,,,,,,,,,"1, 4","https://docs.snowflake.com/en/user-guide/admin-account-identifier As mentioned by 37ceea2, there are 2 options: 1. account name in your organization (preferred) 2. Account locator in region. The question is a bit confusing, but since there are 2 answers expected, Cloud region and Account locator seems to be the right option.
https://docs.snowflake.com/en/user-guide/admin-account-identifier Finding the region and locator for an account If you can connect to your Snowflake account, you can query the following context functions to identify the region and account locator for the Snowflake account you are connected to:  CURRENT_REGION retrieves the region in which your account is located.  CURRENT_ACCOUNT retrieves the account locator.  If you are unable to connect to Snowflake, contact the Snowflake administrator for your account to retrieve this information. This is the most close to the question's topic, I was able to find/",
What kind of value does a User-Defined Function (UDF) return? (Choose two.),multi-select,A. Dictionary,B. List,C. Object,D. Scalar,E. Tabular,,,,,,,,,,,"4, 5","https://docs.snowflake.com/en/developer-guide/udf/udf-overview
UDF are further grouped into tabular and scalar based on their return value. The possible output values are Scalar and Tabular",
"When a transient table in Snowflake is dropped, what happens to the table?",multiple-choice,A. The table is no longer available for use.,B. The table can be undropped using Fail-safe.,C. The table can be recovered for 1 day only and after that it is no longer available.,D. The table can be recovered only with the assistance of Snowflake Support.,,,,,,,,,,,,3,"Transient tables in Snowflake behave much like permanent tables except they have no Fail‑Safe period and support at most a 1‑day Time Travel retention window. When you drop a transient table, it is moved into Time Travel and can be undropped only within that retention period; after the 1‑day window lapses, the table (and its data) is permanently irrecoverable.
Time Travel for Temporary and Transient tables is 0 or 1. Hence, even if the tables itself is no longer available for being used, it is possible to use it for 1 more day, if the Time Travel was set to 1. Hence, I vote C.
Snowflake didn't provide explicit information about the impact of dropping the transient table, but I have found this: https://hevodata.com/learn/what-is-snowflake-transient-table/. ""For instance, if a system failure occurs and a Transitory Table is dropped or lost, the data is no longer accessible by you or Snowflake after one day. As a result, it’s advisable to use Snowflake Transient Table only for data that does not require failure protection or can be recreated outside of Snowflake."" Hence, after max 1 day, the data will be lost.",
Which function produces a lateral view of a VARIANT column?,multiple-choice,A. GET_PATH,B. FLATTEN,C. GET,D. PARSE_JSON,,,,,,,,,,,,2,"B is correct
https://docs.snowflake.com/en/sql-reference/functions/flatten#:~:text=FLATTEN%20is%20a%20table%20function%20that%20takes%20a%20VARIANT%2C%20OBJECT%2C%20or%20ARRAY%20column%20and%20produces%20a%20lateral%20view",
Snowflake strongly recommends that all users with what type of role be required to use Multi-Factor Authentication (MFA)?,multiple-choice,A. USERADMIN,B. ACCOUNTADMIN,C. SECURITYADMIN,D. SYSADMIN,,,,,,,,,,,,2,"B is correct
I request to please confirm answers for below questions also 527 536 550 558 559 561 580 588 601 604 610 611 612 613 614",
What does it mean when the sample function uses the Bernoulli sampling method?,multiple-choice,A. The data is based on sampling every row.,B. The data is based on sampling 10% of the source data.,C. The data is based on sampling blocks of the source data.,D. The data is based on sampling 1000 rows of the source data.,,,,,,,,,,,,1,"correct
https://docs.snowflake.com/en/sql-reference/constructs/sample#syntax
BERNOULLI (or ROW): Includes each row with a probability of p/100. Similar to flipping a weighted coin for each row.",
Which function should be used to find the query ID of the second query executed in a current session?,multiple-choice,A. Select LAST_QUERY_ID(-2),B. Select LAST_QUERY_ID(-1),C. Select LAST_QUERY_ID(1),D. Select LAST_QUERY_ID(2),,,,,,,,,,,,2,"A. Select LAST_QUERY_ID(-2): This would return the ID of the third-to-last query.
B. Select LAST_QUERY_ID(-1): This would return the ID of the second-to-last query.
C. Select LAST_QUERY_ID(1): Positive integers are not valid arguments for LAST_QUERY_ID(). The argument must be 0 or a negative integer.
D. Select LAST_QUERY_ID(2): Positive integers are not valid arguments for LAST_QUERY_ID().",
How is the hierarchy of database objects organized in Snowflake?,multiple-choice,A. A database consists of one or more schemas. A schema contains tables and views.,B. A schema consists of one or more databases. A database contains tables and views.,"C. A schema consists of one or more databases. A database contains tables, views, and warehouses.",D. A database consists of one of more schemas and warehouses. A schema contains tables and views.,,,,,,,,,,,,1,"correct
A is correct. Ref: https://docs.snowflake.com/en/sql-reference/ddl-database
Please confirm answers for below questions also  527 536 558 561 580 588 601 604 610 611 612 613 614",
Which role can execute the SHOW ORGANIZATION ACCOUNTS command successfully?,multiple-choice,A. ACCOUNTADMIN,B. SECURITYADMIN,C. ORGADMIN,D. USERADMIN,,,,,,,,,,,,3,"correct
https://docs.snowflake.com/en/sql-reference/sql/show-organization-accounts",
Which data types in Snowflake are synonymous for FLOAT? (Choose two.),multi-select,A. DECIMAL,B. DOUBLE,C. NUMBER,D. NUMERIC,E. REAL,,,,,,,,,,,"2, 5","B, E is the correct answer. DOUBLE, DOUBLE PRECISION, REAL are synonymous with float
B,E is correct answer. DOUBLE, DOUBLE PRECISION, REAL are synonymous with float  https://docs.snowflake.com/en/sql-reference/intro-summary-data-types
Correct answer : BE https://docs.snowflake.com/en/sql-reference/data-types-numeric",
What ensures that a user with the role SECURITYADMIN can activate a network policy for an individual user?,multiple-choice,A. A role that has been granted the EXECUTE TASK privilege,B. A role that has been granted the global ATTACH POLICY privilege,C. Ownership privilege on only the role that created the network policy,D. Ownership privilege on both the user and the network policy,,,,,,,,,,,,4,"ATTACH POLICY is used to activate the network policy for an account and hence B is not applicable Since network policy is applied at the user level , C is not applicable  By snowflake documentation, network policy is applied both at the user and the account level. to apply at the user level, the SECURITY ADMIN should have the additional privilege of OWNERSHIP on the USER and the NETWORK
The correct answer is D.  Only the role with the OWNERSHIP privilege on both the user and the network policy, or a higher role, can activate a network policy for an individual user.  https://docs.snowflake.com/en/user-guide/network-policies#activating-network-policies-for-individual-users
Only the role with the OWNERSHIP privilege on both the user and the network policy, or a higher role, can activate a network policy for an individual user.  https://docs.snowflake.com/en/user-guide/network-policies",
Which function can be combined with the copy command to unload a relational table into a JSON file?,multiple-choice,A. FLATTEN,B. LISTAGG,C. OBJECT_CONSTRUCT,D. PARSE_JSON,,,,,,,,,,,,3,"C is correct as it's relation to semi conversion
c is correct answer
https://docs.snowflake.com/en/user-guide/data-unload-considerations#unloading-a-relational-table-to-json",
"A user needs to MINIMIZE the cost of large tables that are used to store transitory data. The data does not need to be protected against failures, because the data can be reconstructed outside of Snowflake.

What table type should be used?",multiple-choice,A. Permanent,B. Transient,C. Temporary,D. External,,,,,,,,,,,,2,"transient tables provide a good option for managing the cost of very large tables used to store transitory data; recommend using transient tables only for data that does not need to be protected against failures or data that can be reconstructed outside of Snowflake.
https://docs.snowflake.com/en/user-guide/tables-temp-transient#transient-tables",
"While loading data from a JSON file, what enables the removal of the outer array structure from the file and loads the records into separate table rows?",multiple-choice,A. SKIP_BYTE_ORDER_MARK,B. STRIP_NULL_VALUE,C. STRIP_OUTER_ARRAY,D. STRIP_OUTER_ELEMENT,,,,,,,,,,,,3,"correct
https://docs.snowflake.com/en/user-guide/semistructured-considerations#data-size-limitations
I request to please start discussion on below questions also 527 536 546 550 558 559 561 580 588 601 604 610 611 612 613 614",
Which functions can be used to share unstructured data through a secure view? (Choose two.),multi-select,A. BUILD_SCOPED_FILE_URL,B. BUILD_STAGE_FILE_URL,C. GET_ABSOLUTE_PATH,D. GET_PRESIGNED_URL,E. GET_RELATIVE_PATH,,,,,,,,,,,"1, 4","https://docs.snowflake.com/en/user-guide/unstructured-data-sharing
A & D is correct",
"Which function will return a row for each for each object in a VARIANT, OBJECT, or ARRAY column?",multiple-choice,A. CAST,B. FLATTEN,C. GET,D. PARSE_JSON,,,,,,,,,,,,2,"Correct
The function that will return a row for each object in a VARIANT, OBJECT, or ARRAY column is B. FLATTEN.  The FLATTEN function is a table function that takes a VARIANT, OBJECT, or ARRAY column and returns a row for each element or attribute within the column. This can be useful for breaking down complex data structures into a more easily queryable form.",
What is the MINIMUM size of a table for which Snowflake recommends considering adding a clustering key?,multiple-choice,A. 1 Kilobyte (KB),B. 1 Megabyte (MB),C. 1 Gigabyte (GB),D. 1 Terabyte (TB),,,,,,,,,,,,4,"correct
Ans: D  https://docs.snowflake.com/en/user-guide/tables-clustering-keys",
"For the ALLOWED_VALUES tag property, what is the MAXIMUM number of possible string values for a single tag?",multiple-choice,A. 10,B. 50,C. 64,D. 256,,,,,,,,,,,,4,"it's 300
None of them As of Feb 2024, it's 300  The ALLOWED_VALUES tag property enables specifying the possible string values that can be assigned to the tag when the tag is set on an object. The maximum number of possible string values for a single tag is 300.  https://docs.snowflake.com/en/user-guide/object-tagging#label-object-tagging-specify-tag-values
https://docs.snowflake.com/en/user-guide/object-tagging#label-object-tagging-specify-tag-values:~:text=The%20ALLOWED_VALUES%20tag%20property%20enables%20specifying%20the%20possible%20string%20values%20that%20can%20be%20assigned%20to%20the%20tag%20when%20the%20tag%20is%20set%20on%20an%20object.%20The%20maximum%20number%20of%20possible%20string%20values%20for%20a%20single%20tag%20is%2050.",
"Which Snowflake table type is only visible to the user who creates it, can have the same name as permanent tables in the same schema, and is dropped at the end of the session?",multiple-choice,A. Temporary,B. Local,C. User,D. Transient,,,,,,,,,,,,1,"Correct
https://docs.snowflake.com/en/user-guide/tables-temp-transient",
What is a characteristic of a role in Snowflake?,multiple-choice,A. Roles cannot be granted to other roles.,B. System-defined roles can be dropped.,C. Privileges granted to system roles by Snowflake can be revoked.,D. Privileges on securable objects can be granted and revoked to a role.,,,,,,,,,,,,4,"https://docs.snowflake.com/en/user-guide/security-access-control-overview
A: False, https://docs.snowflake.com/en/sql-reference/sql/grant-role B, C: False, https://docs.snowflake.com/en/user-guide/security-access-control-overview#:~:text=System%2Ddefined%20roles%20cannot%20be%20dropped.%20In%20addition%2C%20the%20privileges%20granted%20to%20these%20roles%20by%20Snowflake%20cannot%20be%20revoked.",
What command would a user execute to load unstructured data files into a Snowflake internal stage?,multiple-choice,A. PUT,B. GET,C. LIST,D. COPY INTO,,,,,,,,,,,,1,"Copy into command will load data from stage to a table. Data needs to be in stage already. In this case, I think I woul go with A. PUT.   COPY INTO <table> Loads data from staged files to an existing table. The files must already be staged in one of the following locations: Named internal stage, Named external stage. To load data from our local machine into the Snowflake Internal stage: 2. Using PUT command, copy the files from the local folder into snowflake internal stage created in earlier step.",
How do managed access schemas help with data governance?,multiple-choice,A. They log all operations and enable fine-grained auditing.,B. They provide centralized privilege management with the schema owner.,C. They enforce identical privileges across all tables and views in a schema.,D. They require the use of masking and row access policies across every table and view in the schema.,,,,,,,,,,,,2,"B is correct answer  With managed access schemas, object owners lose the ability to make grant decisions. Only the schema owner (i.e. the role with the OWNERSHIP privilege on the schema) or a role with the MANAGE GRANTS privilege can grant privileges on objects in the schema, including future grants, centralizing privilege management.
https://docs.snowflake.com/en/user-guide/security-access-control-configure#creating-managed-access-schemas",
What is the default period of time the Warehouse Activity section provides a graph of Snowsight activity?,multiple-choice,A. 2 hours,B. 1 week,C. 2 weeks,D. 1 month,,,,,,,,,,,,3,"2 Weeks (default)
The correct Answer is C Warehouse Activity The Warehouse Activity section provides a graph of activity over a period of time: Hour Day Week 2 Weeks (default) https://docs.snowflake.com/en/user-guide/ui-snowsight-admin#warehouse-activity
https://docs.snowflake.com/en/user-guide/ui-snowsight-admin#warehouse-activity",
"A Snowflake user wants to unload data from a relational table sized 5 GB using CSV. The extract needs to be as performant as possible.

What should the user do?",multiple-choice,"A. Use Parquet as the unload file format, using Parquet's default compression feature.",B. Use a regular expression in the stage specification of the COPY command to restrict parsing time.,C. Increase the default MAX_FILE_SIZE to 5 GB and set SINGLE = true to produce a single file.,D. Leave the default MAX_FILE_SIZE to 16 MB to take advantage of parallel operations.,,,,,,,,,,,,4,"By default, COPY INTO location statements separate table data into a set of output files to take advantage of parallel operations. The maximum size for each file is set using the MAX_FILE_SIZE copy option. The default value is 16777216 (16 MB) but can be increased to accommodate larger files. The maximum file size supported is 5 GB for Amazon S3, Google Cloud Storage, or Microsoft Azure stages.
D is more performant https://docs.snowflake.com/en/user-guide/data-unload-considerations",
How is the MANAGE GRANTS privilege applied?,multiple-choice,A. Globally,B. At the database level,C. At the schema level,D. At the table level,,,,,,,,,,,,1,"correct
In general, a role with any one of the following sets of privileges can grant privileges on an object to other roles:  The global MANAGE GRANTS privilege.  Only the SECURITYADMIN and ACCOUNTADMIN system roles have the MANAGE GRANTS privilege; however, the privilege can be granted to custom roles.
https://docs.snowflake.com/en/sql-reference/sql/grant-privilege#access-control-requirements",
What is required for a query execution to be served from the result cache?,multiple-choice,A. The user is the same.,B. The SQL texts the same.,C. The SQL query profile is the same.,D. The virtual warehouse is the same.,,,,,,,,,,,,2,"The query text (SQL) must be identical for the query execution to be served from the result cache. If a query differs in any aspect of its SQL text, such as whitespace, capitalization, or literal values, it is considered a different query and will not be served from the result cache
I thin D  ""Result Cache: Which holds the results of every query executed in the past 24 hours. These are available across virtual warehouses, so query results returned to one user is available to any other user on the system who executes the same query, provided the underlying data has not changed.""  https://community.snowflake.com/s/article/Caching-in-the-Snowflake-Cloud-Data-Platform",
Which Snowflake URL type is used by directory tables?,multiple-choice,A. File,B. Pre-signed,C. Scoped,D. Virtual-hosted style,,,,,,,,,,,,1,"A.  You can query a directory table to retrieve a list of the file URLs in the  stage along with their relative path, size, date the file was last modified,  md5 hash, and ETag using this command: select * from directory (@my_csv_stage)
Conceptually, directory tables are similar to external tables in that they store file-level metadata about the data files in a stage. Query a directory table to retrieve the Snowflake-hosted file URL to each file in the stage. A file URL permits prolonged access to a specified file. That is, the file URL does not expire. The same file URL is returned by calling the BUILD_STAGE_FILE_URL function.
https://docs.snowflake.com/en/user-guide/data-load-dirtables#:~:text=Directory%20tables%20store%20a%20catalog%20of%20staged%20files%20in%20cloud%20storage.%20Roles%20with%20sufficient%20privileges%20can%20query%20a%20directory%20table%20to%20retrieve%20file%20URLs%20to%20access%20the%20staged%20files%2C%20as%20well%20as%20other%20metadata.",
At which point is data encrypted when using a PUT command?,multiple-choice,A. When it reaches the virtual warehouse,B. When it gets micro-partitioned,C. Before it is sent from the user's machine,D. After it reaches the internal stage,,,,,,,,,,,,3,"It is either before transit client side encryption or during transit sse
Put command means the customer is loading from the user’s local machine into an internal stage via the Snowflake client (SnowSQL).   If the stage is an internal (i.e. Snowflake) stage data files are automatically encrypted by the Snowflake client on the user’s local machine prior to being transmitted to the internal stage, in addition to being encrypted after they are loaded into the stage.  https://docs.snowflake.com/user-guide/security-encryption-end-to-end
SNOWFLAKE_FULL: Client-side encryption. The files are encrypted by a client when it uploads them to the internal stage using PUT.
Always end-to-end encryption https://docs.snowflake.com/en/sql-reference/sql/put#:~:text=Uploaded%20files%20are%20automatically%20encrypted%20with%20128%2Dbit%20or%20256%2Dbit%20keys.%20The%20CLIENT_ENCRYPTION_KEY_SIZE%20account%20parameter%20specifies%20the%20size%20key%20used%20to%20encrypt%20the%20files.",
Which privileges are required for a user to restore an object? (Choose two.),multi-select,A. UPDATE,B. OWNERSHIP,C. MODIFY,D. UNDROP,E. CREATE,,,,,,,,,,,"2, 5","Similar to dropping an object, a user must have OWNERSHIP privileges for an object to restore it. In addition, the user must have CREATE privileges on the object type for the database or schema where the dropped object will be restored. https://docs.snowflake.com/en/user-guide/data-time-travel
Similar to dropping an object, a user must have OWNERSHIP privileges for an object to restore it. In addition, the user must have CREATE privileges on the object type for the database or schema where the dropped object will be restored.
https://docs.snowflake.com/en/user-guide/data-time-travel#:~:text=Similar%20to%20dropping%20an%20object%2C%20a%20user%20must%20have%20OWNERSHIP%20privileges%20for%20an%20object%20to%20restore%20it.%20In%20addition%2C%20the%20user%20must%20have%20CREATE%20privileges%20on%20the%20object%20type%20for%20the%20database%20or%20schema%20where%20the%20dropped%20object%20will%20be%20restored.",
"For a multi-cluster virtual warehouse, which parameters are used to calculate the number of credits billed? (Choose two.)",multi-select,A. Cache size,B. Warehouse size,C. Number of clusters,D. Volume of data processed,E. Number of queries executed,,,,,,,,,,,"2, 3","https://docs.snowflake.com/en/user-guide/warehouses-overview
BC is correct",
What happens when the values for both an ALLOWED_IP_LIST and a BLOCKED_IP_LIST are used in a network policy?,multiple-choice,A. Snowflake ignores the BLOCKED_IP_LIST first.,B. Snowflake applies the BLOCKED_IP_LIST first.,C. Snowflake applies the ALLOWED_IP_LIST first.,D. Snowflake ignores the ALLOWED_IP_LIST first.,,,,,,,,,,,,2,"B is correct. https://docs.snowflake.com/en/user-guide/network-policies#:~:text=When%20a%20network%20policy%20includes%20values%20in%20both%20the%20allowed%20and%20blocked%20IP%20address%20lists%2C%20Snowflake%20applies%20the%20blocked%20IP%20address%20list%20first.
B - When a network policy includes values in both the allowed and blocked IP address lists, Snowflake applies the blocked IP address list first.",
"When unloading data from Snowflake, what is the default file size of each file?",multiple-choice,A. 16 MB,B. 32 MB,C. 64 MB,D. 5 GB,,,,,,,,,,,,1,"A is the correct answer
The default value is 16777216 (16 MB) but can be increased to accommodate larger files. The maximum file size supported is 5 GB for Amazon S3, Google Cloud Storage, or Microsoft Azure stages",
What is the abbreviated form to get all the files in the stage for the current user?,multiple-choice,A. LIST @~;,B. LS @~;,C. LS @usr;,D. SHOW @%;,,,,,,,,,,,,2,"B is correct because it says abbreviated form
https://docs.snowflake.com/en/sql-reference/sql/list
There is https://docs.snowflake.com/en/sql-reference/sql/list Use the abbreviated form of the command to list all the files in the stage for the current user: LS @~;  Because it asks for ""abbreviated form"" B is correct
Thanks for the correction and yes LS is the abbreviated for form of List, so both are correct",
Which features make up Snowflake's column level security? (Choose two.),multi-select,A. Continuous Data Protection (CDP),B. Dynamic Data Masking,C. External Tokenization,D. Key pair authentication,E. Row access policies,,,,,,,,,,,"2, 3","Dynamic Data Masking is a Column-level Security feature that uses masking policies to selectively mask plain-text data in table and view columns at query time.  External Tokenization enables accounts to tokenize data before loading it into Snowflake and detokenize the data at query runtime. Tokenization is the process of removing sensitive data by replacing it with an undecipherable token. External Tokenization makes use of masking policies with external functions.
B - Dynamic Data Masking C - External Tokenization
B. Dynamic Data Masking C. External Tokenization
B and C  https://docs.snowflake.com/en/user-guide/security-column",
Which programming languages are supported for Snowflake User-Defined Functions (UDFs)? (Choose two.),multi-select,A. C#,B. JavaScript,C. PHP,D. Python,E. TypeScript,,,,,,,,,,,"2, 4","B & D is the right answer
he following topics describe how you can write UDF handlers in various languages.  Writing Java UDFs Develop handlers in Java to manipulate data and return scalar or tabular results.  Writing JavaScript UDFs Develop handlers in JavaScript to manipulate data and return scalar or tabular results.  Writing Python UDFs Develop handlers in Python to manipulate data and return scalar or tabular results.  Writing SQL UDFs Develop handlers in SQL to evaluate an arbitrary SQL expression and return scalar or tabular results.",
What is the MAXIMUM number of days that Snowflake resets the 24-hour retention period for a query result every time the result is used?,multiple-choice,A. 1 day,B. 10 days,C. 31 days,D. 60 days,,,,,,,,,,,,3,"Each time the persisted result for a query is reused, Snowflake resets the 24-hour retention period for the result, up to a maximum of 31 days from the date and time that the query was first executed. After 31 days, the result is purged and the next time the query is submitted, a new result is generated and persisted.
given ans is  correct
https://docs.snowflake.com/en/user-guide/querying-persisted-results#:~:text=Each%20time%20the%20persisted%20result%20for%20a%20query%20is%20reused%2C%20Snowflake%20resets%20the%2024%2Dhour%20retention%20period%20for%20the%20result%2C%20up%20to%20a%20maximum%20of%2031%20days%20from%20the%20date%20and%20time%20that%20the%20query%20was%20first%20executed.",
"There are 300 concurrent users on a production Snowflake account using a single cluster virtual warehouse. The queries are small, but the response time is very slow.

What is causing this to occur?",multiple-choice,"A. The warehouse is queuing the queries, increasing the overall query execution time.",B. The warehouse parameter STATEMENT_QUEUED_TIMEOUT_IN_SECONDS is set too low.,C. The application is not using the latest native ODBC driver which is causing latency.,D. The queries are not taking advantage of the data cache.,,,,,,,,,,,,1,"I choose A although D in my opinion is also correct.  B - STATEMENT_QUEUED_TIMEOUT_IN_SECONDS - from snowflake:  ""Amount of time, in seconds, a SQL statement (query, DDL, DML, etc.) remains queued for a warehouse before it is canceled by the system. This parameter can be used in conjunction with the MAX_CONCURRENCY_LEVEL parameter to ensure a warehouse is never backlogged.""  D - if queries do not take advantage of cached results, it causes the queries to be fully executed --> meaning, they take compute resources and time.
A is correct",
Which Snowflake edition offers the highest level of security for organizations that have the strictest requirements?,multiple-choice,A. Standard,B. Enterprise,C. Business Critical,D. Virtual Private Snowflake (VPS),,,,,,,,,,,,4,"The 2025-03 bundle is not enabled by default atleast til May 2025. It is supposed to move to the status Enabled by Default in June 2025  https://docs.snowflake.com/en/release-notes/bcr-bundles/2025_03_bundle
Virtual Private Snowflake (VPS) Virtual Private Snowflake offers our highest level of security for organizations that have the strictest requirements https://docs.snowflake.com/en/user-guide/intro-editions#feature-edition-matrix",
What is the MAXIMUM size limit for a record of a VARIANT data type?,multiple-choice,A. 8 MB,B. 16 MB,C. 32 MB,D. 128 MB,,,,,,,,,,,,2,"If the 2025_02 behavior change bundle is enabled, the maximum size for a VARIANT value is 128 MB. For more information, see Size limits for database objects.
The maximum length of a VARIANT is 16 MB. https://docs.snowflake.com/en/sql-reference/data-types-semistructured",
What criteria does Snowflake use to determine the current role when initiating a session? (Choose two.),multi-select,"A. If a role was specified as part of the connection and that role has been granted to the Snowflake user, the specified role becomes the current role.","B. If no role was specified as part of the connection and a default role has been defined for the Snowflake user, that role becomes the current role.","C. If no role was specified as part of the connection and a default role has not been set for the Snowflake user, the session will not be initiated and the log in will fail.","D. If a role was specified as part of the connection and that role has not been granted to the Snowflake user, it will be ignored and the default role will become the current role.","E. If a role was specified as part of the connection and that role has not been granted to the Snowflake user, the role is automatically granted and it becomes the current role.",,,,,,,,,,,"1, 2","what about D?
Correct
the answer is correct https://docs.snowflake.com/en/user-guide/security-access-control-overview#label-access-control-role-enforcement:~:text=If%20a%20role,PUBLIC%20is%20used.",
What command should be used to move data from a Snowflake database table into one or more files in an external stage?,multiple-choice,A. GET,B. COPY INTO,C. PUT,D. SHOW,,,,,,,,,,,,2,"Correct
https://docs.snowflake.com/en/sql-reference/sql/copy-into-location",
How does a Snowflake user reference a directory table created on stage mystage in a SQL query?,multiple-choice,A. SELECT * FROM @mystage::DIRECTORY,B. SELECT * FROM DIRECTORY (@mystage),C. SELECT * FROM TO_TABLE (DIRECTORY @mystage),D. SELECT * FROM TABLE (@mystage DIRECTORY),,,,,,,,,,,,2,"SELECT * FROM DIRECTORY(@mystage);  https://docs.snowflake.com/en/user-guide/data-load-dirtables-manage
B is correct.  Ref: https://docs.snowflake.com/en/user-guide/data-load-dirtables-query",
Why would a Snowflake user create a secure view instead of a standard view?,multiple-choice,A. The secure view is only available to end users with the corresponding SECURE_ACCESS property.,"B. End users are unable to see the view definition, and internal optimizations differ with a secure view.","C. With a secure view, the underlying data is replicated to a separate storage layer with enhanced encryption.","D. Secure views support additional functionality that is not supported for standard views, such as column masking and row level access policies.",,,,,,,,,,,,2,"Answer should be B Why Should I Use Secure Views? For a non-secure view, internal optimizations can indirectly expose data.  Some of the internal optimizations for views require access to the underlying data in the base tables for the view. This access might allow data that is hidden from users of the view to be exposed through user code, such as user-defined functions, or other programmatic methods. Secure views do not utilize these optimizations, ensuring that users have no access to the underlying data.
B is correct answer. https://docs.snowflake.com/en/user-guide/views-secure",
"Which command can be added to the COPY command to make it load all files, whether or not the load status of the files is known?",multiple-choice,A. FORCE = TRUE,B. FORCE = FALSE,C. LOAD_UNCERTAIN_FILES = TRUE,D. LOAD_UNCERTAIN_FILES = FALSE,,,,,,,,,,,,1,"Parameter FORCE - Applies to all files in the source.Reload previously loaded files.  LOAD_UNCERTAIN_FILES Applies only to files flagged as uncertain.Retry loading files with uncertain status.
A is correct. https://docs.snowflake.com/en/sql-reference/sql/copy-into-table To force the COPY command to load all files regardless of whether the load status is known, use the FORCE option instead.
Workarounds To load files whose metadata has expired, set the LOAD_UNCERTAIN_FILES copy option to true. The copy option references load metadata, if available, to avoid data duplication, but also attempts to load files with expired load metadata.  Alternatively, set the FORCE option to load all files, ignoring load metadata if it exists. Note that this option reloads files, potentially duplicating data in a table.",
How can a Snowflake user improve long-running query performance?,multiple-choice,A. Reduce the virtual warehouse size.,B. Cluster the underlying table being queried.,C. Disable the result cache.,D. Add ORDER BY to the query.,,,,,,,,,,,,2,"B is correct
B seems correct",
Which Snowflake feature allows administrators to identify unused data that may be archived or deleted?,multiple-choice,A. Access history,B. Data classification,C. Dynamic Data Masking,D. Object tagging,,,,,,,,,,,,1,"Access history in Snowflake provides the following benefits pertaining to read and write operations: Data discovery: Discover unused data to determine whether to archive or delete the data.  https://docs.snowflake.com/en/user-guide/access-history
https://docs.snowflake.com/en/user-guide/access-history#:~:text=Discover%20unused%20data%20to%20determine%20whether%20to%20archive%20or%20delete%20the%20data.
Each row in the ACCESS_HISTORY view contains a single record per SQL statement. The record describes the columns the query accessed directly and indirectly (i.e. the underlying tables that the data for the query comes from). These records facilitate regulatory compliance auditing and provide insights on popular and frequently accessed tables and columns since there is a direct link between the user (i.e. query operator), the query, the table or view, the column, and the data
Data classification is to classify personal data. it is a governance feature, https://docs.snowflake.com/en/user-guide/governance-classify. So answer should be A.",
Which SQL commands should be used to write a recursive query if the number of levels is unknown? (Choose two.),multi-select,A. CONNECT BY,B. LISTAGG,C. MATCH RECOGNIZE,D. QUALIFY,E. WITH,,,,,,,,,,,"1, 5","CONNECT BY , the recursive CTE portion of the WITH command , Working with CTEs (Common Table Expressions) , Tabular SQL UDFs (UDTFs)
AE is the correct answer.  https://docs.snowflake.com/en/user-guide/queries-hierarchical",
What information is stored in the ACCESS_HISTORY view?,multiple-choice,A. History of the files that have been loaded into Snowflake,B. Names and owners of the roles that are currently enabled in the session,C. Query details such as the objects included and the user who executed the query,D. Details around the privileges that have been granted for all objects in an account,,,,,,,,,,,,3,"This correct answer
https://docs.snowflake.com/en/sql-reference/account-usage/access_history#columns",
What privilege does a user need in order to receive or request data from the Snowflake Marketplace?,multiple-choice,A. CREATE DATA EXCHANGE LISTING,B. CREATE SHARE,C. IMPORT SHARE,D. IMPORTED PRIVILEGES,,,,,,,,,,,,3,"IMPORTED PRIVILEGES is the right answer. https://docs.snowflake.com/en/user-guide/security-access-control-privileges#:~:text=Usage-,IMPORTED%20PRIVILEGES,-Enables%20roles%20other
C.  When logging in to the Data Exchange as a consumer:  All roles can browse data listings.  All roles with the ACCOUNTADMIN role can request and get data.  All roles with the IMPORT SHARE and CREATE DATABASE privileges can get and request data. https://docs.snowflake.com/en/user-guide/data-exchange-accessing",
Which Snowflake database object can be shared with other accounts?,multiple-choice,A. Tasks,B. Pipes,C. Secure User-Defined Functions (UDFs),D. Stored Procedures,,,,,,,,,,,,3,"correct
from doc: https://docs.snowflake.com/en/user-guide/data-sharing-intro  You can share the following Snowflake database objects:  Tables External tables Secure views Secure materialized views Secure UDFs
C https://docs.snowflake.com/en/user-guide/data-sharing-intro",
Which identity providers are valid type values for federated authentication on the SAML_IDENTITY_PROVIDER parameter? (Choose two.),multi-select,A. Identity Access Management (IAM),B. Microsoft Active Directory Federation Services (AD FS),C. OAuth,D. Okta,E. PingFederate,,,,,,,,,,,"2, 4","Answer is B,D. But this parameter is deprecated  https://docs.snowflake.com/ko/sql-reference/parameters#label-saml-identity-provider
https://docs.snowflake.com/user-guide/admin-security-fed-auth-overview",
"A Snowflake user wants to share data using my_share with account xy12345.

Which command should be used?",multiple-choice,A. grant usage on share my_share to account xy12345;,B. grant select on share my_share to account xy12345;,C. alter share my_share add accounts = xy12345;,D. alter account xy12345 add share my_share;,,,,,,,,,,,,3,"ALTER SHARE [ IF EXISTS ] <name> { ADD | REMOVE } ACCOUNTS = <consumer_account> [ , <consumer_account> , ... ]  [ SHARE_RESTRICTIONS = { TRUE | FALSE } ]  ALTER SHARE [ IF  ALTER SHARE [ IF EXISTS ] <name> SET { [ ACCOUNTS = <consumer_account> [ , <consumer_account> ... ] ]",
What role is required to use Partner Connect?,multiple-choice,A. ACCOUNTADMIN,B. ORGADMIN,C. SECURITYADMIN,D. SYSADMIN,,,,,,,,,,,,1,"Partner Connect is limited to account administrators (i.e. users with the ACCOUNTADMIN role) who have a verified email address in Snowflake: To use Partner Connect, you must switch to the ACCOUNTADMIN role or contact someone in your organization who has the role.
https://docs.snowflake.com/en/user-guide/ecosystem-partner-connect",
How can a Snowflake user configure a virtual warehouse to support over 100 users if their company has Enterprise Edition?,multiple-choice,A. Add additional warehouses and configure them as a cluster.,B. Set the auto-scale to 100.,C. Use a multi-cluster warehouse.,D. Use a larger warehouse.,,,,,,,,,,,,3,"multi-cluster warehouse is the solution for simultaneous querying.
Multi-cluster warehouses are best utilized for scaling resources to improve concurrency for users/queries. They are not as beneficial for improving the performance of slow-running queries or data loading. For these types of operations, resizing the warehouse provides more benefits.  https://docs.snowflake.com/en/user-guide/warehouses-multicluster",
How is table data compressed in Snowflake?,multiple-choice,A. Each column is compressed as it is stored in a micro-partition.,B. Each micro-partition is compressed as it is written into cloud storage using GZIP.,C. The micro-partitions are stored in compressed cloud storage and the cloud storage handles compression.,D. The text data in a micro-partition is compressed with GZIP but other types are not compressed.,,,,,,,,,,,,1,"Answer is A
https://docs.snowflake.com/en/user-guide/tables-clustering-micropartitions#what-are-micro-partitions",
"What will be the output of the below query against the table name gold_data?

select * from gold_data tablesample (100);",multiple-choice,A. It will return an empty sample.,B. It will return a random 100 rows.,C. It will return an entire table.,D. It will produce an error message.,,,,,,,,,,,,3,"c is the answer. ""100 Rows"" will return 100 rows. 100 is the probability. so all columns will be returned.
Correct :C,https://docs.snowflake.com/en/sql-reference/constructs/sampleReturn an entire table, including all rows in the table:  SELECT * FROM testtable TABLESAMPLE (100);",
"A Snowflake query took 40 minutes to run. The results indicate that ‘Bytes spilled to local storage’ was a large number.

What is the issue and how can it be resolved?",multiple-choice,A. The warehouse is too large. Decrease the size of the warehouse to reduce the spillage.,B. The warehouse is too small. Increase the size of the warehouse to reduce the spillage.,C. The Snowflake console has timed-out. Contact Snowflake Support.,D. The warehouse consists of a single cluster. Use a multi-cluster warehouse to reduce the spillage.,,,,,,,,,,,,2,"Answer is B. warehouse size should be increased. multi cluster warehouse will just help in increasing paralelism.
B is correct https://github.com/dbt-labs/docs.getdbt.com/discussions/1550 When you have spillage, increasing warehouse size almost always helps.",
What is the MOST efficient way to load streaming data into Snowflake?,multiple-choice,A. Use the COPY command.,B. Use Snowpipe.,C. Use the Load Data Wizard.,D. Use tasks and streams.,,,,,,,,,,,,2,"Correct
The MOST efficient way to load streaming data into Snowflake is to use Snowpipe (option B). Snowpipe is a native, automated data ingestion service within Snowflake that can continuously load data from various sources in near real-time.",
Which COPY INTO statement accurately describes how to unload data from a Snowflake table?,multiple-choice,A. The default value for the SINGLE option is set to TRUE.,"B. By default, COPY INTO [location] statements do not separate table data into a set of output files.",C. The OBJECT_CONSTRUCT function can be combined with the COPY command to convert the rows in a relational table to a single VARIANT column.,"D. If the COMPRESSION option is set to TRUE, a file's name can be specified with the appropriate file extension so that the output file can be compressed.",,,,,,,,,,,,3,"""You can use the OBJECT_CONSTRUCT function combined with the COPY command to convert the rows in a relational table to a single VARIANT column and unload the rows into a file."" https://docs.snowflake.com/en/user-guide/data-unload-considerations
COMPRESSION option can't be set to TRUE  -- If FILE_FORMAT = ( TYPE = CSV ... )  COMPRESSION = AUTO | GZIP | BZ2 | BROTLI | ZSTD | DEFLATE | RAW_DEFLATE | NONE  -- If FILE_FORMAT = ( TYPE = JSON ... )  COMPRESSION = AUTO | GZIP | BZ2 | BROTLI | ZSTD | DEFLATE | RAW_DEFLATE | NONE  -- If FILE_FORMAT = ( TYPE = PARQUET ... )  COMPRESSION = AUTO | LZO | SNAPPY | NONE https://docs.snowflake.com/en/sql-reference/sql/copy-into-location",
What command is used to download data from a Snowflake stage?,multiple-choice,A. PUT,B. INSERT,C. GET,D. COPY,,,,,,,,,,,,3,"GET Downloads data files from one of the following Snowflake stages to a local directory/folder on a client machine:  Named internal stage.  Internal stage for a specified table.  Internal stage for the current user.  Typically, this command is executed after using the COPY INTO <location> command to unload data from a table into a Snowflake stage.",
"By default, which role has privileges to create tables and views in an account?",multiple-choice,A. PUBLIC,B. SECURITYADMIN,C. SYSADMIN,D. USERADMIN,,,,,,,,,,,,3,"The SYSADMIN role is a system-defined role that has privileges to create warehouses, databases, and database objects in an account and grant those privileges to other roles.  https://docs.snowflake.com/en/user-guide/security-access-control-configure#creating-a-role-hierarchy
Correct",
What does Snowflake recommend as a best practice for using secure views?,multiple-choice,A. Use sequence-generated values.,B. Programmatically reveal the identifiers.,C. Use secure views solely for query convenience.,D. Do not expose the sequence-generated column(s).,,,,,,,,,,,,4,"Sequence-generated Columns Do not expose the sequence-generated column as part of the view.
A is Answer .. https://docs.snowflake.com/en/user-guide/views-secure",
What is the Fail-safe period for a transient table in the Snowflake Enterprise edition and higher?,multiple-choice,A. 0 days,B. 1 day,C. 7 days,D. 14 days,,,,,,,,,,,,1,"Temporary and Transient Tables¶ To help manage the storage costs associated with Time Travel and Fail-safe, Snowflake provides two table types, temporary and transient, which do not incur the same fees as standard (i.e. permanent) tables:  Transient tables can have a Time Travel retention period of either 0 or 1 day.  Temporary tables can also have a Time Travel retention period of 0 or 1 day; however, this retention period ends as soon as the table is dropped or the session in which the table was created ends.  Transient and temporary tables have no Fail-safe period.  As a result, the maximum
https://docs.snowflake.com/en/user-guide/tables-temp-transient Transient tables are similar to permanent tables with the key difference that they do not have a Fail-safe period",
How does a Snowflake user enable Multi-Factor Authentication (MFA)?,multiple-choice,A. The user must enroll themselves through the web interface.,B. The user must submit their encrypted private key to Snowflake.,C. The user must sign up with Duo Mobile for approval to use the service.,D. The user must configure Snowflake to use Single Sign-On (SSO).,,,,,,,,,,,,1,"A is correct. https://docs.snowflake.com/en/user-guide/security-mfa
https://docs.snowflake.com/en/user-guide/security-mfa#:~:text=Any%20Snowflake%20user%20can%20self%2Denroll%20in%20MFA%20through%20the%20web%20interface.",
What allows a user to limit the number of credits consumed within a Snowflake account?,multiple-choice,A. Tracking account usage,B. Creating resource monitors,C. Automatic virtual warehouse scaling,D. Automatic clustering,,,,,,,,,,,,2,"B correct
B - Resource monitor
Correct answer b",
Which statement accurately describes Snowflake's architecture?,multiple-choice,A. It uses a local data repository for all compute nodes in the platform.,B. It is a blend of shared-disk and shared-everything database architectures.,C. It is a hybrid of traditional shared-disk and shared-nothing database architectures.,"D. It reorganizes loaded data into internal optimized, compressed, and row-based format.",,,,,,,,,,,,3,"Snowflake Architecture Snowflake’s architecture is a hybrid of traditional shared-disk and shared-nothing database architectures. Similar to shared-disk architectures, Snowflake uses a central data repository for persisted data that is accessible from all compute nodes in the platform. But similar to shared-nothing architectures, Snowflake processes queries using MPP (massively parallel processing) compute clusters where each node in the cluster stores a portion of the entire data set locally. This approach offers the data management simplicity of a shared-disk architecture, but with the performance and scale-out benefits of a shared-nothing architecture.  https://docs.snowflake.com/en/user-guide/intro-key-concepts
Correct
Snowflake architecture base question",
Which Snowflake SQL command is used to get a subset of rows randomly from a table?,multiple-choice,A. GENERATOR,B. LATERAL,C. PIVOT,D. SAMPLE,,,,,,,,,,,,4,"D is correct
Correct -- D https://docs.snowflake.com/en/sql-reference/constructs/sample",
Which statement accurately describes how a virtual warehouse functions?,multiple-choice,A. Increasing the size of a virtual warehouse will always improve data loading performance.,B. Each virtual warehouse is an independent compute cluster that shares compute resources with other warehouses.,C. Each virtual warehouse is a compute cluster composed of multiple compute nodes allocated by Snowflake from a cloud provider.,D. All virtual warehouses share the same compute resources so performance degradation of one warehouse can significantly affect all the other warehouses.,,,,,,,,,,,,3,"https://docs.snowflake.com/en/user-guide/intro-key-concepts  Query Processing Query execution is performed in the processing layer. Snowflake processes queries using “virtual warehouses”. Each virtual warehouse is an MPP compute cluster composed of multiple compute nodes allocated by Snowflake from a cloud provider.
C is correct.",
Which Snowflake object can be used to record DML changes made to a table?,multiple-choice,A. Snowpipe,B. Stage,C. Stream,D. Task,,,,,,,,,,,,3,"A stream object records data manipulation language (DML) changes made to tables, including inserts, updates, and deletes, as well as metadata about each change, so that actions can be taken using the changed data.
https://docs.snowflake.com/en/user-guide/streams",
Which statistic displayed in a Query Profile is specific to external functions?,multiple-choice,A. Bytes written,B. Total invocations,C. Partitions scanned,D. Bytes sent over the network,,,,,,,,,,,,2,"for sure B total invocations
The following statistics are shown for each external function called by the SQL statement. If the same function was called more than once from the same SQL statement, then the statistics are aggregated.  Total invocations — number of times that an external function was called. (This can be different from the number of external function calls in the text of the SQL statement due to the number of batches that rows are divided into, the number of retries (if there are transient network problems), etc.)
https://docs.snowflake.com/en/user-guide/ui-query-profile",
"If there is queueing in the virtual warehouse load monitoring chart, what should a Snowflake user do?",multiple-choice,A. Decrease the warehouse size.,B. Decrease the MIN_CLUSTER_COUNT parameter.,C. Change the multi-cluster settings to add additional clusters.,D. Start a separate warehouse and move queued queries there.,,,,,,,,,,,,3,"We don't have information about Snowflake edition. For Standard edition we don't have option with multi-cluster.
It's queuing issue hence you dont need new warehouse but need additional clusters within same warehouse. And as queries are already in system hence can't move queries to new warehouse without killing and resubmitting.
Both C & D are correct. C: If the running query load is high or there’s queuing, consider starting a separate warehouse and moving queued queries to that warehouse. D: Alternatively, if you are using multi-cluster warehouses, you could change your multi-cluster settings to add additional clusters to handle higher concurrency going forward.
https://docs.snowflake.com/en/user-guide/warehouses-load-monitoring  Slow Query Performance When you notice that a query is running slowly, check whether an overloaded warehouse is causing the query to compete for resources or get queued:  If the running query load is high or there’s queuing, consider starting a separate warehouse and moving queued queries to that warehouse. Alternatively, if you are using multi-cluster warehouses, you could change your multi-cluster settings to add additional clusters to handle higher concurrency going forward.",
"Which command is used to generate a zero-copy ""snapshot"" of any table, schema, or database?",multiple-choice,A.,B.,C.,D.,,,,,,,,,,,,2,"Create... clone is the correct answer.
https://docs.snowflake.com/en/sql-reference/sql/create-clone",
How long is the load history stored in the metadata of the pipe in Snowpipe?,multiple-choice,A. 2 days,B. 7 days,C. 14 days,D. 64 days,,,,,,,,,,,,3,C correct,
What are the key characteristics of ACСOUNT_USAGE views? (Choose two.),multi-select,A. There is no data latency.,B. The data latency can vary from 45 minutes to 3 hours.,C. The historical data is not retained.,D. The historical data can be retained from 7 days to 6 months.,E. Records for dropped objects are included in each view.,,,,,,,,,,,"2, 5","BE is right
B E correct
https://docs.snowflake.com/en/sql-reference/account-usage#differences-between-account-usage-and-information-schema
https://docs.snowflake.com/en/sql-reference/account-usage#differences-between-account-usage-and-information-schema BE is correct",
How does a scoped URL expire?,multiple-choice,A. When the data cache clears.,B. When the persisted query result period ends.,C. The encoded URL access is permanent.,D. The length of time is specified in the expiration_time argument.,,,,,,,,,,,,2,"B The expiration period of Scoped URL: The URL expires when the persisted query result period ends.  The expiration period of the File URL: It is permanent.  The expiration period of Pre-Signed URL: Length of time specified in the expiration_time argument.
Expiration  Expiration period for the query results cache (currently 24 hours). https://docs.snowflake.com/en/user-guide/unstructured-intro",
What are the available Snowflake scaling modes for configuring multi-cluster virtual warehouses? (Choose two.),multi-select,A. Auto-Scale,B. Economy,C. Maximized,D. Scale-Out,E. Standard,,,,,,,,,,,"1, 3","https://docs.snowflake.com/en/user-guide/warehouses-multicluster#maximized-vs-auto-scale
AC is Correct. Note, that there are Scaling Policies called ""Economy"" and ""Standard"" in ""Auto-Scale"" mode.
https://hevodata.com/learn/snowflake-scaling-policy/",
Which loop type iterates until a condition is true?,multiple-choice,A. FOR,B. LOOP,C. REPEAT,D. WHILE,,,,,,,,,,,,3,"The WHILE loop checks the condition before each iteration, so if the condition is not met initially, the loop will not execute at all. On the other hand, the REPEAT loop (or DO...WHILE loop) checks the condition after executing the loop's body, ensuring that the loop runs at least once regardless of the condition.
cccccc
A REPEAT loop iterates until a condition is true. In a REPEAT loop, the condition is tested immediately after executing the body of the loop. As a result, the body of the loop always executes at least once.  A WHILE loop iterates while a condition is true. In a WHILE loop, the condition is tested immediately before executing the body of the loop. If the condition is false before the first iteration, then the body of the loop does not execute even once.
https://docs.snowflake.com/en/developer-guide/snowflake-scripting/loops",
Which property needs to be added to the ALTER WAREHOUSE command to verify the additional compute resources for a virtual warehouse have been fully provisioned?,multiple-choice,A. QUERY_ACCELERATION_MAX_SCALE_FACTOR,B. RESOURCE_MONITOR,C. SCALING_POLICY,D. WAIT_FOR_COMPLETION,,,,,,,,,,,,4,"D correct
Correct
https://docs.snowflake.com/en/user-guide/warehouses-tasks
https://docs.snowflake.com/en/user-guide/warehouses-tasks#:~:text=To%20verify%20the%20additional%20compute%20resources%20for%20your%20warehouse%20have%20been%20fully%20provisioned%2C%20add%20the%20WAIT_FOR_COMPLETION%20parameter%20to%20the%20ALTER%20WAREHOUSE%20command.",
How is enhanced authentication achieved in Snowflake? (Choose two.),multi-select,B. Snowflake-managed keys,C. Object level access control,D. Multi-Factor Authentication (MFA),E. Federated authentication and Single Sign-On (SSO),,,,,,,,,,,,"4, 5","Correct
Wondering where does answer A go
Correct -- DE https://docs.snowflake.com/guides-overview-secure",
What are the native data types that Snowflake provides to store semi-structured data? (Choose two.),multi-select,A. ARRAY,B. JSON,C. ORC,D. Parquet,E. VARIANT,,,,,,,,,,,"1, 5","The question is about data type not file type
Snowflake provides built-in support for importing data from (and exporting data to) the following semi-structured data formats: JSON Avro ORC Parquet XML Snowflake provides native data types (ARRAY, OBJECT, and VARIANT) for storing semi-structured data.",
How long is the Fail-safe period for recovering historical data from permanent tables?,multiple-choice,A. 1 day,B. 3 days,C. 7 days,D. 14 days,,,,,,,,,,,,3,"Correct
https://docs.snowflake.com/en/user-guide/data-failsafe",
What does the average_overlaps in the output of SYSTEM$CLUSTERING_INFORMATION refer to?,multiple-choice,A. The average number of micro-partitions stored in Time Travel.,B. The average number of partitions physically stored in the same location.,C. The average number of micro-partitions which contain overlapping value ranges.,D. The average number of micro-partitions in the table associated with cloned objects.,,,,,,,,,,,,3,"C correct
Correct
https://docs.snowflake.com/en/sql-reference/functions/system_clustering_information",
If queries start to queue in a multi-cluster virtual warehouse an additional compute cluster starts immediately under what setting?,multiple-choice,A. Auto-scale mode,B. Maximized mode,C. Economy scaling policy,D. Standard scaling policy,,,,,,,,,,,,4,"D correct
Correct
D https://docs.snowflake.com/en/user-guide/warehouses-multicluster Standard (default)  Prevents/minimizes queuing by favoring starting additional clusters over conserving credits.",
"When floating-point number columns are unloaded to CSV or JSON files, Snowflake truncates the values to approximately what?",multiple-choice,"A. (12,2)","B. (10,4)","C. (14,8)","D. (15,9)",,,,,,,,,,,,4,"When floating-point number columns are unloaded to CSV or JSON files, Snowflake truncates the values to approximately (15,9).  The values are not truncated when unloading floating-point number columns to Parquet files.
D Correct: https://docs.snowflake.com/en/user-guide/data-unload-considerations
https://docs.snowflake.com/en/user-guide/data-unload-considerations#:~:text=When%20floating%2Dpoint%20number%20columns%20are%20unloaded%20to%20CSV%20or%20JSON%20files%2C%20Snowflake%20truncates%20the%20values%20to%20approximately%20(15%2C9).",
"By definition, a secure view is exposed only to users with what privilege?",multiple-choice,A. IMPORT SHARE,B. OWNERSHIP,C. REFERENCES,D. USAGE,,,,,,,,,,,,2,"B is correct
B The definition of a secure view is only exposed to authorized users (i.e. users who have been granted the role that owns the view).
https://www.bing.com/search?q=By+definition%2C+a+secure+view+is+exposed+only+to+users+with+what+privilege%3F&qs=n&form=QBRE&sp=-1&lq=1&pq=by+definition%2C+a+secure+view+is+exposed+only+to+users+with+what+privilege%3F&sc=1-74&sk=&cvid=0C736B21938E4126ABA51B4764C220F0&ghsh=0&ghacc=0&ghpl=",
What happens when a user exits Snowsight during a session that a query is running?,multiple-choice,A. Snowflake executes the query during the same session immediately.,B. Snowflake cancels any queries submitted during this session that are still running.,C. Snowflake will cancel any queries submitted during this session after 24 hours.,D. Snowflake will continue to execute and complete upon the next login.,,,,,,,,,,,,4,"B Correct: When you exit Snowsight, Snowflake cancels any queries that you submitted during this session that are still running.  https://docs.snowflake.com/en/user-guide/ui-snowsight-quick-tour
This is confusing. https://docs.snowflake.com/en/user-guide/session-policies --> Caution Active queries are not canceled when the session ends and the user is logged out, even if the ABORT_DETACHED_QUERY parameter is set to true.  https://docs.snowflake.com/en/user-guide/ui-snowsight-quick-tour --> Important: When you exit Snowsight, Snowflake cancels any queries that you submitted during this session that are still running.",
Which columns are available in the output of a Snowflake directory table? (Choose two.),multi-select,A. CATALOG_NAME,B. FILE_NAME,C. LAST_MODIFIED,D. RELATIVE_PATH,E. STAGE_NAME,,,,,,,,,,,"3, 4","acc. to https://docs.snowflake.com/en/user-guide/data-load-dirtables-query
Hi. Can you paste the link where you saw the FILE_NAME? wanted to ensure if its in older version of Snowflake. https://docs.snowflake.com/en/user-guide/data-load-dirtables-manage#output clearly mentions the columns.",
What is used to diagnose and troubleshoot network connections to Snowflake?,multiple-choice,A. SnowCD,B. Snowpark,C. Snowsight,D. SnowSQL,,,,,,,,,,,,1,SnowCD (i.e. Snowflake Connectivity Diagnostic Tool) helps users to diagnose and troubleshoot their network connection to Snowflake.,
What Snowflake object records Data Manipulation Language (DML) changes so that actions can be taken using the changed data?,multiple-choice,A. Pipe,B. Stream,C. Task,D. View,,,,,,,,,,,,2,"B is correct
for sure ""Stream""",
"By default, the COPY INTO [location] statement will separate table data into a set of output files to take advantage of which Snowflake feature?",multiple-choice,A. Query acceleration,B. Query plan caching,C. Parallel processing,D. Time Travel,,,,,,,,,,,,3,"C is correct
C:  By default, the COPY INTO statement will separate table data into a set of output files to take advantage of Snowflake's parallel processing feature. This means that when data is unloaded, it can be split into multiple files and each file can be processed simultaneously by different nodes in the cluster, improving performance. The number of output files can be controlled by specifying the number of file parts in the COPY INTO statement.",
Which command can be used to view the allowed and blocked IP list of a network policy?,multiple-choice,A. ALTER NETWORK POLICY,B. CREATE NETWORK POLICY,C. DESCRIBE NETWORK POLICY,D. SHOW NETWORK POLICIES,,,,,,,,,,,,3,. DESCRIBE NETWORK POLICY is correct DESC NETWORK POLICY mypolicy;  -----------------+---------------+  name | value | -----------------+---------------+  ALLOWED_IP_LIST | 192.168.0.100 |  BLOCKED_IP_LIST | 192.168.0.101 | -----------------+---------------+,
Which file functions are non-deterministic? (Choose two.),multi-select,A. BUILD_SCOPED_FILE_URL,B. BUILD_STAGE_FILE_URL,C. GET_ABSOLUTE_PATH,D. GET_PRESIGNED_URL,E. GET_RELATIVE_PATH,,,,,,,,,,,"1, 4","AD BUILD_SCOPED_FILE_URL encodes the URL. GET_PRESIGNED_URL adds credentials to the URL. These are both non-deterministic.
correct answer - BD https://docs.snowflake.com/en/sql-reference/functions-file GET_PRESIGNED_URL and BUILD_SCOPED_FILE_URL are non-deterministic functions; the others are deterministic.",
How can a Snowflake user optimize query performance in Snowflake? (Choose two.),multi-select,A. Create a view.,B. Cluster a table.,C. Enable the search optimization service.,D. Enable Time Travel.,E. Index a table.,,,,,,,,,,,"2, 3","The correct answers are B and C.  Clustering a table physically reorders the rows in a table to improve the performance of queries that filter on specific columns. The search optimization service creates a search index for a table, which can be used to improve the performance of queries that filter on specific columns.  Creating a view does not improve query performance. Enabling Time Travel allows you to query data from a specific point in time, but it does not improve query performance. Indexing a table creates an index that can be used to improve the performance of queries, but it is not as effective as clustering or the search optimization service.",
What is the MINIMUM role required to set the value for the parameter ENABLE_ACCOUNT_DATABASE_REPLICATION?,multiple-choice,A. ACCOUNTADMIN,B. SECURITYADMIN,C. SYSADMIN,D. ORGADMIN,,,,,,,,,,,,4,"https://docs.snowflake.com/en/user-guide/account-replication-config#label-enabling-accounts-for-replication To enable replication for accounts, a user with the ORGADMIN role uses the SYSTEM$GLOBAL_ACCOUNT_SET_PARAMETER function to set the ENABLE_ACCOUNT_DATABASE_REPLICATION parameter to true. Note that multiple accounts in an organization can be enabled for replication from the same ORGADMIN account.
its ORG AdMIN
The organization administrator (ORGADMIN role) must enable replication for the source and target accounts before replicating a database  https://docs.snowflake.com/en/user-guide/database-replication-config#",
Which file format will keep floating-point numbers from being truncated when data is unloaded?,multiple-choice,A. CSV,B. JSON,C. ORC,D. Parquet,,,,,,,,,,,,4,"https://docs.snowflake.com/en/user-guide/data-unload-considerations#floating-point-numbers-truncated The values are not truncated when unloading floating-point number columns to Parquet files.
https://community.snowflake.com/s/article/Data-precision-loss-with-Double-Float-REAL-Snowflake-Data-type-with-unloading",
"A user has semi-structured data to load into Snowflake but is not sure what types of operations will need to be performed on the data.

Based on this situation, what type of column does Snowflake recommend be used?",multiple-choice,A. ARRAY,B. OBJECT,C. TEXT,D. VARIANT,,,,,,,,,,,,4,Correct because its key value pair,
Which Snowflake object helps evaluate virtual warehouse performance impacted by query queuing?,multiple-choice,A. Resource monitor,B. Account_usage.query_history,C. Information_schema.warehouse_load_history,D. Information_schema.warehouse_metering_history,,,,,,,,,,,,2,"warehouse_load_history
The user is referring to this in particular:  Query History: It keeps a record of all queries executed in your Snowflake account. This allows you to analyze the performance of individual queries, including their execution time, number of rows processed, etc. However, it does not provide specific information on the impact of query queuing on virtual warehouse performance. WAREHOUSE_LOAD_HISTORY: This system view provides specific information on the usage of the virtual warehouse, including the wait times of queries in the queue. This allows you to evaluate the impact of query queuing on virtual warehouse performance by providing data on warehouse load and usage. So, if you want to assess the impact of query queuing on virtual warehouse performance, the WAREHOUSE_LOAD_HISTORY view would be more appropriate. If you want to examine the performance of individual queries as a whole, then Query History would be more relevant
https://docs.snowflake.com/en/user-guide/warehouses-load-monitoring
Even C seems to be correct. But, the Query History provides more information than the Load history.  AVG_QUEUED_LOAD. Query load value for queries queued because the warehouse was overloaded. https://docs.snowflake.com/en/sql-reference/account-usage/warehouse_load_history",
Which Snowflake object can be created to be temporary?,multiple-choice,A. Role,B. Stage,C. User,D. Storage integration,,,,,,,,,,,,2,"The stage can be created to be temporary by adding a TEMP parameter. CREATE TEMP STAGE
https://www.bing.com/search?q=snowflake+temporary+stage&cvid=998cb1d21c5d48bdb3a7dae1885e147f&aqs=edge.2.0j69i57j0l7j69i11004.11917j0j4&FORM=ANAB01&PC=U531",
Which stream type can be used for tracking the records in external tables?,multiple-choice,A. Append-only,B. External,C. Insert-only,D. Standard,,,,,,,,,,,,3,"C. Insert-only : Supported for streams on external tables only.  https://docs.snowflake.com/en/user-guide/streams-intro
Insert-only: Supported for streams on external tables only.   https://docs.snowflake.com/en/user-guide/streams-intro",
What is the recommended approach for unloading data to a cloud storage location from Snowflake?,multiple-choice,A. Use a third-party tool to unload the data to cloud storage.,B. Unload the data directly to the cloud storage location.,"C. Unload the data to a local file system, then upload it to cloud storage.","D. Unload the data to a user stage, then upload the data to cloud storage",,,,,,,,,,,,2,"B. Unload the data directly to the cloud storage location, which is an External Stage.
This tricky the precise answer is unload to an external stage in the cloud first.",
Which command is used to unload files from an internal or external stage to a local file system?,multiple-choice,A. COPY INTO,B. GET,C. PUT,D. TRANSFER,,,,,,,,,,,,2,"B. GET: https://docs.snowflake.com/en/user-guide/data-unload-snowflake.  Table -> Copy into -> Stage -> Get -> Local File System
If I had to choose, I would choose B. COPY INTO - is used to unload data into either internal or external stage, then we use GET to download files from INTERNAL stage into local system, or we use tools provided by external provider to download files.  ""Bulk unloading process The process for unloading data into files is the same as the loading process, except in reverse: Step 1 Use the COPY INTO <location> command to copy the data from the Snowflake database table into one or more files in a Snowflake or external stage. Step 2 Download the file from the stage:  From a Snowflake stage, use the GET command to download the data file(s).  From S3, use the interfaces/tools provided by Amazon S3 to get the data file(s).  From Azure, use the interfaces/tools provided by Microsoft Azure to get the data file(s)."" https://docs.snowflake.com/en/user-guide/data-unload-overview  ChatGPT says you can download files from external stage through SnowSQL by using GET command.",
A tabular User-Defined Function (UDF) is defined by specifying a return clause that contains which keyword?,multiple-choice,A. ROW_NUMBER,B. TABLE,C. TABULAR,D. VALUES,,,,,,,,,,,,2,"CREATE FUNCTION t()  RETURNS TABLE(msg VARCHAR)  AS  $$  SELECT 'Hello'  UNION  SELECT 'World'  $$;
B https://docs.snowflake.com/en/developer-guide/udf/sql/udf-sql-tabular-functions",
Which SQL statement will require a virtual warehouse to run?,multiple-choice,A. SELECT COUNT(*) FROM TBL_EMPLOYEE;,B. ALTER TABLE TBL_EMPLOYEE ADD COLUMN EMP_REGION VARCHAR(20);,"C. INSERT INTO TBL_EMPLOYEE(EMP_ID, EMP_NAME, EMP_SALARY, DEPT) VALUES(1, 'Adam', 20000, 'Finance’);","D. CREATE OR REPLACE TABLE TBL_EMPLOYEE
(
EMP_ID NUMBER,
EMP_NAME VARCHAR(30),
EMP_SALARY NUMBER,
DEPT VARCHAR(20)
);",,,,,,,,,,,,3,"A warehouse provides the required resources, such as CPU, memory, and temporary storage, to perform the following operations in a Snowflake session:   Executing SQL SELECT statements that require compute resources (e.g. retrieving rows from tables and views).   Performing DML operations, such as:   Updating rows in tables (DELETE , INSERT , UPDATE).   Loading data into tables (COPY INTO <table>).   Unloading data from tables (COPY INTO <location>).",
Which REST API can be used with unstructured data?,multiple-choice,A. insertFiles,B. insertReport,C. GET /api/files/,D. loadHistoryScan,,,,,,,,,,,,3,"https://docs.snowflake.com/en/user-guide/data-load-unstructured-rest-api
The insertFiles API can be used to upload and insert unstructured data files into Snowflake. This is typically used for loading various types of unstructured data, such as JSON, XML, CSV, and more, into Snowflake for further processing or analysis.",
Which query contains a Snowflake hosted file URL in a directory table for a stage named bronzestage?,multiple-choice,A. list @bronzestage;,B. select * from directory(@bronzestage);,C. select metadata$filename from @bronzestage;,D. select * from table(information_schema.stage_directory_file_registration_history( stage_name=>'bronzestage'));,,,,,,,,,,,,2,"Querying directory tables This topic covers how to query a directory table to retrieve a list of all files on a stage with metadata, such as the Snowflake file URL, for each file. SELECT * FROM DIRECTORY( @<stage_name> )  https://docs.snowflake.com/en/user-guide/data-load-dirtables-query
FILE_URL -Snowflake-hosted file URL to the file.  https://docs.snowflake.com/en/user-guide/data-load-dirtables-manage",
Which feature is integrated to support Multi-Factor Authentication (MFA) at Snowflake?,multiple-choice,A. Authy,B. Duo Security,C. One Login,D. RSA SecurID Access,,,,,,,,,,,,2,correct,
"In which Snowflake layer does Snowflake reorganize data into its internal optimized, compressed, columnar format?",multiple-choice,A. Cloud Services,B. Database Storage,C. Query Processing,D. Metadata Management,,,,,,,,,,,,2,"Database storage layer
correct",
When can user session variables be accessed in a Snowflake scripting procedure?,multiple-choice,A. When the procedure is defined as STRICT.,B. When the procedure is defined to execute as CALLER.,C. When the procedure is defined to execute as OWNER.,D. When the procedure is defined with an argument that has the same name and type as the session variable.,,,,,,,,,,,,2,"Using session variables in a stored procedure Session variables can only be used in a Javascript Stored Procedure when it's created with Caller rights.
https://community.snowflake.com/s/article/Using-session-variables-in-a-stored-procedure",
What computer language can be selected when creating User-Defined Functions (UDFs) using the Snowpark API?,multiple-choice,A. Swift,B. JavaScript,C. Python,D. SQL,,,,,,,,,,,,3,"Snowpark API supports: Python, Scala and Java
C Python Snowpark API supports: Python, Scala and Java
https://docs.snowflake.com/en/developer-guide/snowpark/index
Java, Python, Scala https://docs.snowflake.com/en/developer-guide/snowpark/index",
"A user needs to ingest 1 GB of data that is available in an external stage using a COPY INTO command.

How can this be done with MAXIMUM performance and the LEAST cost?",multiple-choice,A. Ingest the data in a compressed format as a single file.,B. Ingest the data in an uncompressed format as a single file.,"C. Split the file into smaller files of 100-250 MB each, compress and ingest each of the smaller files.",D. Split the file into smaller files of 100-250 MB each and ingest each of the smaller files in an uncompressed format.,,,,,,,,,,,,3,https://docs.snowflake.com/en/user-guide/data-load-considerations-prepare,
"A Snowflake user has two tables that contain numeric values and is trying to find out which values are present in both tables.

Which set operator should be used?",multiple-choice,A. INTERSECT,B. MERGE,C. MINUS,D. UNION,,,,,,,,,,,,1,"https://docs.snowflake.com/en/sql-reference/operators-query INTERSECT Returns rows from one query’s result set which also appear in another query’s result set, with duplicate elimination.
Correct",
"A view is defined on a permanent table. A temporary table with the same name is created in the same schema as the referenced table.

What will the query from the view return?",multiple-choice,A. The data from the permanent table.,B. The data from the temporary table.,C. An error stating that the view could not be compiled.,D. An error stating that the referenced object could not be uniquely identified.,,,,,,,,,,,,2,"Similar to the other table types (transient and permanent), temporary tables belong to a specified database and schema; however, because they are session-based, they aren’t bound by the same uniqueness requirements. This means you can create temporary and non-temporary tables with the same name within the same schema. However, note that the temporary table takes precedence in the session over any other table with the same name in the same schema.   https://docs.snowflake.com/en/user-guide/tables-temp-transient
Changing my answer to A - According to the documentation, when a view is defined on a permanent table, it continues to reference the permanent table even if a temporary table with the same name is created in the same schema. The view will not be affected by the temporary table.",
Which file function generates a Snowflake-hosted file URL to a staged file using the stage name and relative file path as inputs?,multiple-choice,A. BUILD_STAGE_FILE_URL,B. GET_ABSOLUTE_PATH,C. GET_RELATIVE_PATH,D. GET_STAGE_LOCATION,,,,,,,,,,,,1,https://docs.snowflake.com/en/sql-reference/functions/build_stage_file_url,
Which service or feature in Snowflake is used to improve the performance of certain types of lookup and analytical queries that use an extensive set of WHERE conditions?,multiple-choice,A. Data classification,B. Query acceleration service,C. Search optimization service,D. Tagging,,,,,,,,,,,,3,"C is correct
https://www.snowflake.com/blog/now-generally-available-snowflakes-search-optimization-service-accelerates-queries-dramatically/",
What is the name of the SnowSQL file that can store connection information?,multiple-choice,A. history,B. config,C. snowsql.cnf,D. snowsql.pubkey,,,,,,,,,,,,2,"https://docs.snowflake.com/en/user-guide/snowsql-config#connection-parameters-section In the [connections] section of the config file, optionally set the default connection parameters for SnowSQL, e.g. account identifier, user login credentials, and the default database and warehouse. You can also define named connections to make multiple simultaneous connections to Snowflake or store different sets of connection configurations. For more information, see Connecting through SnowSQL. https://docs.snowflake.com/en/user-guide/snowsql-start
B: https://docs.snowflake.com/en/user-guide/snowsql-config  B and C?  When SnowSQL starts, it loads configuration parameter values from the following configuration file locations in order, overriding values from files loaded previously:   /etc/snowsql.cnf   /etc/snowflake/snowsql.cnf   /usr/local/etc/snowsql.cnf   <HOME_DIR>/.snowsql.cnf (supported only for backward compatibility)   <HOME_DIR>/.snowsql/config
https://www.bing.com/search?q=snowsql+config+file&cvid=2892d844f70d4eea84d1269a1f7e9668&aqs=edge.2.69i59j69i57j0l2j69i58j69i11004.17557j0j4&FORM=ANAB01&PC=U531",
How do secure views compare to non-secure views in Snowflake?,multiple-choice,A. Secure views execute slowly compared to non-secure views.,B. Non-secure views are preferred over secure views when sharing data.,C. Secure views are similar to materialized views in that they are the most performant.,D. There are no performance differences between secure and non-secure views.,,,,,,,,,,,,1,"https://docs.snowflake.com/en/user-guide/views-secure#:~:text=Secure%20views%20can%20execute%20more%20slowly%20than%20non%2Dsecure%20views.
correct",
"Which type of join will list all rows in the specified table, even if those rows have no match in the other table?",multiple-choice,A. Cross join,B. Inner join,C. Natural join,D. Outer join,,,,,,,,,,,,4,"In some way CROSS JOIN also lists all rows.
correct",
"When unloading data to an external stage, what is the MAXIMUM file size supported?",multiple-choice,A. 1 GB,B. 5 GB,C. 10 GB,D. 16 GB,,,,,,,,,,,,2,"By default, COPY INTO location statements separate table data into a set of output files to take advantage of parallel operations. The maximum size for each file is set using the MAX_FILE_SIZE copy option. The default value is 16777216 (16 MB) but can be increased to accommodate larger files. The maximum file size supported is 5 GB for Amazon S3, Google Cloud Storage, or Microsoft Azure stages. https://docs.snowflake.com/en/user-guide/data-unload-considerations#
https://docs.snowflake.com/en/user-guide/data-unload-considerations",
How long does Snowflake retain information in the ACCESS_HISTORY view?,multiple-choice,A. 7 days,B. 14 days,C. 28 days,D. 365 days,,,,,,,,,,,,4,"ACCESS_HISTORY in Enterprise Edition (or higher) is retained for 1 year. https://docs.snowflake.com/en/sql-reference/account-usage
https://docs.snowflake.com/en/sql-reference/account-usage
https://www.bing.com/search?q=How+long+does+Snowflake+retain+information+in+the+ACCESS_HISTORY+view&qs=n&form=QBRE&sp=-1&lq=1&pq=how+long+does+snowflake+retain+information+in+the+access_history+view&sc=1-69&sk=&cvid=82C471FF83A54A3388BF99DDF50BE969&ghsh=0&ghacc=0&ghpl=",
Which encryption type will enable client-side encryption for a directory table?,multiple-choice,A. AES,B. AWS_CSE,C. SNOWFLAKE_SSE,D. SNOWFLAKE_FULL,,,,,,,,,,,,4,"SNowflake_full for client and snowflake_sse for server side
https://suya-huang.medium.com/snowflakes-client-side-encryption-and-server-side-encryption-4c7a83427010",
"If file format options are specified in multiple locations, the load operation selects which option FIRST to apply in order of precedence?",multiple-choice,A. Table definition,B. Stage definition,C. Session level,D. COPY INTO TABLE statement,,,,,,,,,,,,4,"D - no doubts
correct
https://docs.snowflake.com/en/user-guide/data-load-prepare",
"A complex SQL query involving eight tables with joins is taking a while to execute. The Query Profile shows that all partitions are being scanned.

What is causing the query performance issue?",multiple-choice,A. Pruning is not being performed efficiently.,"B. A huge volume of data is being fetched, with many joins applied.","C. Incorrect joins are being used, leading to scanning and pulling too many records.",D. The columns in the micro-partitions need granular ordering based on the dataset.,,,,,,,,,,,,1,"correct
I think the answer is C.  https://docs.snowflake.com/en/user-guide/ui-query-profile#exploding-joins",
What does Snowflake's search optimization service support?,multiple-choice,A. External tables,B. Materialized views,C. Tables and views that are not protected by row access policies,D. Casts on table columns (except for fixed-point numbers cast to strings),,,,,,,,,,,,3,"Queries Not Supported By the Search Optimization Service¶ The search optimization service does not support the following:  External tables.  Materialized views.  Columns defined with a COLLATE clause.  Column concatenation.  Analytical expressions.  Casts on table columns (except for fixed-point numbers cast to strings).  https://docs.snowflake.com/en/user-guide/search-optimization-service#label-search-optimization-service-supported-data-types
All four looks incorrect  A, B & D are incorrect as per https://docs.snowflake.com/en/user-guide/search-optimization-service#:~:text=Queries%20Not%20Supported%20By%20the%20Search%20Optimization%20Service%C2%B6  and C is s twisted statement and leans towards the correct answer as per this https://docs.snowflake.com/en/user-guide/search-optimization-service#:~:text=Tables%20with%20Masking%20Policies%20and%20Row%20Access%20Policies%C2%B6",
Which table type is no longer available after the close of the session and therefore has no Fail-safe or Time Travel recovery option?,multiple-choice,A. External,B. Permanent,C. Temporary,D. Transient,,,,,,,,,,,,3,C correct,
How many network policies can be assigned to an account or specific user at a time?,multiple-choice,A. One,B. Two,C. Three,D. Unlimited,,,,,,,,,,,,1,"You can create multiple network policies, however only one network policy can be associated with an account at any one time. https://docs.snowflake.com/en/user-guide/network-policies
https://docs.snowflake.com/en/user-guide/network-policies",
What is a characteristic of a tag associated with a masking policy?,multiple-choice,A. A tag can be dropped after a masking policy is assigned.,B. A tag can have only one masking policy for each data type.,C. A tag can have multiple masking policies for each data type.,D. A tag can have multiple masking policies with varying data types.,,,,,,,,,,,,2,"https://docs.snowflake.com/en/user-guide/tag-based-masking-policies
The tag can support one masking policy for each data type that Snowflake supports.  https://docs.snowflake.com/en/user-guide/tag-based-masking-policies#overview",
Which clients does Snowflake support Multi-Factor Authentication (MFA) token caching for? (Choose two.),multi-select,A. GO driver,B. Node.js driver,C. ODBC driver,D. Python connector,E. Spark connector,,,,,,,,,,,"3, 4","https://docs.snowflake.com/en/user-guide/security-mfa ODBC driver version 2.23.0 (or later).  JDBC driver version 3.12.16 (or later).  Python Connector for Snowflake version 2.3.7 (or later).
C&D are correct ODBC and Python https://docs.snowflake.com/en/user-guide/security-mfa",
What is the Snowflake recommended Parquet file size when querying from external tables to optimize the number of parallel scanning operations?,multiple-choice,A. 1-16 MB,B. 16-128 MB,C. 100-250 MB,D. 256-512 MB,,,,,,,,,,,,4,"D To optimize the number of parallel scanning operations when querying external tables, we recommend the following file or row group sizes per format: Parquet files 256 - 512 MB
https://docs.snowflake.com/en/user-guide/tables-external-intro.
Answer is D: https://docs.snowflake.com/en/user-guide/tables-external-intro. ""Parquet Files, Recommended Size Range: 256-512MB""",
Which data types can be used in a Snowflake table that holds semi-structured data? (Choose two.),multi-select,A. ARRAY,B. BINARY,C. TEXT,D. VARIANT,E. VARCHAR,,,,,,,,,,,"1, 4","Correct answer
https://docs.snowflake.com/en/user-guide/semistructured-intro",
Which constraint is enforced in Snowflake?,multiple-choice,A. FOREIGN KEY,B. NOT NULL,C. PRIMARY KEY,D. UNIQUE KEY,,,,,,,,,,,,2,Correct,
Which pages are included in the Activity area of Snowsight? (Choose two.),multi-select,A. Contacts,B. Sharing settings,C. Copy History,D. Query History,E. Automatic Clustering History,,,,,,,,,,,"3, 4","Pages included in Activity Area of Snowsight Query History Copy History Task History Dynamic Tables
C&D are correct  https://docs.snowflake.com/en/user-guide/ui-snowsight-quick-tour",
When should a user consider disabling auto-suspend for a virtual warehouse? (Choose two.),multi-select,A. When users will be using compute at different times throughout a 24/7 period,B. When managing a steady workload,C. When the compute must be available with no delay or lag time,D. When the user does not want to have to manually turn on the warehouse each time it is needed,E. When the warehouse is shared across different teams,,,,,,,,,,,"2, 3","confirmed https://www.bing.com/search?q=When+should+a+user+consider+disabling+auto-suspend+for+a+virtual+warehouse%3F&cvid=23aca38a3cde4a21b08a926f8a3e6398&aqs=edge..69i57j69i11004.2238j0j9&FORM=ANAB01&PC=U531
Makes sense",
What can a Snowflake user do in the Activity section in Snowsight?,multiple-choice,A. Create dashboards.,B. Write and run SQL queries.,C. Explore databases and objects.,D. Explore executed query performance.,,,,,,,,,,,,4,"https://www.bing.com/search?q=What+can+a+Snowflake+user+do+in+the+Activity+section+in+Snowsight%3F&cvid=619f477cfe384ad682420085ded0ec51&aqs=edge..69i57j69i11004.1597j0j9&FORM=ANAB01&PC=U531
https://docs.snowflake.com/en/user-guide/ui-snowsight-quick-tour
D is correct https://docs.snowflake.com/en/user-guide/ui-snowsight-quick-tour",
How does Snowflake reorganize data when it is loaded? (Choose two.),multi-select,A. Binary format,B. Columnar format,C. Compressed format,D. Raw format,E. Zipped format,,,,,,,,,,,"2, 3","When data is loaded into Snowflake, Snowflake reorganizes that data into its internal optimized, compressed, columnar format. Snowflake stores this optimized data in cloud storage.
correct
https://docs.snowflake.com/en/user-guide/intro-key-concepts#database-storage",
Which operations are handled in the Cloud Services layer of Snowflake? (Choose two.),multi-select,A. Security,B. Data storage,C. Data visualization,D. Query computation,E. Metadata management,,,,,,,,,,,"1, 5","A and E r correct
A and E are correct answers. Query Computation happens on VW (Compute layer)
https://www.bing.com/search?q=Which+operations+are+handled+in+the+Cloud+Services+layer+of+Snowflake%3F&cvid=b42d4b21da9c42e3abb3543b7261a44e&aqs=edge..69i57j69i11004.1323j0j9&FORM=ANAB01&PC=U531
https://www.projectpro.io/article/snowflake-architecture-what-does-snowflake-do/556#:~:text=The%20cloud%20services%20layer%20contains,highly%20accessible%20and%20usable%20information.",
What type of columns does Snowflake recommend to be used as clustering keys? (Choose two.),multi-select,A. A VARIANT column,B. A column with very low cardinality,C. A column with very high cardinality,D. A column that is most actively used in selective filters,E. A column that is most actively used in join predicates,,,,,,,,,,,"4, 5","correct
https://docs.snowflake.com/en/user-guide/tables-clustering-keys",
Which objects together comprise a namespace in Snowflake? (Choose two.),multi-select,A. Account,B. Database,C. Schema,D. Table,E. Virtual warehouse,,,,,,,,,,,"2, 3","correct
https://docs.snowflake.com/en/sql-reference/ddl-database",
What statistical information in a Query Profile indicates that the query is too large to fit in memory? (Choose two.),multi-select,A. Bytes spilled to local cache.,B. Bytes spilled to local storage.,C. Bytes spilled to remote cache.,D. Bytes spilled to remote storage.,E. Bytes spilled to remote metastore.,,,,,,,,,,,"2, 4","https://www.bing.com/search?q=bytes+spilled+to+local+storage+snowflake&cvid=e844f19876134a32bab1cd2c43995f87&aqs=edge.2.0j69i57j0l7j69i11004.7813j0j9&FORM=ANAB01&PC=U531
https://docs.snowflake.com/en/user-guide/ui-query-profile",
How do Snowflake data providers share data that resides in different databases?,multiple-choice,A. External tables,B. Secure views,C. Materialized views,D. User-Defined Functions (UDFs),,,,,,,,,,,,2,"Snowflake data providers can share data that resides in different databases by using secure views. A secure view can reference objects such as schemas, tables, and other views from one or more databases, as long as these databases belong to the same account.
https://docs.snowflake.com/en/user-guide/data-sharing-mutiple-db",
What operations can be performed while loading a simple CSV file into a Snowflake table using the COPY INTO command? (Choose two.),multi-select,A. Performing aggregate calculations,B. Reordering the columns,C. Grouping by operations,D. Converting the datatypes,E. Selecting the first few rows,,,,,,,,,,,"2, 4","https://www.bing.com/search?q=What+operations+can+be+performed+while+loading+a+simple+CSV+file+into+a+Snowflake+table+using+the+COPY+INTO+command%3F&cvid=a3217f4a0efc47a08668464ee418e9bb&aqs=edge..69i57j69i11004.2008j0j9&FORM=ANAB01&PC=U531
https://docs.snowflake.com/en/user-guide/data-load-transform",
Which commands support a multiple-statement request to access and update Snowflake data? (Choose two.),multi-select,A. CALL,B. COMMIT,C. GET,D. PUT,E. ROLLBACK,,,,,,,,,,,"2, 5","https://docs.snowflake.com/en/sql-reference/transactions#explicit-transactions
Why not A. we can write multiple statements in a stored procedure.",
Why should a Snowflake user implement a secure view? (Choose two.),multi-select,A. To store unstructured data,B. To increase query performance,C. To limit access to sensitive data,D. To optimize query concurrency and queuing,E. To hide view definition and details from unauthorized users,,,,,,,,,,,"3, 5","Views should be defined as secure when they are specifically designated for data privacy (i.e. to limit access to sensitive data that should not be exposed to all users of the underlying table(s)). The definition of a secure view is only exposed to authorized users (i.e. users who have been granted the role that owns the view). https://docs.snowflake.com/en/user-guide/views-secure
Commit
https://docs.snowflake.com/en/user-guide/views-secure",
At what levels can a resource monitor be configured? (Choose two.),multi-select,A. Account,B. Database,C. Organization,D. Schema,E. Virtual warehouse,,,,,,,,,,,"1, 5","An account monitor monitors the credit usage of all the warehouses in the account. An account can only have one account monitor.  A warehouse monitor monitors the credit usage of the warehouses assigned to the resource monitor. An account can have multiple warehouse monitors.
https://docs.snowflake.com/en/user-guide/resource-monitors",
What activities can be monitored by a user directly from Snowsight's Activity tab without using the Account_Usage views? (Choose two.),multi-select,A. Login history,B. Query history,C. Copy history,D. Event usage history,E. Virtual warehouse metering history,,,,,,,,,,,"2, 3","Correct
https://docs.snowflake.com/en/user-guide/ui-snowsight-activity",
What can a Snowflake user do with the information included in the details section of a Query Profile?,multiple-choice,A. Determine the total duration of the query.,B. Determine the role of the user who ran the query.,C. Determine the source system that the queried table is from.,D. Determine if the query was on structured or semi-structured data.,,,,,,,,,,,,1,"Correct
https://docs.snowflake.com/en/user-guide/ui-query-profile#query-operator-details",
Which term is used to describe information about disk usage for operations where intermediate results cannot be accommodated in a Snowflake virtual warehouse memory?,multiple-choice,A. Pruning,B. Spilling,C. Join explosion,D. Queue overloading,,,,,,,,,,,,2,correct,
"There are two Snowflake accounts in the same cloud provider region: one is production and the other is non-production.

How can data be easily transferred from the production account to the non-production account?",multiple-choice,A. Clone the data from the production account to the non-production account.,B. Create a data share from the production account to the non-production account.,C. Create a subscription in the production account and have it publish to the non-production account.,D. Create a reader account using the production account and link the reader account to the non-production account.,,,,,,,,,,,,2,"Can't clone data across accounts
Cannot clone across accounts, hence B",
"A user is unloading data to a stage using this command:

copy into @message from (select object_construct('id', 1, 'first_name', 'Snowflake', 'last_name', 'User', 'city', 'Bozeman')) file_format = (type = json)

What will the output file in the stage be?",multiple-choice,A. A single compressed JSON file with a single VARIANT column,B. Multiple compressed JSON files with a single VARIANT column,C. A single uncompressed JSON file with multiple VARIANT columns,D. Multiple uncompressed JSON files with multiple VARIANT columns,,,,,,,,,,,,1,"You can use the OBJECT_CONSTRUCT function combined with the COPY command to convert the rows in a relational table to a single VARIANT column and unload the rows into a file.
https://docs.snowflake.com/en/user-guide/data-unload-considerations#:~:text=You%20can%20use%20the%20OBJECT_CONSTRUCT%20function%20combined%20with%20the%20COPY%20command%20to%20convert%20the%20rows%20in%20a%20relational%20table%20to%20a%20single%20VARIANT%20column%20and%20unload%20the%20rows%20into%20a%20file.",
"A JSON file that contains lots of dates and arrays needs to be processed in Snowflake. The user wants to ensure optimal performance while querying the data.

How can this be achieved?",multiple-choice,A. Flatten the data and store it in structured data types in a flattened table. Query the table.,B. Store the data in a table with a VARIANT data type. Query the table.,C. Store the data in a table with a VARIANT data type and include STRIP_NULL_VALUES while loading the table. Query the table.,D. Store the data in an external stage and create views on top of it. Query the views.,,,,,,,,,,,,1,"From Snowflake documentation If you are not sure yet what types of operations you want to perform on your semi-structured data, Snowflake recommends storing the data in a VARIANT column for now.  For data that is mostly regular and uses only data types that are native to the semi-structured format you are using (e.g. strings and integers for JSON format), the storage requirements and query performance for operations on relational data and data in a VARIANT column is very similar.  For better pruning and less storage consumption, we recommend flattening your OBJECT and key data into separate relational columns if your semi-structured data includes:  Dates and timestamps, especially non-ISO 8601 dates and timestamps, as string values  Numbers within strings  Arrays  Non-native values (such as dates and timestamps in JSON) are stored as strings when loaded into a VARIANT column, so operations on these values could be slower and also consume more space than when stored in a relational column with the corresponding data type.
why not C?
I'm undecided between A vs. B. In a real-world task, I would do B and do some ELT if needed to prep the data for analysis.  Based on the docs below, it appears that A is recommended by Snowflake as more performant. https://docs.snowflake.com/en/user-guide/semistructured-considerations Storing Semi-structured Data in a VARIANT Column vs. Flattening the Nested Structure¶ For better pruning and less storage consumption, we recommend flattening your OBJECT and key data into separate relational columns if your semi-structured data includes:  Dates and timestamps, especially non-ISO 8601 dates and timestamps, as string values Numbers within strings Arrays
I hesitate between A&B And will be happy to provoke a discussion  If you know your use cases for the data, perform tests on a typical data set. Load the data set into a VARIANT column in a table. Use the FLATTEN function to extract the OBJECTs and keys you plan to query into a separate table. Run a typical set of queries against both tables to see which structure provides the best performance. https://docs.snowflake.com/en/user-guide/semistructured-considerations",
"When referring to User-Defined Function (UDF) names in Snowflake, what does the term overloading mean?",multiple-choice,A. There are multiple SQL UDFs with the same names and the same number of arguments.,B. There are multiple SQL UDFs with the same names and the same number of argument types.,C. There are multiple SQL UDFs with the same names but with a different number of arguments or argument types.,D. There are multiple SQL UDFs with different names but the same number of arguments or argument types.,,,,,,,,,,,,3,"Overloading procedures and functions Snowflake supports overloading procedures and functions. In a given schema, you can define multiple procedures or functions that have the same name but different signatures. The signatures must differ by the number of arguments, the types of the arguments, or both. https://docs.snowflake.com/en/developer-guide/udf-stored-procedure-naming-conventions#overloading-procedures-and-functions
https://www.bing.com/search?q=When+referring+to+User-Defined+Function+%28UDF%29+names+in+Snowflake%2C+what+does+the+term+overloading+mean%3F&qs=n&form=QBRE&sp=-1&lq=1&pq=when+referring+to+user-defined+function+%28udf%29+names+in+snowflake%2C+what+does+the+term+overloading+mean%3F&sc=1-102&sk=&cvid=9657B73889BB4C33A673D15B5035044C&ghsh=0&ghacc=0&ghpl=",
Which key governance feature in Snowflake allows users to identify data objects that contain sensitive data and their related objects?,multiple-choice,A. Object tagging,B. Data classification,C. Row access policy,D. Column-level security,,,,,,,,,,,,2,"Data classification in Snowflake is a feature that allows users to automatically identify and classify columns in their tables containing personal or sensitive data.
https://www.bing.com/search?q=Which+key+governance+feature+in+Snowflake+allows+users+to+identify+data+objects+that+contain+sensitive+data+and+their+related+objects%3F&qs=n&form=QBRE&sp=-1&lq=1&pq=which+key+governance+feature+in+snowflake+allows+users+to+identify+data+objects+that+contain+sensitive+data+and+their+related+objects%3F&sc=1-134&sk=&cvid=8B493761844044C48A2C50322DCC8F24&ghsh=0&ghacc=0&ghpl=",
What can a Snowflake user do in the Admin area of Snow right?,multiple-choice,A. Analyze query performance.,B. Write queries and execute them.,C. Provide an overview of the listings in the Snowflake Marketplace.,D. Connect to Snowflake partners to explore extended functionality.,,,,,,,,,,,,4,"Deprecated question.
Administer Snowflake by using the Admin area of Snowsight. Use the Admin area to:  Understand your Snowflake usage.  Manage Snowflake warehouses.  Set up and view details about resource monitors.  Manage users and roles.  Administer Snowflake accounts in your organization.  Administer network policies and monitor session activity.  Set up payment and payout methods.  Review and accept the Provider and Consumer Terms of Service.  Set organization contacts for Snowflake security, privacy, and product notifications.  Connect to Snowflake partners to explore extended functionality.
https://www.bing.com/search?q=What+can+a+Snowflake+user+do+in+the+Admin+area+of+Snow+right%3F&qs=n&form=QBRE&sp=-1&lq=0&pq=what+can+a+snowflake+user+do+in+the+admin+area+of+snow+right%3F&sc=1-61&sk=&cvid=75DD9F7F014D4BA68FE5221245041746&ghsh=0&ghacc=0&ghpl=",
Which function generates a Snowflake hosted file URL to a staged file using the stage name and relative file path as inputs?,multiple-choice,A. BUILD_STAGE_FILE_URL,B. BUILD_SCOPED_FILE_URL,C. GET_PRESIGNED_URL,D. GET_STAGE_LOCATION,,,,,,,,,,,,1,"BUILD_STAGE_FILE_URL Generates a Snowflake-hosted file URL to a staged file using the stage name and relative file path as inputs. A file URL permits prolonged access to a specified file. That is, the file URL does not expire.
https://www.bing.com/search?q=Which+function+generates+a+Snowflake+hosted+file+URL+to+a+staged+file+using+the+stage+name+and+relative+file+path+as+inputs%3F&qs=n&form=QBRE&sp=-1&lq=1&pq=which+function+generates+a+snowflake+hosted+file+url+to+a+staged+file+using+the+stage+name+and+relative+file+path+as+inputs%3F&sc=1-124&sk=&cvid=5528116F9D4748FBB98781BDF20E3EBA&ghsh=0&ghacc=0&ghpl=",
What is the purpose of using the OBJECT_CONSTRUCT function with the COPY INTO command?,multiple-choice,A. Reorder the rows in a relational table and then unload the rows into a file.,B. Convert the rows in a relational table to a single VARIANT column and then unload the rows into a file.,C. Reorder the data columns according to a target table definition and then unload the rows into the table.,D. Convert the rows in a source file to a single VARIANT column and then load the rows from the file to a variant table.,,,,,,,,,,,,2,Unloading a Relational Table to JSON¶ You can use the OBJECT_CONSTRUCT function combined with the COPY command to convert the rows in a relational table to a single VARIANT column and unload the rows into a file.,
Which URL provides access to files in Snowflake without authorization?,multiple-choice,A. File URL,B. Scoped URL,C. Pre-signed URL,D. Scoped file URL,,,,,,,,,,,,3,C - This URL type allows users to access unstructured data without authenticating into Snowflake or passing an authorization token.,
What type of NULL values are supported in semi-structured data? (Choose two.),multi-select,A. Avro,B. JSON,C. ORC,D. Parquet,E. SQL,,,,,,,,,,,"2, 5","https://docs.snowflake.com/en/user-guide/semistructured-considerations  Snowflake supports two types of NULL values in semi-structured data:  SQL NULL: SQL NULL means the same thing for semi-structured data types as it means for structured data types: the value is missing or unknown.  JSON null (sometimes called “VARIANT NULL”): In a VARIANT column, JSON null values are stored as a string containing the word “null” to distinguish them from SQL NULL values.
https://www.bing.com/search?q=What+type+of+NULL+values+are+supported+in+semi-structured+data%3F&qs=n&form=QBRE&sp=-1&lq=0&pq=what+type+of+null+values+are+supported+in+semi-structured+data%3F&sc=1-63&sk=&cvid=552AB51872BC42958FA09BAF7727140F&ghsh=0&ghacc=0&ghpl=",
What are characteristics of transient tables in Snowflake? (Choose two.),multi-select,A. Transient tables have a Fail-safe period of 7 days.,B. Transient tables can be cloned to permanent tables.,C. Transient tables persist until they are explicitly dropped.,D. Transient tables can be altered to make them permanent tables.,E. Transient tables have Time Travel retention periods of 0 or 1 day.,,,,,,,,,,,"3, 5","""Transient tables do not have a Fail-safe period. They are designed to minimize storage costs by not retaining historical data.""  > ""Transient tables can be cloned to create permanent tables.""  > ""Transient tables persist until they are explicitly dropped by the user.""  > ""Transient tables cannot be altered to become permanent tables. You would need to create a new permanent table and migrate the data.""  > ""Transient tables have a Time Travel retention period of either 0 or 1 day.""
see the comparison of table types - https://docs.snowflake.com/en/user-guide/tables-temp-transient
https://www.bing.com/search?q=What+are+characteristics+of+transient+tables+in+Snowflake%3F&qs=n&form=QBRE&sp=-1&lq=0&pq=what+are+characteristics+of+transient+tables+in+snowflake%3F&sc=1-58&sk=&cvid=82C0B06F8F6B402FABAB2E7EC1CFAAAF&ghsh=0&ghacc=0&ghpl=",
The INFORMATION_SCHEMA included in each database contains which objects? (Choose two.),multi-select,A. Views for all the objects contained in the database,B. Views for all the objects contained in the Snowflake account,C. Views for historical and usage data across the Snowflake account,D. Table functions for historical and usage data across the Snowflake account,"E. Table functions for account-level objects, such as roles, virtual warehouses, and databases",,,,,,,,,,,"1, 4","https://docs.snowflake.com/en/sql-reference/info-schema#what-is-information-schema
I have check and it seems to be A & E ...
I vote AD. https://docs.snowflake.com/en/sql-reference/info-schema Each database created in your account automatically includes a built-in, read-only schema named INFORMATION_SCHEMA. The schema contains the following objects:  Views for all the objects contained in the database, as well as views for account-level objects (i.e. non-database objects such as roles, warehouses, and databases)  Table functions for historical and usage data across your account. The table functions in INFORMATION_SCHEMA can be used to return account-level usage and historical information for storage, warehouses, user logins, and queries:  AD directly matches docs E is not correct. There are no roles table functions
https://docs.snowflake.com/en/sql-reference/info-schema The info for account-level objects is represented in views",
The use of which technique or tool will improve Snowflake query performance on very large tables?,multiple-choice,A. Indexing,B. Clustering keys,C. Multi-clustering,D. Materialized views,,,,,,,,,,,,2,"correct answer is B
Correct",
Which Snowflake layer is associated with virtual warehouses?,multiple-choice,A. Cloud services,B. Query processing,C. Elastic memory,D. Database storage,,,,,,,,,,,,2,"B correct  https://docs.snowflake.com/en/user-guide/intro-key-concepts
Correct",
Which MINIMUM set of privileges is required to temporarily bypass an active network policy by configuring the user object property MINS_TO_BYPASS_NETWORK_POLICY?,multiple-choice,A. Only while in the ACCOUNTADMIN role,B. Only while in the SECURITYADMIN role,C. Only the role with the OWNERSHIP privilege on the network policy,D. Only Snowflake Support can set the value for this object property,,,,,,,,,,,,4,"It is possible to temporarily bypass a network policy for a set number of minutes by configuring the user object property MINS_TO_BYPASS_NETWORK_POLICY, which can be viewed by executing DESCRIBE USER. Only Snowflake can set the value for this object property. Please contact Snowflake Support to set a value for this property.
D only snowflake support allows that https://docs.snowflake.com/en/user-guide/network-policies#bypassing-a-network-policy",
What authentication method does the Kafka connector use within Snowflake?,multiple-choice,A. Key pair authentication,B. Multi-Factor Authentication (MFA),C. OAuth,D. Username and password,,,,,,,,,,,,1,"https://www.bing.com/search?q=What+authentication+method+does+the+Kafka+connector+use+within+Snowflake%3F&qs=n&form=QBRE&sp=-1&lq=1&pq=what+authentication+method+does+the+kafka+connector+use+within+snowflake%3F&sc=1-73&sk=&cvid=F1A4FEE251F74FFF9171AA41AD3EBA9D&ghsh=0&ghacc=0&ghpl=
A https://docs.snowflake.com/en/user-guide/kafka-connector-install#download-the-kafka-connector-files",
What is the purpose of the Snowflake SPLIT_TO_TABLE function?,multiple-choice,A. To count the number of characters in a string,B. To split a string into an array of sub-strings,C. To split a string and flatten the results into rows,D. To split a string and flatten the results into columns,,,,,,,,,,,,3,"https://docs.snowflake.com/en/sql-reference/functions/split_to_table
https://www.bing.com/search?q=What+is+the+purpose+of+the+Snowflake+SPLIT_TO_TABLE+function%3F&qs=ds&form=QBRE",
What feature of Snowflake Continuous Data Protection can be used for maintenance of historical data?,multiple-choice,A. Access control,B. Fail-safe,C. Network policies,D. Time Travel,,,,,,,,,,,,4,"Why not Fail-Safe?
Only snowflake support has access to fail safe and can restore data. Time travel the user can do it.
correct",
What aspect of an executed query is represented by the remote disk I/O statistic of the Query Profile in Snowflake?,multiple-choice,A. Time spent scanning the table partitions to filter data based on the predicate,B. Time spent caching the data to remote storage in order to buffer the data being extracted and exported,C. Time spent reading and writing data from and to remote storage when the data being accessed does not fit into the executing virtual warehouse node memory,D. Time spent reading and writing data from and to remote storage when the data being accessed does not fit into either the virtual warehouse memory or the local disk,,,,,,,,,,,,4,"I think the correct answer is A B - not correct C - the correct metric for that would be Bytes spilled to local storage D - the correct metric for that would be Bytes spilled to remote storage A - correct, we're accessing the remote disk (the Storage Layer) to retrieve the data for the query. https://community.snowflake.com/s/article/Performance-impact-from-local-and-remote-disk-spilling https://community.snowflake.com/s/article/Performance-impact-from-local-and-remote-disk-spilling https://community.snowflake.com/s/article/Performance-impact-from-local-and-remote-disk-spilling
""local disk"" is remote storage, with respect to warehouse memory. So, I feel C is correct.
C would assume writing to local disk is also ""remote disk IO"" which doesn't seem to be the case
I think it's D  C would assume writing to local disk is also ""remote disk IO"" which doesn't seem to be the case
Changing my mind to B. We can cross-reference the options against this doc: https://docs.snowflake.com/en/user-guide/ui-query-profile#statistics A - Pruning B - IO C - Spilling D- Spilling",
What action can a user take to address query concurrency issues?,multiple-choice,A. Enable the search optimization service.,B. Enable the query acceleration service.,C. Add additional clusters to the virtual warehouse.,D. Resize the virtual warehouse to a larger instance size.,,,,,,,,,,,,3,D is wrong because here we need to (scale out) parallelism by adding more cluster no (scale up) mean adding more CPU/memory,
What does the client redirect feature in Snowflake enable?,multiple-choice,A. A redirect of client connections to Snowflake accounts in the same regions for business continuity.,B. A redirect of client connections to Snowflake accounts in different regions for business continuity.,C. A redirect of client connections to Snowflake accounts in different regions for data replication.,D. A redirect of client connections to Snowflake accounts in the same regions for data replication.,,,,,,,,,,,,2,"Client Redirect enables redirecting your client connections to Snowflake accounts in different regions for business continuity and disaster recovery, or when migrating your account to another region or cloud platform.
https://docs.snowflake.com/en/user-guide/client-redirect
https://www.bing.com/search?q=What+does+the+client+redirect+feature+in+Snowflake+enable%3F%0D%0A%0D%0A&qs=n&form=QBRE&sp=-1&lq=1&pq=what+does+the+client+redirect+feature+in+snowflake+enable%3F&sc=1-60&sk=&cvid=A6CA669ADC70464CB415B766A6818C26&ghsh=0&ghacc=0&ghpl=",
Which Snowflake feature can be used to find sensitive data in a table or column?,multiple-choice,A. Masking policies,B. Data classification,C. Row level policies,D. External functions,,,,,,,,,,,,2,"Why not masking policies?
Classification will let you find sensitive data.  Masking policies are used to mask sensitive data after you found them.  Dynamic Data Masking is a Column-level Security feature that uses masking policies to selectively mask plain-text data in table and view columns at query time https://docs.snowflake.com/en/user-guide/security-column-ddm-intro  https://docs.snowflake.com/en/user-guide/governance-classify-concepts
Correct",
"Which Snowflake feature allows a user to track sensitive data for compliance, discovery, protection, and resource usage?",multiple-choice,A. Tags,B. Comments,C. Internal tokenization,D. Row access policies,,,,,,,,,,,,1,"At Snowflake, data governance is all about providing our customers native capabilities to easily and efficiently govern data at scale. Previously, we launched capabilities such as Object Tagging, Dynamic Data Masking, Row Access Policies, and Access History to help keep track of sensitive data by tagging it, assigning masking policies to protect columns with sensitive data from unauthorized access, and audit the access of sensitive columns using Access History.  https://www.snowflake.com/blog/protect-sensitive-data-tag-based-masking/
https://www.snowflake.com/blog/protect-sensitive-data-tag-based-masking/",
Snowflake’s hierarchical key mode includes which keys? (Choose two.),multi-select,A. Account master keys,B. Database master keys,C. File keys,D. Secure view keys,E. Schema master keys,,,,,,,,,,,"1, 3","Answer is A & C Snowflake’s hierarchical key model consists of four levels of keys: The root key Account master keys Table master keys File keys
Answer is A&C https://docs.snowflake.com/en/user-guide/security-encryption-manage",
What can the Snowflake SCIM API be used to manage? (Choose two.),multi-select,A. Integrations,B. Network policies,C. Session policies,D. Roles,E. Users,,,,,,,,,,,"4, 5","Snowflake is compatible with SCIM2.0, SCIM is an open standard for automating user provisioning. The SCIM API allows us to programmatically manage roles and users within the Snowflake platform, making it easier to automate identity and access management tasks.
https://www.bing.com/search?q=What+can+the+Snowflake+SCIM+API+be+used+to+manage%3F&qs=n&form=QBRE&sp=-1&lq=0&pq=what+can+the+snowflake+scim+api+be+used+to+manage%3F&sc=1-50&sk=&cvid=47C7AA1360D14182AF0E91056C3FBB60&ghsh=0&ghacc=0&ghpl=",
Which privilege is required to use the search optimization service in Snowflake?,multiple-choice,A. GRANT SEARCH OPTIMIZATION ON SCHEMA [schema_name] TO ROLE [role],B. GRANT SEARCH OPTIMIZATION ON DATABASE [database_name] TO ROLE [role],C. GRANT ADD SEARCH OPTIMIZATION ON SCHEMA [schema_name] TO ROLE [role],D. GRANT ADD SEARCH OPTIMIZATION ON DATABASE [database_name] TO ROLE [role],,,,,,,,,,,,3,"C correct https://docs.snowflake.com/en/user-guide/search-optimization-service  What Access Control Privileges Are Needed For the Search Optimization Service?¶ To add, configure, or remove search optimization for a table, you must have the following privileges:  You must have OWNERSHIP privilege on the table.  You must have ADD SEARCH OPTIMIZATION privilege on the schema that contains the table.  GRANT ADD SEARCH OPTIMIZATION ON SCHEMA <schema_name> TO ROLE <role>
https://www.bing.com/search?q=Which+privilege+is+required+to+use+the+search+optimization+service+in+Snowflake%3F&qs=n&form=QBRE&sp=-1&lq=1&pq=which+privilege+is+required+to+use+the+search+optimization+service+in+snowflake%3F&sc=1-80&sk=&cvid=B4C1407FB1A046E49C04B50ACAFBA18C&ghsh=0&ghacc=0&ghpl=",
What is generally the FASTEST way to bulk load data files from a stage?,multiple-choice,A. Specifying a list of specific files to load,B. Loading by path (internal stages) / prefix,C. Using the Snowpipe REST API,D. Using pattern matching to identify specific files by pattern,,,,,,,,,,,,1,"https://docs.snowflake.com/en/user-guide/data-load-considerations-load#:~:text=Of%20the%20three%20options%20for,load%20up%20to%201%2C000%20files.
https://docs.snowflake.com/en/user-guide/data-load-considerations-load  Tip Of the three options for identifying/specifying data files to load from a stage, providing a discrete list of files is generally the fastest; however, the FILES parameter supports a maximum of 1,000 files, meaning a COPY command executed with the FILES parameter can only load up to 1,000 files.",
How does a Snowflake user extract the URL of a directory table on an external stage for further transformation?,multiple-choice,A. Use the SHOW STAGES command.,B. Use the DESCRIBE STAGE command.,C. Use the GET_ABSOLUTE_PATH function.,D. Use the GET_STAGE_LOCATION function.,,,,,,,,,,,,4,"The GET_STAGE_LOCATION function returns the location of a stage, including the URL of the directory table. The syntax for the GET_STAGE_LOCATION function. SELECT GET_STAGE_LOCATION('my_stage')
D https://docs.snowflake.com/en/sql-reference/functions/get_stage_location",
"A Snowflake user needs to share unstructured data from an internal stage to a reporting tool that does not have Snowflake access.

Which file function should be used?",multiple-choice,A. BUILD_SCOPED_FILE_URL,B. BUILD_STAGE_FILE_URL,C. GET_PRESIGNED_URL,D. GET_STAGE_LOCATION,,,,,,,,,,,,3,"https://docs.snowflake.com/en/user-guide/unstructured-intro Search in page for Types of URLs Available to Access Files  Pre-signed URL Used to download or access files without authenticating into Snowflake or passing an authorization token. Pre-signed URLs are open; any user or application can directly access or download the files. Ideal for business intelligence applications or reporting tools that need to display the unstructured file contents.
B https://docs.snowflake.com/en/sql-reference/functions/build_stage_file_url",
The use of which Snowflake table type will reduce costs when working with ETL workflows?,multiple-choice,A. External,B. Permanent,C. Temporary,D. Transient,,,,,,,,,,,,3,"C since temporary tables are only available for the duration of a session, and they are not stored in Snowflake's permanent storage. This means that they do not incur any storage costs.
Temporary tables exist only for the duration of the session and do not incur long-term storage costs. However, they are not accessible across sessions, which can limit their use in complex ETL workflows.  Transient tables strike the right balance between cost-effectiveness and functionality for ETL processes.",
What is one of the characteristics of data shares?,multiple-choice,A. Data shares support full DML operations.,B. Data shares work by copying data to consumer accounts.,C. Data shares utilize secure views for sharing view objects.,D. Data shares are cloud agnostic and can cross regions by default.,,,,,,,,,,,,3,"A view can only be shared if it is created as a secure view or marked secure using the ALTER VIEW view_name SET_SECURE statement.
Data sharing in Snowflake is read-only, meaning that all database objects shared between accounts cannot be modified or deleted, including adding or modifying table data 1. https://docs.snowflake.com/en/user-guide/data-sharing-intro",
What is the MINIMUM configurable idle timeout value for a session policy in Snowflake?,multiple-choice,A. 2 minutes,B. 5 minutes,C. 10 minutes,D. 15 minutes,,,,,,,,,,,,2,"The timeout period begins upon a successful authentication to Snowflake. If a session policy is not set, Snowflake uses a default value of 240 minutes (i.e. 4 hours). The minimum configurable idle timeout value for a session policy is 5 minutes. When the session expires, the user must authenticate to Snowflake again.
5 min https://docs.snowflake.com/en/user-guide/session-policies",
Which command is used to unload data from a Snowflake table to an external stage?,multiple-choice,A. COPY INTO,B. COPY INTO followed by GET,C. GET,D. COPY INTO followed by PUT,,,,,,,,,,,,1,"B is correct  Bulk unloading process The process for unloading data into files is the same as the loading process, except in reverse:  Step 1 Use the COPY INTO <location> command to copy the data from the Snowflake database table into one or more files in a Snowflake or external stage.  Step 2 Download the file from the stage:  From a Snowflake stage, use the GET command to download the data file(s).  From S3, use the interfaces/tools provided by Amazon S3 to get the data file(s).  From Azure, use the interfaces/tools provided by Microsoft Azure to get the data file(s).
Correct",
What is a characteristic of materialized views in Snowflake?,multiple-choice,A. Materialized views do not allow joins.,B. Clones of materialized views can be created directly by the user.,C. Multiple tables can be joined in the underlying query of a materialized view.,D. Aggregate functions can be used as window functions in materialized views.,,,,,,,,,,,,1,"https://docs.snowflake.com/en/user-guide/views-materialized - A materialized view can query only a single table. - Joins, including self-joins, are not supported.
Materialized views can be created on a single table or on multiple tables. The underlying query of a materialized view can contain any valid Snowflake query, including joins, aggregations, and window functions. CREATE MATERIALIZED VIEW my_view AS SELECT  customer_id,  customer_name,  order_id,  order_date FROM  customers  JOIN orders  ON customers.customer_id = orders.customer_id;  CREATE MATERIALIZED VIEW my_view AS SELECT  customer_id,  SUM(order_total) AS total_order_amount FROM  orders GROUP BY  customer_id;",
Which Snowflake URL type allows users or applications to download or access files directly from Snowflake stage without authentication?,multiple-choice,A. Directory,B. File,C. Pre-signed,D. Scoped,,,,,,,,,,,,3,"Pre-signed allows to download without auth
D is correct  https://docs.snowflake.com/en/sql-reference/functions/build_scoped_file_url",
Which SQL command will download all the data files from an internal table stage named TBL_EMPLOYEE to a local window directory or folder on a client machine in a folder named folder with space within the C drive?,multiple-choice,A. GET @%TBL_EMPLOYEE 'file://C:\folder with space\';,B. GET @%TBL_EMPLOYEE 'file://C:/folder with space/';,C. PUT 'file://C:\folder with space\*' @%TBL_EMPLOYEE;,D. PUT 'file://C:/folder with space/*' @%TBL_EMPLOYEE;,,,,,,,,,,,,2,"I think is A, because windows file system use back slash
https://docs.snowflake.com/en/sql-reference/sql/get#required-parameters",
How can the COPY command be used to unload data from a table to an internal stage?,multi-select,A. COPY INTO [location],B. COPY INTO [table],C. COPY INTO [location] with single-true,D. COPY INTO S3://[bucket],,,,,,,,,,,,"1, 2","A and B
Sorry it A and B, internal stage is not in S3
https://www.bing.com/search?q=How+can+the+COPY+command+be+used+to+unload+data+from+a+table+to+an+internal+stage%3F&form=ANNH01&refig=949856b1a071499f93c3a7dd636c1c60",
How does a Snowflake stored procedure compare to a User-Defined Function (UDF)?,multiple-choice,"A. A single executable statement can call only two stored procedures. In contrast, a single SQL statement can call multiple UDFs.","B. A single executable statement can call only one stored procedure. In contrast, a single SQL statement can call multiple UDFs.","C. A single executable statement can call multiple stored procedures. In contrast, multiple SQL statements can call the same UDFs.","D. Multiple executable statements can call more than one stored procedure. In contrast, a single SQL statement can call multiple UDFs.",,,,,,,,,,,,2,"Multiple UDFs may be called with one statement;  A single stored procedure is called with one statement A single SQL statement can call multiple UDFs. A single SQL statement can call only one stored procedure.
https://docs.snowflake.com/en/developer-guide/stored-procedures-vs-udfs Multiple UDFs May Be Called With One Statement; a Single Stored Procedure Is Called With One Statement
https://alexandersks.medium.com/difference-between-stored-procedures-and-udfs-snowflake-9e5b93cdb081
It is true that a single executable statement can call multiple UDFs, but it is also possible to call multiple stored procedures in a single executable statement, as long as they are called in separate statements. CALL proc1(); CALL proc2(); so i think it can be option C",
Which command should be used to unload all the rows from a table into one or more files in a named stage?,multiple-choice,A. COPY INTO,B. GET,C. INSERT INTO,D. PUT,,,,,,,,,,,,1,"A: Unload from Table to Named Stage : https://docs.snowflake.com/en/user-guide/data-unload-overview.
The correct answer is A - The COPY INTO command is used to unload all the rows from a table into one or more files in a named stage in Snowflake.",
Which command is used to unload data from a table or move a query result to a stage?,multiple-choice,A. COPY INTO,B. GET,C. MERGE,D. PUT,,,,,,,,,,,,1,"The COPY INTO command is used to unload all the rows from a table into one or more files in a named stage in Snowflake.
A is Correct",
What privileges are necessary for a consumer in the Data Exchange to make a request and receive data? (Choose two.),multi-select,A. CREATE DATABASE,B. IMPORT SHARE,C. OWNERSHIP,D. REFERENCE_USAGE,E. USAGE,,,,,,,,,,,"1, 2","https://other-docs.snowflake.com/en/collaboration/consumer-becoming Set Up Required Privileges  To access a listing, you must use the ACCOUNTADMIN role or another role with the CREATE DATABASE and IMPORT SHARE privileges. To pay for a paid listing, your role must also have the PURCHASE DATA EXCHANGE LISTING privilege.
https://www.bing.com/search?q=which+snowflake+privileges+are+necessary+for+a+consumer+in+the+Data+Exchange+to+make+a+request+and+receive+data%3F&qs=n&form=QBRE&sp=-1&lq=1&pq=whichsnowflake+privileges+are+necessary+for+a+consumer+in+the+data+exchange+to+make+a+request+and+receive+data%3F&sc=1-111&sk=&cvid=FBC0C5B232194B11B0B3FA4FA5693759&ghsh=0&ghacc=0&ghpl=",
What are benefits of using Snowpark with Snowflake? (Choose two.),multi-select,A. Snowpark uses a Spark engine to generate optimized SQL query plans.,B. Snowpark automatically sets up Spark within Snowflake virtual warehouses.,C. Snowpark does not require that a separate cluster be running outside of Snowflake.,D. Snowpark allows users to run existing Spark code on virtual warehouses without the need to reconfigure the code.,E. Snowpark executes as much work as possible in the source databases for all operations including User-Defined Functions (UDFs).,,,,,,,,,,,"3, 5","https://docs.snowflake.com/en/developer-guide/snowpark/index Support for pushdown for all operations, including Snowflake UDFs. This means Snowpark pushes down all data transformation and heavy lifting to the Snowflake data cloud, enabling you to efficiently work with data of any size.  No requirement for a separate cluster outside of Snowflake for computations. All of the computations are done within Snowflake. Scale and compute management are handled by Snowflake.
https://www.snowflake.com/en/data-cloud/snowpark/spark-to-snowpark/ https://www.snowflake.com/en/data-cloud/snowpark/ https://docs.snowflake.com/en/developer-guide/snowpark/index https://medium.com/snowflake/pyspark-versus-snowpark-for-ml-in-terms-of-mindset-and-approach-8be4bdafa547#:~:text=Snowpark%20pushes%20all%20of%20its,leverage%20the%20power%20of%20Snowflake. https://www.snowflake.com/blog/snowpark-designing-performant-processing-python-java-scala/ https://docs.snowflake.com/en/user-guide/warehouses-snowpark-optimized
https://docs.snowflake.com/en/developer-guide/snowpark/index  Benefits When Compared with the Spark Connector  In comparison to using the Snowflake Connector for Spark, developing with Snowpark includes the following benefits:   Support for interacting with data within Snowflake using libraries and patterns purpose built for different languages without compromising on performance or functionality.   Support for authoring Snowpark code using local tools such as Jupyter, VS Code, or IntelliJ.   Support for pushdown for all operations, including Snowflake UDFs. This means Snowpark pushes down all data transformation and heavy lifting to the Snowflake data cloud, enabling you to efficiently work with data of any size.   No requirement for a separate cluster outside of Snowflake for computations. All of the computations are done within Snowflake. Scale and compute management are handled by Snowflake.",
What are Snowflake best practices when assigning the ACCOUNTADMIN role to users? (Choose two.),multi-select,A. The ACCOUNTADMIN role should be assigned to at least two users.,B. The ACCOUNTADMIN role should be used to create Snowflake objects.,C. The ACCOUNTADMIN role should be used for running automated scripts.,D. The ACCOUNTADMIN role should be given to any user who needs a high level of authority.,E. All users assigned the ACCOUNTADMIN role should use Multi-Factor Authentication (MFA).,,,,,,,,,,,"1, 5","A and E
Sysadmin should be given to 2 users. Account Admin should have highest authority an MFA as per best practices",
What is a recommended approach for optimizing query performance in Snowflake?,multiple-choice,A. Use subqueries whenever possible.,B. Use a large number of joins to combine data from multiple tables.,"C. Select all columns from tables, even if they are not needed in the query.",D. Use a smaller number of larger tables rather than a larger number of smaller tables.,,,,,,,,,,,,4,"D this time
D is the correct answer. Snowflake makes use of clustering on tables. Users can utilize cluster key to enhance query performance (partition pruning) on large tables. Lesser the number of joins between several tables = better performance in general.
The correct answer is D. Use a smaller number of larger tables rather than a larger number of smaller tables.  Here are some of the reasons why using a smaller number of larger tables can improve query performance in Snowflake:  Reduced data movement: When you join multiple tables, Snowflake needs to move data between the tables. This can be a bottleneck, especially if the tables are large. Using a smaller number of larger tables can reduce the amount of data that needs to be moved, which can improve performance. Improved caching: Snowflake caches data in memory. When you use a smaller number of larger tables, the data is more likely to be cached in memory, which can also improve performance. Simplified query planning: Snowflake's query planner is more efficient when it has to plan queries for a smaller number of tables. This can also improve performance.",
"When using SnowSQL, which configuration options are required when unloading data from a SQL query run on a local machine? (Choose two.)",multi-select,A. echo,B. quiet,C. output_file,D. output_format,E. force_put_overwrite,,,,,,,,,,,"3, 4","https://docs.snowflake.com/en/user-guide/snowsql-use#exporting-data. Quiet is also correct, but this is optional. Not a REQUIRED parameter.
Looks like a good choice",
Which Snowflake view is used to support compliance auditing?,multiple-choice,A. ACCESS_HISTORY,B. COPY_HISTORY,C. QUERY_HISTORY,D. ROW_ACCESS_POLICIES,,,,,,,,,,,,1,"The ""ACCESS_HISTORY"" view in Snowflake is primarily used to support compliance auditing. This view contains information about historical access and usage patterns related to tables and views within your Snowflake account. It provides details on who accessed the data, when, and from which IP addresses, among other audit-related information.
https://docs.snowflake.com/en/user-guide/access-history",
How can a Snowflake user load duplicate files with a COPY INTO command?,multiple-choice,A. The COPY INTO options should be set to PURGE = FALSE,B. The COPY INTO options should be set to FORCE = TRUE,C. The COPY INTO options should be set to RETURN_FAILED_ONLY = FALSE,D. The COPY INTO options should be set to ON_ERROR = CONTINUE,,,,,,,,,,,,2,"B is correct
B is correct.
https://docs.snowflake.com/en/sql-reference/sql/copy-into-table FORCE = TRUE | FALSE Definition Boolean that specifies to load all files, regardless of whether they’ve been loaded previously and have not changed since they were loaded. Note that this option reloads files, potentially duplicating data in a table.",
Which statement describes Snowflake tables?,multiple-choice,A. Snowflake tables are logical representations of underlying physical data.,B. Snowflake tables are the physical instantiation of data loaded into Snowflake.,C. Snowflake tables require that clustering keys be defined to perform optimally.,D. Snowflake tables are owned by a user.,,,,,,,,,,,,1,"It's A
A: Micropartition is physical representation of data",
Which type of charts are supported by Snowsight? (Choose two.),multi-select,A. Flowcharts,B. Gantt charts,C. Line charts,D. Pie charts S3,E. Scatterplots,,,,,,,,,,,"3, 5","76. Snow sight supports the following types of charts: • Bar charts • Line charts • Scatterplots • Heat grids • Scorecards
Visualizing worksheet data This topic describes how to visualize your SQL worksheet results using charts in Snowsight. Charts transform your query results into visualizations that communicate logical relationships and lead to more informed decision making. Charts let you quickly identify and understand patterns and outliers in data.  Snowsight supports the following types of charts:  Bar charts  Line charts  Scatterplots  Heat grids  Scorecards  You can also visualize your data using dashboards.",
"A user wants to upload a file to an internal Snowflake stage using a PUT command.

Which tools and/or connectors could be used to execute this command? (Choose two.)",multi-select,A. SnowCD,B. SnowSQL,C. SQL API,D. Python connector,E. Snowsight worksheets,,,,,,,,,,,"2, 4","https://docs.snowflake.com/en/developer-guide/sql-api/intro#label-sql-api-limitations: The following commands are not supported:  The PUT command (in Snowflake SQL)  The GET command (in Snowflake SQL) https://docs.snowflake.com/en/sql-reference/sql/put: The command cannot be executed from the Worksheets Worksheet tab page in either Snowflake web interface; instead, use the SnowSQL client or Drivers to upload data files, or check the documentation for a specific Snowflake client to verify support for this command.
The SQL API is a programmatic interface for connecting to Snowflake. It is the most powerful way to execute SQL commands in Snowflake.(The Python connector is a library that allows you to connect to Snowflake from Python. It can be used to execute SQL commands, but it is not as well-supported as SnowSQL or the SQL API.)  Therefore, the two tools that can be used to execute the command are SnowSQL and the SQL API.",
"Which Snowflake table is an implicit object layered on a stage, where the stage can be either internal or external?",multiple-choice,A. Directory table,B. Temporary table,C. Transient table,D. A table with a materialized view,,,,,,,,,,,,1,https://www.bing.com/search?q=Which+Snowflake+table+is+an+implicit+object+layered+on+a+stage%2C+where+the+stage+can+be+either+internal+or+external%3F&aqs=edge..69i57j69i11004&FORM=ANCMS9&PC=U531,
What is a characteristic of the maintenance of a materialized view?,multiple-choice,A. Materialized views cannot be refreshed automatically.,B. An additional set of scripts is needed to refresh data in materialized views.,C. A materialized view is automatically refreshed by a Snowflake managed warehouse.,D. A materialized view can be set up with the auto-refresh feature using the SQL SET command.,,,,,,,,,,,,3,"answer is C
C: Materialized views are automatically and transparently maintained by Snowflake. A background service updates the materialized view after changes are made to the base table. This is more efficient and less error-prone than manually maintaining the equivalent of a materialized view at the application level. Materialized views are designed to improve query performance for workloads composed of common, repeated query patterns. However, materializing intermediate results incurs additional costs. As such, before creating any materialized views, you should consider whether the costs are offset by the savings from re-using these results frequently enough.",
Which command should be used to implement a masking policy that was already created in Snowflake?,multiple-choice,A. ALTER MASKING POLICY,B. APPLY MASKING POLICY,C. CREATE MASKING POLICY,D. SET MASKING POLICY,,,,,,,,,,,,4,"ALTER MASKING POLICY  ENTERPRISE EDITION FEATURE  This feature requires Enterprise Edition (or higher). To inquire about upgrading, please contact Snowflake Support. Replaces the existing masking policy rules with new rules or a new comment and allows the renaming of a masking policy.  Any changes made to the policy rules go into effect when the next SQL query that uses the masking policy runs.  See also: Masking policy DDL  Syntax  ALTER MASKING POLICY [ IF EXISTS ] <name> RENAME TO <new_name>  ALTER MASKING POLICY [ IF EXISTS ] <name> SET BODY -> <expression_on_arg_name_to_mask>  ALTER MASKING POLICY [ IF EXISTS ] <name> SET TAG <tag_name> = '<tag_value>' [ , <tag_name> = '<tag_value>' ... ]  ALTER MASKING POLICY [ IF EXISTS ] <name> UNSET TAG <tag_name> [ , <tag_name> ... ]
D. modify column SET MASKING POLICY. APPLY MASKING is privilege that should grant to role to apply the masking policy
-- apply masking policy to a table column  ALTER TABLE IF EXISTS user_info MODIFY COLUMN email SET MASKING POLICY email_mask;  -- apply the masking policy to a view column  ALTER VIEW user_info_v MODIFY COLUMN email SET MASKING POLICY email_mask; https://docs.snowflake.com/en/user-guide/security-column-ddm-use
https://community.snowflake.com/s/article/Privilege-Updates-APPLY-MASKING-POLICY-APPLY-ROW-ACCESS-POLICY-Allow-DESCRIBE-object-Operation-on-Tables-and-Views-Only-2021-07-xx-Pending",
Which statement accurately describes a characteristic of a materialized view?,multiple-choice,A. A materialized view can query only a single table.,B. Data accessed through materialized views can be stale.,C. Materialized view refreshes need to be maintained by the user.,D. Querying a materialized view is slower than executing a query against the base table of the view.,,,,,,,,,,,,1,"A- Can query only a single table No join, no multiple tables, no aggregations , auto-refreshed
Can query only a single table
https://docs.snowflake.com/en/user-guide/views-materialized#label-limitations-on-creating-materialized-views",
"A user wants to unload data from a relational table into a CSV file in an external stage. The table must be named exactly as specified by the user.

Which file format option MUST be used to do this?",multiple-choice,A. encoding,B. escape,C. file_extension,D. single,,,,,,,,,,,,3,"FILE_EXTENSION = 'string' | NONE String that specifies the extension for files unloaded to a stage. Accepts any extension. The user is responsible for specifying a valid file extension that can be read by the desired software or service.  Note If the SINGLE copy option is TRUE, then the COPY command unloads a file without a file extension by default. To specify a file extension, provide a file name and extension in the internal_location or external_location path. For example:  copy into @stage/data.csv ...
C. file_extension  The file_extension option must be used to specify the exact name of the file when unloading data from a relational table into a CSV file in an external stage.
It's either C or D. The question asks: ""which file format option..."".   D SINGLE is not about file format option. It's a parameter for COPY INTO <location>.  Also is the question asking about the table name? or a file name? It sounds like it's about the file name, but the question says ""table name"", which is confusing.   I'd vote D, but I'm not 100% sure.   https://docs.snowflake.com/en/sql-reference/sql/copy-into-location https://docs.snowflake.com/en/sql-reference/sql/create-file-format",
Which account usage view in Snowflake can be used to identify the most-frequently accessed tables?,multiple-choice,A. Access_History,B. Object_Dependencies,C. Table_Storage_Metrics,D. Tables,,,,,,,,,,,,1,"A. Access_History  The ACCESS_HISTORY view in Snowflake provides detailed information about user access to data, including which queries accessed specific tables and columns. This makes it useful for identifying the most-frequently accessed tables.
The ""Access_History"" view in Snowflake can be used to identify the most frequently accessed tables. This view contains information about the historical access patterns for tables and views in your Snowflake account, including details on queries, users, and access frequency. By querying this view, you can analyze which tables are being accessed most frequently in your Snowflake environment.",
What metadata does Snowflake store concerning all rows stored in a micro-partition? (Choose two.),multi-select,A. A count of the number of total values in the micro-partition,B. The range of values for each partition in the micro-partition,C. The range of values for each of the rows in the micro-partition,D. The range of values for each of the columns in the micro-partition,E. The number of distinct values for each column in the micro-partition,,,,,,,,,,,"4, 5","DE, according to the doc https://docs.snowflake.com/en/user-guide/tables-clustering-micropartitions Snowflake stores metadata about all rows stored in a micro-partition, including: The range of values for each of the columns in the micro-partition. The number of distinct values. Additional properties used for both optimization and efficient query processing.  AD according to my testing I ran the following queries. Only COUNT (DISTINCT) used the warehouse. Scanned only 1 partition. This contradicts the documentation> select min(cc_call_center_sk) from snowflake_sample_data.tpcds_sf100tcl.call_center; select max(cc_call_center_sk) from snowflake_sample_data.tpcds_sf100tcl.call_center; select count(distinct cc_call_center_sk) from snowflake_sample_data.tpcds_sf100tcl.call_center; select count(*) from snowflake_sample_data.tpcds_sf100tcl.call_center;  Also see related Q157
correct answer. https://docs.snowflake.com/en/user-guide/tables-clustering-micropartitions",
What role has the privileges to create and manage data shares by default?,multiple-choice,A. ACCOUNTADMIN,B. SECURITYADMIN,C. SYSADMIN,D. USERADMIN,,,,,,,,,,,,1,"A is correct
A is correct",
Which function determines the kind of value stored in a VARIANT column?,multiple-choice,A. CHECK_JSON,B. IS_ARRAY,C. IS_JSON,D. TYPEOF,,,,,,,,,,,,4,"Typeof returns the type of a value stored in a VARIANT column
Reports the type of a value stored in a VARIANT column. The type is returned as a string.   https://docs.snowflake.com/en/sql-reference/functions/typeof",
What operation can be performed using Time Travel?,multiple-choice,A. Restoring tables that have been dropped from a data share,B. Extending a permanent table’s retention duration from 90 to 100 days,C. Creating a clone of an entire table at a specific point in the past from a permanent table,D. Disabling Time Travel for a specific object by setting DATA_RETENTION_TIME_IN_DAYS to NULL,,,,,,,,,,,,3,"Time Travel in Snowflake allows you to create a clone of a table at a specific point in the past, which is useful for recovering data or analyzing historical data.
https://docs.snowflake.com/en/user-guide/data-time-travel
Using Time Travel, you can perform the following actions within a defined period of time:  Query data in the past that has since been updated or deleted.  Create clones of entire tables, schemas, and databases at or before specific points in the past.  Restore tables, schemas, and databases that have been dropped.",
What does the VARIANT data type impose a 16 MB size limit on?,multiple-choice,A. All rows,B. All columns,C. Individual rows,D. Individual columns,,,,,,,,,,,,3,"correct
Correct C - The VARIANT data type imposes a 16 MB size limit on individual rows.  https://docs.snowflake.com/en/user-guide/semistructured-considerations",
Which activities are included in the Cloud Services layer? (Choose two.),multi-select,A. Data storage,B. Dynamic data masking,C. Partition scanning,D. User authentication,E. Infrastructure management,,,,,,,,,,,"4, 5","correct answer D&E
what about B, masking policy?
The Cloud Services layer in Snowflake is responsible for critical data-related activities1. Services managed in this layer include:   Authentication  Infrastructure management  Metadata management  Query parsing and optimization  Access control",
What does the “percentage scanned from cache” represent in the Query Profile?,multiple-choice,A. The percentage of data scanned from the query cache,B. The percentage of data scanned from the result cache,C. The percentage of data scanned from the remote disk cache,D. The percentage of data scanned from the local disk cache,,,,,,,,,,,,4,"D Percentage scanned from cache — the percentage of data scanned from the local disk cache. https://docs.snowflake.com/en/user-guide/ui-query-profile  Result cache looks differently: it would just say ""QUERY RESULT REUSE""
No, it's D  Percentage scanned from cache — the percentage of data scanned from the local disk cache.  https://docs.snowflake.com/en/user-guide/ui-query-profile",
Which role has the ability to create a share from a shared database by default?,multiple-choice,A. ACCOUNTADMIN,B. SECURITYADMIN,C. SYSADMIN,D. ORGADMIN,,,,,,,,,,,,1,"correct
Correct A - By default, the ACCOUNTADMIN role is required to create and manage shares",
Which object-level parameters can be set to help control query processing and concurrency? (Choose two).,multi-select,A. MAX_CONCURRENCY_LEVEL,B. DATA_RETENTION_TIME_IN_DAYS,C. MIN_DATA_RETENTION_TIME_IN_DAYS,D. STATEMENT_TIMEOUT_IN_SECONDS,E. STATEMENT_QUEUED_TIMEOUT_IN_SECONDS,,,,,,,,,,,"4, 5","D correct - Snowflake provides some object-level parameters that can be set to help control query processing and concurrency:   STATEMENT_QUEUED_TIMEOUT_IN_SECONDS   STATEMENT_TIMEOUT_IN_SECONDS  https://docs.snowflake.com/en/user-guide/warehouses-overview
Statements A and E are correct: https://docs.snowflake.com/en/sql-reference/parameters#statement-queued-timeout-in-seconds STATEMENT_QUEUED_TIMEOUT_IN_SECONDS Amount of time, in seconds, a SQL statement (query, DDL, DML, etc.) remains queued for a warehouse before it is canceled by the system. This parameter can be used in conjunction with the MAX_CONCURRENCY_LEVEL parameter to ensure a warehouse is never backlogged.",
What metadata does Snowflake store for rows in micro-partitions? (Choose two.),multi-select,A. Range of values,B. Distinct values,C. Index values,D. Sorted values,E. Null values,,,,,,,,,,,"1, 2","correct
AB correct",
What are valid sub-clauses to the OVER clause for a window function? (Choose two.),multi-select,A. GROUP BY,B. LIMIT,C. ORDER BY,D. PARTITION BY,E. UNION ALL,,,,,,,,,,,"3, 4","SELECT menu_category, menu_price_usd, menu_cogs_usd,  AVG(menu_cogs_usd) OVER(PARTITION BY menu_category ORDER BY menu_price_usd ROWS BETWEEN CURRENT ROW and 2 FOLLOWING) avg_cogs  FROM menu_items  ORDER BY menu_category, menu_price_usd;
Similarly to standard SQL syntax - C and D
CD correct - syntax <function> ([ <arguments> ]) OVER ([ PARTITION BY <expr1> ] [ ORDER BY <expr2> ])",
Which kind of Snowflake table stores file-level metadata for each file in a stage?,multiple-choice,A. Directory,B. External,C. Temporary,D. Transient,,,,,,,,,,,,1,Correct A - The kind of Snowflake table that stores file-level metadata for each file in a stage is called a directory table  https://docs.snowflake.com/en/user-guide/data-load-dirtables,
Which privileges apply to stored procedures? (Choose two.),multi-select,A. MODIFY,B. MONITOR,C. OPERATE,D. OWNERSHIP,E. USAGE,,,,,,,,,,,"4, 5","Privileges on Stored Procedures Similar to other database objects (tables, views, UDFs, etc.), stored procedures are owned by a role and have one or more privileges that can be granted to other roles.  Currently, the following privileges apply to stored procedures:  USAGE  OWNERSHIP  For a role to use a stored procedure, the role must either be the owner or have been granted USAGE privilege on the stored procedure.
USAGE  Enables calling a stored procedure.  ALL [ PRIVILEGES ]  Grants all privileges, except OWNERSHIP, on the stored procedure.  OWNERSHIP  Grants full control over the stored procedure; required to alter the stored procedure. Only a single role can hold this privilege on a specific object at a time. Note that in a managed access schema, only the schema owner (i.e. the role with the OWNERSHIP privilege on the schema) or a role with the MANAGE GRANTS privilege can grant or revoke privileges on objects in the schema, including future grants.",
What column type does a Kafka connector store formatted information in a single column?,multiple-choice,A. ARRAY,B. OBJECT,C. VARCHAR,D. VARIANT,,,,,,,,,,,,4,"correct
D correct  https://docs.snowflake.com/en/user-guide/kafka-connector-overview",
"If a size Small virtual warehouse costs two credits per hour, what is the credit cost per hour of a size Large virtual warehouse?",multiple-choice,A. 4,B. 8,C. 16,D. 32,,,,,,,,,,,,2,B. correct small = 2 m = 4 l = 8,
Which SQL command will list the files in a named stage?,multiple-choice,A. list @~;,B. get @%mytable;,C. list @my_stage;,D. get @my_stage;,,,,,,,,,,,,3,"correct C   To list files that have been uploaded to a Snowflake stage, you can use the LIST command  C correct - @~ is used only when you shortcut even list command, so ""ls @~"" should work as well",
What is the effect of configuring a virtual warehouse auto-suspend value to ‘0’?,multiple-choice,A. The warehouse will never suspend.,B. The warehouse will suspend immediately upon work completion.,C. The warehouse will not resume automatically.,D. All clusters in the multi-cluster warehouse will resume immediately.,,,,,,,,,,,,1,"https://docs.snowflake.com/en/sql-reference/sql/alter-warehouse#AUTO_SUSPEND Check AUTO_SUSPEND section.
A correct - Valid values   Any integer 0 or greater, or NULL:   Setting a value less than 60 is allowed, but might not result in the desired/expected behavior because the background process that suspends a warehouse runs approximately every 60 seconds and, therefore, is not intended for enabling exact control over warehouse suspension.   Setting a 0 or NULL value means the warehouse never suspends.",
Which data types can be used in Snowflake to store semi-structured data? (Choose two.),multi-select,A. ARRAY,B. BLOB,C. CLOB,D. JSON,E. VARIANT,,,,,,,,,,,"1, 5","AE  https://docs.snowflake.com/en/sql-reference/data-types-semistructured
JSON is file type, not Data type",
"While attempting to avoid data duplication, which COPY INTO [location] option should be used to load files with expired load metadata?",multiple-choice,A. LOAD_UNCERTAIN_FILES,B. FORCE,C. VALIDATION_MODE,D. LAST_MODIFIED,,,,,,,,,,,,1,"To load files whose metadata has expired, set the LOAD_UNCERTAIN_FILES copy option to true. The copy option references load metadata, if available, to avoid data duplication, but also attempts to load files with expired load metadata.
sorry, found it https://docs.snowflake.com/en/user-guide/data-load-considerations-load A correct",
What service is provided as an integrated Snowflake feature to enhance Multi-Factor Authentication (MFA) support?,multiple-choice,A. Duo Security,B. OAuth,C. Okta,D. Single Sign-On (SSO),,,,,,,,,,,,1,"A is correct
A correct - MFA provides increased login security for users connecting to Snowflake. MFA support is provided as an integrated Snowflake feature, powered by the Duo Security service, which is managed completely by Snowflake.  https://docs.snowflake.com/en/user-guide/ui-snowsight-profile",
What is the impact on queries that are being executed when a resource monitor set to the “Notify &amp; Suspend” threshold level is exceeded?,multiple-choice,A. All statements being executed are queued.,B. All statements being executed are restarted.,C. All statements being executed are cancelled.,D. All statements being executed are completed.,,,,,,,,,,,,4,"D is correct  Reference: https://docs.snowflake.com/en/user-guide/resource-monitors
correct
D correct - Notify & Suspend   Send a notification (to all account administrators with notifications enabled) and suspend all assigned warehouses after all statements being executed by the warehouse(s) have completed. Notify & Suspend Immediately   Send a notification (to all account administrators with notifications enabled) and suspend all assigned warehouses immediately, which cancels any statements being executed by the warehouses at the time.
Correct answer is D https://docs.snowflake.com/en/user-guide/resource-monitors Notify Notify&Suspend Notify and suspend immediately where the running queries are cancelled",
What tasks can an account administrator perform in the Data Exchange? (Choose two.),multi-select,A. Add and remove members.,B. Delete data categories.,C. Approve and deny listing approval requests.,D. Transfer listing ownership.,E. Transfer ownership of a provider profile.,,,,,,,,,,,"1, 3","AC correct  By default, only an account administrator (a user with the ACCOUNTADMIN role) in the Data Exchange administrator account can manage a Data Exchange, which includes the following tasks: Add or remove members. Approve or deny listing approval requests. Approve or deny provider profile approval requests.  docs.snowflake.com/en/user-guide/data-exchange-marketplace-privileges",
Which types of subqueries does Snowflake support? (Choose two.),multi-select,A. Uncorrelated scalar subqueries in WHERE clauses,B. Uncorrelated scalar subqueries in any place that a value expression can be used,"C. EXISTS, ANY / ALL, and IN subqueries in WHERE clauses: these subqueries can be uncorrelated only","D. EXISTS, ANY / ALL, and IN subqueries in WHERE clauses: these subqueries can be correlated only","E. EXISTS, ANY / ALL, and IN subqueries in WHERE clauses: these subqueries can be correlated or uncorrelated",,,,,,,,,,,"2, 5","correct
BE correct  Snowflake currently supports the following types of subqueries:   Uncorrelated scalar subqueries in any place that a value expression can be used.   Correlated scalar subqueries in WHERE clauses.   EXISTS, ANY / ALL, and IN subqueries in WHERE clauses. These subqueries can be correlated or uncorrelated.  https://docs.snowflake.com/en/user-guide/querying-subqueries
Correct ans BE https://docs.snowflake.com/en/user-guide/querying-subqueries",
How can network and private connectivity security be managed in Snowflake?,multiple-choice,A. By setting up network policies with IPv4 IP addresses,B. By putting the Snowflake URL on the allowed list for get method responses,C. By manually setting up vulnerability patch management policies,D. By manually setting up an Intrusion Prevention System (IPS) on each account,,,,,,,,,,,,1,"Network and private connectivity security in Snowflake can be managed by setting up network policies with IPv4 IP addresses.
correct",
What consideration should be made when loading data into Snowflake?,multiple-choice,A. Create small data files and stage them in cloud storage frequently.,B. Create large data files to maximize the processing overhead for each file.,C. The number of load operations that run in parallel can exceed the number of data files to be loaded.,D. The number of data files that are processed in parallel is determined by the virtual warehouse.,,,,,,,,,,,,4,"Answer: D When loading data into Snowflake, the number of data files processed in parallel is limited by the size and compute capacity of the virtual warehouse being used. Larger warehouses can process more files in parallel, enabling faster data loading.  Why not A? Snowflake recommends moderately sized files (100 MB to 1 GB compressed) to maximize performance and efficiency. Creating very small files leads to high overhead due to metadata management and increases processing time.  Key Snowflake Best Practices for Data Loading:  1. Optimize File Size: Use file sizes between 100 MB and 1 GB (compressed) for efficient parallel loading.   2. Utilize Virtual Warehouse Scaling: Use larger virtual warehouses to increase parallelism and processing capacity.   3. Batch Data: Minimize small file uploads; batch files into recommended sizes before staging.
D The number of data files that can be processed in parallel is determined by the amount of compute resources in a warehouse.  https://docs.snowflake.com/en/user-guide/data-load-considerations-plan",
How can a user improve the performance of a single large complex query in Snowflake?,multiple-choice,A. Scale up the virtual warehouse.,B. Scale out the virtual warehouse.,C. Enable standard warehouse scaling.,D. Enable economy warehouse scaling.,,,,,,,,,,,,1,"We don't have information about Snowflake edition hence multi-cluster options couldn't be available to us
A Scaling up is for improving speed of a single complex query.  Scaling out is for solving concurrency issues (queueing of many queries) Resizing a warehouse generally improves query performance, particularly for larger, more complex queries. It can also help reduce the queuing that occurs if a warehouse does not have enough compute resources to process all the queries that are submitted concurrently. Note that warehouse resizing is not intended for handling concurrency issues; instead, use additional warehouses to handle the workload or use a multi-cluster warehouse (if this feature is available for your account). https://docs.snowflake.com/en/user-guide/warehouses-considerations
A correct - https://dzone.com/articles/snowflake-performance-tuning-top-5-best-practices",
Who can access a referenced file through a scoped URL?,multiple-choice,A. Only the ACCOUNTADMIN,B. Only the user who generates the URL,C. Any role specified in the GET REST API call with sufficient privileges,D. Any user specified in the GET REST API call with sufficient privileges,,,,,,,,,,,,2,"Only the user who generates a scoped URL can use the URL to access the referenced file.
B correct -    Only the user who generated the scoped URL can use the URL to access the referenced file.  https://docs.snowflake.com/en/user-guide/data-load-unstructured-rest-api",
Snowflake will return an error when a user attempts to share which object?,multiple-choice,A. Tables,B. Secure views,C. Standard views,D. Secure materialized views,,,,,,,,,,,,3,"C is correct, please find Snowflake doc link: https://docs.snowflake.com/en/user-guide/data-sharing-provider
C  You can share the following Snowflake database objects:  External tables Dynamic tables Secure views Secure materialized views Secure UDFs Tables  https://docs.snowflake.com/en/user-guide/data-sharing-intro
A correct - For data security and privacy reasons, only secure views are supported in shares at this time. If a standard view is added to a share, Snowflake returns an error  https://docs.snowflake.com/en/user-guide/data-sharing-provider",
"What setting in Snowsight determines the databases, tables, and other objects that can be seen and the actions that can be performed on them?",multiple-choice,A. Active role,B. Masking policy,C. Column-level security,D. Multi-Factor Authentication (MFA),,,,,,,,,,,,1,"Switch your active role: While using Snowsight, you can change the active role in your current session. Your active role determines which pages in Snowsight you can access, as well as which databases, tables, and other objects you can see and the actions you can perform on them.
A correct  https://docs.snowflake.com/en/user-guide/ui-snowsight-gs#:~:text=While%20using%20Snowsight%2C%20you%20can%20change%20the%20active,and%20the%20actions%20you%20can%20perform%20on%20them.",
Why would a Snowflake user decide to use a materialized view instead of a regular view?,multiple-choice,A. The base tables do not change frequently.,B. The results of the view change often.,C. The query is not resource intensive.,D. The query results are not used frequently.,,,,,,,,,,,,1,A correct - https://docs.snowflake.com/en/user-guide/views-materialized,
"When a database is cloned, which objects in the clone inherit all granted privileges from the source object? (Choose two.)",multi-select,A. Account,B. Database,C. Schemas,D. Tables,E. Internal named stages,,,,,,,,,,,"3, 4","If the source object is a database or schema, the clone inherits all granted privileges on the clones of all child objects contained in the source object:  For databases, contained objects include schemas, tables, views, etc.  For schemas, contained objects include tables, views, etc.  Note that the clone of the container itself (database or schema) does not inherit the privileges granted on the source container.  c d
Note that the clone of the container itself (database or schema) does not inherit the privileges granted on the source container.
BC correct - https://docs.snowflake.com/en/user-guide/object-clone",
How does the Access_History view enhance overall data governance pertaining to read and write operations? (Choose two.),multi-select,A. Shows how the accessed data was moved from the source to the target objects,B. Provides a unified picture of what data was accessed and when it was accessed,C. Protects sensitive data from unauthorized access while allowing authorized users to access it at query runtime,D. Identifies columns with personal information and tags them so masking policies can be applied to protect sensitive data,E. Determines whether a given row in a table can be accessed by the user by filtering the data based on a given policy,,,,,,,,,,,"1, 2","The ACCESS_HISTORY view provides a unified picture of what data was accessed, when the data access took place, and how the accessed data moved from the data source object to the data target object. https://docs.snowflake.com/en/user-guide/access-history
DE https://docs.snowflake.com/en/guides-overview-govern",
What does Snowflake recommend a user do if they need to connect to Snowflake with a tool or technology that is not listed in Snowflake’s partner ecosystem?,multiple-choice,A. Use Snowflake’s native API.,B. Use a custom-built connector.,C. Contact Snowflake Support for a new driver.,D. Connect through Snowflake’s JDBC or ODBC drivers.,,,,,,,,,,,,4,"D https://docs.snowflake.com/en/user-guide/ecosystem-all
D correct",
What is the expiration period for a file URL used to access unstructured data in cloud storage?,multiple-choice,A. The remainder of the session,B. An unlimited amount of time,C. The length of time specified in the expiration_time argument,D. The same length of time as the expiration period for the query results cache,,,,,,,,,,,,2,"Its says FILE URL. Only the Scope and Presigned will expire.
correction to B - https://docs.snowflake.com/en/user-guide/unstructured-intro",
Which applications can use key pair authentication? (Choose two).,multi-select,A. Snowflake Marketplace,B. SnowCD,C. Snowsight,D. SnowSQL,E. Snowflake connector for Python,,,,,,,,,,,"4, 5",DE correct - https://docs.snowflake.com/en/user-guide/key-pair-auth,
Which commands can only be executed using SnowSQL? (Choose two.),multi-select,A. COPY INTO,B. GET,C. LIST,D. PUT,E. REMOVE,,,,,,,,,,,"2, 4",Answer is B and D,
"A user has enabled the STRIP_OUTER_ARRAY file format option for the COPY INTO {table} command to remove the outer array structure.

What else will this format option and command do?",multiple-choice,A. Load the records into separate table rows.,B. Unload the records from separate table rows.,C. Export data files in smaller chunks.,D. Ensure each unique element stores values of a single native data type.,,,,,,,,,,,,1,"A. Load the records into separate table rows.  When the STRIP_OUTER_ARRAY file format option is enabled for the COPY INTO {table} command, it removes the outer array structure and loads the records into separate table rows.
correct
A correct - https://interworks.com/blog/chastie/2020/01/28/zero-to-snowflake-loading-and-querying-semi-structured-json-data/",
Which objects will incur storage costs associated with Fail-safe?,multiple-choice,A. External tables,B. Permanent tables,C. Data files available in internal stages,D. Data files available in external stages,,,,,,,,,,,,2,"B correct - https://docs.snowflake.com/en/user-guide/cost-understanding-data-storage#:~:text=Files%20staged%20for%20bulk%20data%20loading%2Funloading%20%28stored%20compressed,deleted%20in%20the%20table%20that%20owns%20the%20clones.",
What technique does Snowflake use to limit the number of micro-partitions scanned by each query?,multiple-choice,A. B-tree,B. Indexing,C. Map reduce,D. Pruning,,,,,,,,,,,,4,D correct - https://docs.snowflake.com/en/user-guide/tables-clustering-micropartitions,
What activities can a user with the ORGADMIN role perform? (Choose two.),multi-select,A. Create INFORMATION_SCHEMA in a database.,B. View usage information for all accounts in the organization.,C. Enable database cloning for an account in the organization.,D. Enable database replication for an account in the organization.,E. View micro-partition information for all accounts in the organization.,,,,,,,,,,,"2, 4","View usage information for all accounts in the organization Enable database replication for an account in the organization.
correct
BD correct - https://docs.snowflake.com/en/user-guide/organizations",
"In a managed access schema, who can grant privileges on objects in the schema to other roles? (Choose two.)",multi-select,A. The schema owner role,B. The ORGADMIN system role,C. The USERADMIN system role,D. The role with the MANAGE GRANTS privilege,E. The role that owns the object in the schema,,,,,,,,,,,"1, 4","AD correct
AD correct - https://docs.snowflake.com/en/user-guide/security-access-control-overview#:~:text=In%20a%20regular%20schema%2C%20the%20owner%20role%20has,owners%20lose%20the%20ability%20to%20make%20grant%20decisions.",
What are the recommended steps to address poor SQL query performance due to data spilling? (Choose two.),multi-select,A. Clone the base table.,B. Fetch required attributes only.,C. Use a larger virtual warehouse.,D. Process the data in smaller batches.,E. Add another cluster in the virtual warehouse.,,,,,,,,,,,"3, 4","performance problem scale up
Answer is C and D https://docs.snowflake.com/en/user-guide/ui-query-profile For some operations (e.g. duplicate elimination for a huge data set), the amount of memory available for the compute resources used to execute the operation might not be sufficient to hold intermediate results. As a result, the query processing engine will start spilling the data to local disk. If the local disk space is not sufficient, the spilled data is then saved to remote disks.  This spilling can have a profound effect on query performance (especially if remote disk is used for spilling). To alleviate this, we recommend:  Using a larger warehouse (effectively increasing the available memory/local disk space for the operation), and/or  Processing data in smaller batches.
CD correct  https://community.snowflake.com/s/article/Performance-impact-from-local-and-remote-disk-spilling",
"A Snowflake user wants to share unstructured data through the use of secure views.

Which URL types can be used? (Choose two.)",multi-select,A. Scoped URL,B. HTTPS URL,C. Cloud storage URL,D. File URL,E. Pre-signed URL,,,,,,,,,,,"1, 5",AE correct   https://docs.snowflake.com/en/user-guide/unstructured-data-sharing,
What are characteristics of reader accounts in Snowflake? (Choose two.),multi-select,A. Reader account users cannot add new data to the account.,B. Reader account users can share data to other reader accounts.,C. A single reader account can consume data from multiple provider accounts.,D. Data consumers are responsible for reader account setup and data usage costs.,E. Reader accounts enable data consumers to access and query data shared by the provider.,,,,,,,,,,,"1, 5","correct
AE correct - https://docs.snowflake.com/en/user-guide/data-sharing-reader-create
CE. reader account can add new data if has own account or using separate account",
Why should a Snowflake user configure a secure view? (Choose two.),multi-select,A. To encrypt the data in transit,B. To execute faster than a standard view,C. To protect hidden data from other users,D. To improve the performance of a query,E. To hide the view definition from other users,,,,,,,,,,,"3, 5","CE Some of the internal optimizations for views require access to the underlying data in the base tables for the view. This access might allow data that is hidden from users of the view to be exposed through user code, such as user-defined functions, or other programmatic methods. Secure views do not utilize these optimizations, ensuring that users have no access to the underlying data.  For security or privacy reasons, you might not wish to expose the underlying tables or internal structural details for a view. With secure views, the view definition and details are visible only to authorized users (i.e. users who are granted the role that owns the view).",
Which activities are managed by Snowflake’s Cloud Services layer? (Choose two.),multi-select,A. Authentication,B. Access delegation,C. Data pruning,D. Data compression,E. Query parsing and optimization,,,,,,,,,,,"1, 5",AE correct,
The COPY INTO [location] command can unload data from a table directly into which locations? (Choose two.),multi-select,A. A named internal stage,B. A Snowpipe REST endpoint,C. A network share on a client machine,D. A local directory or folder on a client machine,E. A named external stage that references an external cloud location,,,,,,,,,,,"1, 5","AE is correct  Copy into is possible for  1) Named internal stage (or table/user stage).  2) Named external stage that references an external location (Amazon S3, Google Cloud Storage, or Microsoft Azure). 3) External location https://docs.snowflake.com/en/sql-reference/sql/copy-into-location
AE correct - https://docs.snowflake.com/en/sql-reference/sql/copy-into-location",
What does the Activity area of Snowsight allow users to do? (Choose two.),multi-select,A. Schedule automated data backups.,B. Explore each step of an executed query.,C. Monitor queries executed by users in an account.,D. Create and manage user roles and permissions.,E. Access Snowflake Marketplace to find and integrate datasets.,,,,,,,,,,,"2, 3","BC correct. No longer called Activity, called Monitoring now
BC is correct.  The keyword is activity area!  The Activity area of Snowsight, the Snowflake web interface, lets you:  1)Monitor queries executed by users in your account. 2)View details about queries. 3)View performance data. 4)Explore each step of an executed query. 5)Monitor the status of data loading using COPY INTO (bulk loading) and pipes (continuous loading). 6)View details about instances of bulk and continuous data loading. 7)Navigate to the copy history for individual tables. https://docs.snowflake.com/en/user-guide/ui-snowsight-activity
BC correct   https://docs.snowflake.com/en/user-guide/ui-snowsight-activity https://docs.snowflake.com/en/user-guide/ui-snowsight-quick-tour",
"In which Snowsight section can a user switch roles, modify their profile, and access documentation?",multiple-choice,A. The user menu,B. The activity page,C. The content pane,D. The worksheets page,,,,,,,,,,,,1,"None of them. Account Menu as of 2024-02-14 https://docs.snowflake.com/en/user-guide/ui-snowsight-quick-tour#get-account-information-and-update-your-user-profile-from-the-account-menu
A correct - https://docs.snowflake.com/en/user-guide/ui-snowsight-quick-tour",
What is the recommended way to change the existing file format type in my_format from CSV to JSON?,multiple-choice,A. ALTER FILE FORMAT my_format SET TYPE=JSON;,B. ALTER FILE FORMAT my_format SWAP TYPE WITH JSON;,C. CREATE OR REPLACE FILE FORMAT my_format TYPE=JSON;,D. REPLACE FILE FORMAT my_format TYPE=JSON;,,,,,,,,,,,,3,"C A doesn't work, I tested: --- 803  CREATE FILE FORMAT ET_803 TYPE=CSV;  DESCRIBE FILE FORMAT ET_803;  ALTER FILE FORMAT ET_803 SET TYPE =JSON; ---File format type cannot be changed.  CREATE OR REPLACE FILE FORMAT ET_803 TYPE=JSON;  DESCRIBE FILE FORMAT ET_803;  DROP FILE FORMAT ET_803;
ALTER FILE FORMAT does not support the following actions: - Changing the type (CSV, JSON, etc.) for the file format.  To make any of these changes, you must recreate the file format.
C correct - https://docs.snowflake.com/en/sql-reference/sql/create-file-format",
Which features are included in Snowsight? (Choose two.),multi-select,A. Worksheet sharing,B. Referencing SnowSQL,C. Exploring the Snowflake Marketplace,D. Changing the Snowflake account cloud provider,E. Downloading query result data larger than 100 MB,,,,,,,,,,,"1, 3","AC are for sure possible. E is also possible https://docs.snowflake.com/en/user-guide/ui-snowsight-query To download your query results as a CSV-formatted or TSV-formatted file, select Download results.  The size of your file depends on the amount of data returned by your query. Snowflake does not limit the size of files exported for query results.
AC is correct!
AC correct - https://docs.snowflake.com/en/user-guide/ui-snowsight-quick-tour",
How long can a data consumer who has a pre-signed URL access data files using Snowflake?,multiple-choice,A. Indefinitely,B. Until the result_cache expires,C. Until the retention_time is met,D. Until the expiration_time is exceeded,,,,,,,,,,,,4,"Indefinitely - for file URL Result cache - scoped URL  Pre-signed - ans D
D correct - https://docs.snowflake.com/en/sql-reference/functions/get_presigned_url",
What mechanisms can be used to inform Snowpipe that there are staged files available to load into a Snowflake table? (Choose two.),multi-select,A. Cloud messaging,B. Email integrations,C. Error notifications,D. REST endpoints,E. Snowsight interactions,,,,,,,,,,,"1, 4","answer is AD  as per DOc 1) Automating Snowpipe using cloud messaging 2) Calling Snowpipe REST endpoints
AD correct - https://docs.snowflake.com/en/user-guide/data-load-snowpipe-intro#:~:text=Different%20mechanisms%20for%20detecting%20the%20staged%20files%20are,Snowpipe%20using%20cloud%20messaging%20Calling%20Snowpipe%20REST%20endpoints",
"A Snowflake user needs to import a JSON file larger than 16 MB.

What file format option could be used?",multiple-choice,A. trim_space = true,B. compression = auto,C. strip_outer_array = true,D. strip_outer_array = false,,,,,,,,,,,,3,"C is correct
The correct answer is C.  strip_outer_array = true will remove the outer array structure and copy the file into multiple table rows instead of row. (the limitation for table rows is max 16MB) with this solution it will be fine.  https://docs.snowflake.com/en/user-guide/data-load-considerations-prepare#semi-structured-data-size-limitations
C correct - https://docs.snowflake.com/en/user-guide/data-load-considerations-prepare",
What is a feature of column-level security in Snowflake?,multiple-choice,A. Role access policies,B. Network policies,C. Internal tokenization,D. External tokenization,,,,,,,,,,,,4,"C. Internal tokenization  This feature helps protect sensitive data by replacing it with a token that can only be mapped back to the original data by authorized users or systems.
The correct answer is D. Currently, Column-level Security includes two features:  1)Dynamic Data Masking 2)External Tokenization  https://docs.snowflake.com/user-guide/security-column-intro#what-is-column-level-security
D correct - https://docs.snowflake.com/user-guide/security-column-intro",
Which common query problems can the Query Profile help a user identify and troubleshoot? (Choose two.),multi-select,A. When window functions are used incorrectly,B. When there are exploding joins,C. When there is a UNION without ALL,D. When the SELECT DISTINCT command returns too many values,E. When there are Common Table Expressions (CTEs) without a final SELECT statement,,,,,,,,,,,"2, 3","B - Exploding JOIN well they are almost always bad produces a ton of result records C - UNION without ALL needs extra compute to dedupe the combined results
BC correct - https://www.snowflake.com/blog/new-approaches-visualizing-snowflake-query-statistics/#:~:text=For%20years%2C%20our%20documentation%20has%20helped%20customers%20identify,pruning%20%28most%20often%20evidenced%20by%20large%20table%20scans%29",
What is the Fail-safe retention period for transient and temporary tables?,multiple-choice,A. 0 days,B. 1 day,C. 7 days,D. 90 days,,,,,,,,,,,,1,A correct - https://docs.snowflake.com/en/user-guide/tables-temp-transient,
Which Snowflake features can be enabled by calling the SYSTEM$GLOBAL_ACCOUNT_SET_PARAMETER function by a user with the ORGADMIN role? (Choose two.),multi-select,A. Clustering,B. Client redirect,C. Fail-safe,D. Search optimization service,E. Account and database replication,,,,,,,,,,,"2, 5","BE is correct answer!  https://docs.snowflake.com/en/sql-reference/functions/system_global_account_set_parameter#:~:text=for%20the%20account%3A-,Replication,-Client%20Redirect
BE correct - https://docs.snowflake.com/en/sql-reference/functions/system_global_account_set_parameter",
What are characteristics of directory tables when used with unstructured data? (Choose two.),multi-select,A. Only cloud storage stages support directory tables.,B. Each directory table has grantable privileges of its own.,C. Directory tables store a catalog of staged files in cloud storage.,D. A directory table can be added explicitly to a stage when the stage is created.,E. A directory table is a separate database object that can be layered explicitly on a stage.,,,,,,,,,,,"3, 4","CD is correct!  Directory table: 1- its implicit not separate database object 2 - like external table stores file-level metadata about the data files in the stage 3 - has NO grantable privileges of its own  https://docs.snowflake.com/en/user-guide/data-load-dirtables#what-is-a-directory-table
CD correct - https://docs.snowflake.com/en/user-guide/data-load-dirtables",
Snowflake best practice recommends that which role be used to enforce a network policy on a Snowflake account?,multiple-choice,A. ACCOUNTADMIN,B. SECURITYADMIN,C. SYSADMIN,D. USERADMIN,,,,,,,,,,,,2,B correct - https://docs.snowflake.com/en/sql-reference/sql/create-network-policy,
What is the default behavior of internal stages in Snowflake?,multiple-choice,A. Named internal stages are created by default.,B. Users must manually create their own internal stages.,C. Data files are automatically staged to a default location.,D. Each user and table are automatically allocated an internal stage.,,,,,,,,,,,,4,"Correct answer is D. https://docs.snowflake.com/en/user-guide/data-load-local-file-system-create-stage#types-of-internal-stages
D correct - https://docs.snowflake.com/en/user-guide/data-load-local-file-system-create-stage",
The MAXIMUM size for a serverless task run is equivalent to what size virtual warehouse?,multiple-choice,A. Medium,B. Large,C. 2X-Large,D. 4X-Large,,,,,,,,,,,,3,"The maximum compute size for a serverless task is equivalent to an XXLARGE user-managed virtual warehouse.
C correct - https://docs.snowflake.com/en/user-guide/tasks-intro#:~:text=The%20maximum%20size%20for%20a%20serverless%20task,run%20is%20equivalent%20to%20an%20XXLARGE%20warehouse.",
What storage cost is completely eliminated when a Snowflake table is defined as transient?,multiple-choice,A. Active,B. Fail-safe,C. Staged,D. Time Travel,,,,,,,,,,,,2,B correct - https://docs.snowflake.com/en/user-guide/tables-temp-transient,
How can a Snowflake user traverse semi-structured data?,multiple-choice,A. Insert a colon (:) between the VARIANT column name and any first-level element.,B. Insert a colon (:) between the VARIANT column name and any second-level element.,C. Insert a double colon (::) between the VARIANT column name and any first-level element.,D. Insert a double colon (::) between the VARIANT column name and any second-level element.,,,,,,,,,,,,1,"A : select column:first_level_column from json_table
A correct - https://community.snowflake.com/s/article/querying-semi-structured-data#:~:text=Snowflake%20supports%20SQL%20queries%20that%20access%20semi-structured%20data,as%20the%20path%20delimiter%2C%20i.e.%20the%20form%20table.column%3Apathelement1.pathelement2.pathelement3.",
"Based on Snowflake recommendations, when creating a hierarchy of custom roles, the top-most custom role should be assigned to which role?",multiple-choice,A. ACCOUNTADMIN,B. SECURITYADMIN,C. SYSADMIN,D. USERADMIN,,,,,,,,,,,,3,"https://docs.snowflake.com/en/user-guide/security-access-control-overview#custom-roles  When creating roles that will serve as the owners of securable objects in the system, Snowflake recommends creating a hierarchy of custom roles, with the top-most custom role assigned to the system role SYSADMIN.
correct
correct answer is C https://community.snowflake.com/s/article/Quickly-Visualize-Snowflake-s-Roles-Grants-and-Privileges",
How does Snowflake improve the performance of queries that are designed to filter out a significant amount of data?,multiple-choice,A. The use of indexing,B. The use of pruning,C. The use of TableScan,D. By increasing the number of partitions scanned,,,,,,,,,,,,2,"B : Purring improves query efficiency
B correct",
"A JSON document is stored in the source_column of type VARIANT. The document has an array called elements. The array contains the name key that has a string value.

How can a Snowflake user extract the name from the first element?",multiple-choice,A. source_column.elements[1]:name,B. source_column.elements[0]:name,C. source_column:elements[1].name,D. source_column:elements[0].name,,,,,,,,,,,,4,"D correct
This is not related to the FLATTEN function. This is merely a question on traversing semi-structured datatypes: https://docs.snowflake.com/en/user-guide/querying-semistructured Insert a colon : between the VARIANT column name and any first-level element: <column>:<level1_element>. There are two ways to access elements in a JSON object: Dot Notation Bracket Notation Retrieve a specific numbered instance of a child element in a repeating array by adding a numbered predicate (starting from 0) to the array reference. so the answer is D",
Which function should be used to insert JSON formatted string data into a VARIANT field?,multiple-choice,A. FLATTEN,B. CHECK_JSON,C. PARSE_JSON,D. TO_VARIANT,,,,,,,,,,,,3,"The correct answer is C. PARSE_JSON https://docs.snowflake.com/en/sql-reference/functions/parse_json
correct link - https://docs.snowflake.com/en/sql-reference/functions/parse_json",
Which permission on a Snowflake virtual warehouse allows the role to resize the warehouse?,multiple-choice,A. ALTER,B. MODIFY,C. MONITOR,D. USAGE,,,,,,,,,,,,2,"B is the correct answer!  https://docs.snowflake.com/en/sql-reference/sql/alter-warehouse#access-control-requirements
B correct - https://stackoverflow.com/questions/67444656/how-do-you-restrict-a-warehouse-to-resize-to-role-in-snowflake",
What is it called when a customer managed key is combined with a Snowflake managed key to create a composite key for encryption?,multiple-choice,A. Hierarchical key model,B. Client-side encryption,C. Tri-secret secure encryption,D. Key pair authentication,,,,,,,,,,,,3,"The correct answer is C. https://docs.snowflake.com/en/user-guide/security-encryption-manage
C correct - https://www.phdata.io/blog/encrypting-snowflake-data-with-own-keys/",
"A size 3X-Large multi-cluster warehouse runs one cluster for one full hour and then runs two clusters for the next full hour.

What would be the total number of credits billed?",multiple-choice,A. 64,B. 128,C. 149,D. 192,,,,,,,,,,,,4,"I hope I don't have to calculate this in my head on the exam :)  D XS - S - M - L - XL - 2XL - 3XL 1 - 2 -4 - 8 - 16 - 32 -64 1st hr - 1 2nd hr - 2 64*3 = 192
Correct D - 64 + 128   https://docs.snowflake.com/en/user-guide/warehouses-overview",
What is the impact of increasing the number of concurrent users on a Snowflake virtual warehouse?,multiple-choice,"A. Improved performance for small, simple queries","B. Improved performance for large, complex queries","C. Decreased performance for large, complex queries",D. Decreased consumption of Snowflake credits,,,,,,,,,,,,3,"C correct. Multi-cluster warehouses are best utilized for scaling resources to improve concurrency for users/queries. https://docs.snowflake.com/en/user-guide/warehouses-multicluster#benefits-of-multi-cluster-warehouses
C correct - https://docs.snowflake.com/en/user-guide/warehouses-multicluster#:~:text=As%20the%20number%20of%20concurrent%20user%20sessions%20and%2For,to%20the%20maximum%20number%20defined%20for%20the%20warehouse.",
"By default, how long is the standard retention period for Time Travel across all Snowflake accounts?",multiple-choice,A. 0 days,B. 1 day,C. 7 days,D. 14 days,,,,,,,,,,,,2,"B is correct. The standard retention period is 1 day (24 hours) and is automatically enabled for all Snowflake accounts: For Snowflake Standard Edition, the retention period can be set to 0 (or unset back to the default of 1 day) at the account and object level (i.e. databases, schemas, and tables).
B correct - https://docs.snowflake.com/en/user-guide/data-time-travel",
What type of query will benefit from the query acceleration service?,multiple-choice,A. Queries without filters or aggregation,B. Queries with large scans and selective filters,C. Queries where the GROUP BY has high cardinality,D. Queries of tables that have search optimization service enabled,,,,,,,,,,,,2,"B is correct. Examples of the types of workloads that might benefit from the query acceleration service:  1) Ad hoc analytics. 2) Workloads with unpredictable data volume per query. 3) Queries with large scans and selective filters.  https://docs.snowflake.com/en/user-guide/query-acceleration-service#label-query-acceleration-scale-factor
Answer B is correct  https://docs.snowflake.com/en/user-guide/query-acceleration-service",
How does the search optimization service help Snowflake users improve query performance?,multiple-choice,A. It scans the micro-partitions based on the joins used in the queries and scans only join columns.,B. It maintains a persistent data structure that keeps track of the values of the table’s columns in each of its micro-partitions.,C. It scans the local disk cache to avoid scans on the tables used in the query.,D. It keeps track of running queries and their results and saves those extra scans on the table.,,,,,,,,,,,,2,"B Correct .  To improve performance for point lookups, the search optimization service creates and maintains a persistent data structure called a search access path. The search access path keeps track of which values of the table’s columns might be found in each of its micro-partitions, allowing some to be skipped when scanning the table.  https://docs.snowflake.com/en/user-guide/search-optimization-service#how-does-the-search-optimization-service-work
B correct - https://docs.snowflake.com/en/user-guide/search-optimization-service",
What can be done to reduce queueing on a virtual warehouse?,multiple-choice,A. Increase the AUTO_SUSPEND setting for the warehouse.,B. Change the warehouse to a multi-cluster warehouse.,C. Increase the warehouse size.,D. Lower the MAX_CONCURRENCY_LEVEL setting for the warehouse.,,,,,,,,,,,,2,B correct - https://docs.snowflake.com/en/user-guide/performance-query-warehouse-queue,
What are characteristics of Snowsight worksheets? (Choose two.),multi-select,"A. Worksheets can be grouped under folders, and a folder of folders.",B. Each worksheet is a unique Snowflake session.,C. Users are limited to running only one query on a worksheet.,D. The Snowflake session ends when a user switches worksheets.,E. Users can import worksheets and share them with other users.,,,,,,,,,,,"2, 5","According to documentation:  You can share worksheets and folders of worksheets with other Snowflake users in your account.  Each worksheet is a unique session and can use roles different from the role you select   A is incorrect because you can't nest folders   Thus B&E
AB correct - https://docs.snowflake.com/en/user-guide/ui-snowsight-worksheets",
What are reasons for using the VALIDATE function in Snowflake after a COPY INTO command execution? (Choose two.),multi-select,A. To validate the files that have been loaded earlier using the COPY INTO command,B. To fix errors that were made during the execution of the COPY INTO command,C. To return errors encountered during the execution of the COPY INTO command,D. To identify potential issues in the COPY INTO command before it is executed,E. To count the number of errors encountered during the execution of the COPY INTO command,,,,,,,,,,,"1, 3","AC correct - https://docs.snowflake.com/en/sql-reference/functions/validate
You confused it, the question is about this command and the first sentence says validating files: https://docs.snowflake.com/en/sql-reference/functions/validate",
Which types of URLs are provided by Snowflake to access unstructured data files? (Choose two).,multi-select,A. Absolute URL,B. Dynamic URL,C. File URL,D. Relative URL,E. Scoped URL,,,,,,,,,,,"3, 5","CE is correct.  there are 3 URLs 1-File URL 2-Scoped URL 3-Pre-signed URL https://docs.snowflake.com/en/user-guide/unstructured-intro#types-of-urls-available-to-access-files
CE correct - https://hevodata.com/learn/snowflake-unstructured-data/",
"Which query will return a sample of a table with 1000 rows named testtable, in which each row has a 10% probability of being included in the sample?",multiple-choice,A. select * from testtable sample (0.1);,B. select * from testtable sample (10);,C. select * from testtable sample (0.1 rows);,D. select * from testtable sample (10 rows);,,,,,,,,,,,,2,"B for 10%
B correct - https://docs.snowflake.com/en/sql-reference/constructs/sample",
How can a Snowflake user validate data that is unloaded using the COPY INTO [location] command?,multiple-choice,A. Load the data into a CSV file.,B. Load the data into a relational table.,C. Use the VALIDATION_MODE = SQL statement.,D. Use the VALIDATION_MODE = RETURN_ROWS statement.,,,,,,,,,,,,4,"D is correct Use the VALIDATION_MODE = RETURN_ROWS statement. https://docs.snowflake.com/en/sql-reference/sql/copy-into-location#optional-parameters
D correct - https://community.snowflake.com/s/article/Best-Practices-for-Data-Unloading",
What role in Snowflake separates the management of users and roles from the management of all grants?,multiple-choice,A. ACCOUNTADMIN,B. SYSADMIN,C. SECURITYADMIN,D. USERADMIN,,,,,,,,,,,,4,"USERADMIN
D correct - https://medium.com/snowflake/role-based-access-control-rbac-with-secondary-roles-8ce3c7bb57df",
Which command will unload data from a table into an external stage?,multiple-choice,A. PUT,B. INSERT,C. COPY INTO [location],D. GET,,,,,,,,,,,,3,C correct,
Why is a federated environment used for user authentication in Snowflake?,multiple-choice,A. To enhance data security and privacy,B. To provide real-time monitoring of user activities,C. To separate user authentication from user access,D. To enable direct integration with external databases,,,,,,,,,,,,3,"C is correct  In a federated environment, user authentication is separated from user access.  https://docs.snowflake.com/en/user-guide/admin-security-fed-auth-overview#what-is-a-federated-environment
C correct - https://docs.snowflake.com/en/user-guide/admin-security-fed-auth-overview",
What will happen if a Snowflake user increases the size of a suspended virtual warehouse?,multiple-choice,A. The provisioning of new compute resources for the warehouse will begin immediately.,B. The warehouse will remain suspended but new resources will be added to the query acceleration service.,C. The provisioning of additional compute resources will be in effect when the warehouse is next resumed.,D. The warehouse will resume immediately and start to share the compute load with other running virtual warehouses.,,,,,,,,,,,,3,"C -> Resizing a suspended warehouse does not provision any new compute resources for the warehouse. It simply instructs Snowflake to provision the additional compute resources when the warehouse is next resumed, at which time all the usage and credit rules associated with starting a warehouse apply.
C correct - https://docs.snowflake.com/en/user-guide/warehouses-tasks",
The VALIDATE table function has which parameter as an input argument for a Snowflake user?,multiple-choice,A. LAST_QUERY_ID,B. CURRENT_STATEMENT,C. UUID_STRING,D. JOB_ID,,,,,,,,,,,,4,"D correct. Job_ID which is query ID https://docs.snowflake.com/en/sql-reference/functions/validate#syntax
D correct - https://docs.snowflake.com/en/sql-reference/functions/validate",
"Which Snowflake edition supports Protected Health Information (PHI) data (in accordance with HIPAA and HITRUST CSF regulations), and has a dedicated metadata store and pool of compute resources?",multiple-choice,A. Standard,B. Enterprise,C. Business Critical,D. Virtual Private Snowflake (VPS),,,,,,,,,,,,4,"Only VPS offer such option
C correct - https://docs.snowflake.com/en/user-guide/intro-editions",
Which Snowflake table types are used to manage costs for short-lived tables? (Choose two.),multi-select,A. External tables,B. Permanent tables,C. Shared tables,D. Temporary tables,E. Transient tables,,,,,,,,,,,"4, 5",DE correct - https://docs.snowflake.com/en/user-guide/tables-storage-considerations,
What are key characteristics of virtual warehouses in Snowflake? (Choose two.),multi-select,A. Warehouses that are multi-cluster can have nodes of different sizes.,B. Warehouses can be started and stopped at any time.,"C. Warehouses can be resized at any time, even while running.",D. Warehouses are billed on a per-minute usage basis.,E. Warehouses can only be used for querying and cannot be used for data loading.,,,,,,,,,,,"2, 3","B&C D is incorrect as warehouses are billed on per second basis
BC - correct",
What strategies can be used to optimize the performance of a virtual warehouse? (Choose two.),multi-select,A. Reduce queuing.,B. Allow memory spillage.,C. Increase the MAX_CONCURRENCY_LEVEL parameter.,D. Increase the warehouse size.,E. Suspend the warehouse frequently.,,,,,,,,,,,"1, 4","AD is correct. Optimizing Warehouses for Performance: 1-Reduce queues (if WH is not multi cluster make it multi cluster else add another WH) 2-Resolve memory spillage ( scale up or convert it to Snowpark-optimized WH) 3-Increase warehouse size (Scale up) 4-Trying Query Acceleration - set ENABLE_QUERY_ACCELERATION = true 5-Optimizing the Warehouse Cache (by increasing Auto-suspension) 6-Limiting Concurrently Running Queries (Decrease the MAX_CONCURRENCY_LEVEL)  https://docs.snowflake.com/en/user-guide/performance-query-warehouse
AD correct - https://docs.snowflake.com/en/user-guide/performance-query-warehouse",
How are privileges inherited in a role hierarchy in Snowflake?,multiple-choice,A. Privileges are inherited by any roles above that role in the hierarchy.,B. Privileges are inherited by any roles at the same level in the hierarchy.,C. Privileges are only inherited by the direct parent role in the hierarchy.,D. Privileges are only inherited by the direct child role in the hierarchy.,,,,,,,,,,,,3,"Roles can be also granted to other roles, creating a hierarchy of roles. The privileges associated with a role are inherited by any roles above that role in the hierarchy. For more information about role hierarchies and privilege inheritance, see Role Hierarchy and Privilege Inheritance (in this topic). a
C is correct !  https://docs.snowflake.com/en/user-guide/security-access-control-overview#role-hierarchy-and-privilege-inheritance
A correct - https://docs.snowflake.com/en/user-guide/security-access-control-privileges",
At what level can the ALLOW_CLIENT_MFA_CACHING parameter be set?,multiple-choice,A. Account,B. Role,C. Session,D. User,,,,,,,,,,,,1,A correct - https://docs.snowflake.com/en/user-guide/security-mfa,
What entity is responsible for hosting and sharing data in Snowflake?,multiple-choice,A. Data provider,B. Data consumer,C. Reader account,D. Managed account,,,,,,,,,,,,1,"A is correct
A. Data provider
A correct - https://docs.snowflake.com/en/user-guide/data-sharing-intro",
Which function will provide the proxy information needed to protect Snowsight?,multiple-choice,A. SYSTEM$GET_TAG,B. SYSTEM$GET_PRIVATELINK,C. SYSTEM$ALLOWLIST,D. SYSTEM$AUTHORIZE_PRIVATELINK,,,,,,,,,,,,3,"C correct To determine the fully qualified URL and port for Snowsight, review the SNOWSIGHT_DEPLOYMENT entry in the return value of the SYSTEM$ALLOWLIST function.  https://docs.snowflake.com/en/user-guide/ui-snowsight-gs#accessing-sf-web-interface-through-a-proxy-or-firewall
C correct - https://docs.snowflake.com/en/user-guide/ui-snowsight-gs",
The property MINS_TO_BYPASS_NETWORK_POLICY is set at which level?,multiple-choice,A. User,B. Role,C. Account,D. Organization,,,,,,,,,,,,1,"A correct.  Its at user level  https://docs.snowflake.com/en/sql-reference/sql/desc-user#usage-notes
https://docs.snowflake.com/en/sql-reference/sql/desc-user A",
"When unloading the data for file format type specified (TYPE = 'CSV'), SQL NULL can be converted to string ‘null’ using which file format option?",multiple-choice,A. SKIP_BYTE_ORDER_MARK,B. EMPTY_FIELD_AS_NULL,C. NULL_IF,D. ESCAPE_UNENCLOSED_FIELD,,,,,,,,,,,,3,"C correct  NULL_IF https://docs.snowflake.com/en/user-guide/data-unload-considerations#empty-strings-and-null-values
C correct - https://docs.snowflake.com/en/user-guide/data-unload-considerations",
"What Snowflake database object is derived from a query specification, stored for later use, and can speed up expensive aggregation on large data sets?",multiple-choice,A. Temporary table,B. External table,C. Secure view,D. Materialized view,,,,,,,,,,,,4,D correct - https://docs.snowflake.com/en/user-guide/views-materialized,
"User1, who has the SYSADMIN role, executed a query on Snowsight. User2, who is in the same Snowflake account, wants to view the result set of the query executed by User1 using the Snowsight query history.

What will happen if User2 tries to access the query history?",multiple-choice,A. If User2 has the SYSADMIN role they will be able to see the results.,B. If User2 has the SECURITYADMIN role they will be able to see the results.,C. If User2 has the ACCOUNTADMIN role they will be able to see the results.,D. User2 will be unable to view the result set of the query executed by User1.,,,,,,,,,,,,4,"In Snowflake's Snowsight query history, while administrative roles (like SYSADMIN, SECURITYADMIN, or ACCOUNTADMIN) can view the metadata of queries executed by other users (e.g., query text, execution time, user, role, warehouse used), they cannot directly view or access the actual result set of a query executed by another user.

This is a fundamental security and privacy measure. The result set of a query is considered specific to the user who ran it. To view the data, User2 would need to copy the query text and execute it themselves, provided they have the necessary access privileges to the underlying data at that time.

Therefore, regardless of User2's role (even if it's SYSADMIN, SECURITYADMIN, or ACCOUNTADMIN), they will not be able to view the result set of the query executed by User1 from User1's query history.

The final answer is  
D
​	",
"A permanent table and temporary table have the same name, TBL1, in a schema.

What will happen if a user executes select * from TBL1;?",multiple-choice,A. The temporary table will take precedence over the permanent table.,B. The permanent table will take precedence over the temporary table.,C. An error will say there cannot be two tables with the same name in a schema.,D. The table that was created most recently will take precedence over the older table.,,,,,,,,,,,,1,"A is correct .  All queries and other operations performed in the session on the table affect only the temporary table  https://docs.snowflake.com/en/user-guide/tables-temp-transient#potential-naming-conflicts-with-other-table-types
A correct - https://docs.snowflake.com/en/user-guide/tables-temp-transient",
The effects of query pruning can be observed by evaluating which statistics? (Choose two.),multi-select,A. Partitions scanned,B. Partitions total,C. Bytes scanned,D. Bytes read from result,E. Bytes written,,,,,,,,,,,"1, 2","AB The efficiency of pruning can be observed by comparing Partitions scanned and Partitions total statistics in the TableScan operators. If the former is a small fraction of the latter, pruning is efficient. If not, the pruning did not have an effect.
AC is correct  A. Partitions scanned: This statistic indicates the number of data partitions (or micro-partitions in Snowflake's terms) that were actually accessed during the execution of a query. Efficient query pruning will reduce the number of partitions scanned because it avoids reading data that does not match the query's filters. A lower number compared to the total available partitions can show that query pruning has effectively reduced the dataset that needed to be scanned.  C. Bytes scanned: This statistic shows the volume of data scanned to fulfill the query. Just like with partitions scanned, effective query pruning should reduce the amount of data that needs to be scanned, as it skips over blocks of data that are determined (via metadata inspection) not to contain relevant data. This can significantly enhance query performance, especially in large datasets.
AB - correct  https://docs.snowflake.com/en/user-guide/ui-query-profile",
Which data types optimally store semi-structured data? (Choose two.),multi-select,A. ARRAY,B. CHARACTER,C. STRING,D. VARCHAR,E. VARIANT,,,,,,,,,,,"1, 5",AE - correct,
What compute resource is used when loading data using Snowpipe?,multiple-choice,A. Snowpipe uses virtual warehouses provided by the user.,B. Snowpipe uses an Apache Kafka server for its compute resources.,C. Snowpipe uses compute resources provided by Snowflake.,D. Snowpipe uses cloud platform compute resources provided by the user.,,,,,,,,,,,,3,"Confirmed, C is correct, according to docs: ""Snowpipe uses compute resources provided by Snowflake (i.e. a serverless compute model).""
C correct - https://docs.snowflake.com/en/user-guide/data-load-overview",
Which file function gives a user or application access to download unstructured data from a Snowflake stage?,multiple-choice,A. BUILD_SCOPED_FILE_URL,B. BUILD_STAGE_FILE_URL,C. GET_PRESIGNED_URL,D. GET_STAGE_LOCATION,,,,,,,,,,,,3,"Access and download - hence C. GET_PRESIGNED_URL
it's C : https://docs.snowflake.com/en/sql-reference/functions/get_presigned_url
BUILD_SCOPED_FILE_URL Ideal for use in custom applications, for providing unstructured data to other accounts through a share, or for downloading and analysis of unstructured data in Snowsight.
C correct - https://docs.snowflake.com/en/user-guide/unstructured-intro",
"By default, which role can create resource monitors?",multiple-choice,A. ACCOUNTADMIN,B. SECURITYADMIN,C. SYSADMIN,D. USERADMIN,,,,,,,,,,,,1,"Only users with the ACCOUNTADMIN role can create a resource monitor, but an account administrator can grant privileges to other roles to allow other users to view and modify resource monitors.
A correct - https://docs.snowflake.com/en/user-guide/resource-monitors",
Which DDL/DML operation is allowed on an inbound data share?,multiple-choice,A. ALTER TABLE,B. INSERT INTO,C. MERGE,D. SELECT,,,,,,,,,,,,4,"D. SELECT
You can't alter a shared table, only the share itself to add/remove accounts
https://docs.snowflake.com/en/user-guide/data-sharing-provider#ddl-for-shares",
Which types of charts does Snowsight support? (Choose two.),multi-select,A. Area charts,B. Bar charts,C. Column charts,D. Radar charts,E. Scorecards,,,,,,,,,,,"2, 5","BE.  Snowsight supports the following types of charts: Bar charts. Line charts. Scatterplots. Heat grids. Scorecards.
BE correct - https://docs.snowflake.com/en/user-guide/ui-snowsight-visualizations",
Which role in Snowflake allows a user to enable replication for multiple accounts?,multiple-choice,A. ACCOUNTADMIN,B. SECURITYADMIN,C. SYSADMIN,D. ORGADMIN,,,,,,,,,,,,4,"Enable replication for accounts in the organization The organization administrator (ORGADMIN role) must enable replication for the source and target accounts.
D correct - https://docs.snowflake.com/en/user-guide/database-replication-config",
Which Snowflake tool is recommended for data batch processing?,multiple-choice,A. SnowCD,B. SnowSQL,C. Snowsight,D. The Snowflake API,,,,,,,,,,,,2,"C to do batch processing, you can run some command in the UI, which is Snowsight
B correct - https://www.snowflake.com/guides/how-data-ingestion-framework-powers-large-data-set-usage#:~:text=For%20batch%20data%20loading%2C%20you%20can%20use%20the,leave%20the%20ongoing%20management%20of%20ingestion%20to%20Snowflake.",
Which Snowflake mechanism is used to limit the number of micro-partitions scanned by a query?,multiple-choice,A. Caching,B. Cluster depth,C. Query pruning,D. Retrieval optimization,,,,,,,,,,,,3,C correct - https://blog.devgenius.io/snowflake-micro-partitions-clustering-keys-dbt-b6cb1212dcbe,
"While clustering a table, columns with which data types can be used as clustering keys? (Choose two.)",multi-select,A. BINARY,B. GEOGRAPHY,C. GEOMETRY,D. OBJECT,E. VARIANT,,,,,,,,,,,"1, 3","AC correct. (Binary & Geometry)  It can be any datatype except  GEOGRAPHY.  VARIANT.  OBJECT. ARRAY.
AC correct - A clustering key can be defined when a table is created by appending a CLUSTER  Where each clustering key consists of one or more table columns/expressions, which can be of any data type, except GEOGRAPHY, VARIANT, OBJECT, or ARRAY  https://docs.snowflake.com/en/user-guide/tables-clustering-keys",
Which use case does the search optimization service support?,multiple-choice,A. Disjuncts (OR) in join predicates,B. LIKE/ILIKE/RLIKE join predicates,C. Join predicates on VARIANT columns,D. Conjunctions (AND) of multiple equality predicates,,,,,,,,,,,,4,"The search optimization service can improve the performance of queries with the following types of join predicates:  i> Equality predicates of the form dimension_table.column = fact_table.column. ii> Transformations on the side of the predicate with the dimension (e.g. string concatenation, addition, etc.). iii> Conjunctions (AND) of multiple equality predicates. https://medium.com/snowflake/snowflake-performance-search-optimization-service-part-2-382714956588
D correct. Search optimization can improve the performance of these types of queries: 1)Equality or IN Predicates 2)Substrings and Regular Expressions (LIKE/ILIKE/RLIKE/CONTAINS,... ) 3)Fields in VARIANT Columns 4)Geospatial Functions 5)Conjunctions of Supported Predicates (AND) 6)Disjunctions of Supported Predicates (OR) ----------------------------------------------------------------------------------- The search optimization service does not directly improve the performance of joins.  https://docs.snowflake.com/en/user-guide/search-optimization-service#label-search-optimization-service-queries
D correct - https://docs.snowflake.com/en/user-guide/search-optimization-service",
What should be used when creating a CSV file format where the columns are wrapped by single quotes or double quotes?,multiple-choice,A. BINARY_FORMAT,B. ESCAPE_UNENCLOSED_FIELD,C. FIELD_OPTIONALLY_ENCLOSED_BY,D. SKIP_BYTE_ORDER_MARK,,,,,,,,,,,,3,"C correct  Leave string fields unenclosed by setting the FIELD_OPTIONALLY_ENCLOSED_BY option to NONE (default) https://docs.snowflake.com/en/user-guide/data-unload-considerations#empty-strings-and-null-values
C correct - https://community.snowflake.com/s/article/Escaping-double-quotes-from-source-file",
"If a multi-cluster warehouse is using an economy scaling policy, how long will queries wait in the queue before another cluster is started?",multiple-choice,A. 1 minute,B. 2 minutes,C. 6 minutes,D. 8 minutes,,,,,,,,,,,,3,"Economy - 6 minutes Standard - immediately  Thus C is correct answer
C correct - https://community.snowflake.com/s/article/Cluster-Spin-up-criteria-in-MCW",
What does the TableScan operator represent in the Query Profile?,multiple-choice,A. The access to a single table,B. The access to data stored in stage objects,C. The list of values provided with the VALUES clause,D. The records generated using the TABLE(GENERATOR(...)) construct,,,,,,,,,,,,1,A correct - https://docs.snowflake.com/en/sql-reference/functions/get_query_operator_stats,
What information is found within the Statistic output in the Query Profile Overview?,multiple-choice,A. Operator tree,B. Table pruning,C. Most expensive nodes,D. Nodes by execution time,,,,,,,,,,,,2,"it's B - https://docs.snowflake.com/en/user-guide/ui-query-profile
D probably - https://docs.snowflake.com/en/user-guide/ui-query-profile",
Which roles can make grant decisions to objects within a managed access schema? (Choose two.),multi-select,A. ACCOUNTADMIN,B. SECURITYADMIN,C. SYSADMIN,D. ORGADMIN,E. USERADMIN,,,,,,,,,,,"1, 2","A and B are correct: https://docs.snowflake.com/en/sql-reference/sql/grant-privilege Only the SECURITYADMIN and ACCOUNTADMIN system roles have the MANAGE GRANTS privilege; however, the privilege can be granted to custom roles.  https://docs.snowflake.com/en/user-guide/security-access-control-configure With managed access schemas, object owners lose the ability to make grant decisions. Only the schema owner (i.e. the role with the OWNERSHIP privilege on the schema) or a role with the MANAGE GRANTS privilege can grant privileges on objects in the schema, including future grants, centralizing privilege management.  Since SECURITYADMIN and ACCOUNTADMIN have the MANAGE GRANTS global privilege, they can grant privileges on objects in a managed access schema.
AB - SECURITYADMIN or higher....higher is only AccountAdmin  https://docs.snowflake.com/en/user-guide/security-access-control-configure#label-managed-access-schemas",
How can a Snowflake user post-process the result of SHOW FILE FORMATS?,multiple-choice,A. Use the RESULT_SCAN function.,B. Create a CURSOR for the command.,C. Put it in the FROM clause in brackets.,D. Assign the command to RESULTSET.,,,,,,,,,,,,1,"To post-process the output of File Format command, you can use the RESULT_SCAN function, which treats the output as a table that can be queried.
A correct. first run SHOW FILE FORMATS then SELECT * FROM TABLE(RESULT_SCAN(LAST_QUERY_ID(-1)))  https://docs.snowflake.com/en/sql-reference/functions/result_scan#usage-notes
A correct - https://docs.snowflake.com/en/sql-reference/sql/show-file-formats",
"When initially creating an account in Snowflake, which settings can be specified? (Choose two.)",multi-select,A. Account name,B. Organization name,C. Account locator,D. Region,E. Snowflake edition,,,,,,,,,,,"4, 5","A, D, E are correct - https://docs.snowflake.com/en/sql-reference/sql/create-account#access-control-requirements
D and E
AE correct - https://docs.snowflake.com/en/sql-reference/sql/create-account",
What is one of the benefits of using a multi-cluster virtual warehouse?,multiple-choice,A. It will speed up data loading.,B. It will reduce the cost of running the warehouse.,C. It will automatically increase the warehouse size as needed.,D. It will automatically start and stop additional clusters as needed.,,,,,,,,,,,,4,"D is correct.
D correct - https://docs.snowflake.com/en/user-guide/warehouses-multicluster",
When should a multi-cluster virtual warehouse be used in Snowflake?,multiple-choice,A. When queuing is delaying query execution on the warehouse,B. When there is significant disk spilling shown on the Query Profile,C. When dynamic vertical scaling is being used in the warehouse,D. When there are no concurrent queries running on the warehouse,,,,,,,,,,,,1,"A is correct.
A correct. https://docs.snowflake.com/en/user-guide/warehouses-multicluster#what-is-a-multi-cluster-warehouse
A correct - https://docs.snowflake.com/en/user-guide/warehouses-multicluster",
What is used to denote a pre-computed data set derived from a SELECT query specification and stored for later use?,multiple-choice,A. View,B. Secure view,C. Materialized view,D. External table,,,,,,,,,,,,3,"C is correct.
C correct - https://docs.snowflake.com/en/user-guide/views-materialized",
"A Snowflake user wants to temporarily bypass a network policy by configuring the user object property MINS_TO_BYPASS_NETWORK_POLICY.

What should they do?",multiple-choice,A. Use the SECURITYADMIN role.,B. Use the SYSADMIN role.,C. Use the USERADMIN role.,D. Contact Snowflake Support.,,,,,,,,,,,,4,"D is the correct Answer https://docs.snowflake.com/en/user-guide/network-policies#bypassing-a-network-policy
D correct - https://docs.snowflake.com/en/user-guide/network-policies",
What is the default access of a securable object until other access is granted?,multiple-choice,A. No access,B. Read access,C. Write access,D. Full access,,,,,,,,,,,,1,"Correct Answer is A https://docs.snowflake.com/en/user-guide/security-access-control-overview#:~:text=in%20Snowflake%20are%3A-,Securable%20object,-%3A%20An%20entity
A correct - https://docs.snowflake.com/en/user-guide/security-access-control-overview",
From what stage can a Snowflake user omit the FROM clause while loading data into a table?,multiple-choice,A. The user stage,B. The table stage,C. The internal named stage,D. The external named stage,,,,,,,,,,,,2,"B - https://docs.snowflake.com/en/user-guide/data-load-local-file-system-copy
Confirmed, B, according to docs: ""Note that when copying data from files in a table stage, the FROM clause can be omitted because Snowflake automatically checks for files in the table stage.""
B correct - https://docs.snowflake.com/en/user-guide/data-load-local-file-system-copy",
What is used during the FIRST execution of SELECT COUNT(*) FROM ORDER?,multiple-choice,A. Remote disk cache,B. Virtual warehouse cache,C. Cache result,D. Metadata-based result,,,,,,,,,,,,4,"Metadata keeps information about the row count
D correct - https://community.snowflake.com/s/question/0D5Do00000IaCZlKAN/what-is-the-difference-between-metadata-cache-and-result-cache",
What is the purpose of a resource monitor in Snowflake?,multiple-choice,A. To monitor the query performance of virtual warehouses,B. To create and suspend virtual warehouses automatically,C. To manage cloud services needed for virtual warehouses,D. To control costs and credit usage by virtual warehouses,,,,,,,,,,,,4,D correct - https://docs.snowflake.com/en/user-guide/resource-monitors,
Which data formats are supported by Snowflake when unloading semi-structured data? (Choose two.),multi-select,A. Binary file in Avro,B. Binary file in Parquet,C. Comma-separated JSON,D. Newline Delimited JSON,E. Plain text file containing XML elements,,,,,,,,,,,"2, 4","BD probably - NDJSON mentioned in https://docs.snowflake.com/en/user-guide/data-unload-prepare and particualry Parquet as well
Correct answer is B and D.  Binary file in Parquet Newline Delimited JSON (ndjson)  https://docs.snowflake.com/en/user-guide/data-unload-prepare#supported-file-formats",
"In Snowflake, the use of federated authentication enables which Single Sign-On (SSO) workflow activities? (Choose two.)",multi-select,A. Authorizing users,B. Initiating user sessions,C. Logging into Snowflake,D. Logging out of Snowflake,E. Performing role authentication,,,,,,,,,,,"3, 4","The correct Answer is C and D.  Federated authentication enables the following SSO workflows: Logging into Snowflake. Logging out of Snowflake. System timeout due to inactivity.  https://docs.snowflake.com/en/user-guide/admin-security-fed-auth-overview#supported-sso-workflows
CD correct - https://docs.snowflake.com/en/user-guide/admin-security-fed-auth-overview",
What does the worksheet and database explorer feature in Snowsight allow users to do?,multiple-choice,A. Add or remove users from a worksheet.,B. Move a worksheet to a folder or a dashboard.,C. Combine multiple worksheets into a single worksheet.,D. Tag frequently accessed worksheets for ease of access.,,,,,,,,,,,,2,"The correct answer is B. Move a worksheet to a folder or a dashboard.  The worksheet and database explorer feature in Snowsight, Snowflake's web-based SQL editor and data visualization tool, allows users to organize and manage their worksheets effectively. While the other options mentioned (A, C, and D) are not specific to the worksheet and database explorer feature, moving a worksheet to a folder or a dashboard is a key functionality provided by Snowsight.  By using the worksheet and database explorer, users can easily organize their worksheets by creating folders or dashboards and moving worksheets into them. This helps in maintaining a structured and organized workspace, making it easier to locate and access specific worksheets when needed.
B correct - https://docs.snowflake.com/en/user-guide/ui-snowsight-worksheets",
"When unloading data from Snowflake to AWS, what permissions are required? (Choose two.)",multi-select,A. s3:DeleteObject,B. s3:CopyObject,C. s3:GetBucketAcl,D. s3:PutObject,E. s3:GetBucketLocation,,,,,,,,,,,"1, 4","Answer is A & D.  Snowflake requires the following permissions on an S3 bucket and folder to create new files in the folder (and any sub-folders):  s3:DeleteObject s3:PutObject  https://docs.snowflake.com/en/user-guide/data-unload-s3#configuring-an-s3-bucket-for-unloading-data
AD correct - https://docs.snowflake.com/en/user-guide/data-unload-s3",
What step can reduce data spilling in Snowflake?,multiple-choice,A. Using a larger virtual warehouse,B. Increasing the virtual warehouse maximum timeout limit,C. Increasing the amount of remote storage for the virtual warehouse,D. Using a Common Table Expression (CTE) instead of a temporary table,,,,,,,,,,,,1,"Answer is A: https://docs.snowflake.com/en/user-guide/ui-query-profile For some operations (e.g. duplicate elimination for a huge data set), the amount of memory available for the compute resources used to execute the operation might not be sufficient to hold intermediate results. As a result, the query processing engine will start spilling the data to local disk. If the local disk space is not sufficient, the spilled data is then saved to remote disks.  This spilling can have a profound effect on query performance (especially if remote disk is used for spilling). To alleviate this, we recommend:  Using a larger warehouse (effectively increasing the available memory/local disk space for the operation), and/or  Processing data in smaller batches.
Answer A is correct! Adjusting the available memory of a warehouse can improve performance because a query runs substantially slower when a warehouse runs out of memory, which results in bytes “spilling” onto storage. https://docs.snowflake.com/en/user-guide/performance-query-warehouse
A correct - https://community.snowflake.com/s/article/Performance-impact-from-local-and-remote-disk-spilling",
Which user preferences can be set for a user profile in Snowsight? (Choose two.),multi-select,A. Multi-Factor Authentication (MFA),B. Default database,C. Default schema,D. Notifications,E. Username,,,,,,,,,,,"1, 4","Correct Ans is A&D. default warehouse and role can be set not Database and schema
The correct Answer is A & D.  Setting User Details and Preferences: ------------------------------------------------------------------------------------- Profile photo Username (cannot be changed) First name Last name Password Email Default experience (Snowsight or Classic) Language (English, Japanese) *Notifications (Browser Notification) *Multi-factor authentication Session Timeout  https://docs.snowflake.com/en/user-guide/ui-snowsight-gs#setting-user-details-and-preferences",
What privilege is needed for a Snowflake user to see the definition of a secure view?,multiple-choice,A. OWNERSHIP,B. MODIFY,C. CREATE,D. USAGE,,,,,,,,,,,,1,"The definition of a secure view is only exposed to authorized users (i.e. users who have been granted the role that owns the view).  However, users that have been granted IMPORTED PRIVILEGES privilege on the SNOWFLAKE database or another shared database have access to secure view definitions via the VIEWS Account Usage view.  Users granted the ACCOUNTADMIN role or the SNOWFLAKE.OBJECT_VIEWER database role can also see secure view definitions via this view. The preferred, least-privileged means of access is the SNOWFLAKE.OBJECT_VIEWER database role.  https://docs.snowflake.com/en/user-guide/views-secure",
What general guideline does Snowflake recommend when setting the auto-suspension time limit?,multiple-choice,A. Set tasks for immediate suspension.,B. Set tasks for suspension after 5 minutes.,C. Set query warehouses for suspension after 15 minutes.,D. Set query warehouses for suspension after 30 minutes.,,,,,,,,,,,,2,"B is correct. https://docs.snowflake.com/en/user-guide/warehouses-considerations#automating-warehouse-suspension
If you enable auto-suspend, we recommend setting it to a low value (e.g. 5 or 10 minutes or less) because Snowflake utilizes per-second billing. This will help keep your warehouses from running (and consuming credits) when not in use.  https://docs.snowflake.com/en/user-guide/warehouses-considerations#automating-warehouse-suspension",
When does Snowflake automatically encrypt data that is loaded into Snowflake? (Choose two.),multi-select,A. After the data is micro-partitioned.,B. After loading the data into a table.,C. After loading the data into an internal stage.,D. After loading data into an external stage.,E. Only when using an encrypted stage.,,,,,,,,,,,"2, 3","https://docs.snowflake.com/en/user-guide/security-encryption-end-to-end 1. A user uploads one or more data files to a stage. If the stage is an internal (i.e. Snowflake) stage (Image B) data files are automatically encrypted by the Snowflake client on the user’s local machine prior to being transmitted to the internal stage, in addition to being encrypted after they are loaded into the stage. 2. The user loads the data from the stage into a table. In Snowflake, all data at rest is always encrypted and encrypted with TLS in transit
CD should be correct",
"When data is loaded into Snowflake, what formats does Snowflake use internally to store the data in cloud storage? (Choose two.)",multi-select,A. Key-value,B. Columnar,C. Graph,D. Document,E. Compressed,,,,,,,,,,,"2, 5","B and E are correct
BE is correct",
"A user has 10 files in a stage containing new customer data. The ingest operation completes with no errors, using the following command:

COPY INTO my_table FROM @my_stage;

The next day the user adds 10 files to the stage so that now the stage contains a mixture of new customer data and updates to the previous data. The user did not remove the 10 original files.

If the user runs the same COPY INTO command what will happen?",multiple-choice,A. All data from all of the files on the stage will be appended to the table.,B. Only data about new customers from the new files will be appended to the table.,C. The operation will fail with the error UNCERTAIN FILES IN STAGE.,D. All data from only the newly-added files will be appended to the table.,,,,,,,,,,,,4,"According to the Snowflake documentation, when you run the COPY INTO command again without removing the original files, all data from all of the files on the stage will be appended to the table
D is correct
D - only the new files will be appended B - SF doesn't know which customer is new (COPY doesn't care about the meaning of data, care about files (file names) which are new (no kept in metadata as loaded)
D is correct Loading Older Files¶ This section describes how the COPY INTO <table> command prevents data duplication differently based on whether the load status for a file is known or unknown. If you partition your data in stages using logical, granular paths by date (as recommended in Organizing Data by Path) and load data within a short period of time after staging it, this section largely does not apply to you. However, if the COPY command skips older files (i.e. historical data files) in a data load, this section describes how to bypass the default behavior. https://docs.snowflake.com/en/user-guide/data-load-considerations-load#executing-parallel-copy-statements-that-reference-the-same-data-files",
Which SQL command can be used to see the CREATE definition of a masking policy?,multiple-choice,A. SHOW MASKING POLICIES,B. DESCRIBE MASKING POLICY,C. GET_DDL,D. LIST MASKING POLICIES,,,,,,,,,,,,3,"This is the result of B https://docs.snowflake.com/en/sql-reference/sql/desc-masking-policy.html#example So B can't be the answer  And this is the result of C https://docs.snowflake.com/en/sql-reference/functions/get_ddl.html#examples So C is the answer
Going by snowflake documentation, seems both b & c is correct.  https://docs.snowflake.com/en/sql-reference/sql/create-masking-policy#usage-notes",
Which of the following is the Snowflake Account_Usage.Metering_History view used for?,multiple-choice,A. Gathering the hourly credit usage for an account,B. Compiling an account's average cloud services cost over the previous month,C. Summarizing the throughput of Snowpipe costs for an account,D. Calculating the funds left on an account's contract,,,,,,,,,,,,1,"The METERING_HISTORY view in the ACCOUNT_USAGE schema can be used to return the hourly credit usage for an account within the last 365 days (1 year).  https://docs.snowflake.com/en/sql-reference/account-usage/metering_history.html
A is correct: https://docs.snowflake.com/en/sql-reference/account-usage/metering_history.html#metering-history-view",
Query parsing and compilation occurs in which architecture layer of the Snowflake Cloud Data Platform?,multiple-choice,A. Cloud services layer,B. Compute layer,C. Storage layer,D. Cloud agnostic layer,,,,,,,,,,,,1,"Answer : Cloud Service Layer
https://docs.snowflake.com/en/user-guide/intro-key-concepts.html#cloud-services",
Which of the following Snowflake objects can be shared using a secure share? (Choose two.),multi-select,A. Materialized views,B. Sequences,C. Procedures,D. Tables,E. Secure User Defined Functions (UDFs),,,,,,,,,,,"4, 5","The following Snowflake database objects can be shared:  Tables External tables Secure views Secure materialized views Secure UDFs  https://docs.snowflake.com/en/user-guide/data-sharing-intro.html#introduction-to-secure-data-sharing
D&E https://docs.snowflake.com/en/user-guide/data-sharing-intro.html#introduction-to-secure-data-sharing",
What happens to the underlying table data when a CLUSTER BY clause is added to a Snowflake table?,multiple-choice,A. Data is hashed by the cluster key to facilitate fast searches for common data values,B. Larger micro-partitions are created for common data values to reduce the number of partitions that must be scanned,C. Smaller micro-partitions are created for common data values to allow for more parallelism,D. Data may be colocated by the cluster key within the micro-partitions to improve pruning performance,,,,,,,,,,,,4,"I think D: https://docs.snowflake.com/en/user-guide/tables-clustering-keys.html#benefits-of-defining-clustering-keys-for-very-large-tables
A clustering key is a subset of columns in a table (or expressions on a table) that are explicitly designated to co-locate the data in the table in the same micro-partitions. This is useful for very large tables where the ordering was not ideal (at the time the data was inserted/loaded) or extensive DML has caused the table’s natural clustering to degrade.  https://docs.snowflake.com/en/user-guide/tables-clustering-keys.html#benefits-of-defining-clustering-keys-for-very-large-tables",
Which of the following conditions must be met in order to return results from the results cache? (Choose two.),multi-select,A. The user has the appropriate privileges on the objects associated with the query.,B. Micro-partitions have been reclustered since the query was last run.,C. The new query is run using the same virtual warehouse as the previous query.,D. The query includes a User Defined Function (UDF).,E. The query has been run within 24 hours of the previously-run query.,,,,,,,,,,,"1, 5","A&E as the below  link: https://docs.snowflake.com/en/user-guide/querying-persisted-results.html#retrieval-optimization
E is correct and maybe A If the same query is fired again in 24 hrs, it will not be COMPUTED, which means it will not be charged. and it is not affected by WH suspension. So as the previous question the same exact query will return the pre-computed results if the underlying data hasn't changed and the results were last accessed within previous 24-hour period",
Which statement about billing applies to Snowflake credits?,multiple-choice,A. Credits are billed per-minute with a 60-minute minimum.,B. Credits are used to pay for cloud data storage usage.,C. Credits are consumed based on the number of credits billed for each hour that a warehouse runs.,D. Credits are consumed based on the warehouse size and the time the warehouse is running.,,,,,,,,,,,,4,"D is the answer. A virtual warehouse is one or more clusters of compute resources that enable executing queries, loading data, and performing other DML operations. Snowflake credits are used to pay for the processing time used by each virtual warehouse.  Snowflake credits are charged based on the number of virtual warehouses you use, how long they run, and their size.
I think D https://docs.snowflake.com/en/user-guide/cost-understanding-compute.html#virtual-warehouse-credit-usage",
"A user needs to create a materialized view in the schema MYDB.MYSCHEMA.

Which statements will provide this access?",multiple-choice,"A. GRANT ROLE MYROLE TO USER USER1;
CREATE MATERIALIZED VIEW ON SCHEMA MYDB.MYSCHEMA TO ROLE MYROLE;","B. GRANT ROLE MYROLE TO USER USER1;
CREATE MATERIALIZED VIEW ON SCHEMA MYDB.MYSCHEMA TO USER USER1;","C. GRANT ROLE MYROLE TO USER USER1;
CREATE MATERIALIZED VIEW ON SCHEMA MYDB.MYSCHEMA TO USER1;","D. GRANT ROLE MYROLE TO USER USER1;
CREATE MATERIALIZED VIEW ON SCHEMA MYDB.MYSCHEMA TO MYROLE;",,,,,,,,,,,,1,"A is the correct answer https://docs.snowflake.com/en/sql-reference/sql/grant-privilege.html#examples
in all commands it is missing the keyword GRANT before ""CREATE MATERIALIZED VIEW"" The answer A is correct but the answer D is correct too because the keyword ROLE is  optional:  https://docs.snowflake.com/en/sql-reference/sql/grant-privilege.html TO [ ROLE ] <role_name> [ WITH GRANT OPTION ]  So the question must allow for multiple answers.",
What is the purpose of multi-cluster virtual warehouses?,multiple-choice,A. To create separate data warehouses to increase query optimization,B. To allow users the ability to choose the type of compute nodes that make up a virtual warehouse cluster,C. To eliminate or reduce queuing of concurrent queries,D. To allow the warehouse to resize automatically,,,,,,,,,,,,3,"answer is correct
C. To eliminate or reduce queuing of concurrent queries",
Which of the following is a valid source for an external stage when the Snowflake account is located on Microsoft Azure?,multiple-choice,A. An FTP server with TLS encryption,B. An HTTPS server with WebDAV,C. A Google Cloud storage bucket,D. A Windows server file share on Azure,,,,,,,,,,,,3,"Correct answer is C. Snowflake supports loading data from files staged in any of the following locations, regardless of the cloud platform for your Snowflake account: • Internal (i.e. Snowflake) stages • Amazon S3 • Google Cloud Storage • Microsoft Azure blob storage
https://docs.snowflake.com/en/sql-reference/sql/create-stage  External stage References data files stored in a location outside of Snowflake. Currently, the following cloud storage services are supported:  Amazon S3 buckets  Google Cloud Storage buckets  Microsoft Azure containers",
Which database objects can be shared with the Snowflake secure data sharing feature? (Choose two.),multi-select,A. Files,B. External tables,C. Secure User-Defined Functions (UDFs),D. Sequences,E. Streams,,,,,,,,,,,"2, 3","BC are correct
https://docs.snowflake.com/en/user-guide/data-sharing-intro  Secure Data Sharing lets you share selected objects in a database in your account with other Snowflake accounts. You can share the following Snowflake database objects:  Tables  External tables  Secure views  Secure materialized views  Secure UDFs
B. External tables C. Secure User-Defined Functions (UDFs)",
Which statements reflect key functionalities of a Snowflake Data Exchange? (Choose two.),multiple-choice,"A. If an account is enrolled with a Data Exchange, it will lose its access to the Snowflake Marketplace.",B. A Data Exchange allows groups of accounts to share data privately among the accounts.,"C. A Data Exchange allows accounts to share data with third, non-Snowflake parties.",D. Data Exchange functionality is available by default in accounts using the Enterprise edition or higher.,E. The sharing of data in a Data Exchange is bidirectional. An account can be a provider for some datasets and a consumer for others.,,,,,,,,,,,5,"B and E
Answer : B and C https://docs.snowflake.com/en/user-guide/data-exchange-benefits.html",
"A Snowflake user executed a query and received the results. Another user executed the same query 4 hours later. The data had not changed.

What will occur?",multiple-choice,"A. No virtual warehouse will be used, data will be read from the result cache.","B. No virtual warehouse will be used, data will be read from the local disk cache.",C. The default virtual warehouse will be used to read all data.,D. The virtual warehouse that is defined at the session level will be used to read all data.,,,,,,,,,,,,1,"A is right. Don't overthink it
seems i am already overthinking - why A? if another user is from diff account then how the results can be retrieved from result cache ?, Thanks",
Which feature allows a user the ability to control the organization of data in a micro-partition?,multiple-choice,A. Range Partitioning,B. Search Optimization Service,C. Automatic Clustering,D. Horizontal Partitioning,,,,,,,,,,,,3,"I think C
Automatic Clustering = Defining Clustering key ""All you need to do is define a clustering key for each table"" https://docs.snowflake.com/en/user-guide/tables-auto-reclustering",
Which privilege must be granted to a share to allow secure views the ability to reference data in multiple databases?,multiple-choice,A. CREATE_SHARE on the account,B. SHARE on databases and schemas,C. SELECT on tables used by the secure view,D. REFERENCE_USAGE on databases,,,,,,,,,,,,4,"https://docs.snowflake.com/en/user-guide/data-sharing-mutiple-db.html
https://docs.snowflake.com/en/user-guide/data-sharing-mutiple-db",
In which use case does Snowflake apply egress charges?,multiple-choice,A. Data sharing within a specific region,B. Query result retrieval,C. Database replication,D. Loading data into Snowflake,,,,,,,,,,,,3,"Answer is Database Replication
https://docs.snowflake.com/en/user-guide/cost-understanding-data-transfer.html",
Which of the following compute resources or features are managed by Snowflake? (Choose two.),multi-select,A. Execute a COPY command,B. Updating data,C. Snowpipe,D. AUTOMATIC_CLUSTERING,E. Scaling up a warehouse,,,,,,,,,,,"3, 4","CD are correct
https://docs.snowflake.com/en/user-guide/cost-understanding-compute.html#serverless-features
- Snowpipe uses Snowflake-supplied compute resources. - Automatic Clustering is the Snowflake service that seamlessly and continually manages all reclustering, as needed, of clustered tables.",
A materialized view should be created when which of the following occurs? (Choose two.),multi-select,A. There is minimal cost associated with running the query.,B. The query consumes many compute resources every time it runs.,C. The base table gets updated frequently.,D. The query is highly optimized and does not consume many compute resources.,E. The results of the query do not change often and are used frequently.,,,,,,,,,,,"2, 5","B&E https://docs.snowflake.com/en/user-guide/views-materialized.html#deciding-when-to-create-a-materialized-view
B and D is the right answer Create a materialized view when all of the following are true:  The query results from the view don’t change often. This almost always means that the underlying/base table for the view doesn’t change often, or at least that the subset of base table rows used in the materialized view don’t change often.  The results of the view are used often (typically significantly more often than the query results change).  The query consumes a lot of resources. Typically, this means that the query consumes a lot of processing time or credits, but it could also mean that the query consumes a lot of storage space for intermediate results.",
What privilege should a user be granted to change permissions for new objects in a managed access schema?,multiple-choice,A. Grant the OWNERSHIP privilege on the schema.,B. Grant the OWNERSHIP privilege on the database.,C. Grant the MANAGE GRANTS global privilege.,D. Grant ALL privileges on the schema.,,,,,,,,,,,,1,"It should be A because as both a & c answer are correct, the 'minimum' impacting option is Ownership
https://docs.snowflake.com/en/sql-reference/sql/create-schema CREATE SCHEMA  WITH MANAGED ACCESS Specifies a managed schema. Managed access schemas centralize privilege management with the schema owner.  In regular schemas, the owner of an object (i.e. the role that has the OWNERSHIP privilege on the object) can grant further privileges on their objects to other roles. In managed schemas, the schema owner manages all privilege grants, including future grants, on objects in the schema. Object owners retain the OWNERSHIP privileges on the objects; however, only the schema owner can manage privilege grants on the objects.",
What happens when a Data Provider revokes privileges to a share on an object in their source database?,multiple-choice,A. The object immediately becomes unavailable for all Data Consumers.,B. Any additional data arriving after this point in time will not be visible to Data Consumers.,C. The Data Consumers stop seeing data updates and become responsible for storage charges for the object.,D. A static copy of the object at the time the privilege was revoked is created in the Data Consumers account.,,,,,,,,,,,,1,"A is correct
Correct answer
Answer correct Revokes access privileges for databases and other supported database objects (schemas, tables, and views) from a share. Revoking privileges on these objects effectively removes the objects from the share, disabling access to the objects granted via the database role in all consumer accounts that have created a database from the share.",
Which command can be used to load data into an internal stage?,multiple-choice,A. LOAD,B. COPY,C. GET,D. PUT,,,,,,,,,,,,4,"D is the correct answer
Option D as per  https://docs.snowflake.com/en/user-guide/data-load-local-file-system-create-stage#types-of-internal-stages",
What is the MINIMUM Snowflake edition required to use the periodic rekeying of micro-partitions?,multiple-choice,A. Enterprise,B. Business Critical,C. Standard,D. Virtual Private Snowflake,,,,,,,,,,,,1,"Enterprise Edition Feature Periodic rekeying requires Enterprise Edition (or higher). To inquire about upgrading, please contact Snowflake Support  https://docs.snowflake.com/en/user-guide/security-encryption-manage.html#label-periodic-rekeying
Answer is Enterprise https://docs.snowflake.com/en/user-guide/security-encryption-manage.html#label-periodic-rekeying",
Which stage type can be altered and dropped?,multiple-choice,A. Database stage,B. External stage,C. Table stage,D. User stage,,,,,,,,,,,,2,"The answer is correct as we cannot drop the stage associated with a table or user; only named stages (internal or external) can be dropped.
https://docs.snowflake.com/en/user-guide/data-load-local-file-system-create-stage",
Which Snowflake object enables loading data from files as soon as they are available in a cloud storage location?,multiple-choice,A. Pipe,B. External stage,C. Task,D. Stream,,,,,,,,,,,,1,"I think A
A. https://docs.snowflake.com/en/user-guide/data-load-snowpipe-intro.html",
"A user is loading JSON documents composed of a huge array containing multiple records into Snowflake. The user enables the STRIP_OUTER_ARRAY file format option.

What does the STRIP_OUTER_ARRAY file format do?",multiple-choice,A. It removes the last element of the outer array.,B. It removes the outer array structure and loads the records into separate table rows.,C. It removes the trailing spaces in the last element of the outer array and loads the records into separate table columns.,D. It removes the NULL elements from the JSON object eliminating invalid data and enables the ability to load the records.,,,,,,,,,,,,2,"https://cloudyard.in/2021/05/snowflake-strip_outer_array-in-json/
STRIP_OUTER_ARRAY, Removes the outer set of square brackets [ ] when loading the data, separating the initial array into multiple lines",
Which of the following describes how multiple Snowflake accounts in a single organization relate to various cloud providers?,multiple-choice,A. Each Snowflake account can be hosted in a different cloud vendor and region.,B. Each Snowflake account must be hosted in a different cloud vendor and region.,C. All Snowflake accounts must be hosted in the same cloud vendor and region.,"D. Each Snowflake account can be hosted in a different cloud vendor, but must be in the same region.",,,,,,,,,,,,1,"I think A
The cloud platform you choose for each Snowflake account is completely independent from your other Snowflake accounts. In fact, you can choose to host each Snowflake account on a different platform, although this may have some impact on data transfer billing when loading data.  https://docs.snowflake.com/en/user-guide/intro-cloud-platforms.html",
"If a Snowflake user decides a table should be clustered, what should be used as the cluster key?",multiple-choice,A. The columns that are queried in the select clause.,B. The columns with very high cardinality.,C. The columns with many different values.,D. The columns most actively used in the select filters.,,,,,,,,,,,,4,"correct
D is correct answer.  Snowflake recommends prioritizing keys in the order below:  Cluster columns that are most actively used in selective filters. For many fact tables involved in date-based queries (for example “WHERE invoice_date > x AND invoice date <= y”), choosing the date column is a good idea. For event tables, event type might be a good choice, if there are a large number of different event types. (If your table has only a small number of different event types, then see the comments on cardinality below before choosing an event column as a clustering key.)  If there is room for additional cluster keys, then consider columns frequently used in join predicates, for example “FROM table1 JOIN table2 ON table2.column_A = table1.column_B”.
D correct",
What are value types that a VARIANT column can store? (Choose two.),multi-select,A. STRUCT,B. OBJECT,C. BINARY,D. ARRAY,E. CLOB,,,,,,,,,,,"2, 4","Answer : OBJECT and ARRAY
BD is correct.  https://docs.snowflake.com/en/sql-reference/data-types-semistructured",
"A company needs to read multiple terabytes of data for an initial load as part of a Snowflake migration. The company can control the number and size of CSV extract files.

How does Snowflake recommend maximizing the load performance?",multiple-choice,A. Use auto-ingest Snowpipes to load large files in a serverless model.,"B. Produce the largest files possible, reducing the overall number of files to process.",C. Produce a larger number of smaller files and process the ingestion with size Small virtual warehouses.,D. Use an external tool to issue batched row-by-row inserts within BEGIN TRANSACTION and COMMIT commands.,,,,,,,,,,,,3,"c i think  https://www.analytics.today/blog/top-3-snowflake-performance-tuning-tactics#:~:text=Avoid%20Scanning%20Files&text=Before%20copying%20data%2C%20Snowflake%20checks,that%20have%20already%20been%20loaded.
https://www.snowflake.com/blog/best-practices-for-data-ingestion/ I think A is correct",
"For non-materialized views, what column in Information Schema and Account Usage identifies whether a view is secure or not?",multiple-choice,A. CHECK_OPTION,B. IS_SECURE,C. IS_UPDATEABLE,D. TABLE_NAME,,,,,,,,,,,,2,"correct
https://docs.snowflake.com/en/user-guide/views-secure#determining-if-a-view-is-secure
Answer is correct",
The bulk data load history that is available upon completion of the COPY statement is stored where and for how long?,multiple-choice,A. In the metadata of the target table for 14 days,B. In the metadata of the pipe for 14 days,C. In the metadata of the target table for 64 days,D. In the metadata of the pipe for 64 days,,,,,,,,,,,,3,"Correct Answer : C https://docs.snowflake.com/en/user-guide/data-load-snowpipe-intro.html#load-history
Bulk data load Stored in the metadata of the target table for 64 days. Available upon completion of the COPY statement as the statement output.  https://docs.snowflake.com/en/user-guide/data-load-snowpipe-intro.html#load-history",
"User INQUISITIVE_PERSON has been granted the role DATA_SCIENCE. The role DATA_SCIENCE has privileges OWNERSHIP on the schema MARKETING of the database ANALYTICS_DW.

Which command will show all privileges granted to that schema?",multiple-choice,A. SHOW GRANTS ON ROLE DATA_SCIENCE,B. SHOW GRANTS ON SCHEMA ANALYTICS_DW.MARKETING,C. SHOW GRANTS TO USER INQUISITIVE_PERSON,D. SHOW GRANTS OF ROLE DATA_SCIENCE,,,,,,,,,,,,2,"correct
SHOW GRANTS ON DATABASE, WAREHOUSE, SCHEMA name
https://docs.snowflake.com/en/sql-reference/sql/show-grants#variants",
Which of the following are characteristics of security in Snowflake?,multiple-choice,A. Account and user authentication is only available with the Snowflake Business Critical edition.,B. Support for HIPAA and GDPR compliance is available for UI Snowflake editions.,C. Periodic rekeying of encrypted data is available with the Snowflake Enterprise edition and higher,D. Private communication to internal stages is allowed in the Snowflake Enterprise edition and higher.,,,,,,,,,,,,3,"Correct
https://docs.snowflake.com/en/user-guide/intro-editions.html",
Which of the following objects can be shared through secure data sharing?,multiple-choice,A. Masking policy,B. Stored procedure,C. Task,D. External table,,,,,,,,,,,,4,The following Snowflake database objects can be shared:  Tables External tables Secure views Secure materialized views Secure UDFs,
Which formats does Snowflake store unstructured data in? (Choose two.),multi-select,A. GeoJSON,B. Array,C. XML,D. Object,E. BLOB,,,,,,,,,,,"2, 4","Answer is B & D
I am very confusion about this question. Because I read the information that  Unstructured data is information that does not fit into a predefined data model or schema. https://docs.snowflake.com/en/user-guide/unstructured-intro.html#sql-functions.",
"A user is preparing to load data from an external stage.

Which practice will provide the MOST efficient loading performance?",multiple-choice,A. Organize files into logical paths,B. Store the files on the external stage to ensure caching is maintained,C. Use pattern matching for regular expression execution,D. Load the data in one large file,,,,,,,,,,,,1,"Both internal (i.e. Snowflake) and external (Amazon S3, Google Cloud Storage, or Microsoft Azure) stage references can include a path (or prefix in AWS terminology). When staging regular data sets, we recommend partitioning the data into logical paths that include identifying details such as geographical location or other source identifiers, along with the date when the data was written.  Organizing your data files by path lets you copy any fraction of the partitioned data into Snowflake with a single command. This allows you to execute concurrent COPY statements that match a subset of files, taking advantage of parallel operations.  https://docs.snowflake.com/en/user-guide/data-load-considerations-stage.html#organizing-data-by-path
https://docs.snowflake.com/en/user-guide/data-load-considerations-stage.html#organizing-data-by-path",
What effect does WAIT_FOR_COMPLETION = TRUE have when running an ALTER WAREHOUSE command and changing the warehouse size?,multiple-choice,A. The warehouse size does not change until all queries currently running in the warehouse have completed.,B. The warehouse size does not change until all queries currently in the warehouse queue have completed.,C. The warehouse size does not change until the warehouse is suspended and restarted.,D. It does not return from the command until the warehouse has finished changing its size.,,,,,,,,,,,,4,"WAIT_FOR_COMPLETION = FALSE | TRUE When resizing a warehouse, you can use this parameter to block the return of the ALTER WAREHOUSE command until the resize has finished provisioning all its compute resources. Blocking the return of the command when resizing to a larger warehouse serves to notify you that your compute resources have been fully provisioned and the warehouse is now ready to execute queries using all the new resources.  https://docs.snowflake.com/en/sql-reference/sql/alter-warehouse.html
correct To block the immediate return of the ALTER WAREHOUSE command until the resize is complete, add the WAIT_FOR_COMPLETION parameter. https://docs.snowflake.com/en/sql-reference/sql/alter-warehouse",
Which of the following can be used when unloading data from Snowflake? (Choose two.),multi-select,"A. When unloading semi-structured data, it is recommended that the STRIP_OUTER_ARRAY option be used.",B. Use the ENCODING file format option to change the encoding from the default UTF-8.,C. The OBJECT_CONSTRUCT function can be used to convert relational data to semi-structured data.,"D. By using the SINGLE = TRUE parameter, a single file up to 5 GB in size can be exported to the storage layer.",E. Use the PARSE_JSON function to ensure structured data will be unloaded into the VARIANT data type.,,,,,,,,,,,"3, 4","correct
https://docs.snowflake.com/en/user-guide/data-unload-considerations.html
Specifically mentioned in Snowflake Documentation: ""Output files are always encoded using UTF-8, regardless of the file format; no other character sets are supported."" https://docs.snowflake.com/en/user-guide/intro-summary-unloading#:~:text=File%20encoding,sets%20are%20supported.",
What data is stored in the Snowflake storage layer? (Choose two.),multi-select,A. Snowflake parameters,B. Micro-partitions,C. Query history,D. Persisted query results,E. Standard and secure view results,,,,,,,,,,,"2, 3","B. Micro-partitions C. Query history (also stored in the data layer of SNOWFLAKE.USAGE_SCHEMA)
B & D. https://www.snowflake.com/data-cloud-glossary/data-storage/",
"A data provider wants to share data with a consumer who does not have a Snowflake account. The provider creates a reader account for the consumer following these steps:

1. Created a user called ""CONSUMER""
2. Created a database to hold the share and an extra-small warehouse to query the data
3. Granted the role PUBLIC the following privileges: Usage on the warehouse, database, and schema, and SELECT on all the objects in the share

Based on this configuration what is true of the reader account?",multiple-choice,A. The reader account will automatically use the Standard edition of Snowflake.,B. The reader account compute will be billed to the provider account.,"C. The reader account can clone data the provider has shared, but cannot re-share it.",D. The reader account can create a copy of the shared data using CREATE TABLE AS...,,,,,,,,,,,,2,"Answer is B: https://docs.snowflake.com/en/user-guide/data-sharing-reader-create.html#overview
the user has not a snowflake account, so the user compute will be billed to provider accoutn",
Which of the following activities consume virtual warehouse credits in the Snowflake environment? (Choose two.),multi-select,A. Caching query results,B. Running EXPLAIN and SHOW commands,C. Cloning a database,D. Running a custom query,E. Running COPY commands,,,,,,,,,,,"4, 5","https://docs.snowflake.com/en/user-guide/warehouses.html
A warehouse provides the required resources, such as CPU, memory, and temporary storage, to perform the following operations in a Snowflake session:  Executing SQL SELECT statements that require compute resources (e.g. retrieving rows from tables and views).  Performing DML operations, such as:  Updating rows in tables (DELETE , INSERT , UPDATE).  Loading data into tables (COPY INTO <table>).  Unloading data from tables (COPY INTO <location>).  Note - To perform these operations, a warehouse must be running and in use for the session. While a warehouse is running, it consumes Snowflake credits.  https://docs.snowflake.com/en/user-guide/warehouses.html",
"When loading data into Snowflake, the COPY command supports which of the following?",multiple-choice,A. Joins,B. Filters,C. Column reordering,D. Aggregates,,,,,,,,,,,,3,"https://docs.snowflake.com/en/user-guide/data-load-transform.html#reorder-csv-columns-during-a-load
Verified",
What is cached during a query on a virtual warehouse?,multiple-choice,A. All columns in a micro-partition,B. Any columns accessed during the query,C. The columns in the result set of the query,D. All rows accessed during the query,,,,,,,,,,,,2,"In Snowflake, micro-partitions are the fundamental unit of data storage. They contain a subset of columns from the table and are compressed and encoded for efficient storage and query processing.  When a query is executed on a virtual warehouse in Snowflake, only the micro-partitions containing the columns accessed during the query are cached. This approach optimizes caching resources by storing only the necessary data for the query, rather than caching all columns or all rows.
https://billigence.com/blog/snowflake-data-caching/ . There is no clear explanation from Snowflake on this. But this site tells that the entire Micro Partition accessed is cached. In that case Option A (All Columns from a Micropartition) is correct.   ""The query will use all of the micro-partitions, which means neither the first or second query are actually pruning any micro-partitions in your table scan. It’s important to understand that the cache is made up of the entire micro-partitions that were fetched and not just the records that were selected in the first query""
If I consider the sequence of the data scan: 1. according to the select command, find the specific columns, it means all columns accessed 2.according to the micro-partition metadata, find all micro partition that potentially have the values I needed. it means ALL rows in all the eligible micro-partitions. 3. get the rows I needed as the final results 4. cached it. If it is work in this way, I guess the B is better than D as the final result cache may not include all rows accessed in step 2.
B is correct.  Each warehouse, when running, maintains a cache of table data accessed as queries are processed by the warehouse. https://docs.snowflake.com/en/user-guide/warehouses-considerations",
What is the default character set used when loading CSV files into Snowflake?,multiple-choice,A. UTF-8,B. UTF-16,C. ISO 8859-1,D. ANSI_X3.4,,,,,,,,,,,,1,"Verified
For delimited files (CSV, TSV, etc.), the default character set is UTF-8.  https://docs.snowflake.com/en/user-guide/intro-summary-loading.html",
Which of the following describes external functions in Snowflake?,multiple-choice,A. They are a type of User-defined Function (UDF).,B. They contain their own SQL code.,C. They call code that is stored inside of Snowflake.,D. They can return multiple rows for each row received.,,,,,,,,,,,,1,"A correct An external function is a type of UDF. Unlike other UDFs, an external function does not contain its own code; instead, the external function calls code that is stored and executed outside Snowflake
A https://docs.snowflake.com/en/sql-reference/external-functions-introduction.html",
Which of the following are valid methods for authenticating users for access into Snowflake? (Choose three.),multi-select,A. SCIM,B. Federated authentication,C. TLS 1.2,D. Key-pair authentication,E. OAuth,F. OCSP authentication,,,,,,,,,,"2, 4, 5","Sorry, answer is B,D and E https://docs.snowflake.com/en/user-guide/authentication.html
SCIM nothing to do with user authentication so B,D,E",
"A user has a standard multi-cluster warehouse auto-scaling policy in place.

Which condition will trigger a cluster to shut-down?",multiple-choice,A. When after 2-3 consecutive checks the system determines that the load on the most-loaded cluster could be redistributed.,B. When after 5-6 consecutive checks the system determines that the load on the most-loaded cluster could be redistributed.,C. When after 5-6 consecutive checks the system determines that the load on the least-loaded cluster could be redistributed.,D. When after 2-3 consecutive checks the system determines that the load on the least-loaded cluster could be redistributed.,,,,,,,,,,,,4,"https://hevodata.com/learn/snowflake-scaling-policy/#:~:text=Every%20minute%2C%20the%20system%20checks,1%20every%202%2D3%20minutes.
Answer D bcos it clearly says Standard
After 2 to 3 consecutive successful checks (performed at 1 minute intervals), which determine whether the load on the least-loaded cluster could be redistributed to the other clusters without spinning up the cluster again.  https://docs.snowflake.com/en/user-guide/warehouses-multicluster.html
Answer Correct https://docs.snowflake.com/en/user-guide/warehouses-multicluster.html#:~:text=The%20scaling%20policy%20for%20a%20multi%2Dcluster%20warehouse%20only%20applies,or%20shut%20down%20individual%20clusters.&text=Prevents%2Fminimizes%20queuing%20by%20favoring%20starting%20additional%20clusters%20over%20conserving%20credits.",
What is the minimum Snowflake edition needed for database failover and fail-back between Snowflake accounts for business continuity and disaster recovery?,multiple-choice,A. Standard,B. Enterprise,C. Business Critical,D. Virtual Private Snowflake,,,,,,,,,,,,3,"answer is C Business Critical https://docs.snowflake.com/en/user-guide/replication-intro.html#business-continuity-and-disaster-recovery
Requires Business Critical (or higher). https://docs.snowflake.com/en/user-guide/database-failover-config.html#failing-over-databases-across-multiple-accounts",
How would a user execute a series of SQL statements using a task?,multiple-choice,A. Include the SQL statements in the body of the task CREATE TASK mytask .. AS INSERT INTO target1 SELECT .. FROM stream_s1 WHERE .. INSERT INTO target2 SELECT .. FROM stream_s1 WHERE ..,B. A stored procedure can have only one DML statement per stored procedure invocation and therefore the user should sequence stored procedure calls in the task definition CREATE TASK mytask .... AS call stored_proc1(); call stored_proc2();,C. Use a stored procedure executing multiple SQL statements and invoke the stored procedure from the task. CREATE TASK mytask .... AS call stored_proc_multiple_statements_inside();,"D. Create a task for each SQL statement (e.g. resulting in task1, task2, etc.) and string the series of SQL statements by having a control task calling task1, task2, etc. sequentially.",,,,,,,,,,,,3,"C is the answer
https://community.snowflake.com/s/question/0D53r00009kC6WhCAK/can-a-task-have-multiple-sql-queries  C is the answer",
How many resource monitors can be assigned at the account level?,multiple-choice,A. 1,B. 2,C. 3,D. 4,,,,,,,,,,,,1,"An account monitor monitors the credit usage of all the warehouses in the account. An account can only have one account monitor.  A warehouse monitor monitors the credit usage of the warehouses assigned to the resource monitor. An account can have multiple warehouse monitors.  A warehouse monitor can have one or more warehouses assigned to it, but each warehouse can only be assigned to one resource monitor.
A https://docs.snowflake.com/en/user-guide/resource-monitors
A single monitor can be set at the account level to control credit usage for all warehouses in your account.  https://docs.snowflake.com/en/user-guide/resource-monitors.html#monitor-level
https://docs.snowflake.com/en/user-guide/resource-monitors.html",
Data storage for individual tables can be monitored using which commands and/or objects? (Choose two.),multi-select,A. SHOW STORAGE BY TABLE;,B. SHOW TABLES;,C. Information Schema -> TABLE_HISTORY,D. Information Schema -> TABLE_FUNCTION,E. Information Schema -> TABLE_STORAGE_METRICS,,,,,,,,,,,"2, 5","B. SHOW TABLES E. TABLE_STORAGE_METRICS  These two options will show bytes stored. https://docs.snowflake.com/en/sql-reference/sql/show-tables.html https://docs.snowflake.com/en/sql-reference/info-schema/table_storage_metrics.html
B,E is the right answer",
How would a user run a multi-cluster warehouse in maximized mode?,multiple-choice,"A. Configure the maximum clusters setting to ""Maximum.""",B. Turn on the additional clusters manually after starting the warehouse.,C. Set the minimum Clusters and maximum Clusters settings to the same value.,D. Set the minimum clusters and maximum clusters settings to different values.,,,,,,,,,,,,3,"It is C.  If min=max, there is no room for increasing any clusters and min and max would be same. Hence same value for maximized mode. If min < max then there is room for more clusters to go up till max, hence best for scaling.",
What internal stages are available in Snowflake? (Choose three.),multi-select,A. Schema stage,B. Named stage,C. User stage,D. Stream stage,E. Table stage,F. Database stage,,,,,,,,,,"2, 3, 5","It should be BCE  User stage, Table Stage and Named stage are internal stages of snowflake
See: https://docs.snowflake.com/en/user-guide/data-load-local-file-system-create-stage",
Which stages are used with the Snowflake PUT command to upload files from a local file system? (Choose three.),multi-select,A. Schema Stage,B. User Stage,C. Database Stage,D. Table Stage,E. External Named Stage,F. Internal Named Stage,,,,,,,,,,"2, 4, 6","BDF is right one.  User stage, Table Stage and named internal staged
https://docs.snowflake.com/en/sql-reference/sql/put.html",
Which data type can store more than one type of data structure?,multiple-choice,A. JSON,B. BINARY,C. VARCHAR,D. VARIANT,,,,,,,,,,,,4,"D. VARIANT
variant",
User-level network policies can be created by which of the following roles? (Choose two.),multi-select,A. ROLEADMIN,B. ACCOUNTADMIN,C. SYSADMIN,D. SECURITYADNIN,E. USERADMIN,,,,,,,,,,,"2, 4","B & D is right.  https://docs.snowflake.com/en/sql-reference/ddl-user-security.html
Only security administrators (i.e. users with the SECURITYADMIN role) or higher or a role with the global CREATE NETWORK POLICY privilege can create network policies. Ownership of a network policy can be transferred to another role.  https://docs.snowflake.com/en/user-guide/network-policies.html#:~:text=A%20security%20administrator%20(or%20higher,any%20number%20of%20network%20policies.",
What SQL command would be used to view all roles that were granted to USER1?,multiple-choice,A. show grants to user USER1;,B. show grants user USER1;,C. describe user USER1;,D. show grants on user USER1;,,,,,,,,,,,,1,"A  https://docs.snowflake.com/en/sql-reference/sql/show-grants.html#variants
https://docs.snowflake.com/en/sql-reference/sql/show-grants.html#variants SHOW GRANTS TO ROLE role_name Lists all privileges and roles granted to the role.",
Which ACCOUNT_USAGE views are used to evaluate the details of dynamic data masking? (Choose two.),multi-select,A. ROLES,B. POLICY_REFERENCES,C. QUERY_HISTORY,D. RESOURCE_MONITORS,E. ACCESS_HISTORY,F. MASKING_POLICIES,,,,,,,,,,"2, 6","Snowflake provides two Account Usage views to obtain information about masking policies: 1. The MASKING POLICIES view provides a list of all masking policies in your Snowflake account. 2. The POLICY_REFERENCES view provides a list of all objects in which a masking policy is set.  https://docs.snowflake.com/en/user-guide/security-column-ddm-intro.html
B & F. https://docs.snowflake.com/en/user-guide/security-column-ddm-intro.html",
Which of the following are considerations when using a directory table when working with unstructured data? (Choose two.),multi-select,A. A directory table is a separate database object.,B. Directory tables store data file metadata.,C. A directory table will be automatically added to a stage.,D. Directory tables do not have their own grantable privileges.,E. Directory table data can not be refreshed manually.,,,,,,,,,,,"2, 4","BD are correct
B and D https://docs.snowflake.com/en/user-guide/data-load-dirtables-intro
Answer is correct https://docs.snowflake.com/en/user-guide/data-load-dirtables.html",
"The first user assigned to a new account, ACCOUNTADMIN, should create at least one additional user with which administrative privilege?",multiple-choice,A. USERADMIN,B. PUBLIC,C. ORGADMIN,D. SYSADMIN,,,,,,,,,,,,1,"A:UserAdmin https://docs.snowflake.com/en/user-guide/security-access-control-considerations.html#using-the-accountadmin-role By default, when your account is provisioned, the first user is assigned the ACCOUNTADMIN role. This user should then create one or more additional users who are assigned the USERADMIN role. All remaining users should be created by the user(s) with the USERADMIN role or another role that is granted the global CREATE USER privilege
Answer A https://docs.snowflake.com/en/user-guide/security-access-control-considerations.html#",
Which statement describes how Snowflake supports reader accounts?,multiple-choice,A. A reader account can consume data from the provider account that created it and combine it with its own data.,B. A consumer needs to become a licensed Snowflake customer as data sharing is only supported between Snowflake accounts.,C. The users in a reader account can query data that has been shared with the reader account and can perform DML tasks.,D. The SHOW MANAGED ACCOUNTS command will view all the reader accounts that have been created for an account.,,,,,,,,,,,,4,"D is correct https://docs.snowflake.com/en/sql-reference/sql/show-managed-accounts.html
D https://docs.snowflake.com/en/user-guide/data-sharing-reader-create#viewing-reader-accounts",
How does Snowflake allow a data provider with an Azure account in central Canada to share data with a data consumer on AWS in Australia?,multiple-choice,"A. The data provider in Azure Central Canada can create a direct share to AWS Asia Pacific, if they are both in the same organization.",B. The data consumer and data provider can form a Data Exchange within the same organization to create a share from Azure Central Canada to AWS Asia Pacific.,C. The data provider uses the GET DATA workflow in the Snowflake Data Marketplace to create a share between Azure Central Canada and AWS Asia Pacific.,D. The data provider must replicate the database to a secondary account in AWS Asia Pacific within the same organization then create a share to the data consumer's account,,,,,,,,,,,,4,"Answer-- D https://docs.snowflake.com/en/user-guide/secure-data-sharing-across-regions-plaforms.html
I think answer is D, please confirm",
Which Snowflake objects can be shared with other Snowflake accounts? (Choose three.),multi-select,A. Schemas,B. Roles,C. Secure Views,D. Stored Procedures,E. Tables,F. Secure User-Defined Functions (UDFs),,,,,,,,,,"3, 5, 6","Answer : Tables, Secure Views and Secure UDFs  https://docs.snowflake.com/en/user-guide/data-sharing-intro.html
The following Snowflake database objects can be shared: Tables External tables Secure views Secure materialized views Secure UDFs  https://docs.snowflake.com/en/user-guide/data-sharing-intro.html",
Which Snowflake feature will allow small volumes of data to continuously load into Snowflake and will incrementally make the data available for analysis?,multiple-choice,A. COPY INTO,B. CREATE PIPE,C. INSERT INTO,D. TABLE STREAM,,,,,,,,,,,,2,"correct
Answer is correct CREATE PIPE
PIPE for sure... keyword "" continuously""",
Which Snowflake partner specializes in data catalog solutions?,multiple-choice,A. Alation,B. DataRobot,C. dbt,D. Tableau,,,,,,,,,,,,1,"To prepare for this kind of questions, we have to remember the entire list of ecosystem? That’s so absurd….
https://docs.snowflake.com/en/user-guide/ecosystem-all.html",
Which of the following can be executed/called with Snowpipe?,multiple-choice,A. A User Defined Function (UDF),B. A stored procedure,C. A single COPY_INTO statement,D. A single INSERT_INTO statement,,,,,,,,,,,,3,"correct
I think C  https://docs.snowflake.com/en/sql-reference/sql/create-pipe.html
Shoud be D? https://docs.snowflake.com/en/user-guide/data-load-snowpipe-intro.html#snowpipe-ddl",
Which snowflake objects will incur both storage and cloud compute charges? (Choose two.),multi-select,A. Materialized view,B. Sequence,C. Secure view,D. Transient table,E. Clustered table,,,,,,,,,,,"1, 5",I think it is A and E. Clustered table needs to undergo clustering as the data changes and Materialized view also undergoes changes every time the underlying data changes or when the view is set to refresh.,
What file formats does Snowflake support for loading semi-structured data? (Choose three.),multi-select,A. TSV,B. JSON,C. PDF,D. Avro,E. Parquet,F. JPEG,,,,,,,,,,"2, 4, 5","correct
Snowflake can import semi-structured data from JSON, Avro, ORC, Parquet, and XML formats and store it in Snowflake data types designed specifically to support semi-structured data.  And it stores in Array, Object, and Variant formats   https://docs.snowflake.com/en/user-guide/semistructured-intro.html#:~:text=Snowflake%20can%20import%20semi%2Dstructured,to%20support%20semi%2Dstructured%20data.
Sorry for typo, it is B D E",
Which of the following statements about data sharing are true? (Choose two.),multi-select,A. New objects created by a Data Provider are automatically shared with existing Data Consumers and Reader Accounts.,B. All database objects can be included in a shared database.,C. Reader Accounts are created by Data Providers.,D. Shared databases are read-only.,E. Reader Accounts are charged for warehouse usage.,,,,,,,,,,,"3, 4","Answer : C and D
https://docs.snowflake.com/en/user-guide/ui-snowsight-private-sharing-reader-accounts.html",
Credit charges for Snowflake virtual warehouses are calculated based on which of the following considerations? (Choose two.),multi-select,A. The number of queries executed,B. The number of active users assigned to the warehouse,C. The size of the virtual warehouse,D. The length of time the warehouse is running,E. The duration of the queries that are executed,,,,,,,,,,,"3, 4","CD Snowflake credits are charged based on the number of virtual warehouses you use, how long they run, and their size.",
Which of the following are handled by the cloud services layer of the Snowflake architecture? (Choose two.),multi-select,A. Query execution,B. Data loading,C. Time Travel data,D. Security,E. Authentication and access control,,,,,,,,,,,"4, 5","D ^ E is right
all the rest are not mentioned as a cloud services service https://docs.snowflake.com/en/user-guide/intro-key-concepts.html",
What features does Snowflake Time Travel enable?,multiple-choice,A. Querying data-related objects that were created within the past 365 days,B. Restoring data-related objects that have been deleted within the past 90 days,C. Conducting point-in-time analysis for BI reporting,D. Analyzing data usage/manipulation over all periods of time,,,,,,,,,,,,2,"B is right
Snowflake Time Travel enables accessing historical data (i.e. data that has been changed or deleted) at any point within a defined period. It serves as a powerful tool for performing the following tasks:   Restoring data-related objects (tables, schemas, and databases) that might have been accidentally or intentionally deleted.   Duplicating and backing up data from key points in the past.   Analyzing data usage/manipulation over specified periods of time.",
Which of the following statements describes a schema in Snowflake?,multiple-choice,A. A logical grouping of objects that belongs to a single database,B. A logical grouping of objects that belongs to multiple databases,C. A named Snowflake object that includes all the information required to share a database,D. A uniquely identified Snowflake account within a business entity,,,,,,,,,,,,1,"A is correct
A is correct answer",
What is the recommended compressed file size range for continuous data loads using Snowpipe?,multiple-choice,A. 8-16 MB,B. 16-24 MB,C. 10-99 MB,D. 100-250 MB,,,,,,,,,,,,4,"Snowpipe is typically used to load data that is arriving continuously. File sizing plays an important role in Snowpipe's performance. The recommended file size for data loading is 100-250MB compressed, however, if data is arriving continuously, then try to stage the data within one-minute intervals.",
How long is Snowpipe data load history retained?,multiple-choice,A. As configured in the CREATE PIPE settings,B. Until the pipe is dropped,C. 64 days,D. 14 days,,,,,,,,,,,,4,"When a pipe is paused, event messages received for the pipe enter a limited retention period. The period is 14 days by default. If a pipe is paused for longer than 14 days, it is considered stale.
https://docs.snowflake.com/en/sql-reference/functions/pipe_usage_history.html",
"A company strongly encourages all Snowflake users to self-enroll in Snowflake's default Multi-Factor Authentication (MFA) service to provide increased login security for users connecting to Snowflake.

Which application will the Snowflake users need to install on their devices in order to connect with MFA?",multiple-choice,A. Okta Verify,B. Duo Mobile,C. Microsoft Authenticator,D. Google Authenticator,,,,,,,,,,,,2,"https://docs.snowflake.com/en/user-guide/ui-preferences.html#:~:text=Enrolling%20in%20MFA%20(Multi%2DFactor%20Authentication),-MFA%20is%20a&text=This%20second%20form%20of%20authentication,smart%20phone%20or%20similar%20device.
https://docs.snowflake.com/en/user-guide/security-mfa.html",
Which URL type allows users to access unstructured data without authenticating into Snowflake or passing an authorization token?,multiple-choice,A. Pre-signed URL,B. Scoped URL,C. Signed URL,D. File URL,,,,,,,,,,,,1,"Pre-signed URLs are used to download or access files, via a web browser for example, without authenticating into Snowflake or passing an authorization token. These URLs are ideal for business intelligence applications or reporting tools that need to display the unstructured file contents.
https://docs.snowflake.com/en/sql-reference/functions/get_presigned_url.html",
Where would a Snowflake user find information about query activity from 90 days ago?,multiple-choice,A. account_usage.query_history view,B. account_usage.query_history_archive view,C. information_schema.query_history view,D. information_schema.query_history_by_session view,,,,,,,,,,,,1,"https://docs.snowflake.com/en/sql-reference/account-usage/query_history.html
https://docs.snowflake.com/en/sql-reference/account-usage/query_history",
"A marketing co-worker has requested the ability to change a warehouse size on their medium virtual warehouse called MKTG_WH.

Which of the following statements will accommodate this request?",multiple-choice,A. ALLOW RESIZE ON WAREHOUSE MKTG_WH TO USER MKTG_LEAD;,B. GRANT MODIFY ON WAREHOUSE MKTG_WH TO ROLE MARKETING;,C. GRANT MODIFY ON WAREHOUSE MKTG_WH TO USER MKTG_LEAD;,D. GRANT OPERATE ON WAREHOUSE MKTG_WH TO ROLE MARKET;,,,,,,,,,,,,2,"https://docs.snowflake.com/en/sql-reference/sql/grant-privilege.html
Answer is B  https://docs.snowflake.com/en/user-guide/security-access-control-privileges  MODIFY  Enables altering any properties of a warehouse, including changing its size. Required to assign a warehouse to a resource monitor. Note that only the ACCOUNTADMIN role can assign warehouses to resource monitors. OPERATE  Enables changing the state of a warehouse (stop, start, suspend, resume). In addition, enables viewing current and past queries executed on a warehouse and aborting any executing queries.",
Which of the following commands cannot be used within a reader account?,multiple-choice,A. CREATE SHARE,B. ALTER WAREHOUSE,C. DROP ROLE,D. SHOW SCHEMAS,E. DESCRIBE TABLE,,,,,,,,,,,1,"https://docs.snowflake.com/en/user-guide/data-sharing-reader-create.html#what-is-restricted-allowed-in-a-reader-account
A. CREATE SHARE  In Snowflake, a reader account is a special type of user account that has read-only access to data in Snowflake. This means that reader accounts can only perform actions that are related to querying data, such as running SELECT statements and viewing metadata.  As a result, reader accounts cannot perform actions that modify the data or metadata stored in Snowflake, such as creating new objects, modifying existing objects, or dropping objects. This includes the CREATE SHARE command, which is used to create a new share and make it available to other users.  The other commands listed (ALTER WAREHOUSE, DROP ROLE, SHOW SCHEMAS, and DESCRIBE TABLE) are all allowed within reader accounts and can be used to query metadata and data stored in Snowflake.",
Which TABLE function helps to convert semi-structured data to a relational representation?,multiple-choice,A. CHECK_JSON,B. TO_JSON,C. FLATTEN,D. PARSE_JSON,,,,,,,,,,,,3,"Answer : C https://docs.snowflake.com/en/sql-reference/functions/flatten.html
It should be C",
Which query profile statistics help determine if efficient pruning is occurring? (Choose two.),multi-select,A. Bytes sent over network,B. Percentage scanned from cache,C. Partitions total,D. Bytes spilled to local storage,E. Partitions scanned,,,,,,,,,,,"3, 5","https://docs.snowflake.com/en/user-guide/ui-query-profile.html#inefficient-pruning
The efficiency of pruning can be observed by comparing Partitions scanned and Partitions total statistics in the TableScan operators. If the former is a small fraction of the latter, pruning is efficient. If not, the pruning did not have an effect.",
What are the default Time Travel and Fail-safe retention periods for transient tables?,multiple-choice,"A. Time Travel - 1 day, Fail-safe - 1 day","B. Time Travel - 0 days, Fail-safe - 1 day","C. Time Travel - 1 day, Failsafe - 0 days",D. Transient tables are retained in neither Fail-safe nor Time Travel.,,,,,,,,,,,,3,"Transient tables can have a Time Travel retention period of either 0 or 1 day.  Temporary tables can also have a Time Travel retention period of 0 or 1 day; however, this retention period ends as soon as the table is dropped or the session in which the table was created ends.  Transient and temporary tables have no Fail-safe period.
https://docs.snowflake.com/en/user-guide/tables-temp-transient.html#comparison-of-table-types",
Which command is used to unload data from a Snowflake table into a file in a stage?,multiple-choice,A. COPY INTO,B. GET,C. WRITE,D. EXTRACT INTO,,,,,,,,,,,,1,"A is correct
A. COPY INTO  In Snowflake, the ""COPY INTO"" command is used to unload data from a Snowflake table into a file in a stage. The stage acts as an intermediate storage location for the unloaded data, and the data can then be transferred to an external storage location such as Amazon S3 or Microsoft Azure Blob Storage.  The syntax for the ""COPY INTO"" command is as follows:  COPY INTO [table_name] FROM [stage_name] FILE_FORMAT = [file_format];  Where [table_name] is the name of the Snowflake table from which data is being unloaded, [stage_name] is the name of the stage where the unloaded data is stored, and [file_format] is the format of the unloaded data files (such as CSV or Parquet).
As illustrated in the diagram below, unloading data to a local file system is performed in two, separate steps:  Step 1 Use the COPY INTO <location> command to copy the data from the Snowflake database table into one or more files in a Snowflake stage. In the SQL statement, you specify the stage (named stage or table/user stage) where the files are written.  Regardless of the stage you use, this step requires a running, current virtual warehouse for the session if you execute the command manually or within a script. The warehouse provides the compute resources to write rows from the table.  Step 2 Use the GET command to download the data files to your local file system.  https://docs.snowflake.com/en/user-guide/data-unload-snowflake.html",
What are advantages clones have over tables created with CREATE TABLE AS SELECT statement? (Choose two.),multi-select,A. The clone always stays in sync with the original table.,B. The clone has better query performance.,C. The clone is created almost instantly.,D. The clone will have time travel history from the original table.,E. The clone saves space by not duplicating storage.,,,,,,,,,,,"3, 5","CD - correct answers. The question ask about the advantage of clones OVER tables created with a statement CREATE TABLE AS SELECT ... Both tables (clone and the one created with the statement) do not copy the underlaying data, so there is NO advantage of a clone over the other table.
C and E are correct.
C,E are correct
I am going for D&E after going through https://docs.snowflake.com/en/sql-reference/sql/create-clone may be D option is hinting towards creation time of clone it will copy data from time travel",
How often are the Account and Table master keys automatically rotated by Snowflake?,multiple-choice,A. 30 Days,B. 60 Days,C. 90 Days,D. 365 Days.,,,,,,,,,,,,1,"All Snowflake-managed keys are automatically rotated by Snowflake when they are more than 30 days old.
https://docs.snowflake.com/en/user-guide/security-encryption-manage Encryption Key Rotation  All Snowflake-managed keys are automatically rotated by Snowflake when they are more than 30 days old. Active keys are retired, and new keys are created. When Snowflake determines the retired key is no longer needed, the key is automatically destroyed. When active, a key is used to encrypt data and is available for usage by the customer. When retired, the key is used solely to decrypt data and is only available for accessing the data.",
Which privilege is required for a role to be able to resume a suspended warehouse if auto-resume is not enabled?,multiple-choice,A. USAGE,B. OPERATE,C. MONITOR,D. MODIFY,,,,,,,,,,,,2,"B is correct
b correct
OPERATE: Enables changing the state of a warehouse (stop, start, suspend, resume). In addition, enables viewing current and past queries executed on a warehouse and aborting any executing queries. https://docs.snowflake.com/en/user-guide/security-access-control-privileges.html#virtual-warehouse-privileges",
Which statement MOST accurately describes clustering in Snowflake?,multiple-choice,A. The database ACCOUNTADMIN must define the clustering methodology for each Snowflake table.,B. Clustering is the way data is grouped together and stored within Snowflake micro-partitions.,C. The clustering key must be included in the COPY command when loading data into Snowflake.,D. Clustering can be disabled within a Snowflake account.,,,,,,,,,,,,2,"B is correct
B is the most accurate statement about clustering.
I guess it is B, but I am happy, if someone can confirm or deny! (P.S. sorry for my bad englisch!)",
Which of the following practices are recommended when creating a user in Snowflake? (Choose two.),multi-select,A. Configure the user to be initially disabled.,B. Force an immediate password change.,C. Set a default role for the user.,D. Set the number of minutes to unlock to 15 minutes.,E. Set the user's access to expire within a specified timeframe.,,,,,,,,,,,"2, 3","The answer is B,C https://docs.snowflake.com/en/user-guide/admin-user-management.html#creating-users
B and not sure what else https://docs.snowflake.com/en/user-guide/admin-user-management.html#best-practices-for-password-policies-and-passwords",
Network policies can be applied to which of the following Snowflake objects? (Choose two.),multi-select,A. Roles,B. Databases,C. Warehouses,D. Users,E. Accounts,,,,,,,,,,,"4, 5","DE are correct
https://docs.snowflake.com/en/user-guide/network-policies.html#label-verify-network-policy-activation
https://docs.snowflake.com/en/user-guide/network-policies.html#label-verify-network-policy-activation
Users & accounts  https://docs.snowflake.com/en/user-guide/network-policies.html#label-verify-network-policy-activation",
Where is Snowflake metadata stored?,multiple-choice,A. Within the data files,B. In the virtual warehouse layer,C. In the cloud services layer,D. In the remote storage layer,,,,,,,,,,,,3,"C is correct
Cloud services layer  https://docs.snowflake.com/en/user-guide/intro-key-concepts.html#cloud-services
Metadata management https://docs.snowflake.com/en/user-guide/intro-key-concepts.html#cloud-services
https://docs.snowflake.com/en/user-guide/intro-key-concepts.html#cloud-services",
What columns are returned when performing a FLATTEN command on semi-structured data? (Choose two.),multi-select,A. KEY,B. NODE,C. VALUE,D. LEVEL,E. ROOT,,,,,,,,,,,"1, 3","https://docs.snowflake.com/en/sql-reference/functions/flatten.html#output
Output  The returned rows consist of a fixed set of columns:  +-----+------+------+-------+-------+------+ | SEQ | KEY | PATH | INDEX | VALUE | THIS | |-----+------+------+-------+-------+------| SEQ A unique sequence number associated with the input record; the sequence is not guaranteed to be gap-free or ordered in any particular way.  KEY For maps or objects, this column contains the key to the exploded value.  PATH The path to the element within a data structure that needs to be flattened.  INDEX The index of the element, if it is an array; otherwise NULL.  VALUE The value of the element of the flattened array/object.  THIS The element being flattened (useful in recursive flattening).",
Which of the following Snowflake features provide continuous data protection automatically? (Choose two.),multi-select,A. Internal stages,B. Incremental backups,C. Time Travel,D. Zero-copy clones,E. Fail-safe,,,,,,,,,,,"3, 5","https://docs.snowflake.com/en/user-guide/data-cdp.html
CE are correct",
"A developer is granted ownership of a table that has a masking policy. The developer’s role is not able to see the masked data.

Will the developer be able to modify the table to read the masked data?",multiple-choice,"A. Yes, because a table owner has full control and can unset masking policies.","B. Yes, because masking policies only apply to cloned tables.","C. No, because masking policies must always reference specific access roles.","D. No, because ownership of a table does not include the ability to change masking policies.",,,,,,,,,,,,4,"Object owners (i.e. the role that has the OWNERSHIP privilege on the object) do not have the privilege to unset masking policies.  Object owners cannot view column data in which a masking policy applies. https://docs.snowflake.com/en/user-guide/security-column-intro.html#what-are-masking-policies
The question here is Will the developer be able to modify the table to read the masked data? It is about modifying the table to read the data from masked column. Owner of the table can definitely UNSET the masking policy by using this command ALTER TABLE <name> modify column <col_name> unset masking policy;",
How should a virtual warehouse be configured if a user wants to ensure that additional multi-clusters are resumed with no delay?,multiple-choice,A. Configure the warehouse to a size larger than generally required,B. Set the minimum and maximum clusters to autoscale,C. Use the standard warehouse scaling policy,D. Use the economy warehouse scaling policy,,,,,,,,,,,,3,"C. Use the standard warehouse scaling policy
The economy policy doesn't start immediately Only if the system estimates there’s enough query load to keep the cluster busy for at least 6 minutes. https://docs.snowflake.com/en/user-guide/warehouses-multicluster.html",
"During periods of warehouse contention, which parameter controls the maximum length of time a warehouse will hold a query for processing?",multiple-choice,A. STATEMENT_TIMEOUT_IN_SECONDS,B. STATEMENT_QUEUED_TIMEOUT_IN_SECONDS,C. MAX_CONCURRENCY_LEVEL,D. QUERY_TIMEOUT_IN_SECONDS,,,,,,,,,,,,2,"Answer B  STATEMENT_QUEUED_TIMEOUT_IN_SECONDS is a configuration parameter in Snowflake that specifies the maximum amount of time, in seconds, that a statement can remain in a queued state before timing out.   STATEMENT_TIMEOUT_IN_SECONDS is a parameter in Snowflake that specifies the maximum amount of time that a query can execute before being automatically terminated by the system. The default value for this parameter is 0, which means there is no timeout limit set.
STATEMENT_QUEUED_TIMEOUT_IN_SECONDS Amount of time, in seconds, a SQL statement (query, DDL, DML, etc.) remains queued for a warehouse before it is canceled by the system. https://docs.snowflake.com/en/sql-reference/parameters#statement-queued-timeout-in-seconds",
"Files have been uploaded to a Snowflake internal stage. The files now need to be deleted.

Which SQL command should be used to delete the files?",multiple-choice,A. PURGE,B. MODIFY,C. REMOVE,D. DELETE,,,,,,,,,,,,3,"https://docs.snowflake.com/en/sql-reference/sql/remove.html
Staged files can be deleted from a Snowflake stage (user stage, table stage, or named stage) using the following methods:  Files that were loaded successfully can be deleted from the stage during a load by specifying the PURGE copy option in the COPY INTO <table> command.  After the load completes, use the REMOVE command to remove the files in the stage.",
"In a Snowflake role hierarchy, what is the top-level role?",multiple-choice,A. SYSADMIN,B. ORGADMIN,C. ACCOUNTADMIN,D. SECURITYADMIN,,,,,,,,,,,,3,"Answer - ACCOUNTADMIN https://docs.snowflake.com/en/user-guide/security-access-control-overview.html#
https://docs.snowflake.com/en/user-guide/security-access-control-overview#label-role-hierarchy-and-privilege-inheritance ORGADMIN is a separate system role that manages operations at the organization level. This role is not included in the hierarchy of system roles.",
"By default, which Snowflake role is required to create a share?",multiple-choice,A. ORGADMIN,B. SECURITYADMIN,C. SHAREADMIN,D. ACCOUNTADMIN,,,,,,,,,,,,4,"https://docs.snowflake.com/en/sql-reference/sql/create-share.html#access-control-requirements
CREATE SHARE: Account :Only the ACCOUNTADMIN role has this privilege by default. The privilege can be granted to additional roles as needed. https://docs.snowflake.com/en/sql-reference/sql/create-share.html#access-control-requirements",
What happens to historical data when the retention period for an object ends?,multiple-choice,A. The data is cloned into a historical object.,B. The data moves to Fail-safe,C. Time Travel on the historical data is dropped.,D. The object containing the historical data is dropped.,,,,,,,,,,,,2,"B is correct
When the retention period ends for an object, the historical data is moved into Snowflake Fail-safe: https://docs.snowflake.com/en/user-guide/data-time-travel.html#data-retention-period
When the retention period ends for an object, the historical data is moved into Snowflake Fail-safe: Historical data is no longer available for querying.",
"A company’s security audit requires generating a report listing all Snowflake logins (e.g., date and user) within the last 90 days.

Which of the following statements will return the required information?",multiple-choice,"A. SELECT LAST_SUCCESS_LOGIN, LOGIN_NAME
FROM ACCOUNT_USAGE.USERS;","B. SELECT EVENT_TIMESTAMP, USER_NAME
FROM table(information_schema.login_history_by_user())","C. SELECT EVENT_TIMESTAMP, USER_NAME
FROM ACCOUNT_USAGE.ACCESS_HISTORY;","D. SELECT EVENT_TIMESTAMP, USER_NAME
FROM ACCOUNT_USAGE.LOGIN_HISTORY;",,,,,,,,,,,,4,"correct
LOGIN_HISTORY returns login events within a specified time range.  https://docs.snowflake.com/en/sql-reference/functions/login_history.html",
What are common issues found by using the Query Profile? (Choose two.),multi-select,A. Identifying queries that will likely run very slowly before executing them,B. Locating queries that consume a high amount of credits,C. Identifying logical issues with the queries,D. Identifying inefficient micro-partition pruning,E. Data spilling to a local or remote disk,,,,,,,,,,,"4, 5","https://docs.snowflake.com/en/user-guide/ui-query-profile.html#statistics
DE :: https://docs.snowflake.com/en/user-guide/ui-query-profile.html#common-query-problems-identified-by-query-profile",
The Snowflake Search Optimization Services supports improved performance of which kind of query?,multiple-choice,A. Queries against large tables where frequent DML occurs,B. Queries against tables larger than 1 TB,C. Selective point lookup queries,D. Queries against a subset of columns in a table,,,,,,,,,,,,3,"C. Selective point lookup queries
https://docs.snowflake.com/en/user-guide/search-optimization-service.html",
Which file formats are supported for unloading data from Snowflake? (Choose two.),multi-select,A. Avro,B. JSON,C. ORC,D. XML,"E. Delimited (CSV, TSV, etc.)",,,,,,,,,,,"2, 5","BE are correct
Delimited files (CSV, TSV, etc.) Any valid delimiter is supported; default is comma (i.e. CSV). JSON Parquet https://docs.snowflake.com/en/user-guide/intro-summary-unloading#output-data-file-details
https://docs.snowflake.com/en/user-guide/intro-summary-unloading.html#output-data-file-details
CSV, JSON, Parquet",
Which Snowflake tool would be BEST to troubleshoot network connectivity?,multiple-choice,A. SnowCLI,B. SnowUI,C. SnowSQL,D. SnowCD,,,,,,,,,,,,4,"CD - Connectivity Diagnostics
SnowCD (i.e. Snowflake Connectivity Diagnostic Tool) helps users to diagnose and troubleshoot their network connection to Snowflake. https://docs.snowflake.com/en/user-guide/snowcd.html#snowcd-connectivity-diagnostic-tool",
Increasing the size of a virtual warehouse from an X-Small to an X-Large is an example of which of the following?,multiple-choice,A. Right sizing,B. Concurrent sizing,C. Scaling out,D. Scaling up,,,,,,,,,,,,4,"D. Scaling up
https://docs.snowflake.com/en/user-guide/warehouses-considerations.html#warehouse-resizing-improves-performance",
What are ways to create and manage data shares in Snowflake? (Choose two.),multi-select,A. Through the Snowflake web interface (UI),B. Through the DATA_SHARE=TRUE parameter,C. Through SQL commands,D. Through the ENABLE_SHARE=TRUE parameter,E. Using the CREATE SHARE AS SELECT * FROM TABLE command,,,,,,,,,,,"1, 3","AC are correct
Web Interface and SQL commands",
What is a characteristic of data micro-partitioning in Snowflake?,multiple-choice,A. Micro-partitioning may introduce data skew,B. Micro-partitioning requires the definition of a partitioning schema,C. Micro-partitioning happens when the data is loaded,D. Micro-partitioning can be disabled within a Snowflake account,,,,,,,,,,,,3,"Micro-partitioning is automatically performed on all Snowflake tables. Tables are transparently partitioned using the ordering of the data as it is inserted/loaded. https://docs.snowflake.com/en/user-guide/tables-clustering-micropartitions.html#what-are-micro-partitions
C. Micro-partitioning happens when the data is loaded",
Users with the ACCOUNTADMIN role can execute which of the following commands on existing users?,multiple-choice,"A. Can SHOW users DESCRIBE a given user, or ALTER or DROP a user","B. Can DEFINE users, DESCRIBE a given user, or ALTER or DELETE a user","C. Can SHOW users, INDEX a given user, or ALTER or DELETE a user","D. Can SHOW users, DEFINE a given user or ALTER, DROP, or MODIFY a user",,,,,,,,,,,,1,"A. Can SHOW users DESCRIBE a given user, or ALTER or DROP a user
Only these operations are allowed  CREATE USER , ALTER USER , DROP USER , DESCRIBE USER https://docs.snowflake.com/en/sql-reference/sql/show-users.html
https://docs.snowflake.com/en/user-guide/admin-user-management.html",
"According to Snowflake best practice recommendations, which system-defined roles should be used to create custom roles? (Choose two.)",multi-select,A. ACCOUNTADMIN,B. SYSADMIN,C. SECURITYADMIN,D. USERADMIN,E. ORGADMIN,,,,,,,,,,,"3, 4","https://docs.snowflake.com/en/user-guide/security-access-control-overview.html#system-defined-roles
show this picture https://docs.snowflake.com/ko/user-guide/security-access-control-overview#role-hierarchy-and-privilege-inheritance",
What services are provided by the cloud services layer in Snowflake? (Choose two.),multi-select,A. Metadata management,B. Object authorization,C. Authentication,D. Query execution,E. Result caching,,,,,,,,,,,"1, 3","A. Metadata management C. Authentication  The cloud services layer in Snowflake provides several important services that are used by other parts of the system. Two of the main services provided by the cloud services layer are:  A. Metadata management: The cloud services layer is responsible for managing the metadata that defines the structure and contents of databases and tables in Snowflake, including information about columns, data types, and indexes.  C. Authentication: The cloud services layer is responsible for handling user authentication and authorization, ensuring that only authorized users have access to the data and metadata stored in Snowflake.  Options B, D, and E refer to other parts of the Snowflake system and are not provided by the cloud services layer. Option B refers to object authorization, which is managed by the security layer in Snowflake. Option D refers to query execution, which is performed by the query processing layer. Option E refers to result caching, which can be performed by the query processing layer and the storage layer in Snowflake.
https://docs.snowflake.com/en/user-guide/intro-key-concepts.html#cloud-services",
Which of the following commands are valid options for the VALIDATION_MODE parameter within the Snowflake COPY_INTO command? (Choose two.),multi-select,A. TRUE,B. RETURN_ERROR_SUM,C. RETURN_ALL_ERRORS,D. RETURN_[N]_ROWS,E. RETURN_FIRST__ERRORS,,,,,,,,,,,"3, 4","VALIDATION_MODE = RETURN_n_ROWS | RETURN_ERRORS | RETURN_ALL_ERRORS https://docs.snowflake.com/en/sql-reference/sql/copy-into-table.html
https://docs.snowflake.com/en/sql-reference/sql/copy-into-table.html#optional-parameters",
Snowflake virtual warehouses are part of which layer of the Snowflake architecture?,multiple-choice,A. Compute layer,B. Storage layer,C. Database layer,D. Cloud services layer,,,,,,,,,,,,1,"correct
COMPUTE LAYER
for sure compute layer",
Which of the following are characteristics of schemas used in Snowflake? (Choose two.),multi-select,A. A schema may contain one or more databases.,B. A database may contain one or more schemas.,C. A schema represents a logical grouping of database objects.,D. Each schema is contained within a virtual warehouse.,E. A table can span more than one schema.,,,,,,,,,,,"2, 3","B & C maybe ?
B&C of course  https://docs.snowflake.com/en/user-guide/security-access-control-overview.html#custom-roles",
Which Snowflake objects can be used to reduce data storage costs for short-lived tables? (Choose two.),multi-select,A. Provisional tables,B. Temporary tables,C. Transient tables,D. Permanent tables,E. Lookup tables,,,,,,,,,,,"2, 3","BC Correct
BC is correct",
"A user has unloaded data from Snowflake to a stage.

Which SQL command should be used to validate which data was loaded into the stage?",multiple-choice,A. list @file_stage,B. show @file_stage,C. view @file_stage,D. verify @file_stage,,,,,,,,,,,,1,"correct
https://docs.snowflake.com/en/sql-reference/sql/list
List command is correct",
What are benefits of using the ACCESS_HISTORY view in the SNOWFLAKE database?,multi-select,A. Identification of unused data,B. Identification of which roles have been used,C. Tracking of network policy usage,D. Highlighting of row access policy usage,E. Identification of who has read data,,,,,,,,,,,"1, 5","It could be also BDE
A E   C - no, use this instead: https://docs.snowflake.com/en/sql-reference/account-usage/network_policies B - I would probably use QUERY_HISTORY for that instead https://docs.snowflake.com/en/sql-reference/account-usage/query_history D - I would use this instead: ROW_ACCESS_POLICIES https://docs.snowflake.com/en/sql-reference/account-usage/row_access_policies
A is the right answer. Check the benefit section: https://docs.snowflake.com/en/user-guide/access-history#benefits
ADE A: https://docs.snowflake.com/en/user-guide/access-history#label-access-history-benefits:~:text=Discover%20unused%20data%20to%20determine%20whether%20to%20archive%20or%20delete%20the%20data. D: https://docs.snowflake.com/en/user-guide/access-history#example-track-row-access-policy-references E: https://docs.snowflake.com/en/user-guide/access-history#examples-read-queries",
Which of the following view types are available in Snowflake? (Choose two.),multi-select,A. Layered view,B. Secure view,C. External view,D. Embedded view,E. Materialized view,,,,,,,,,,,"2, 5","https://docs.snowflake.com/en/user-guide/views-introduction
Answer is correct
BE Correct, Never heard any of the views like Layered, External or Embedded in any of the databases.",
Which of the following statements describes a benefit of Snowflake’s separation of compute and storage? (Choose two.),multi-select,A. Growth of storage and compute are tightly coupled.,B. Storage expands without the requirement to add more compute.,C. Compute can be scaled up or down without the requirement to add more storage.,D. Compute and storage can be scaled together.,E. Use of storage avoids disk spilling.,,,,,,,,,,,"2, 3","correct
For Snowflake, this is not an issue. You can grow and shrink the environment dynamically. The data storage grows and shrinks as you add or remove data, while the compute nodes can be ramped up or down, or turned off, as you require. You are not forced to pay for capacity up front, or kick other workloads off, or plan downtimes when ramping up your data warehouse capacity. That is the promise of cloud. This is why Snowflake is the real elastic Data Warehouse as a Service.",
What is the default compression typo when unloading data from Snowflake?,multiple-choice,A. Brotli,B. bzip2,C. Zstandard,D. gzip,,,,,,,,,,,,4,"Correct
By default, all unloaded data files are compressed using gzip, unless compression is explicitly disabled or one of the other supported compression methods is explicitly specified.  https://docs.snowflake.com/en/user-guide/intro-summary-unloading.html#:~:text=By%20default%2C%20all%20unloaded%20data,compression%20methods%20is%20explicitly%20specified.",
Which statement describes when a virtual warehouse can be resized?,multiple-choice,"A. A resize will affect running, queued, and new queries.",B. A resize can only be completed when the warehouse is in an auto-resume status.,C. A resize must be completed when the warehouse is suspended.,D. A resize can be completed at any time.,,,,,,,,,,,,4,"Ours i
A warehouse can be resized up or down at any time, including while it is running and processing statements.",
What is the compressed size limit for semi-structured data loaded into a VARIANT data type using the COPY command?,multiple-choice,A. 8 MB,B. 16 MB,C. 32 MB,D. 64 MB,,,,,,,,,,,,2,"16MB is the answer
B is correct",
"User A cloned a schema and overwrote a schema that User B was working on. User B no longer has access to their version of the tables. However, this all occurred within the Time Travel retention period defined at the database level.

How should the missing tables be restored?",multiple-choice,A. Use an UNDROP TABLE statement.,B. Use a CREATE TABLE AS SELECT statement,C. Rename the cloned schema and use an UNDROP SCHEMA statement.,D. Contact Snowflake Support to retrieve the data from Fail-safe,,,,,,,,,,,,3,"C is correct!  If an object with the same name already exists, UNDROP fails. Need to rename the existing object, which then enables us to restore the previous version of the object.
https://docs.snowflake.com/en/sql-reference/sql/undrop-schema",
How does Snowflake recommend handling the bulk loading of data batches from files already available in cloud storage?,multiple-choice,A. Use Snowpipe.,B. Use the INSERT command.,C. Use an external table.,D. Use the COPY command.,,,,,,,,,,,,4,"answer should be C and D combined
Answer D is correct. Step 1 create external stage Step 2 using copy into  https://docs.snowflake.com/en/user-guide/data-load-gcs#:~:text=You%20can%20load%20directly%20from,manually%20or%20within%20a%20script.
Answer is correct
https://www.bing.com/search?q=How+does+Snowflake+recommend+handling+the+bulk+loading+of+data+batches+from+files+already+available+in+cloud+storage%3F&cvid=872b55f1708c4798b791492277cbcb09&aqs=edge..69i57j69i11004.2129j0j9&FORM=ANAB01&PC=U531",
What is Snowflake's general guideline for files used to load data?,multiple-choice,A. Files can be loaded directly into a table.,B. Any delimiter is supported: the default is a semicolon.,C. Electronic Data Interchange (EDI) is one of the supported semi-structured formats.,"D. For delimited files, the default character set is UTF-8.",,,,,,,,,,,,4,"by discard, not A because you have to load the data on a stage before being able to load it into a table. not b because comma is the default delimiter. not c because edi is not supported.
https://docs.snowflake.com/en/user-guide/intro-summary-loading.html",
How does a Snowflake user execute an anonymous block of code?,multiple-choice,A. The user must run the CALL command to execute the block.,B. The statements that define the block must also execute the block.,C. The SUBMIT command must run immediately after the block is defined,D. The block must be saved to a worksheet and executed using a connector.,,,,,,,,,,,,2,"The BEGIN … END statement that defines the block also executes the block. (You don’t run a separate CALL command to execute the block.)  https://docs.snowflake.com/en/developer-guide/snowflake-scripting/blocks.html#using-an-anonymous-block
https://docs.snowflake.com/en/developer-guide/snowflake-scripting/blocks.html#using-an-anonymous-block",
"A Snowflake user has a query that is running for a long time. When the user opens the query profiler, it indicates that a lot of data is spilling to disk.

What is causing this to happen?",multiple-choice,A. The result cache is almost full and is unable to hold the results.,B. The cloud storage staging area is not sufficient to hold the data results.,C. Clustering has not been applied to the table so the table is not optimized.,D. The warehouse memory is not sufficient to hold the intermediate query results.,,,,,,,,,,,,4,"D is the correct answer
https://community.snowflake.com/s/article/Performance-impact-from-local-and-remote-disk-spilling",
What is the MOST performant file format for loading data in Snowflake?,multiple-choice,A. CSV (Unzipped),B. Parquet,C. CSV (Gzipped),D. ORC,,,,,,,,,,,,3,"Loading from Gzipped CSV is several times faster than loading from ORC and Parquet at an impressive 15 TB/Hour. While 5-6 TB/hour is decent if your data is originally in ORC or Parquet, don’t go out of your way to CREATE ORC or Parquet files from CSV in the hope that it will load Snowflake faster. Loading data into fully structured (columnarized) schema is ~10-20% faster than landing it into a VARIANT.  https://community.snowflake.com/s/article/How-to-Load-Terabytes-Into-Snowflake-Speeds-Feeds-and-Techniques
should be B While CSV (Gzipped) (option C) is a commonly used format and can be efficient in terms of storage space due to compression, it is not as performant as Parquet (option B) for loading data in Snowflake.",
Which chart type does Snowsight support to visualize worksheet data?,multiple-choice,A. Box plot,B. Bubble chart,C. Pie chart,D. Scatterplot,,,,,,,,,,,,4,"Snowsight supports the following types of charts:  Bar charts Line charts Scatterplots Heat grids Scorecards  https://docs.snowflake.com/en/user-guide/ui-snowsight-visualizations.html
https://docs.snowflake.com/en/user-guide/ui-snowsight-visualizations.html#:~:text=Snowsight%20supports%20the%20following%20types,Scatterplots",
Which result shows efficient pruning?,multiple-choice,A. Partitions scanned is greater than partitions total.,B. Partitions scanned is less than partitions total.,C. Partitions scanned is equal to the partitions total.,D. Partitions scanned is greater than or equal to the partitions total.,,,,,,,,,,,,2,"B  https://docs.snowflake.com/en/user-guide/ui-query-profile.html#inefficient-pruning
B-https://docs.snowflake.com/en/user-guide/ui-query-profile.html#inefficient-pruning",
Which clustering indicator will show if a large table in Snowflake will benefit from explicitly defining a clustering key?,multiple-choice,A. Percentage,B. Depth,C. Ratio,D. Total partition count,,,,,,,,,,,,2,"Clustering Depth The clustering depth for a populated table measures the average depth (1 or greater) of the overlapping micro-partitions for specified columns in a table. The smaller the average depth, the better clustered the table is with regards to the specified columns.  Clustering depth can be used for a variety of purposes, including:  Monitoring the clustering “health” of a large table, particularly over time as DML is performed on the table.  Determining whether a large table would benefit from explicitly defining a clustering key.
https://docs.snowflake.com/en/user-guide/tables-clustering-micropartitions.html#label-clustering-depth",
Which file format is MOST performant in Snowflake for data loading?,multiple-choice,A. Parquet,B. CSV,C. ORC,D. Avro,,,,,,,,,,,,2,"B. CSV
Loading from Gzipped CSV is several times faster than loading from ORC and Parquet at an impressive 15 TB/Hour. While 5-6 TB/hour is decent if your data is originally in ORC or Parquet, don’t go out of your way to CREATE ORC or Parquet files from CSV in the hope that it will load Snowflake faster.  https://community.snowflake.com/s/article/How-to-Load-Terabytes-Into-Snowflake-Speeds-Feeds-and-Techniques#:~:text=Loading%20data%20into%20Snowflake%20is,into%20fully%20structured%20Snowflake%20tables.
Changed my mind, Answer is 'A' The most performant file format for loading data in Snowflake is Parquet. According to Snowflake's official documentation, Parquet is a columnar storage file format that provides efficient data compression and encoding schemes, which improves performance for both storage and query execution",
What is to be expected when sharing worksheets in Snowsight?,multiple-choice,A. Worksheets can be shared with users that are internal or external to any organization.,"B. To run a shared worksheet, a user must be granted the role used for the worksheet session context.",C. Snowsight allows users to view and refresh results but not to edit shared worksheets.,"D. Snowsight offers different sharing permissions at the worksheet, folder, and dashboard level.",,,,,,,,,,,,2,"Worksheets in Snowsight use unique sessions with specific roles and warehouses assigned in the context of the worksheet. To view shared query results, the Snowflake user must use the same role as the session context for the worksheet.  https://docs.snowflake.com/en/user-guide/ui-snowsight-worksheets-gs.html#sharing-worksheets-and-folders
https://docs.snowflake.com/en/user-guide/ui-snowsight-worksheets-gs.html#sharing-worksheets-and-folders",
"Which Snowflake objects track DML changes made to tables, like inserts, updates, and deletes?",multiple-choice,A. Pipes,B. Streams,C. Tasks,D. Procedures,,,,,,,,,,,,2,"https://docs.snowflake.com/en/user-guide/streams-intro
B - STREAM (act as Oracle's MV Logs)
Streams monitor DML changes made to tables",
Which constraint type is enforced in Snowflake from the ANSI SQL standard?,multiple-choice,A. UNIQUE,B. PRIMARY KEY,C. FOREIGN KEY,D. NOT NULL,,,,,,,,,,,,4,"Snowflake supports defining and maintaining constraints, but does not enforce them, except for NOT NULL constraints, which are always enforced.  https://docs.snowflake.com/en/sql-reference/constraints-overview.html
Correct. The reason is probably that NOT NULL is the only one that can be verified rapidly. Others need scanning data.",
Which function is used to profile warehouse credit usage?,multiple-choice,A. AUTOMATIC_CLUSTERING_HISTORY,B. MATERIALIZED_VIEW_REFRESH_HISTORY,C. WAREHOUSE_LOAD_HISTORY,D. WAREHOUSE_METERING_HISTORY,,,,,,,,,,,,4,"D. WAREHOUSE_METERING_HISTORY
D is correct  https://docs.snowflake.com/en/sql-reference/functions/warehouse_metering_history",
What is a characteristic of the Snowflake query profiler?,multiple-choice,A. It can provide statistics on a maximum number of 100 queries per week.,B. It provides a graphic representation of the main components of the query processing.,C. It provides detailed statistics about which queries are using the greatest number of compute resources.,D. It can be used by third-party software using the query profiler API.,,,,,,,,,,,,2,"B. It provides a graphic representation of the main components of the query processing.
Correct Answer is B.  Query Profile, available through the Classic Console, provides execution details for a query. For the selected query, it provides a graphical representation of the main components of the processing plan for the query, with statistics for each component, along with details and statistics for the overall query. https://docs.snowflake.com/en/user-guide/ui-query-profile
Query Profile is a feature in the Snowflake UI that gives you detailed insights into the execution of a query. It contains a visual representation of the query plan, with all nodes and links represented. Execution details and statistics are provided for each node as well as the overall query.
https://docs.snowflake.com/en/user-guide/ui-query-profile#:~:text=For%20the%20selected%20query%2C%20it%20provides%20a%20graphical%20representation%20of%20the%20main%20components%20of%20the%20processing%20plan%20for%20the%20query",
"A Snowflake user wants to share transactional data with retail suppliers. However, some of the suppliers do not use Snowflake.

According to best practice, what should the Snowflake user do? (Choose two.)",multi-select,A. Provide each non-Snowflake supplier with their own reader account.,B. Deploy a single reader account to be shared by all of the non-Snowflake suppliers.,C. Create an ETL pipeline that uses select and inserts statements from the source to the target supplier accounts.,D. Use a data share for suppliers in the same cloud region and a replicated proxy share for other cloud deployments.,E. Extract the shared transactional data to an external stage and use cloud storage utilities to reload the suppliers' regions.,,,,,,,,,,,"1, 4","A & D https://docs.snowflake.com/en/user-guide/data-share-replication.html
https://community.snowflake.com/s/question/0D5Do0000073Mo2KAE/can-i-use-one-readeraccount-to-share-data-with-all-my-suppliers-nonsnowflake-or-should-i-create-a-reader-account-for-each  A & D",
Which statement about data sharing is true?,multiple-choice,"A. Accounts can share with other accounts regardless of their Snowflake edition, without requiring help from Snowflake Support.","B. Data sharing can cross regions, but not cloud providers.",C. The Data Consumer can only see objects in the Data Provider’s source database that have been explicitly added to the share.,D. A Data Provider can only share with other Snowflake customers.,,,,,,,,,,,,3,"https://docs.snowflake.com/en/user-guide/data-sharing-provider.html#general-data-sharing-considerations-and-usage
Not entirely sure, but I'd go for (A) here. Sharing is not limited to specific versions.    Why I don't think the correct answer is (C): The earlier mentioned link below is saying that NEW objects are not automatically available to consumers and explicitly need to be added to the share. But answer option (C) is not specifying this.  https://docs.snowflake.com/en/user-guide/data-sharing-provider.html#general-data-sharing-considerations-and-usage",
Which object type is granted permissions for reading a table?,multiple-choice,A. User,B. Role,C. Attribute,D. Schema,,,,,,,,,,,,2,"should be B
https://docs.snowflake.com/en/sql-reference/sql/grant-privilege#:~:text=Grant%20the%20SELECT%20privilege%20on%20all%20existing%20tables%20in%20the%20mydb.myschema%20schema%20to%20the%20analyst%20role%3A",
What is the default value in the Snowflake Web Interface (UI) for auto suspending a Virtual Warehouse?,multiple-choice,A. 1 minute,B. 5 minutes,C. 10 minutes,D. 15 minutes,,,,,,,,,,,,3,"C - 10mn  Checked on Snowflake UI
C  https://docs.snowflake.com/en/sql-reference/sql/create-warehouse#:~:text=Default-,600,-(the%20warehouse%20suspends",
Which data types are valid in Snowflake? (Choose two.),multi-select,A. BLOB,B. Geography,C. JSON,D. CLOB,E. Variant,,,,,,,,,,,"2, 5","BE are correct
B and E  https://docs.snowflake.com/en/sql-reference/intro-summary-data-types.html#:~:text=structured%20Data%20Types-,VARIANT,-OBJECT
Semi-structured Data Types: VARIANT OBJECT ARRAY  Geospatial Data Types: GEOGRAPHY GEOMETRY  https://docs.snowflake.com/en/sql-reference/intro-summary-data-types",
What happens when the size of a virtual warehouse is changed?,multiple-choice,A. Queries that are running on the current warehouse configuration are not impacted.,B. Queries that are running on the current warehouse configuration are aborted and have to be resubmitted by the user.,C. Queries that are running on the current warehouse configuration are aborted and are automatically resubmitted.,D. Queries that are running on the current warehouse configuration are moved to the new configuration and finished there.,,,,,,,,,,,,1,"A. Queries that are running on the current warehouse configuration are not impacted.
A. Queries that are running on the current warehouse configuration are not impacted.
Answer is correct Resizing a running warehouse does not impact queries that are already being processed by the warehouse; the additional compute resources, once fully provisioned, are only used for queued and new queries.",
How often are encryption keys automatically rotated by Snowflake?,multiple-choice,A. 30 Days,B. 60 Days,C. 90 Days,D. 365 Days,,,,,,,,,,,,1,"All Snowflake-managed keys are automatically rotated by Snowflake when they are more than 30 days old
https://docs.snowflake.com/en/user-guide/security-encryption-manage.html#:~:text=it%20is%20usable.-,Encryption%20Key%20Rotation,and%20new%20keys%20are%20created.",
"As a best practice, all custom roles should be granted to which system-defined role?",multiple-choice,A. ACCOUNTADMIN,B. ORGADMIN,C. SECURITYADMIN,D. SYSADMIN,,,,,,,,,,,,4,"D--Sysadmin Role that has privileges to create warehouses and databases (and other objects) in an account.  If, as recommended, you create a role hierarchy that ultimately assigns all custom roles to the SYSADMIN role, this role also has the ability to grant privileges on warehouses, databases, and other objects to other roles.
https://docs.snowflake.com/en/user-guide/security-access-control-overview.html#system-defined-roles",
"Which Snowflake object can be accessed in the FROM clause of a query, returning a set of rows having one or more columns?",multiple-choice,A. A User-Defined Table Function (UDTF),B. A Scalar User Defined Function (UDF),C. A stored procedure,D. A task,,,,,,,,,,,,1,"A. A User-Defined Table Function (UDTF)
https://docs.snowflake.com/en/developer-guide/udf/udf-calling-sql#calling-a-udtf",
How are micro-partitions typically generated in Snowflake?,multiple-choice,A. Automatically,B. ORDER BY [];,C. PARTITION BY [];,D. GROUP BY [];,,,,,,,,,,,,1,"Micro-partitions are generated automatically, you can do it manually though by adding CLUSTER BY statement
A is correct",
What does Snowflake recommend regarding database object ownership? (Choose two.),multi-select,A. Create objects with ACCOUNTADMIN and do not reassign ownership.,B. Create objects with SYSADMIN.,C. Create objects with SECURITYADMIN to ease granting of privileges later.,D. Create objects with a custom role and grant this role to SYSADMIN.,E. Use only managed access schemas for objects owned by ACCOUNTADMIN.,,,,,,,,,,,"2, 4","B and D are correct SYSADMIN - Role that has privileges to create warehouses and databases (and other objects) in an account. If, as recommended, you create a role hierarchy that ultimately assigns all custom roles to the SYSADMIN role, this role also has the ability to grant privileges on warehouses, databases, and other objects to other roles.  https://docs.snowflake.com/en/user-guide/security-access-control-overview.html
B and D are correct",
Other than ownership what privileges does a user need to view and modify resource monitors in Snowflake? (Choose two.),multi-select,A. ALTER,B. MONITOR,C. MODIFY,D. CREATE,E. DROP,,,,,,,,,,,"2, 3","BC is correct https://docs.snowflake.com/en/user-guide/security-access-control-privileges#resource-monitor-privileges
B&C correct  https://docs.snowflake.com/en/user-guide/resource-monitors.html#assignment-of-resource-monitors:~:text=needed%20using%20SQL%3A-,MONITOR,MODIFY,-For%20more%20details",
What technique does Snowflake recommend for determining which virtual warehouse size to select?,multiple-choice,A. Always start with an X-Small and increase the size if the query does not complete in 2 minutes,B. Experiment by running the same queries against warehouses of different sizes,C. Use the default size Snowflake chooses,D. Use X-Large or above for tables larger than 1 GB,,,,,,,,,,,,2,"B is correct https://docs.snowflake.com/en/user-guide/warehouses-considerations.html
B is correct",
Which command should be used when loading many flat files into a single table?,multiple-choice,A. PUT,B. INSERT,C. COPY INTO,D. MERGE,,,,,,,,,,,,3,"Step 1. Upload (i.e. stage) one or more data files to a Snowflake stage (named internal stage or table/user stage) using the PUT command. Step 2. Use the COPY INTO <table> command to load the contents of the staged file(s) into a Snowflake database table.
Correct answer",
How can a Snowflake user share data with another user who does not have a Snowflake account?,multiple-choice,A. Share the data by implementing User-Defined Functions (UDFs),B. Create a reader account and create a share of the data,C. Grant the READER privilege to the database that is going to be shared,D. Move the Snowflake account to a region where data sharing is enabled,,,,,,,,,,,,2,"https://docs.snowflake.com/en/user-guide/data-sharing-gs
correct answer",
Which semi-structured data formats can be loaded into Snowflake with a COPY command? (Choose two.),multi-select,A. CSV,B. EDI,C. HTML,D. ORC,E. XML,,,,,,,,,,,"4, 5","D&E https://docs.snowflake.com/en/user-guide/semistructured-concepts.html#:~:text=Snowflake%20provides%20built%2Din%20support%20for%20importing%20data%20from%20(and%20exporting%20data%20to)%20the%20following%20semi%2Dstructured%20data%20formats%3A
D E is correct",
How long is a query visible in the Query History page in the Snowflake Web Interface (UI)?,multiple-choice,A. 60 minutes,B. 24 hours,C. 14 days,D. 30 days,,,,,,,,,,,,3,"page - 14 days account_usage.query_history - 365 days
https://docs.snowflake.com/en/sql-reference/account-usage/query_history 365 days able to see query history in my local from 31 aug logged in for the first time till 21 sep today",
Which view will return users who have queried a table?,multiple-choice,A. SNOWFLAKE.ACCOUNT_USAGE.WAREHOUSE_EVENT_HISTORY,B. SNOWFLAKE.ACCOUNT_USAGE.ACCESS_HISTORY,C. SNOWFLAKE.ACCOUNT_USAGE.COLUMNS,D. SNOWFLAKE.ACCOUNT_USAGE.OBJECT_DEPENDENCIES,,,,,,,,,,,,2,"That would be B.
https://www.bing.com/search?q=Which+view+will+return+users+who+have+queried+a+table%3F&cvid=006d099a4de04f2db53d6f7840f6110e&aqs=edge..69i57j69i11004.1227j0j4&FORM=ANAB01&PC=U531",
Where can a Snowflake user find the query history in Snowsight?,multiple-choice,A. Admin,B. Activity,C. Dashboards,D. Data,,,,,,,,,,,,2,"I think currently (3/2024) it's under ""Monitoring"" page. ""Activity"" page doesn't exist.
Answer B https://docs.snowflake.com/en/user-guide/ui-snowsight-activity.html",
What is SnowSQL?,multiple-choice,A. Snowflake's new user interface where users can visualize data into charts and dashboards.,"B. Snowflake's proprietary extension of the ANSI SQL standard, including built-in keywords and system functions.",C. Snowflake's command line client built on the Python connector which is used to connect to Snowflake and execute SQL.,D. Snowflake's library that provides a programming interface for processing data on Snowflake without moving it to the system where the application code runs.,,,,,,,,,,,,3,"Correct
correct
SnowSQL is the command line client for connecting to Snowflake to execute SQL queries and perform all DDL and DML operations, including loading data into and unloading data out of database tables.  SnowSQL (snowsql executable) can be run as an interactive shell or in batch mode through stdin or using the -f option.  SnowSQL is an example of an application developed using the Snowflake Connector for Python; however, the connector is not a prerequisite for installing SnowSQL. All required software for installing SnowSQL is bundled in the installers.
Answer should be C",
Which statement is true of zero-copy cloning?,multiple-choice,A. It increases storage costs as cloning a table requires storing its data twice,B. A cloned table includes the load history of the original source,C. It is licensed as an additional Snowflake feature,D. All micro-partitions between the original and cloned tables are fully shared,,,,,,,,,,,,4,"Micro-partitions are shared at the beginning, once changes are made to the copied table, the underlaying data changes and the tables may not share the same micro-partitions.   Though it is true that once a table is cloned it inherits time-travel, clustering keys, comments, ... So I think it's B
- Snowflake’s zero-copy cloning feature provides a convenient way to quickly take a “snapshot” of any table, schema, or database and create a derived copy of that object which initially shares the underlying storage. This can be extremely useful for creating instant backups that do not incur any additional costs (until changes are made to the cloned object). - owever, cloning makes calculating total storage usage more complex because each clone has its own separate life-cycle. This means that changes can be made to the original object or the clone independently of each other and these changes are protected through CDP.  https://docs.snowflake.com/en/user-guide/tables-storage-considerations.html#cloning-tables-schemas-and-databases",
"A Snowflake user has been granted the CREATE DATA EXCHANGE LISTING privilege with their role.

Which tasks can this user now perform on the Data Exchange? (Choose two.)",multi-select,A. Rename listings,B. Delete provider profiles,C. Modify listings properties,D. Modify incoming listing access requests,E. Submit listings for approval/publishing,,,,,,,,,,,"3, 5","With that GRANT can : Create listings Modify listings properties View listings View incoming listing access requests Reject listing requests Submit listings for approval/publishing listings Create and view provider profiles
C and E sorry  https://docs.snowflake.com/en/user-guide/data-exchange-marketplace-privileges.html#label-create-data-exchange-listing-on-account
Selected Answer: CE  If the global CREATE DATA EXCHANGE LISTING privilege is granted to a role, any user with the role can create a listing or provider profile. As the creator and therefore owner of the listing, the role can be used to perform all tasks on the listing, including:  Create listings. Modify listings properties. View listings. View incoming listing requests. Reject listing requests. Submit listings for approval. Publish a listings. Create and view provider profiles.  https://docs.snowflake.com/en/user-guide/data-exchange-marketplace-privileges#global-create-data-exchange-listing-privilege  note: Only account administrators (users with the ACCOUNTADMIN role) can grant the global CREATE DATA EXCHANGE LISTING privilege to a role.",
Which parameter prevents streams on tables from becoming stale?,multiple-choice,A. MAX_DATA_EXTENSION_TIME_IN_DAYS,B. MIN_DATA_RETENSION_TIME_IN_DAYS,C. LOCK_TIMEOUT,D. STALE_AFTER,,,,,,,,,,,,1,"https://docs.snowflake.com/en/user-guide/streams-intro#label-streams-staleness  To prevent a stream from becoming stale, consume the stream records within a DML statement during the table’s retention period and regularly consume its change data before its STALE_AFTER timestamp (that is, within the extended data retention period for the source object).
https://docs.snowflake.com/en/user-guide/streams-intro#label-streams-staleness
D. STALE_AFTER is a parameter for streams in Snowflake that determines when a stream is considered stale and should be refreshed. It specifies the number of seconds before a stream becomes stale, and can be set to any value between 60 seconds and 14,400 seconds (4 hours). When a stream becomes stale, it is no longer guaranteed to contain a complete record of changes to the underlying table, and should be refreshed to ensure consistency.
The answer is correct.  https://docs.snowflake.com/en/user-guide/streams-manage",
"If a virtual warehouse runs for 30 seconds after it is provisioned, how many seconds will the customer be billed for?",multiple-choice,A. 30 seconds,B. 60 seconds,C. 121 seconds,D. 1 hour,,,,,,,,,,,,2,"B. 60 seconds
The answer is correct.",
What JavaScript delimiters are available in Snowflake stored procedures? (Choose two.),multi-select,A. Double quotes (“),B. Single quote (’),C. Double forward slash (//),D. Double backslash (\\),E. Double dollar sign ($$),,,,,,,,,,,"2, 5","People who put syntax questions like these in certification exams deserve to be castrated
https://docs.snowflake.com/en/sql-reference/stored-procedures-javascript",
What type of function can be used to estimate the approximate number of distinct values from a table that has trillions of rows?,multiple-choice,A. MD5,B. Window,C. External,D. HyperLogLog (HLL),,,,,,,,,,,,4,"Snowflake uses HyperLogLog to estimate the approximate number of distinct values in a data set. HyperLogLog is a state-of-the-art cardinality estimation algorithm, capable of estimating distinct cardinalities of trillions of rows with an average relative error of a few percent.  HyperLogLog can be used in place of COUNT(DISTINCT …) in situations where estimating cardinality is acceptable.
https://docs.snowflake.com/en/sql-reference/functions/hll  Uses HyperLogLog to return an approximation of the distinct cardinality of the input (i.e. HLL(col1, col2, ... ) returns an approximation of COUNT(DISTINCT col1, col2, ... )).  For more information about HyperLogLog, see Estimating the Number of Distinct Values.",
Which Data Definition Language (DDL) commands are supported by Snowflake to manage tags? (Choose two.),multi-select,A. ALTER TAG,B. DESCRIBE TAG,C. DROP TAG,D. GRANT [privilege] ... TO TAG,E. GRANT TAG,,,,,,,,,,,"1, 3","AC are correct
https://docs.snowflake.com/en/user-guide/object-tagging#label-object-tags-ddl
Tag DDL Reference Snowflake supports the following DDL to create and manage tags:  CREATE TAG  ALTER TAG  ALTER <object> (to set a tag on a Snowflake object)  SHOW TAGS  DROP TAG  UNDROP TAG",
What Snowflake objects can be added to a share? (Choose two.),multi-select,A. Views,B. Tables,C. Stored procedures,D. Streams,E. Secure views,,,,,,,,,,,"2, 5","BE are correct
Before creating a share, Snowflake recommends identifying the Snowflake objects you plan to share:  Database  Tables  External tables  Secure views  Secure materialized views  Secure UDFs",
"A Query Profile shows a UnionAll operator with an extra Aggregate operator on top.

What does this signify?",multiple-choice,A. Exploding joins,B. Inefficient pruning,C. UNION without ALL,D. Queries that are too large to fit in memory,,,,,,,,,,,,3,"UNION Without ALL In SQL, it is possible to combine two sets of data with either UNION or UNION ALL constructs. The difference between them is that UNION ALL simply concatenates inputs, while UNION does the same, but also performs duplicate elimination.  A common mistake is to use UNION when the UNION ALL semantics are sufficient. These queries show in Query Profile as a UnionAll operator with an extra Aggregate operator on top (which performs duplicate elimination).
https://docs.snowflake.com/en/user-guide/ui-query-profile",
Which data governance control has Snowflake embedded in the application?,multiple-choice,A. Network policies,B. Credit computation,C. Data storage,D. Attribute-based access control,,,,,,,,,,,,4,"While Snowflake primarily employs Role-Based Access Control (RBAC), ABAC can be implemented to enhance data security and governance.  Implementing ABAC in Snowflake:  1. Row Access Policies:  Snowflake's row access policies enable row-level security by defining conditions under which specific rows in a table are visible to users based on their attributes.  These policies evaluate attributes such as user roles, departments, or locations to control data visibility.  2. Dynamic Data Masking:  This feature allows for the masking of sensitive data elements based on user attributes, ensuring that only authorized users can view unmasked data.  It supports ABAC by dynamically adjusting data visibility without altering the underlying data.  3. Integration with External Tools:  Third-party platforms like Immuta provide advanced ABAC capabilities for Snowflake, enabling policy creation based on user attributes and other criteria.
Ans. A Snowflake supports DAC and RBAC, not Attribute-Based-Access-Control.",
What actions does the use of the PUT command do automatically? (Choose two.),multi-select,A. It creates a file format object.,B. It uses the last stage created.,C. It compresses all files using GZIP.,D. It encrypts the file data in transit.,E. It creates an empty target table.,,,,,,,,,,,"3, 4","Compression and Encryption
https://docs.snowflake.com/en/sql-reference/sql/put",
Which command should a Snowflake user execute to load data into a table?,multiple-choice,A. copy into mytable purge_mode = TRUE;,B. copy into mytable from @my_int_stage;,C. copy into mytable file_format = (format_name);,D. copy into mytable validation = ‘RETURN_ERRORS’;,,,,,,,,,,,,2,"B correct
correct",
Which function returns the URL of a stage using the stage name as the input?,multiple-choice,A. BUILD_STAGE_FILE_URL,B. BUILD_SCOPED_FILE_URL,C. GET_PRESIGNED_URL,D. GET_STAGE_LOCATION,,,,,,,,,,,,4,"Retrieves the URL for an external or internal named stage using the stage name as the input.
D) Gives STAGE and uses the STAGE name SELECT GET_STAGE_LOCATION(@images_stage);  => s3://photos/national_parks/us/yosemite/  A) Gives file  SELECT BUILD_STAGE_FILE_URL(@images_stage,'/us/yosemite/half_dome.jpg'); => https://my_account.snowflakecomputing.com/api/files/MY_DB/PUBLIC/IMAGES_STAGE/us/yosemite/half_dome.jpg  https://docs.snowflake.com/en/sql-reference/functions/build_stage_file_url https://docs.snowflake.com/en/sql-reference/functions/get_stage_location",
What is the MAXIMUM number of clusters that can be provisioned with a multi-cluster virtual warehouse?,multiple-choice,A. 1,B. 5,C. 10,D. 100,,,,,,,,,,,,3,"C. 10 is correct
10 clusters
Correct https://docs.snowflake.com/en/user-guide/warehouses-multicluster",
Which Snowflake table supports unstructured data?,multiple-choice,A. Directory,B. Transient,C. Temporary,D. Permanent,,,,,,,,,,,,1,"Answer is A https://quickstarts.snowflake.com/guide/getting_started_with_unstructured_data/?utm_cta=website-workload-data-science-accelerate-your-ds-workflow-unstructured-data-quickstart-guide#0
Directory for sure",
"When unloading data, which file format preserves the data values for floating-point number columns?",multiple-choice,A. Avro,B. CSV,C. JSON,D. Parquet,,,,,,,,,,,,4,"D. Parquet is correct
Correct Answer is D.  * When floating-point number columns are unloaded to CSV or JSON files, Snowflake truncates the values to approximately (15,9).  * The values are not truncated when unloading floating-point number columns to Parquet files. https://docs.snowflake.com/en/user-guide/data-unload-considerations#floating-point-numbers-truncated
Floating-point Numbers Truncated When floating-point number columns are unloaded to CSV or JSON files, Snowflake truncates the values to approximately (15,9).  The values are not truncated when unloading floating-point number columns to Parquet files.
https://docs.snowflake.com/en/user-guide/data-unload-considerations#floating-point-numbers-truncated",
Which virtual warehouse privilege is required to view a load-monitoring chart?,multiple-choice,A. MONTTOR,B. MODIFY,C. OPERATE,D. USAGE,,,,,,,,,,,,1,"To view the load monitoring chart, you must be using a role that has the MONITOR privilege on the warehouse.
https://docs.snowflake.com/en/user-guide/warehouses-load-monitoring",
Which use case will always cause an exploding join in Snowflake?,multiple-choice,A. A query that has more than 10 left outer joins.,B. A query that is using a UNION without an ALL.,C. A query that has not specified join criteria for tables.,D. A query that has requested too many columns of data.,,,,,,,,,,,,3,"“Exploding” joins  One of the common mistakes SQL users make is joining tables without providing a join condition (resulting in a “Cartesian product”), or providing a condition where records from one table match multiple records from another table. For such queries, the Join operator produces significantly (often by orders of magnitude) more tuples than it consumes.
C. A query that has not specified join criteria for tables.
C https://select.dev/posts/snowflake-query-profile",
How many resource monitors can be applied to a single virtual warehouse?,multiple-choice,A. Zero,B. One,C. Eight,D. Unlimited,,,,,,,,,,,,2,"A resource monitor can track multiple warehouses, but each warehouse can be linked to only one resource monitor.
B is the answer.  https://thinketl.com/snowflake-resource-monitors/ A resource monitor can be set to monitor multiple warehouses but a warehouse can be assigned only to a single resource monitor.",
What are the main differences between the account usage views and the information schema views? (Choose two.),multi-select,A. No active warehouse is needed to query account usage views but one is needed to query information schema views.,B. Account usage views do not contain data about tables but information schema views do.,C. Account usage views contain dropped objects but information schema views do not.,"D. Data retention for account usage views is 1 year but is 7 days to 6 months for information schema views, depending on the view.",E. Information schema views are read-only but account usage views are not.,,,,,,,,,,,"3, 4","C&D Certain account usage views provide historical usage metrics. The retention period for these views is 1 year (365 days). In contrast, the corresponding views and table functions in the Snowflake Information Schema have much shorter retention periods, ranging from 7 days to 6 months, depending on the view.
I would say C and D  https://docs.snowflake.com/en/sql-reference/account-usage",
Which file function provides a URL with access to a file on a stage without the need for authentication and authorization?,multiple-choice,A. GET_RELATIVE_PATH,B. GET_PRESIGNED_URL,C. BUILD_STAGE_FILE_URL,D. BUILD_SCOPED_FILE_URL,,,,,,,,,,,,2,"GET_PRESIGNED_URL  Generates the pre-signed URL to a staged file using the stage name and relative file path as inputs. Access files in an external stage using the function.
Correct Answer is B. (GET_PRESIGNED_URL)  Scoped URLs provide better security, while pre-signed URLs can be accessed without authorization or authentication. To choose the correct URL for your use case, see Types of URLs Available to Access Files.  https://docs.snowflake.com/en/user-guide/unstructured-data-sharing#step-1-create-a-secure-view",
Which view can be used to determine if a table has frequent row updates or deletes?,multiple-choice,A. TABLES,B. TABLE_STORAGE_METRICS,C. STORAGE_DAILY_HISTORY,D. STORAGE_USAGE,,,,,,,,,,,,2,"B. TABLE_STORAGE_METRICS
I think B is correct https://docs.snowflake.com/en/user-guide/tables-storage-considerations High-churn dimension tables can be identified by calculating the ratio of FAILSAFE_BYTES divided by ACTIVE_BYTES in the TABLE_STORAGE_METRICS view.
https://docs.snowflake.com/en/sql-reference/info-schema/table_storage_metrics",
How does the Snowflake search optimization service improve query performance?,multiple-choice,A. It improves the performance of range searches.,B. It defines different clustering keys on the same source table.,C. It improves the performance of all queries running against a given table.,D. It improves the performance of equality searches.,,,,,,,,,,,,4,"D is correct
Both A & D https://docs.snowflake.com/en/user-guide/search-optimization-service
D for sure. keyword"" equality searches""",
How is unstructured data retrieved from data storage?,multiple-choice,A. SQL functions like the GET command can be used to copy the unstructured data to a location on the client.,B. SQL functions can be used to create different types of URLs pointing to the unstructured data. These URLs can be used to download the data to a client.,C. SQL functions can be used to retrieve the data from the query results cache. When the query results are output to a client. the unstructured data will be output to the client as files.,D. SQL functions can call on different web extensions designed to display different types of files as a web page. The web extensions will allow the files to be downloaded to the client.,,,,,,,,,,,,2,"B. SQL functions can be used to create different types of URLs pointing to the unstructured data. These URLs can be used to download the data to a client
both A & B are making sense. But since GET is not a SQL function, so A is ruled out.  Hence , correct answer is B
I will go for A because very simplistically it is telling the method to get the job done https://docs.snowflake.com/en/user-guide/unstructured-intro",
What is the recommended way to obtain a cloned table with the same grants as the source table?,multiple-choice,A. Clone the table with the COPY GRANTS command.,B. Use an ALTER TABLE command to copy the grants.,C. Clone the schema then drop the unwanted tables.,D. Create a script to extract grants and apply them to the cloned table.,,,,,,,,,,,,1,"CLONE command syntax supports the COPY GRANTS parameter. When the COPY GRANTS parameter is specified in a CREATE TABLE statement, the create operation copies all privileges, except OWNERSHIP, from the source table to the new table. The same behavior is true for other CREATE commands that support the COPY GRANTS clause.
A https://docs.snowflake.com/en/user-guide/object-clone#:~:text=When%20the%20COPY%20GRANTS%20parameter%20is%20specified%20in%20a%20CREATE%20TABLE%20statement%2C%20the%20create%20operation%20copies%20all%20privileges%2C%20except%20OWNERSHIP%2C%20from%20the%20source%20table%20to%20the%20new%20table.",
What common query issues can be identified using the Query Profile? (Choose two.),multi-select,A. Data classification,B. Exploding joins,C. Unions,D. Inefficient pruning,E. Data masking,,,,,,,,,,,"2, 4","Exploding joins and Inefficient pruning  https://docs.snowflake.com/en/user-guide/ui-query-profile#common-query-problems-identified-by-query-profile
B and D https://docs.snowflake.com/en/user-guide/ui-query-profile",
What is used to extract the content of PDF files stored in Snowflake stages?,multiple-choice,A. FLATTEN function,B. Window function,C. HyperLogLog (HLL) function,D. Java User-Defined Function (UDF),,,,,,,,,,,,4,"even wirk with python UDF https://quickstarts.snowflake.com/guide/analyze_pdf_invoices_snowpark_python_java/index.html#3
https://quickstarts.snowflake.com/guide/analyze_pdf_invoices_java_udf_snowsight/index.html?index=..%2F..index#3",
What happens when a database is cloned?,multiple-choice,A. It does not retain any privileges granted on the source object.,B. It replicates all granted privileges on the corresponding source objects.,C. It replicates all granted privileges on the corresponding child objects.,D. It replicates all granted privileges on the corresponding child schema objects.,,,,,,,,,,,,3,"If the source object is a database or schema, the clone inherits all granted privileges on the clones of all child objects contained in the source object:  For databases, contained objects include schemas, tables, views, etc.  For schemas, contained objects include tables, views, etc.  Note that the clone of the container itself (database or schema) does not inherit the privileges granted on the source container.
https://docs.snowflake.com/en/user-guide/object-clone",
What does a Query Profile provide in Snowflake?,multiple-choice,A. A multi-step query that displays each processing step in the same panel.,B. A pre-computed data set derived from a query specification and stored for later use.,C. A graphical representation of the main components of the processing plan for a query.,D. A collapsible panel in the operator tree pane that lists nodes by execution time in descending order for a query.,,,,,,,,,,,,3,"C. A graphical representation of the main components of the processing plan for a query.
...""A collapsible panel in the operator tree pane lists nodes by execution time in descending order, enabling users to quickly locate the costliest operator nodes in terms of execution time.""... C as well, so there is 2 options ?
D correct - https://docs.snowflake.com/en/user-guide/ui-query-profile",
"When executing a COPY INTO command, performance can be negatively affected by using which optional parameter on a large number of files?",multiple-choice,A. FILE_FORMAT,B. PATTERN,C. VALIDATION_MODE,D. FILES,,,,,,,,,,,,2,"For the best performance, try to avoid applying patterns that filter on a large number of files.
The correct answer is B. Pattern  For the best performance, try to avoid applying patterns that filter on a large number of files. https://docs.snowflake.com/en/sql-reference/sql/copy-into-table#:~:text=paths%20to%20match.-,Tip,-For%20the%20best
https://docs.snowflake.com/en/sql-reference/sql/copy-into-table",
Which URL type should be used to get a permanent URL to a file in a stage?,multiple-choice,A. File URL,B. Pre-signed URL,C. Saved URL,D. Scoped URL,,,,,,,,,,,,1,"File URL https://docs.snowflake.com/en/user-guide/unstructured-intro
https://docs.snowflake.com/en/user-guide/unstructured-intro#:~:text=Permanent%20URL%20to%20a%20file%20on%20a%20stage.",
Which operation will produce an error in Snowflake?,multiple-choice,A. Inserting duplicate values into a PRIMARY KEY column,B. Inserting a NULL into a column with a NOT NULL constraint,C. Inserting duplicate values into a column with a UNIQUE constraint,D. Inserting a value to FOREIGN KEY column that does not match a value in the column referenced,,,,,,,,,,,,2,"B. Inserting a NULL into a column with a NOT NULL constraint
Verified
B - Snowflake supports defining and maintaining constraints, but does not enforce them, except for NOT NULL constraints, which are always enforced.",
How are URLs that access unstructured data in external stages retrieved?,multiple-choice,A. From the Snowsight navigation menu,B. By querying a directory table,C. By creating an external function,D. By using the INFORMATION_USAGE schema,,,,,,,,,,,,2,"B. By querying a directory table
https://docs.snowflake.com/en/user-guide/unstructured-intro#:~:text=Directory%20tables%20store%20a%20catalog%20of%20staged%20files%20in%20cloud%20storage.%20Roles%20with%20sufficient%20privileges%20can%20query%20a%20directory%20table%20to%20retrieve%20file%20URLs%20to%20access%20the%20staged%20files.",
What is the Snowflake multi-clustering feature for virtual warehouses used for?,multiple-choice,A. To improve the data unloading process to the cloud,B. To improve data loading from very large data sets,C. To improve concurrency for users and queries,D. To speed up slow or stalled queries,,,,,,,,,,,,3,"c - correct
C - correct
C. To improve concurrency for users and queries",
Which features could be used to improve the performance of queries that return a small subset of rows from a large table? (Choose two.),multi-select,A. Search optimization service,B. Automatic clustering,C. Row access policies,D. Multi-cluster virtual warehouses,E. Secure views,,,,,,,,,,,"1, 2","C - security D - concurency E - hide the source
Wouldn't this be A&B? What do row access policies (C) have to do with performance?",
Which command would return an empty sample?,multiple-choice,A. select * from testtable sample ();,B. select * from testtable sample (0);,C. select * from testtable sample (null);,D. select * from testtable sample (none);,,,,,,,,,,,,2,"num specifies the number of rows (up to 1,000,000) to sample from the table. Can be any integer between 0 (no rows selected) and 1000000 inclusive.   https://docs.snowflake.com/en/sql-reference/constructs/sample
from doc: Return an empty sample:  SELECT * FROM testtable SAMPLE ROW (0);",
What Snowflake function should be used to unload relational data to JSON?,multiple-choice,A. BUILD_STAGE_FILE_URL(),B. OBJECT_CONSTRUCT(),C. PARSE_JSON(),D. TO_VARIANT(),,,,,,,,,,,,2,"B. OBJECT_CONSTRUCT()
https://docs.snowflake.com/en/user-guide/data-unload-considerations
correct https://community.snowflake.com/s/article/Generating-a-JSON-Dataset-using-Relational-Data-in-Snowflake",
Floating point values are truncated when unloaded to which file format?,multiple-choice,A. ORC,B. CSV,C. Avro,D. Parquet,,,,,,,,,,,,2,"When floating-point number columns are unloaded to CSV or JSON files, Snowflake truncates the values to approximately (15,9). The values are not truncated when unloading floating-point number columns to Parquet files.
correct answer C When floating-point number columns are unloaded to CSV or JSON files, Snowflake truncates the values to approximately (15,9).  The values are not truncated when unloading floating-point number columns to Parquet files.",
Which levels can apply network policies? (Choose two.),multi-select,A. Account,B. Database,C. Role,D. Schema,E. User,,,,,,,,,,,"1, 5","AE are correct
A&E are correct
https://docs.snowflake.com/en/user-guide/network-policies",
What causes objects in a data share to become unavailable to a consumer account?,multiple-choice,A. The DATA_RETENTION_IT parameter in the consumer account is set to 0.,B. The consumer account runs the GRANT INPORTED PRIVILEGES command on the data share every 24 hours.,C. The objects in the data share are being deleted and the grant pattern is not re-applied systematically.,D. The consumer account acquires the data share through a private data exchange.,,,,,,,,,,,,3,"A. The DATA_RETENTION_TIME parameter in the consumer account determines how long data that is imported from a data share is retained in the account. If this parameter is set to 0, the data is immediately deleted after import. This parameter setting does not affect the availability of objects in the data share.  B. The GRANT IMPORTED PRIVILEGES command is used to grant privileges on objects that are imported from a data share to a consumer account. Running this command every 24 hours does not affect the availability of objects in the data share.  D. Private data exchange is a feature that allows two or more Snowflake accounts to exchange data privately, without going through the public internet. Acquiring a data share through a private data exchange does not affect the availability of objects in the data share.",
"How can an administrator check for updates (for example, SCIM API requests) sent to Snowflake by the identity provider?",multiple-choice,A. ACCESS_HYSTORY,B. LOAD_HYSTORY,C. QUERY_HISTORY,D. REST_EVENT_HISTORY,,,,,,,,,,,,4,"https://docs.snowflake.com/en/user-guide/scim-intro  Administrators can query the rest_event_history table to determine whether the identity provider is sending updates (i.e. SCIM API requests) to Snowflake.
https://docs.snowflake.com/pt/sql-reference/functions/rest_event_history",
"A Snowflake user is writing a User-Defined Function (UDF) with some unqualified object names.

How will those object names be resolved during execution?",multiple-choice,A. Snowflake will resolve them according to the SEARCH_PATH parameter.,B. Snowflake will only check the schema the UDF belongs to.,"C. Snowflake will first check the current schema, and then the schema the previous query used.","D. Snowflake will first check the current schema, and then the PUBLIC schema of the current database.",,,,,,,,,,,,2,"In Snowflake, unqualified object names (e.g., just my_table instead of schema.my_table) inside a User-Defined Function (UDF) are resolved using the SEARCH_PATH. This parameter defines the order of schemas that Snowflake searches when trying to resolve object names that are not fully qualified.  This behavior applies both during creation and execution of the UDF.
The correct answer is B.  In queries, unqualified object names are resolved through a search path. The SEARCH_PATH is not used inside views or Writing User-Defined Functions (UDFs). All unqualified objects in a view or UDF definition will be resolved in the view’s or UDF’s schema only. https://docs.snowflake.com/en/sql-reference/name-resolution#name-resolution-in-queries
In queries, unqualified object names are resolved through a search path. The SEARCH_PATH is not used inside views or Writing User-Defined Functions (UDFs). All unqualifed objects in a view or UDF definition will be resolved in the view’s or UDF’s schema only.  https://docs.snowflake.com/en/sql-reference/name-resolution
Should be B https://docs.snowflake.com/en/sql-reference/name-resolution",
Why should a user select the economy scaling policy for a multi-cluster warehouse?,multiple-choice,A. To prevent/minimize query queuing,B. To increase performance of the clusters,C. To reduce queuing concurrent user queries,D. To conserve credits by keeping running clusters fully loaded,,,,,,,,,,,,4,"Economy  Conserves credits by favoring keeping running clusters fully-loaded rather than starting additional clusters, which may result in queries being queued and taking longer to complete.",
What MINIMUM privilege is required on the external stage for any role in the GET REST API to access unstructured data files using a file URL?,multiple-choice,A. READ,B. OWNERSHIP,C. USAGE,D. WRITE,,,,,,,,,,,,3,"Answer is C External: USAGE Internal: READ https://docs.snowflake.com/en/user-guide/data-load-unstructured-rest-api
C. USAGE is correct",
Which view in SNOWFLAKE.ACCOUNT_USAGE shows from which IP address a user connected to Snowflake?,multiple-choice,A. ACCESS_HYSTORY,B. LOGIN_HYSTORY,C. SESSIONS,D. QUERY_HISTORY,,,,,,,,,,,,2,"LOGIN_HISTORY is correct
LOGIN_HISTORY https://docs.snowflake.com/sql-reference/account-usage/login_history#columns",
Snowflake Partner Connect is limited to users with a verified email address and which role?,multiple-choice,A. SYSADMIN,B. SECURITYADMIN,C. ACCOUNTADMIN,D. USERADMIN,,,,,,,,,,,,3,"C. ACCOUNTADMIN
Correct  https://docs.snowflake.com/en/user-guide/ecosystem-partner-connect#security-requirements",
What unit of storage supports efficient query processing in Snowflake?,multiple-choice,A. Blobs,B. JSON,C. Block storage,D. Micro-partitions,,,,,,,,,,,,4,"D is correct
D. Micro-partitions",
What is the difference between a stored procedure and a User-Defined Function (UDF)?,multiple-choice,A. Stored procedures can execute database operations while UDFs cannot.,B. Returning a value is required in a stored procedure while returning values in a UDF is optional.,C. Values returned by a stored procedure can be used directly in a SQL statement while the values returned by a UDF cannot.,D. Multiple stored procedures can be called as part of a single executable statement while a single SQL statement can only call one UDF at a time.,,,,,,,,,,,,1,"A. Stored procedures can execute database operations while UDFs cannot
https://docs.snowflake.com/en/developer-guide/stored-procedures-vs-udfs#udfs-may-not-access-the-database-stored-procedures-can
Stored Procedures Can Access the Database; UDFs May Not
https://docs.snowflake.com/en/sql-reference/stored-procedures-overview#differences-between-stored-procedures-and-udfs",
Which URL type does Snowflake recommend to use when providing unstructured data to other accounts through a share?,multiple-choice,A. File,B. Pre-signed,C. Scoped,D. Staged,,,,,,,,,,,,3,"Scoped https://docs.snowflake.com/en/user-guide/unstructured-intro#types-of-urls-available-to-access-files
C. Scoped https://docs.snowflake.com/en/user-guide/unstructured-intro",
What is the MAXIMUM Time Travel retention period for a transient table?,multiple-choice,A. 0 days,B. 1 day,C. 7 days,D. 90 days,,,,,,,,,,,,2,Time travel - 1 day Fail safe - 0 day,
What is the advantage of using a reader account?,multiple-choice,A. It can be used by a client that does not have a Snowflake account,B. It is read-only and prevents the shared data from being updated by the provider.,C. It can be connected to a Snowflake account in a different region.,D. It provides limited access to the data share and is therefore cheaper for the data provider.,,,,,,,,,,,,1,"A is correct
https://docs.snowflake.com/en/user-guide/ui-snowsight-private-sharing-reader-accounts",
What command is used to export or unload data from Snowflake?,multiple-choice,A. PUT @mystage,B. GET @mystage,C. Copy INTO @mystage,D. INSERT @mystage,,,,,,,,,,,,3,"COPY INTO <location> https://docs.snowflake.com/en/sql-reference/sql/copy-into-location
C https://docs.snowflake.com/en/user-guide/data-unload-considerations",
"A Snowflake user wants to share data with someone who does not have a Snowflake account.

How can the Snowflake user share the data?",multiple-choice,A. Use the Snowflake Marketplace.,B. Create a reader account.,C. Create a consumer account.,D. Use a Snowflake share.,,,,,,,,,,,,2,"Reader account is correct
B - correct",
"A user wants to add additional privileges to the system-defined roles for their virtual warehouse.

How does Snowflake recommend they accomplish this?",multiple-choice,A. Grant the additional privileges to a custom role.,B. Grant the additional privileges to the ACCOUNTADMIN role.,C. Grant the additional privileges to the SYSADMIN role.,D. Grant the additional privileges to the ORGADMIN role.,,,,,,,,,,,,1,"Q: ... to the system-defined roles ... A - is not a system-defined, otherwise would be added: ""and grant this user role to SYSADMIN.""
Check this:  https://docs.snowflake.com/en/user-guide/security-access-control-configure#:~:text=The%20following%20diagram%20shows%20an%20example%20role%20hierarchy%20and%20the%20privileges%20granted%20to%20each%20role%3A  Clearly shows that procedure of adding additional privileges to the system-defined roles is by granting the additional privileges to a custom role which is than assigned to SYSADMIN role. And we know that Snowflake recomends assigning custom roles to SYSADMIN role - which is what this trick questions is all about.",
How does Snowflake store a table's underlying data? (Choose two.),multi-select,A. Columnar file format,B. Micro-partitions,C. Text file format,D. Uncompressed,E. User-defined partitions,,,,,,,,,,,"1, 2",AB - correct,
What is the MAXIMUM number of days a Snowflake-managed encryption key can be used before it gets automatically rotated?,multiple-choice,A. 1 day,B. 14 days,C. 30 days,D. 120 days,,,,,,,,,,,,3,"https://docs.snowflake.com/en/user-guide/security-encryption-manage#:~:text=All%20Snowflake%2Dmanaged%20keys%20are,the%20key%20is%20automatically%20destroyed.
https://docs.snowflake.com/en/user-guide/security-encryption-manage",
How does Snowflake handle the bulk unloading of data into single or multiple files?,multiple-choice,A. It assigns each unloaded data file a unique name.,B. It uses the PUT command to download the data by default.,C. It uses COPY INTO [location] for bulk unloading where the default option is SINGLE = TRUE.,D. It uses COPY INTO [location] to copy the data from a table into one or more files in an external stage only.,,,,,,,,,,,,1,"from doc: Bulk Unloading into Single or Multiple Files The COPY INTO <location> command provides a copy option (SINGLE) for unloading data into a single file or multiple files. The default is SINGLE = FALSE (i.e. unload into multiple files).  Snowflake assigns each file a unique name. The location path specified for the command can contain a filename prefix that is assigned to all the data files generated. If a prefix is not specified, Snowflake prefixes the generated filenames with data_.
Not C because DEFAULT for SINGLE is FALSE Not D Not B Leaves A only  ""However, when an unload operation writes multiple files to a stage, Snowflake appends a suffix that ensures each file name is unique across parallel execution threads"" https://docs.snowflake.com/en/sql-reference/sql/copy-into-location",
What information is included in the display in the Query Profile? (Choose two.),multi-select,A. Index hints used in query,B. Credit usage details,C. Clustering keys details,D. Details and statistics for the overall query,E. Graphical representation of the query processing plan,,,,,,,,,,,"4, 5","Correct
https://docs.snowflake.com/en/user-guide/ui-query-profile#:~:text=Query%20Profile%2C%20available,the%20overall%20query.",
"A Snowflake user wants to optimize performance for a query that queries only a small number of rows in a table. The rows require significant processing. The data in the table does not change frequently.

What should the user do?",multiple-choice,A. Add a clustering key to the table.,B. Add the search optimization service to the table.,C. Create a materialized view based on the query.,D. Enable the query acceleration service for the virtual warehouse.,,,,,,,,,,,,3,"correct
https://docs.snowflake.com/en/user-guide/views-materialized#deciding-when-to-create-a-materialized-view
I request to please start discussion on below questions also 527 536 544 545 546 550 554 556 558 559 561 580 581 582 584 588 594 601 604 610 611 612 613 614",
"When using the ALLOW_CLIENT_MFA_CACHING parameter, how long is a cached Multi-Factor Authentication (MFA) token valid for?",multiple-choice,A. 1 hour,B. 2 hours,C. 4 hours,D. 8 hours,,,,,,,,,,,,3,"The correct answer is C. 4 Hours  A cached MFA token is valid for up to four hours. https://docs.snowflake.com/en/user-guide/security-mfa#using-mfa-token-caching-to-minimize-the-number-of-prompts-during-authentication-optional
4 hours https://docs.snowflake.com/en/user-guide/security-mfa#:~:text=A%20cached%20MFA%20token%20is%20valid%20for%20up%20to%20four%20hours
MFA token caching can help to reduce the number of prompts that must be acknowledged while connecting and authenticating to Snowflake, especially when multiple connection attempts are made within a relatively short time interval.  A cached MFA token is valid for up to four hours.
4 hours https://docs.snowflake.com/en/user-guide/security-mfa#label-mfa-token-caching",
"When unloading data, which file formats are supported by the COPY INTO [location] command? (Choose two.)",multi-select,A. Avro,B. JSON,C. ORC,D. Parquet,E. XML,,,,,,,,,,,"2, 4","correct
B & D  https://docs.snowflake.com/en/user-guide/data-unload-prepare",
"A JSON object is loaded into a column named data using a Snowflake variant datatype. The root node of the object is BIKE. The child attribute for this root node is BIKEID.

Which statement will allow the user to access BIKEID?",multiple-choice,A. select data:BIKEID,B. select data.BIKE.BIKEID,C. select data:BIKE.BIKEID,D. select data:BIKE:BIKEID,,,,,,,,,,,,3,"Both C and D are correct.
SYNATAX --> COLUMN:FirstElement.SubsequentElement
C https://docs.snowflake.com/en/user-guide/querying-semistructured",
"A custom role owns multiple tables. If this role is dropped from the system, who becomes the owner of these tables?",multiple-choice,A. ACCOUNTADMIN,B. SYSADMIN,C. Tables will be standalone or orphaned.,D. The role that dropped the custom role.,,,,,,,,,,,,4,"correct
https://docs.snowflake.com/en/sql-reference/sql/drop-role#:~:text=Ownership%20of%20any%20objects%20owned%20by%20the%20dropped%20role%20is%20transferred%20to%20the%20role%20that%20executes%20the%20DROP%20ROLE%20command.
D is correct",
