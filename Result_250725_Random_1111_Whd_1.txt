==================================================
### Prüfungsprotokoll ###
Datum: 25.07.2025, 14:26:56 Uhr
Modus: Practice
Auswahl: Wiederholung (random) (50 Fragen)
Random Seed: 1111

--- Endergebnis ---
Punkte: 44 von 50
Erfolgsquote: 88.00%
==================================================

--- Frage Nr. 375 (Richtig) ---
Frage: What is a key benefit of using organizations in Snowflake?
Deine Antwort:     C
Korrekte Antwort:  C

Erklärung:
An organization is a first-class Snowflake object that links the accounts owned by your business entity. Organizations simplify account management and billing, Replication and Failover/Failback, Snowflake Secure Data Sharing, and other account administration tasks.
https://docs.snowflake.com/en/user-guide/organizations
--------------------------------------------------

--- Frage Nr. 1184 (Richtig) ---
Frage: Which view in SNOWFLAKE.ACCOUNT_USAGE shows from which IP address a user connected to Snowflake?
Deine Antwort:     B
Korrekte Antwort:  B

Erklärung:
LOGIN_HISTORY is correct
LOGIN_HISTORY https://docs.snowflake.com/sql-reference/account-usage/login_history#columns
--------------------------------------------------

--- Frage Nr. 847 (Richtig) ---
Frage: What role has the privileges to create and manage data shares by default?
Deine Antwort:     A
Korrekte Antwort:  A

Erklärung:
A is correct
A is correct
--------------------------------------------------

--- Frage Nr. 189 (Richtig) ---
Frage: A single user of a virtual warehouse has set the warehouse to auto-resume and auto-suspend after 10 minutes. The warehouse is currently suspended and the user performs the following actions:

1. Runs a query that takes 3 minutes to complete
2. Leaves for 15 minutes
3. Returns and runs a query that takes 10 seconds to complete
4. Manually suspends the warehouse as soon as the last query was completed

When the user returns, how much billable compute time will have been consumed?
Deine Antwort:     C
Korrekte Antwort:  C

Erklärung:
I think it is 14 mins because:  3 Minutes for running first time (starting the WH and first execution) Leave for 15 minutes. WH will be iddle after 10 mins. ==> 10 + 3 New execuion = Minimal is 1 minute billed.   so: 10+3+1 = 14
--------------------------------------------------

--- Frage Nr. 408 (Richtig) ---
Frage: Which Snowflake object contains all the information required to share a database?
Deine Antwort:     D
Korrekte Antwort:  D

Erklärung:
D - straightforward
D.  https://docs.snowflake.com/en/user-guide/data-sharing-intro
--------------------------------------------------

--- Frage Nr. 995 (Richtig) ---
Frage: A Snowflake user executed a query and received the results. Another user executed the same query 4 hours later. The data had not changed.

What will occur?
Deine Antwort:     A
Korrekte Antwort:  A

Erklärung:
A is right. Don't overthink it
seems i am already overthinking - why A? if another user is from diff account then how the results can be retrieved from result cache ?, Thanks
--------------------------------------------------

--- Frage Nr. 432 (Richtig) ---
Frage: How can data be shared between two users who have different Snowflake accounts?
Deine Antwort:     B
Korrekte Antwort:  B

Erklärung:
you create a share in the provider account, grant object privileges to that share, and then assign the IMPORT SHARE privilege to the appropriate role in the consumer account so they can CREATE DATABASE … FROM SHARE
--------------------------------------------------

--- Frage Nr. 988 (Richtig) ---
Frage: Which of the following conditions must be met in order to return results from the results cache? (Choose two.)
Deine Antwort:     A, E
Korrekte Antwort:  A, E

Erklärung:
A&E as the below  link: https://docs.snowflake.com/en/user-guide/querying-persisted-results.html#retrieval-optimization
E is correct and maybe A If the same query is fired again in 24 hrs, it will not be COMPUTED, which means it will not be charged. and it is not affected by WH suspension. So as the previous question the same exact query will return the pre-computed results if the underlying data hasn't changed and the results were last accessed within previous 24-hour period
--------------------------------------------------

--- Frage Nr. 223 (Richtig) ---
Frage: What is a feature of a stored procedure in Snowflake?
Deine Antwort:     D
Korrekte Antwort:  D

Erklärung:
A - False - When you specify that the UDF or procedure is secure, these details are visible only to authorized users – in other words, to users who are granted a role that owns the function.
D is correct...https://docs.snowflake.com/en/sql-reference/stored-procedures-rights
--------------------------------------------------

--- Frage Nr. 1124 (Richtig) ---
Frage: Which data types are valid in Snowflake? (Choose two.)
Deine Antwort:     B, E
Korrekte Antwort:  B, E

Erklärung:
BE are correct
B and E  https://docs.snowflake.com/en/sql-reference/intro-summary-data-types.html#:~:text=structured%20Data%20Types-,VARIANT,-OBJECT
Semi-structured Data Types: VARIANT OBJECT ARRAY  Geospatial Data Types: GEOGRAPHY GEOMETRY  https://docs.snowflake.com/en/sql-reference/intro-summary-data-types
--------------------------------------------------

--- Frage Nr. 702 (Richtig) ---
Frage: Which COPY INTO statement accurately describes how to unload data from a Snowflake table?
Deine Antwort:     C
Korrekte Antwort:  C

Erklärung:
"You can use the OBJECT_CONSTRUCT function combined with the COPY command to convert the rows in a relational table to a single VARIANT column and unload the rows into a file." https://docs.snowflake.com/en/user-guide/data-unload-considerations
COMPRESSION option can't be set to TRUE  -- If FILE_FORMAT = ( TYPE = CSV ... )  COMPRESSION = AUTO | GZIP | BZ2 | BROTLI | ZSTD | DEFLATE | RAW_DEFLATE | NONE  -- If FILE_FORMAT = ( TYPE = JSON ... )  COMPRESSION = AUTO | GZIP | BZ2 | BROTLI | ZSTD | DEFLATE | RAW_DEFLATE | NONE  -- If FILE_FORMAT = ( TYPE = PARQUET ... )  COMPRESSION = AUTO | LZO | SNAPPY | NONE https://docs.snowflake.com/en/sql-reference/sql/copy-into-location
--------------------------------------------------

--- Frage Nr. 433 (Richtig) ---
Frage: Which view will show the MOST recent information about table-level storage utilization?
Deine Antwort:     C
Korrekte Antwort:  C

Erklärung:
The TABLE_STORAGE_METRICS view in the INFORMATION_SCHEMA  Snowflake’s INFORMATION_SCHEMA views reflect metadata in (near) real time, whereas the corresponding ACCOUNT_USAGE views—including its TABLE_STORAGE_METRICS—have built‑in latency of up to a few hours due to their batch extraction process. The STORAGE_USAGE_HISTORY view is a historical, time‑series log (not current point‑in‑time metrics), and data‑share views also surface the same (lagged) Account Usage data.
--------------------------------------------------

--- Frage Nr. 1177 (Richtig) ---
Frage: Floating point values are truncated when unloaded to which file format?
Deine Antwort:     B
Korrekte Antwort:  B

Erklärung:
When floating-point number columns are unloaded to CSV or JSON files, Snowflake truncates the values to approximately (15,9). The values are not truncated when unloading floating-point number columns to Parquet files.
correct answer C When floating-point number columns are unloaded to CSV or JSON files, Snowflake truncates the values to approximately (15,9).  The values are not truncated when unloading floating-point number columns to Parquet files.
--------------------------------------------------

--- Frage Nr. 1121 (Richtig) ---
Frage: Which statement about data sharing is true?
Deine Antwort:     C
Korrekte Antwort:  C

Erklärung:
https://docs.snowflake.com/en/user-guide/data-sharing-provider.html#general-data-sharing-considerations-and-usage
Not entirely sure, but I'd go for (A) here. Sharing is not limited to specific versions.    Why I don't think the correct answer is (C): The earlier mentioned link below is saying that NEW objects are not automatically available to consumers and explicitly need to be added to the share. But answer option (C) is not specifying this.  https://docs.snowflake.com/en/user-guide/data-sharing-provider.html#general-data-sharing-considerations-and-usage
--------------------------------------------------

--- Frage Nr. 1113 (Richtig) ---
Frage: Which clustering indicator will show if a large table in Snowflake will benefit from explicitly defining a clustering key?
Deine Antwort:     B
Korrekte Antwort:  B

Erklärung:
Clustering Depth The clustering depth for a populated table measures the average depth (1 or greater) of the overlapping micro-partitions for specified columns in a table. The smaller the average depth, the better clustered the table is with regards to the specified columns.  Clustering depth can be used for a variety of purposes, including:  Monitoring the clustering “health” of a large table, particularly over time as DML is performed on the table.  Determining whether a large table would benefit from explicitly defining a clustering key.
https://docs.snowflake.com/en/user-guide/tables-clustering-micropartitions.html#label-clustering-depth
--------------------------------------------------

--- Frage Nr. 176 (Falsch) ---
Frage: What impacts the credit consumption of maintaining a materialized view? (Choose two.)
Deine Antwort:     C, E
Korrekte Antwort:  C, D

Erklärung:
In general, the costs are proportional to:  The number of materialized views created on each base table, and the amount of data that changes in each of those materialized views when the base table changes. Any changes to micro-partitions in the base table require eventual materialized view maintenance, whether those changes are due to reclustering or DML statements run on the base table.  The number of those materialized views that are clustered. Maintaining clustering (of either a table or a materialized view) adds costs.  https://docs.snowflake.com/en/user-guide/views-materialized.html#effects-of-changes-to-base-tables-on-materialized-views
--------------------------------------------------

--- Frage Nr. 10 (Richtig) ---
Frage: Which statement best describes `clustering`?
Deine Antwort:     A
Korrekte Antwort:  A

Erklärung:
Strongly agree, A is the correct the correct answer.
https://docs.snowflake.com/en/user-guide/tables-clustering-micropartitions.html  In Snowflake, as data is inserted/loaded into a table, clustering metadata is collected and recorded for each micro-partition created during the process. Snowflake then leverages this clustering information to avoid unnecessary scanning of micro-partitions during querying, significantly accelerating the performance of queries that reference these columns.
--------------------------------------------------

--- Frage Nr. 276 (Richtig) ---
Frage: Which of the following query profiler variables will indicate that a virtual warehouse is not sized correctly for the query being executed?
Deine Antwort:     D
Korrekte Antwort:  D

Erklärung:
D is correct
For some operations (e.g. duplicate elimination for a huge data set), the amount of memory available for the compute resources used to execute the operation might not be sufficient to hold intermediate results. As a result, the query processing engine will start spilling the data to local disk. If the local disk space is not sufficient, the spilled data is then saved to remote disks.  https://docs.snowflake.com/en/user-guide/ui-query-profile
--------------------------------------------------

--- Frage Nr. 3 (Richtig) ---
Frage: True or False: A single database can exist in more than one Snowflake account.
Deine Antwort:     A
Korrekte Antwort:  A

Erklärung:
The question is where the single database (instance) can exist across multiple accounts. Replication creates a separate instance and keeps it in sync with primary DB, but the DB instance can only belong to one account. Its a tricky question
Through database replication, should be A https://docs.snowflake.com/en/user-guide/database-replication-intro.html
--------------------------------------------------

--- Frage Nr. 208 (Richtig) ---
Frage: Which feature is only available in the Enterprise or higher editions of Snowflake?
Deine Antwort:     A
Korrekte Antwort:  A

Erklärung:
Correct
https://docs.snowflake.com/en/user-guide/intro-editions.html#enterprise-edition
--------------------------------------------------

--- Frage Nr. 944 (Richtig) ---
Frage: A permanent table and temporary table have the same name, TBL1, in a schema.

What will happen if a user executes select * from TBL1;?
Deine Antwort:     A
Korrekte Antwort:  A

Erklärung:
A is correct .  All queries and other operations performed in the session on the table affect only the temporary table  https://docs.snowflake.com/en/user-guide/tables-temp-transient#potential-naming-conflicts-with-other-table-types
A correct - https://docs.snowflake.com/en/user-guide/tables-temp-transient
--------------------------------------------------

--- Frage Nr. 61 (Richtig) ---
Frage: To run a Multi-Cluster Warehouse in auto-scale mode, a user would:
Deine Antwort:     D
Korrekte Antwort:  D

Erklärung:
If you set the minimum cluster count less than the maximum cluster count, then the warehouse runs in Auto-scale mode.
The answer is correct as per  Auto-scale:  This mode is enabled by specifying different values for maximum and minimum number of clusters. In this mode, Snowflake starts and stops clusters as needed to dynamically manage the load on the warehouse:  As the number of concurrent user sessions and/or queries for the warehouse increases, and queries start to queue due to insufficient resources, Snowflake automatically starts additional clusters, up to the maximum number defined for the warehouse.  Similarly, as the load on the warehouse decreases, Snowflake automatically shuts down clusters to reduce the number of running clusters and, correspondingly, the number of credits used by the warehouse. refer: https://docs.snowflake.com/en/user-guide/warehouses-multicluster.html
--------------------------------------------------

--- Frage Nr. 958 (Richtig) ---
Frage: If a multi-cluster warehouse is using an economy scaling policy, how long will queries wait in the queue before another cluster is started?
Deine Antwort:     C
Korrekte Antwort:  C

Erklärung:
Economy - 6 minutes Standard - immediately  Thus C is correct answer
C correct - https://community.snowflake.com/s/article/Cluster-Spin-up-criteria-in-MCW
--------------------------------------------------

--- Frage Nr. 144 (Richtig) ---
Frage: What transformations are supported in a CREATE PIPE ... AS COPY `¦ FROM (`¦) statement? (Choose two.)
Deine Antwort:     C, D
Korrekte Antwort:  C, D

Erklärung:
Using a query as the source for the COPY statement for column reordering [C], column omission [D], and casts (i.e. transforming data during a load) is supported. For usage examples, see Transforming Data During a Load. Note that only simple SELECT statements are supported. Filtering using a WHERE clause is not supported [E].
CD is correct  https://docs.snowflake.com/en/sql-reference/sql/create-pipe.html
--------------------------------------------------

--- Frage Nr. 1032 (Falsch) ---
Frage: How many resource monitors can be assigned at the account level?
Deine Antwort:     1
Korrekte Antwort:  A

Erklärung:
An account monitor monitors the credit usage of all the warehouses in the account. An account can only have one account monitor.  A warehouse monitor monitors the credit usage of the warehouses assigned to the resource monitor. An account can have multiple warehouse monitors.  A warehouse monitor can have one or more warehouses assigned to it, but each warehouse can only be assigned to one resource monitor.
A https://docs.snowflake.com/en/user-guide/resource-monitors
A single monitor can be set at the account level to control credit usage for all warehouses in your account.  https://docs.snowflake.com/en/user-guide/resource-monitors.html#monitor-level
https://docs.snowflake.com/en/user-guide/resource-monitors.html
--------------------------------------------------

--- Frage Nr. 438 (Richtig) ---
Frage: Which command can be used to determine if data from a file has been previously loaded?
Deine Antwort:     A
Korrekte Antwort:  A

Erklärung:
Snowflake’s COPY_HISTORY table function (or the COPY_HISTORY view in ACCOUNT_USAGE) lets you query recent load activity—including file names and statuses—to determine if a given staged file has already been loaded into a table  SELECT * FROM TABLE(  INFORMATION_SCHEMA.COPY_HISTORY(  TABLE_NAME => 'ORDERS',  START_TIME => DATEADD(DAY, -1, CURRENT_TIMESTAMP())  ) ) WHERE FILE_NAME = 'orders_20250419.csv';
--------------------------------------------------

--- Frage Nr. 1002 (Richtig) ---
Frage: What happens when a Data Provider revokes privileges to a share on an object in their source database?
Deine Antwort:     A
Korrekte Antwort:  A

Erklärung:
A is correct
Correct answer
Answer correct Revokes access privileges for databases and other supported database objects (schemas, tables, and views) from a share. Revoking privileges on these objects effectively removes the objects from the share, disabling access to the objects granted via the database role in all consumer accounts that have created a database from the share.
--------------------------------------------------

--- Frage Nr. 840 (Richtig) ---
Frage: Which Snowflake table is an implicit object layered on a stage, where the stage can be either internal or external?
Deine Antwort:     A
Korrekte Antwort:  A

Erklärung:
https://www.bing.com/search?q=Which+Snowflake+table+is+an+implicit+object+layered+on+a+stage%2C+where+the+stage+can+be+either+internal+or+external%3F&aqs=edge..69i57j69i11004&FORM=ANCMS9&PC=U531
--------------------------------------------------

--- Frage Nr. 1018 (Richtig) ---
Frage: A user is preparing to load data from an external stage.

Which practice will provide the MOST efficient loading performance?
Deine Antwort:     A
Korrekte Antwort:  A

Erklärung:
Both internal (i.e. Snowflake) and external (Amazon S3, Google Cloud Storage, or Microsoft Azure) stage references can include a path (or prefix in AWS terminology). When staging regular data sets, we recommend partitioning the data into logical paths that include identifying details such as geographical location or other source identifiers, along with the date when the data was written.  Organizing your data files by path lets you copy any fraction of the partitioned data into Snowflake with a single command. This allows you to execute concurrent COPY statements that match a subset of files, taking advantage of parallel operations.  https://docs.snowflake.com/en/user-guide/data-load-considerations-stage.html#organizing-data-by-path
https://docs.snowflake.com/en/user-guide/data-load-considerations-stage.html#organizing-data-by-path
--------------------------------------------------

--- Frage Nr. 145 (Richtig) ---
Frage: Which of the following are characteristics of Snowflake virtual warehouses? (Choose two.)
Deine Antwort:     C, E
Korrekte Antwort:  C, E

Erklärung:
CE are correct.
--------------------------------------------------

--- Frage Nr. 1147 (Richtig) ---
Frage: What Snowflake objects can be added to a share? (Choose two.)
Deine Antwort:     B, E
Korrekte Antwort:  B, E

Erklärung:
BE are correct
Before creating a share, Snowflake recommends identifying the Snowflake objects you plan to share:  Database  Tables  External tables  Secure views  Secure materialized views  Secure UDFs
--------------------------------------------------

--- Frage Nr. 291 (Richtig) ---
Frage: What happens when an external or an internal stage is dropped? (Choose two.)
Deine Antwort:     A, D
Korrekte Antwort:  A, D

Erklärung:
per the docs explain
--------------------------------------------------

--- Frage Nr. 356 (Falsch) ---
Frage: Who can grant object privileges in a regular schema?
Deine Antwort:     B
Korrekte Antwort:  A

Erklärung:
A because it's not managed schema.  For managed Schema Schema Owner can grant Previleges.
https://docs.snowflake.com/en/user-guide/security-access-control-configure#label-managed-access-schemas  Managed access schemas improve security by locking down privilege management on objects.  In regular (i.e. non-managed) schemas, object owners (i.e. a role with the OWNERSHIP privilege on an object) can grant access on their objects to other roles, with the option to further grant those roles the ability to manage object grants.  With managed access schemas, object owners lose the ability to make grant decisions. Only the schema owner (i.e. the role with the OWNERSHIP privilege on the schema) or a role with the MANAGE GRANTS privilege can grant privileges on objects in the schema, including future grants, centralizing privilege management.
In regular (i.e. non-managed) schemas, object owners (i.e. a role with the OWNERSHIP privilege on an object) can grant access on their objects to other roles https://docs.snowflake.com/en/user-guide/security-access-control-configure#label-managed-access-schemas
--------------------------------------------------

--- Frage Nr. 316 (Richtig) ---
Frage: What type of function returns one value for each invocation?
Deine Antwort:     B
Korrekte Antwort:  B

Erklärung:
A scalar function is a function that returns one value per invocation; in most cases, you can think of this as returning one value per row. This contrasts with Aggregate Functions, which return one value per group of rows.
B is correct  https://docs.snowflake.com/en/sql-reference/functions
--------------------------------------------------

--- Frage Nr. 977 (Richtig) ---
Frage: Which user preferences can be set for a user profile in Snowsight? (Choose two.)
Deine Antwort:     A, D
Korrekte Antwort:  A, D

Erklärung:
Correct Ans is A&D. default warehouse and role can be set not Database and schema
The correct Answer is A & D.  Setting User Details and Preferences: ------------------------------------------------------------------------------------- Profile photo Username (cannot be changed) First name Last name Password Email Default experience (Snowsight or Classic) Language (English, Japanese) *Notifications (Browser Notification) *Multi-factor authentication Session Timeout  https://docs.snowflake.com/en/user-guide/ui-snowsight-gs#setting-user-details-and-preferences
--------------------------------------------------

--- Frage Nr. 192 (Richtig) ---
Frage: Which statement is true about running tasks in Snowflake?
Deine Antwort:     A
Korrekte Antwort:  A

Erklärung:
A task can execute any one of the following types of SQL code: Single SQL statement Call to a stored procedure Procedural logic using Snowflake Scripting Developer Guide  https://docs.snowflake.com/en/user-guide/tasks-intro
--------------------------------------------------

--- Frage Nr. 1028 (Richtig) ---
Frage: Which of the following are valid methods for authenticating users for access into Snowflake? (Choose three.)
Deine Antwort:     B, D, E
Korrekte Antwort:  B, D, E

Erklärung:
Sorry, answer is B,D and E https://docs.snowflake.com/en/user-guide/authentication.html
SCIM nothing to do with user authentication so B,D,E
--------------------------------------------------

--- Frage Nr. 621 (Richtig) ---
Frage: What action should be taken if a large number of concurrent queries are queued in a virtual warehouse?
Deine Antwort:     B
Korrekte Antwort:  B

Erklärung:
correct
--------------------------------------------------

--- Frage Nr. 118 (Richtig) ---
Frage: True or False: A 4X-Large Warehouse may, at times, take longer to provision than a X-Small Warehouse.
Deine Antwort:     A
Korrekte Antwort:  A

Erklärung:
You require the warehouse to be available with no delay or lag time. Warehouse provisioning is generally very fast (e.g. 1 or 2 seconds); however, depending on the size of the warehouse and the availability of compute resources to provision, it can take longer.
False   Provisioning the larger warehouse sizes 5X-Large and 6X-Large may take slightly longer while in preview.  https://docs.snowflake.com/en/user-guide/warehouses-overview.html
--------------------------------------------------

--- Frage Nr. 1133 (Richtig) ---
Frage: Which command should be used when loading many flat files into a single table?
Deine Antwort:     C
Korrekte Antwort:  C

Erklärung:
Step 1. Upload (i.e. stage) one or more data files to a Snowflake stage (named internal stage or table/user stage) using the PUT command. Step 2. Use the COPY INTO <table> command to load the contents of the staged file(s) into a Snowflake database table.
Correct answer
--------------------------------------------------

--- Frage Nr. 524 (Falsch) ---
Frage: What function, combined with the copy command, should be used to unload data from a relational table into a JSON file?
Deine Antwort:     B
Korrekte Antwort:  D

Erklärung:
D should be ok
correct
D is correct: Unloading a relational table to JSON You can use the OBJECT_CONSTRUCT function combined with the COPY command to convert the rows in a relational table to a single VARIANT column and unload the rows into a file. https://docs.snowflake.com/en/user-guide/data-unload-considerations
--------------------------------------------------

--- Frage Nr. 405 (Richtig) ---
Frage: When unloading data with the COPY INTO [location] command, what is the purpose of the PARTITION BY <expression> parameter option?
							
						</expression>
Deine Antwort:     D
Korrekte Antwort:  D

Erklärung:
https://docs.snowflake.com/en/sql-reference/sql/copy-into-location#optional-parameters
D is correct.  https://docs.snowflake.com/en/user-guide/data-unload-overview
--------------------------------------------------

--- Frage Nr. 611 (Richtig) ---
Frage: Which command is used to unload data from a Snowflake table into a Snowflake stage?
Deine Antwort:     C
Korrekte Antwort:  C

Erklärung:
C is correct
correct
Option : C -- is correct
--------------------------------------------------

--- Frage Nr. 736 (Richtig) ---
Frage: How can a Snowflake user optimize query performance in Snowflake? (Choose two.)
Deine Antwort:     B, C
Korrekte Antwort:  B, C

Erklärung:
The correct answers are B and C.  Clustering a table physically reorders the rows in a table to improve the performance of queries that filter on specific columns. The search optimization service creates a search index for a table, which can be used to improve the performance of queries that filter on specific columns.  Creating a view does not improve query performance. Enabling Time Travel allows you to query data from a specific point in time, but it does not improve query performance. Indexing a table creates an index that can be used to improve the performance of queries, but it is not as effective as clustering or the search optimization service.
--------------------------------------------------

--- Frage Nr. 128 (Richtig) ---
Frage: Which of the following accurately represents how a table fits into Snowflake's logical container hierarchy?
Deine Antwort:     B
Korrekte Antwort:  B

Erklärung:
Account -> Database -> Schema -> Table
https://docs.snowflake.com/en/sql-reference/ddl-database.html
--------------------------------------------------

--- Frage Nr. 1129 (Falsch) ---
Frage: How are micro-partitions typically generated in Snowflake?
Deine Antwort:     C
Korrekte Antwort:  A

Erklärung:
Micro-partitions are generated automatically, you can do it manually though by adding CLUSTER BY statement
A is correct
--------------------------------------------------

--- Frage Nr. 440 (Richtig) ---
Frage: Which URL identifies the database, schema, stage, and file path to a set of files for accessing the unstructured data files in Snowflake?
Deine Antwort:     B
Korrekte Antwort:  B

Erklärung:
The File URL is the Snowflake URL type that permanently encodes the database, schema, stage, and file path for a set of staged files, allowing any role with appropriate stage privileges to access them directly.
--------------------------------------------------

--- Frage Nr. 889 (Richtig) ---
Frage: What are characteristics of reader accounts in Snowflake? (Choose two.)
Deine Antwort:     A, E
Korrekte Antwort:  A, E

Erklärung:
correct
AE correct - https://docs.snowflake.com/en/user-guide/data-sharing-reader-create
CE. reader account can add new data if has own account or using separate account
--------------------------------------------------

--- Frage Nr. 708 (Richtig) ---
Frage: What allows a user to limit the number of credits consumed within a Snowflake account?
Deine Antwort:     B
Korrekte Antwort:  B

Erklärung:
B correct
B - Resource monitor
Correct answer b
--------------------------------------------------

--- Frage Nr. 232 (Falsch) ---
Frage: What Snowflake role must be granted for a user to create and manage accounts?
Deine Antwort:     A
Korrekte Antwort:  C

Erklärung:
The user administrator (USERADMIN) role includes the privileges to create and manage users and roles (assuming ownership of those roles or users has not been transferred to another role).
The correct answer is C.  The user administrator (USERADMIN) role includes the privileges to create and manage users and roles (assuming ownership of those roles or users has not been transferred to another role).  The security administrator (i.e users with the SECURITYADMIN system role) role includes the global MANAGE GRANTS privilege to grant or revoke privileges on objects in the account. The USERADMIN role is a child of this role in the default access control hierarchy. https://docs.snowflake.com/en/user-guide/security-access-control-considerations
--------------------------------------------------

